{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/image/Nginx-Keepalived.png","path":"image/Nginx-Keepalived.png","modified":0,"renderable":0},{"_id":"source/image/classloader01.png","path":"image/classloader01.png","modified":0,"renderable":0},{"_id":"source/image/W3sDesign_Proxy_Design_Pattern_UML.jpg","path":"image/W3sDesign_Proxy_Design_Pattern_UML.jpg","modified":0,"renderable":0},{"_id":"source/image/classloader02.jpg","path":"image/classloader02.jpg","modified":0,"renderable":0},{"_id":"source/image/snowflake.png","path":"image/snowflake.png","modified":0,"renderable":0},{"_id":"source/image/压测性能调优_01.png","path":"image/压测性能调优_01.png","modified":0,"renderable":0},{"_id":"source/image/F5_ISH_WAS.png","path":"image/F5_ISH_WAS.png","modified":0,"renderable":0},{"_id":"source/image/parallelStream_01.png","path":"image/parallelStream_01.png","modified":0,"renderable":0},{"_id":"source/image/performance_optimization_01.jpeg","path":"image/performance_optimization_01.jpeg","modified":0,"renderable":0},{"_id":"source/image/performance_optimization_02.jpg","path":"image/performance_optimization_02.jpg","modified":0,"renderable":0},{"_id":"source/image/JVM内存模型01.png","path":"image/JVM内存模型01.png","modified":0,"renderable":0},{"_id":"source/image/JVM内存模型02.png","path":"image/JVM内存模型02.png","modified":0,"renderable":0},{"_id":"source/image/DevOps/docker_01.png","path":"image/DevOps/docker_01.png","modified":0,"renderable":0},{"_id":"source/image/ElasticSearch/elasticsearch02.png","path":"image/ElasticSearch/elasticsearch02.png","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型00.png","path":"image/IO/IO模型00.png","modified":0,"renderable":0},{"_id":"source/image/ElasticSearch/elasticsearch01.jpg","path":"image/ElasticSearch/elasticsearch01.jpg","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型00.jpg","path":"image/IO/IO模型00.jpg","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型04.png","path":"image/IO/IO模型04.png","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型02.png","path":"image/IO/IO模型02.png","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型03.png","path":"image/IO/IO模型03.png","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型05.png","path":"image/IO/IO模型05.png","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型07.png","path":"image/IO/IO模型07.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JVM7内存模型.png","path":"image/jvm/JVM7内存模型.png","modified":0,"renderable":0},{"_id":"source/image/jvm/GC.png","path":"image/jvm/GC.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JVM8内存模型.png","path":"image/jvm/JVM8内存模型.png","modified":0,"renderable":0},{"_id":"source/image/loadbalancing/Nginx-Keepalived.png","path":"image/loadbalancing/Nginx-Keepalived.png","modified":0,"renderable":0},{"_id":"source/image/loadbalancing/loadbalancing_layer4&7.jpeg","path":"image/loadbalancing/loadbalancing_layer4&7.jpeg","modified":0,"renderable":0},{"_id":"source/image/cglib_callback.png","path":"image/cglib_callback.png","modified":0,"renderable":0},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/new_favicon_source_01_16x16.jpg","path":"images/new_favicon_source_01_16x16.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/new_favicon_source_01.jpg","path":"images/new_favicon_source_01.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/new_favicon_source_01_180x180.jpg","path":"images/new_favicon_source_01_180x180.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/new_favicon_source_01_32x32.jpg","path":"images/new_favicon_source_01_32x32.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/new_favicon_source_02_16x16.jpg","path":"images/new_favicon_source_02_16x16.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/new_favicon_source_02_180x180.jpg","path":"images/new_favicon_source_02_180x180.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/new_favicon_source_02_32x32.jpg","path":"images/new_favicon_source_02_32x32.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"source/image/ElasticSearch/elastic_stack01.jpg.jpg","path":"image/ElasticSearch/elastic_stack01.jpg.jpg","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型01.png","path":"image/IO/IO模型01.png","modified":0,"renderable":0},{"_id":"source/image/DevOps/docker_02.png","path":"image/DevOps/docker_02.png","modified":0,"renderable":0},{"_id":"source/image/IO/IO模型06.png","path":"image/IO/IO模型06.png","modified":0,"renderable":0},{"_id":"source/image/QRcode/wechat_qrcode.jpg","path":"image/QRcode/wechat_qrcode.jpg","modified":0,"renderable":0},{"_id":"source/image/loadbalancing/DNS.png","path":"image/loadbalancing/DNS.png","modified":0,"renderable":0},{"_id":"source/image/loadbalancing/IP.png","path":"image/loadbalancing/IP.png","modified":0,"renderable":0},{"_id":"source/image/loadbalancing/F5_ISH_WAS.png","path":"image/loadbalancing/F5_ISH_WAS.png","modified":0,"renderable":0},{"_id":"source/image/loadbalancing/LVS.png","path":"image/loadbalancing/LVS.png","modified":0,"renderable":0},{"_id":"source/image/mysql/btree.png","path":"image/mysql/btree.png","modified":0,"renderable":0},{"_id":"source/image/mysql/b+tree.png","path":"image/mysql/b+tree.png","modified":0,"renderable":0},{"_id":"source/image/volatile.png","path":"image/volatile.png","modified":0,"renderable":0},{"_id":"themes/next/source/images/1571293259.jpg","path":"images/1571293259.jpg","modified":0,"renderable":1},{"_id":"source/image/jvm/GC/GC_01.jpg","path":"image/jvm/GC/GC_01.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_05.jpg","path":"image/jvm/GC/GC_05.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_07.jpg","path":"image/jvm/GC/GC_07.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_08.jpg","path":"image/jvm/GC/GC_08.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_09.jpg","path":"image/jvm/GC/GC_09.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_10.jpg","path":"image/jvm/GC/GC_10.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_11.jpg","path":"image/jvm/GC/GC_11.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_12.jpg","path":"image/jvm/GC/GC_12.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_14.jpg","path":"image/jvm/GC/GC_14.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_13.jpg","path":"image/jvm/GC/GC_13.jpg","modified":0,"renderable":0},{"_id":"source/image/ElasticSearch/elasticsearch03.png","path":"image/ElasticSearch/elasticsearch03.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/11.png","path":"image/jvm/JDK自带工具/11.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/10.png","path":"image/jvm/JDK自带工具/10.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/15.png","path":"image/jvm/JDK自带工具/15.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/12.png","path":"image/jvm/JDK自带工具/12.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/16.png","path":"image/jvm/JDK自带工具/16.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/19.png","path":"image/jvm/JDK自带工具/19.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/3.png","path":"image/jvm/JDK自带工具/3.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/5.png","path":"image/jvm/JDK自带工具/5.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/7.png","path":"image/jvm/JDK自带工具/7.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/6.png","path":"image/jvm/JDK自带工具/6.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/8.png","path":"image/jvm/JDK自带工具/8.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/9.png","path":"image/jvm/JDK自带工具/9.png","modified":0,"renderable":0},{"_id":"source/image/jvm/profile_02.png","path":"image/jvm/profile_02.png","modified":0,"renderable":0},{"_id":"source/image/mysql/mysql_index.png","path":"image/mysql/mysql_index.png","modified":0,"renderable":0},{"_id":"source/image/mysql/mysql_myISAM.png","path":"image/mysql/mysql_myISAM.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/4.png","path":"image/jvm/JDK自带工具/4.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/2.png","path":"image/jvm/JDK自带工具/2.png","modified":0,"renderable":0},{"_id":"source/image/mysql/mysql_InnoDB.png","path":"image/mysql/mysql_InnoDB.png","modified":0,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/gitalk/gitalk.css","path":"lib/gitalk/gitalk.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"source/image/jvm/GC/GC_02.jpg","path":"image/jvm/GC/GC_02.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_03.jpg","path":"image/jvm/GC/GC_03.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_06.jpg","path":"image/jvm/GC/GC_06.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/1.png","path":"image/jvm/JDK自带工具/1.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/14.png","path":"image/jvm/JDK自带工具/14.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/17.png","path":"image/jvm/JDK自带工具/17.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"source/image/jvm/JDK自带工具/18.png","path":"image/jvm/JDK自带工具/18.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JDK自带工具/13.png","path":"image/jvm/JDK自带工具/13.png","modified":0,"renderable":0},{"_id":"themes/next/source/images/reward/alipay_reward.jpg","path":"images/reward/alipay_reward.jpg","modified":0,"renderable":1},{"_id":"source/image/ElasticSearch/elasticsearch04.png","path":"image/ElasticSearch/elasticsearch04.png","modified":0,"renderable":0},{"_id":"source/image/jvm/GC/GC_04.jpg","path":"image/jvm/GC/GC_04.jpg","modified":0,"renderable":0},{"_id":"source/image/jvm/profile_03.png","path":"image/jvm/profile_03.png","modified":0,"renderable":0},{"_id":"themes/next/source/images/reward/wechatpay_reward.jpg","path":"images/reward/wechatpay_reward.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/gitalk/gitalk.min.js","path":"lib/gitalk/gitalk.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"source/image/jvm/profile_01.png","path":"image/jvm/profile_01.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/images/new_favicon_source_02.jpg","path":"images/new_favicon_source_02.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/image/springboot/springboot_01.png","path":"image/springboot/springboot_01.png","modified":0,"renderable":0},{"_id":"source/image/jvm/JVM_栈.png","path":"image/jvm/JVM_栈.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"source/image/jvm/执行引擎.png","path":"image/jvm/执行引擎.png","modified":0,"renderable":0}],"Cache":[{"_id":"themes/next/.gitignore","hash":"dac14c54600bc26df8547765c5eb057d8f3e3ddb","modified":1566368909614},{"_id":"themes/next/.hound.yml","hash":"289dcf5bfe92dbd680d54d6e0668f41c9c9c0c78","modified":1566368909614},{"_id":"themes/next/.editorconfig","hash":"211d2c92bfdddb3e81ea946f4ca7a539f150f4da","modified":1566368909612},{"_id":"themes/next/.bowerrc","hash":"334da94ca6f024d60d012cc26ea655681e724ad8","modified":1566368909612},{"_id":"themes/next/.gitattributes","hash":"8454b9313cb1a97b63fb87e2d29daee497ce6249","modified":1566368909613},{"_id":"themes/next/.jshintrc","hash":"b7d23f2ce8d99fa073f22f9960605f318acd7710","modified":1566368909615},{"_id":"themes/next/.javascript_ignore","hash":"cd250ad74ca22bd2c054476456a73d9687f05f87","modified":1566368909615},{"_id":"themes/next/.travis.yml","hash":"6674fbdfe0d0c03b8a04527ffb8ab66a94253acd","modified":1566368909615},{"_id":"themes/next/.stylintrc","hash":"3b7f9785e9ad0dab764e1c535b40df02f4ff5fd6","modified":1566368909615},{"_id":"themes/next/LICENSE","hash":"ec44503d7e617144909e54533754f0147845f0c5","modified":1566368909616},{"_id":"source/404.html","hash":"9eb955271b03c72a4bb23a06b60e4ecb4070a880","modified":1566803926639},{"_id":"themes/next/README.cn.md","hash":"23e92a2599725db2f8dbd524fbef2087c6d11c7b","modified":1566368909616},{"_id":"themes/next/README.md","hash":"50abff86ffe4113051a409c1ed9261195d2aead0","modified":1566368909616},{"_id":"themes/next/_config.yml","hash":"0b7cffa850e0cd08fd68fd65a890cca2e39b2a5b","modified":1571294539772},{"_id":"themes/next/bower.json","hash":"486ebd72068848c97def75f36b71cbec9bb359c5","modified":1566368909617},{"_id":"themes/next/package.json","hash":"3963ad558a24c78a3fd4ef23cf5f73f421854627","modified":1566368909648},{"_id":"themes/next/gulpfile.coffee","hash":"412defab3d93d404b7c26aaa0279e2e586e97454","modified":1566368909617},{"_id":"source/_posts/GC收集器与算法.md","hash":"260987a90eaa7ca179484be3796592b5038914c0","modified":1589990697505},{"_id":"source/_posts/GC调优参数.md","hash":"73e75e3c98e0aa103eb9f901f2c4ab562aeee11a","modified":1590134350528},{"_id":"source/_posts/JDK自带性能调优相关工具.md","hash":"3defd8ece6d6867cd33ccfe6c741a2c4dd9583ac","modified":1589990696737},{"_id":"source/_posts/JVM内存模型.md","hash":"8c2ff8ceeb5296c7244ea662e7b3ca78bec2f955","modified":1589990695979},{"_id":"source/_posts/JAVA程序常见问题与JVM内存模型关系.md","hash":"00478c44d0c1cc3f5b611b561d7dac57e1c543c8","modified":1567840956934},{"_id":"source/_posts/Stream.md","hash":"2b88b69874c6047640bf64c7fa3098401af818ea","modified":1566805986518},{"_id":"source/_posts/docker_01_简介.md","hash":"5b66f2ec224d465d0bfcd05e5afbd0355f2289cd","modified":1566805830477},{"_id":"source/_posts/docker_02_安装.md","hash":"6fe580cb16117b80809bd6bb5295544430bdd157","modified":1566805835066},{"_id":"source/_posts/docker_05_容器的使用.md","hash":"ed55b879a4490dc483c677ef74fea92c2e05933a","modified":1566805850678},{"_id":"source/_posts/docker_03_HelloWorld.md","hash":"44f69da00f8b80b0c4af313ddad2c22d3c1c7fef","modified":1566805841910},{"_id":"source/_posts/docker_07_网络.md","hash":"7db4c70c5cc15a5d0d60474e7739d904ee1c5ed0","modified":1567675220992},{"_id":"source/_posts/SpringBoot自动装配原理.md","hash":"cfff9988a4c551595b759e24dcd0ecbe1d59e262","modified":1588845183538},{"_id":"source/_posts/docker_06_架构.md","hash":"d8ffb9a7b695fff9f9b564737939b014ac89a16c","modified":1567068996451},{"_id":"source/_posts/docker_08_存储.md","hash":"89428f52953934f6c78b157bf1215f7d11beda6b","modified":1567674471645},{"_id":"source/_posts/docker_09_ElasticSearch.md","hash":"8c1128768404045bf31ea0ebfb821baa16e8d3ee","modified":1569373538567},{"_id":"source/_posts/docker_04_基础指令.md","hash":"f3b3b6e25636aa705c833f279a9c9fb4c5064981","modified":1566805846214},{"_id":"source/_posts/elasticsearch_01_简介.md","hash":"b086f47e764fdf8ef13862434503f5bdd3bab771","modified":1566805880118},{"_id":"source/_posts/elasticsearch_02_安装.md","hash":"927fa7393bcb90b88dab84c645ab7ac4548f30d8","modified":1567675938566},{"_id":"source/_posts/elasticsearch_03_基础概念.md","hash":"a78173b9d11a6439671b0a634807666aeb4ac08f","modified":1575795046029},{"_id":"source/_posts/hello-world.md","hash":"f253773977709c2d1d6f8ff321aa6c23e1545e81","modified":1566806189057},{"_id":"source/_posts/docker_06_mysql.md","hash":"41d1d8ee34f031a05e060a87e7f963d5dcc240f5","modified":1567653391805},{"_id":"source/_posts/hexo.md","hash":"000e55a1b1e366b23d7a414a87c97ecaaf85df9f","modified":1566806194076},{"_id":"source/_posts/lambda、函数式接口、引用表达式.md","hash":"327c1666ad068b90da1e00e36570469d9a919b7d","modified":1566805927332},{"_id":"source/_posts/lock.md","hash":"5056b047c0b56c4203c4593728810dd6ff22389c","modified":1566806210157},{"_id":"source/_posts/load-balancing.md","hash":"c6d0d78a881480d7a871cf04a9aa21896afed567","modified":1566806206829},{"_id":"source/_posts/linux命令笔记.md","hash":"aacc88b2258fad64bdb2662081e347e2501ed3cb","modified":1569313876108},{"_id":"source/_posts/elasticsearch_04_基础RESTfulAPI.md","hash":"79aca315ef1309426869eda8af926f22f2162909","modified":1575854058262},{"_id":"source/_posts/parallelStream.md","hash":"5de05515b8cfc4f2d5023a9487e1c9daaa0118f6","modified":1566805965157},{"_id":"source/_posts/mysql性能优化学习笔记.md","hash":"fb05821a8b2c7f2a87da6bac6380b3a13a3bdc01","modified":1589879922011},{"_id":"source/_posts/proxy_pattern.md","hash":"cc336a3745ba592bb0ba822c008d2edfecc1f32b","modified":1566805981213},{"_id":"source/_posts/pattern.md","hash":"03a08e6db65cbffb9c01b7721e86e548f328fbd0","modified":1566805975252},{"_id":"source/_posts/docker_10_dockerfile.md","hash":"e55c45016b5ae69067e38209ab3daf7692b7b962","modified":1576070788521},{"_id":"source/_posts/redis_01_基础指令.md","hash":"54a97fa7926c4bd593768af2a691426abd48c776","modified":1589447857598},{"_id":"source/_posts/redis_02_进阶基础.md","hash":"ec9e4d936daeb9a041c87a7564ea6ad189f3aef1","modified":1589322726140},{"_id":"source/_posts/CAS.md","hash":"766869042e0dd6c835f030e33b3c6a9f4ed00ff2","modified":1581928135070},{"_id":"source/_posts/thread.md","hash":"d1c3d44ac7cd016b65c1dc33419e7af654872940","modified":1566805991261},{"_id":"source/_posts/mybatis_01.md","hash":"666bbf53f18983624f8653aabbee2f59f676d732","modified":1589641948068},{"_id":"source/_posts/事务相关基本概念.md","hash":"3f0dc9953c0cc8a49be7f59fbde38b6687106023","modified":1566806233711},{"_id":"source/_posts/分布式ID.md","hash":"4f0b8a9d63666ac2a685b78e10c1ff3adfc83d32","modified":1578625338640},{"_id":"source/_posts/压测调优.md","hash":"a7239639f0e4e246c4b37cf98ecc8c0b4c6d6dd6","modified":1566806250980},{"_id":"source/_posts/数据库三范式.md","hash":"14345a121e96d310b06588f3f1117b9ebe984882","modified":1566806060251},{"_id":"source/_posts/前端性能优化.md","hash":"23240631f1055664e39c7160505bd4cc20dc0bd1","modified":1566808496633},{"_id":"source/_posts/对象创建及类的加载机制.md","hash":"c47f926209c0a5af59ae78a1cb3e5bca428e8902","modified":1589943938588},{"_id":"source/_posts/线程模型.md","hash":"1fc44bc7fddc1fcdabce25a09f9f19444cde8f44","modified":1566806082995},{"_id":"source/_posts/网络IO模型.md","hash":"d26ab05c9ea4b537f67c65893322e8286b26b0e2","modified":1566806239429},{"_id":"source/_posts/集合容器框架笔记.md","hash":"71f852a4ad110ddc5019687348ab3afba964e11b","modified":1566806029141},{"_id":"source/categories/index.md","hash":"88091aa0130f31e8cf65a3622b34b5a56836c515","modified":1566806349070},{"_id":"source/_posts/缓存应用基础知识.md","hash":"b354a951b43590414159e0792dc52340ca3ed880","modified":1589323557735},{"_id":"source/about/index.md","hash":"a7349851575c5463c8aaaefb028deedcfa0a28be","modified":1588931849891},{"_id":"source/image/Nginx-Keepalived.png","hash":"923d679f2510aeea93a0d4a6c5432b73ef84903d","modified":1566368909571},{"_id":"source/image/classloader01.png","hash":"dd269bacf46fd036e7c35d045585d2b7b3639ca4","modified":1566368909574},{"_id":"source/image/W3sDesign_Proxy_Design_Pattern_UML.jpg","hash":"10f7d521589ae9eba96c10864c3f33ec334ecc35","modified":1566368909572},{"_id":"source/image/classloader02.jpg","hash":"a68b6b7788076ab406f4ff3c6e14ee5923db2c1c","modified":1566368909574},{"_id":"source/_posts/redisson.md","hash":"8c57ef2b55dd08b9c40038aa5cf9febad4fb4d4b","modified":1588847006200},{"_id":"source/image/snowflake.png","hash":"1591b3be2074040b1bb52515e36724695359db48","modified":1578554102267},{"_id":"source/image/压测性能调优_01.png","hash":"7fcdb4dd074e4e983dc3ed481bcf58e62ddee911","modified":1566368909581},{"_id":"source/tags/index.md","hash":"edc842da7d8ca115effe38b58a7eebf1bb9431a6","modified":1566806441812},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5adfad3ef1b870063e621bc0838268eb2c7c697a","modified":1566368909613},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"a0a82dbfabdef9a9d7c17a08ceebfb4052d98d81","modified":1566368909613},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1228506a940114288d61812bfe60c045a0abeac1","modified":1566368909613},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1566368909614},{"_id":"themes/next/languages/de.yml","hash":"fd02d9c2035798d5dc7c1a96b4c3e24b05b31a47","modified":1566368909618},{"_id":"themes/next/languages/fr-FR.yml","hash":"efeeb55d5c4add54ad59a612fc0630ee1300388c","modified":1566368909619},{"_id":"themes/next/languages/default.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1566368909618},{"_id":"themes/next/languages/id.yml","hash":"dccae33e2a5b3c9f11c0e05ec4a7201af1b25745","modified":1566368909619},{"_id":"themes/next/languages/it.yml","hash":"a215d016146b1bd92cef046042081cbe0c7f976f","modified":1566368909619},{"_id":"themes/next/languages/en.yml","hash":"2f4b4776ca1a08cc266a19afb0d1350a3926f42c","modified":1566368909619},{"_id":"themes/next/languages/ko.yml","hash":"dc8f3e8c64eb7c4bb2385025b3006b8efec8b31d","modified":1566368909620},{"_id":"themes/next/languages/ja.yml","hash":"37f954e47a3bc669620ca559e3edb3b0072a4be5","modified":1566368909620},{"_id":"themes/next/languages/nl-NL.yml","hash":"213e7a002b82fb265f69dabafbbc382cfd460030","modified":1566368909621},{"_id":"themes/next/languages/pt.yml","hash":"2efcd240c66ab1a122f061505ca0fb1e8819877b","modified":1566368909622},{"_id":"themes/next/languages/pt-BR.yml","hash":"568d494a1f37726a5375b11452a45c71c3e2852d","modified":1566368909622},{"_id":"themes/next/languages/ru.yml","hash":"e33ee44e80f82e329900fc41eb0bb6823397a4d6","modified":1566368909623},{"_id":"themes/next/languages/vi.yml","hash":"a9b89ebd3e5933033d1386c7c56b66c44aca299a","modified":1566368909623},{"_id":"themes/next/languages/zh-Hans.yml","hash":"66b9b42f143c3cb2f782a94abd4c4cbd5fd7f55f","modified":1566368909623},{"_id":"themes/next/languages/zh-hk.yml","hash":"fe0d45807d015082049f05b54714988c244888da","modified":1566368909623},{"_id":"themes/next/languages/zh-tw.yml","hash":"432463b481e105073accda16c3e590e54c8e7b74","modified":1566368909624},{"_id":"themes/next/layout/_layout.swig","hash":"2164570bb05db11ee4bcfbbb5d183a759afe9d07","modified":1566368909625},{"_id":"themes/next/layout/index.swig","hash":"555a357ecf17128db4e29346c92bb6298e66547a","modified":1566368909647},{"_id":"themes/next/layout/archive.swig","hash":"9a2c14874a75c7085d2bada5e39201d3fc4fd2b4","modified":1566368909646},{"_id":"themes/next/layout/category.swig","hash":"3cbb3f72429647411f9e85f2544bdf0e3ad2e6b2","modified":1566368909646},{"_id":"themes/next/layout/post.swig","hash":"7a6ce102ca82c3a80f776e555dddae1a9981e1ed","modified":1566368909647},{"_id":"themes/next/layout/schedule.swig","hash":"87ad6055df01fa2e63e51887d34a2d8f0fbd2f5a","modified":1566368909647},{"_id":"themes/next/scripts/merge-configs.js","hash":"38d86aab4fc12fb741ae52099be475196b9db972","modified":1566368909648},{"_id":"themes/next/scripts/merge.js","hash":"39b84b937b2a9608b94e5872349a47200e1800ff","modified":1566368909649},{"_id":"themes/next/layout/tag.swig","hash":"34e1c016cbdf94a31f9c5d494854ff46b2a182e9","modified":1566368909648},{"_id":"themes/next/test/.jshintrc","hash":"c9fca43ae0d99718e45a6f5ce736a18ba5fc8fb6","modified":1566368909916},{"_id":"themes/next/layout/page.swig","hash":"e8fcaa641d46930237675d2ad4b56964d9e262e9","modified":1566368909647},{"_id":"themes/next/test/helpers.js","hash":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1566368909916},{"_id":"source/_posts/rabbitMQ知识点整理.md","hash":"6acdfa1af8aa707a9bf412a7156e7e7b207f0dde","modified":1588845205786},{"_id":"source/image/F5_ISH_WAS.png","hash":"7824635a6200e4508c13614509c83f67f8e418d8","modified":1566368909564},{"_id":"themes/next/test/intern.js","hash":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1566368909917},{"_id":"source/_posts/redis_03_客户端源码.md","hash":"60c72116de98e75958ff8b9b6e8c93455e89966b","modified":1589322766594},{"_id":"source/image/parallelStream_01.png","hash":"711c09f534b932c435e23c6741b0bb5252c949b8","modified":1566368909579},{"_id":"source/image/performance_optimization_01.jpeg","hash":"f9c3c12ab74f2e1403080efda8c5fb5933676a91","modified":1566808382442},{"_id":"source/image/performance_optimization_02.jpg","hash":"be2b6262818bc1a6648639dffe78ce462738db9f","modified":1566808428847},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566368909685},{"_id":"source/image/JVM内存模型01.png","hash":"031731ca514cd5e7f1d82542334d973af9f6b3f2","modified":1566368909570},{"_id":"source/image/JVM内存模型02.png","hash":"bf03d26339f5965963476c6c08b5daf674d283ed","modified":1566368909571},{"_id":"source/image/DevOps/docker_01.png","hash":"41837cb220654a047c4443349c67b7d29b839680","modified":1566810664666},{"_id":"source/image/ElasticSearch/elasticsearch02.png","hash":"11406ccacb1ec05ee555260842152ba90e9f559b","modified":1566368909562},{"_id":"source/image/IO/IO模型00.png","hash":"a981beb53424b9596621c2712d84ec506b876c1d","modified":1566368909565},{"_id":"source/image/ElasticSearch/elasticsearch01.jpg","hash":"24ac6a944e50e03bd021afacf49f6cd63ff88450","modified":1566368909562},{"_id":"source/image/IO/IO模型00.jpg","hash":"6bc777f242fe23977ca0aad870a377acbae3ac2e","modified":1566368909565},{"_id":"source/image/IO/IO模型04.png","hash":"5cf87c0c389e166f12ee1549d3714777c14e8988","modified":1566368909567},{"_id":"source/image/IO/IO模型02.png","hash":"fac1afaa31e87e5233256644b82e929fda8b1725","modified":1566368909566},{"_id":"source/image/IO/IO模型03.png","hash":"80df24f058bfb673aca10d6ec8c318c0bfe10d51","modified":1566368909567},{"_id":"source/image/IO/IO模型05.png","hash":"a085f584d6158ae62fecbf0cb1bc9e10f0e11ae5","modified":1566368909568},{"_id":"source/image/IO/IO模型07.png","hash":"1e18dcf011abf42ae491ca4bac8e2b9573c4bd82","modified":1566368909569},{"_id":"source/image/jvm/JVM7内存模型.png","hash":"f66718f8bf704bc1c45de4c4237d243c3c95357e","modified":1589694129493},{"_id":"source/image/jvm/GC.png","hash":"a406ddce2996d580430deee2ee5f431c0a19b4cf","modified":1589695040868},{"_id":"source/image/jvm/JVM8内存模型.png","hash":"0a53190fc445b3638eaa56ea9923bc7033aba5b4","modified":1589694148727},{"_id":"source/image/loadbalancing/Nginx-Keepalived.png","hash":"923d679f2510aeea93a0d4a6c5432b73ef84903d","modified":1566368909578},{"_id":"source/image/loadbalancing/loadbalancing_layer4&7.jpeg","hash":"3c6b85cd80d1c3dbedcab17a47a86734bb95d615","modified":1566368909578},{"_id":"source/image/cglib_callback.png","hash":"60cec8f262884a716ae070b08113e23e1aa0be8c","modified":1566368909573},{"_id":"themes/next/layout/_custom/header.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1566368909624},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1566368909624},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"f83befdc740beb8dc88805efd7fbb0fef9ed19be","modified":1566368909625},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"8c56dd26157cbc580ae41d97ac34b90ab48ced3f","modified":1566368909625},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"e2e4eae391476da994045ed4c7faf5e05aca2cd7","modified":1566368909627},{"_id":"themes/next/layout/_macro/reward.swig","hash":"357d86ec9586705bfbb2c40a8c7d247a407db21a","modified":1566368909626},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"9c7343fd470e0943ebd75f227a083a980816290b","modified":1566368909626},{"_id":"themes/next/layout/_partials/comments.swig","hash":"2651565d020921420df2a92cee11ffafdfd9faa2","modified":1566824174600},{"_id":"themes/next/layout/_partials/footer.swig","hash":"6e02436ca9d437d1deeabcbf27928e5897ad893a","modified":1566808502058},{"_id":"themes/next/layout/_partials/header.swig","hash":"c54b32263bc8d75918688fb21f795103b3f57f03","modified":1566368909629},{"_id":"themes/next/layout/_macro/post.swig","hash":"4ba938822d56c597490f0731893eaa2443942e0f","modified":1566368909626},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"77c61e0baea3544df361b7338c3cd13dc84dde22","modified":1566368909629},{"_id":"themes/next/layout/_partials/head.swig","hash":"f14a39dad1ddd98e6d3ceb25dda092ba80d391b5","modified":1566368909628},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1566368909629},{"_id":"themes/next/layout/_partials/search.swig","hash":"b4ebe4a52a3b51efe549dd1cdee846103664f5eb","modified":1566368909630},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"c0f5a0955f69ca4ed9ee64a2d5f8aa75064935ad","modified":1566368909632},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"931808ad9b8d8390c0dcf9bdeb0954eeb9185d68","modified":1566368909632},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1566368909641},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9be624634703be496a5d2535228bc568a8373af9","modified":1566368909634},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"8301c9600bb3e47f7fb98b0e0332ef3c51bb1688","modified":1566368909642},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"fa882641da3bd83d9a58a8a97f9d4c62a9ee7b5c","modified":1566368909642},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"a0bd3388587fd943baae0d84ca779a707fbcad89","modified":1566368909642},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"99b66949f18398689b904907af23c013be1b978f","modified":1566368909649},{"_id":"themes/next/scripts/tags/button.js","hash":"eddbb612c15ac27faf11c59c019ce188f33dec2c","modified":1566368909649},{"_id":"themes/next/scripts/tags/exturl.js","hash":"5022c0ba9f1d13192677cf1fd66005c57c3d0f53","modified":1566368909650},{"_id":"themes/next/scripts/tags/full-image.js","hash":"c9f833158c66bd72f627a0559cf96550e867aa72","modified":1566368909650},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1566368909650},{"_id":"themes/next/scripts/tags/label.js","hash":"6f00952d70aadece844ce7fd27adc52816cc7374","modified":1566368909650},{"_id":"themes/next/scripts/tags/note.js","hash":"f7eae135f35cdab23728e9d0d88b76e00715faa0","modified":1566368909651},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"bcba2ff25cd7850ce6da322d8bd85a8dd00b5ceb","modified":1566368909651},{"_id":"themes/next/scripts/tags/tabs.js","hash":"aa7fc94a5ec27737458d9fe1a75c0db7593352fd","modified":1566368909652},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"554ec568e9d2c71e4a624a8de3cb5929050811d6","modified":1566368909643},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"9a188938d46931d5f3882a140aa1c48b3a893f0c","modified":1566368909643},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1566368909686},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1566368909685},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1566368909686},{"_id":"themes/next/source/css/main.styl","hash":"a91dbb7ef799f0a171b5e726c801139efe545176","modified":1566368909685},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"db15d7e1552aa2d2386a6b8a33b3b3a40bf9e43d","modified":1566368909643},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1566368909686},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1566368909689},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1566368909687},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1566368909694},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1566368909689},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1566368909689},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1566368909693},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1566368909694},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1566368909693},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1566368909694},{"_id":"themes/next/source/images/new_favicon_source_01_16x16.jpg","hash":"4d7c034b33affc22b4bc0cabbc4ee4a0d8a5bf09","modified":1566893863181},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1566368909694},{"_id":"themes/next/source/images/new_favicon_source_01.jpg","hash":"00b1b4e06e6149410d859dedf17915037e3f6102","modified":1566887557228},{"_id":"themes/next/source/images/new_favicon_source_01_180x180.jpg","hash":"ab6bdc8bf1a37f8618729d3dcb0d19af948f486b","modified":1566887581974},{"_id":"themes/next/source/images/new_favicon_source_01_32x32.jpg","hash":"41f44eba6a21e1a19b84e7a688b57e76baa40f62","modified":1566887604264},{"_id":"themes/next/source/images/new_favicon_source_02_16x16.jpg","hash":"d3bcc57f2bc33dbaa8e42932d634c5c160f3b049","modified":1566893838580},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1566368909695},{"_id":"themes/next/source/images/new_favicon_source_02_180x180.jpg","hash":"5473f097e8f00bf613c261d47acfdf3c644533ea","modified":1566887637758},{"_id":"themes/next/source/images/new_favicon_source_02_32x32.jpg","hash":"66544564cf229c08cdccb4b731e249cc3a63d25c","modified":1566887651170},{"_id":"themes/next/source/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1566368909695},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1566368909695},{"_id":"themes/next/source/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1566368909695},{"_id":"source/image/ElasticSearch/elastic_stack01.jpg.jpg","hash":"6638d06bfe1f5b7f50ad855064a2d1168e648ff6","modified":1566368909561},{"_id":"source/image/IO/IO模型01.png","hash":"583c12dc702d3d39f9eaa7dbfc2c3ca3aa82ae47","modified":1566368909566},{"_id":"source/image/DevOps/docker_02.png","hash":"fed79dae1f6d4ab915f0c5c44babbdcdb24aca12","modified":1566810672574},{"_id":"source/image/IO/IO模型06.png","hash":"3c642b0acc0db2f56464a5f98e944770b78616cd","modified":1566368909569},{"_id":"source/image/QRcode/wechat_qrcode.jpg","hash":"c146b58898b62459ac3e5b8d76d2e5574ed6dabe","modified":1566819488350},{"_id":"source/image/loadbalancing/DNS.png","hash":"9c4690ed18ee0d68f18323c7fb52e6a2c1e56bfc","modified":1566368909575},{"_id":"source/image/loadbalancing/IP.png","hash":"b40e4c7e4d44d90300c9a436e76ba0c8e7f96ffa","modified":1566368909577},{"_id":"source/image/loadbalancing/F5_ISH_WAS.png","hash":"7824635a6200e4508c13614509c83f67f8e418d8","modified":1566368909576},{"_id":"source/image/loadbalancing/LVS.png","hash":"8938245784788e780d2f3d6d297cbef3cfcf0562","modified":1566368909578},{"_id":"source/image/mysql/btree.png","hash":"21956a89ec21bf63cb1809143b637729b54f07dd","modified":1589793914332},{"_id":"source/image/mysql/b+tree.png","hash":"56218025c67b7f0575e1e534d7a79ff6db5e343b","modified":1589793929414},{"_id":"source/image/volatile.png","hash":"4f1fae3fdeb807a6030b0b62b9742abc0c5baaa1","modified":1566368909580},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566368909633},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566368909634},{"_id":"themes/next/source/images/1571293259.jpg","hash":"6043ba07ec23006de18aba3a3603add0d849db17","modified":1402287188000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566368909675},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566368909675},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566368909676},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566368909684},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1566368909684},{"_id":"source/image/jvm/GC/GC_01.jpg","hash":"f09c1820e7313e64327e986fa8da4b2cf8b86dc1","modified":1589960163869},{"_id":"source/image/jvm/GC/GC_05.jpg","hash":"a6f860e433033115518d50cfbfce08412983543f","modified":1589960690623},{"_id":"source/image/jvm/GC/GC_07.jpg","hash":"cec9a5ef1ae4c0dac292e8dbe1892b4a77389f54","modified":1589960868772},{"_id":"source/image/jvm/GC/GC_08.jpg","hash":"51fa9cb8f737071b474653fdfc609715ec8c6692","modified":1589960944368},{"_id":"source/image/jvm/GC/GC_09.jpg","hash":"51fa9cb8f737071b474653fdfc609715ec8c6692","modified":1589961068170},{"_id":"source/image/jvm/GC/GC_10.jpg","hash":"e10b34d12340d98529a33f787923355a316fabbd","modified":1589961211998},{"_id":"source/image/jvm/GC/GC_11.jpg","hash":"13cb4d1e217b65037bd73e48a8d9d6bb155ed892","modified":1589961348097},{"_id":"source/image/jvm/GC/GC_12.jpg","hash":"0afbb21825dbabd67eb4e2899898afbbc8ebe226","modified":1589961357251},{"_id":"source/image/jvm/GC/GC_14.jpg","hash":"dc622c024b7fe89e285912d329e430016fb10491","modified":1589961861679},{"_id":"source/image/jvm/GC/GC_13.jpg","hash":"5271b7f65e4674f7b29035e411e07e6c5d2f8cd0","modified":1589961467960},{"_id":"source/image/ElasticSearch/elasticsearch03.png","hash":"c46376bf637361cb14523d096b764a24cc80047d","modified":1566368909563},{"_id":"source/image/jvm/JDK自带工具/11.png","hash":"e9ff7b13f8220a9975a6ef7a5ceac453ab97e352","modified":1589949524416},{"_id":"source/image/jvm/JDK自带工具/10.png","hash":"70fd183a8f70ef25b0d5ac3d72ed7aa471461423","modified":1589949508260},{"_id":"source/image/jvm/JDK自带工具/15.png","hash":"9db5ec681d44be07b558c2243bacb603a60ac82e","modified":1589949574510},{"_id":"source/image/jvm/JDK自带工具/12.png","hash":"5dac6c3f492cc13bed3bb6fb922922f3f9f2bfeb","modified":1589949534061},{"_id":"source/image/jvm/JDK自带工具/16.png","hash":"8fec11e572ad0c208bca7e837a515fbbb989555c","modified":1589949581639},{"_id":"source/image/jvm/JDK自带工具/19.png","hash":"c1e79e8d80547bf2f2eacc357da2665b8a8d20ae","modified":1589949629215},{"_id":"source/image/jvm/JDK自带工具/3.png","hash":"54ead790a520b3274d492f74b4e8a7ccf5fcd987","modified":1589949429913},{"_id":"source/image/jvm/JDK自带工具/5.png","hash":"73756814c0f04b8e6f7fba8af7e0c91bfa74e4d4","modified":1589949461214},{"_id":"source/image/jvm/JDK自带工具/7.png","hash":"0527550487488e03dd09b3c0a7b58e2311d2b7c0","modified":1589949483096},{"_id":"source/image/jvm/JDK自带工具/6.png","hash":"5c47f5344dbd8302bb92d903b4f0337cf8cf042a","modified":1589949473672},{"_id":"source/image/jvm/JDK自带工具/8.png","hash":"d19496cc5605bd61b16d29f04211227bf557e05c","modified":1589949491466},{"_id":"source/image/jvm/JDK自带工具/9.png","hash":"7c94ea854905eeef926f8b4ab58ba9900c780756","modified":1589949498950},{"_id":"source/image/jvm/profile_02.png","hash":"c75703a59138e8d3fa4b7ea61a14e6d5cc1f4c95","modified":1589697486379},{"_id":"source/image/mysql/mysql_index.png","hash":"41d377228d34dd990da08ffaea6d7a1f319ef580","modified":1589793697384},{"_id":"source/image/mysql/mysql_myISAM.png","hash":"12c121ea998f0f7df2f25f2a0dbeefced2d33711","modified":1589793824543},{"_id":"source/image/jvm/JDK自带工具/4.png","hash":"c4446d0c55ad712f80d419cf8622b0f20a983fb4","modified":1589949445819},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"a223919d2e1bf17ca4d6abb2c86f2efca9883dc1","modified":1566368909628},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"f5e487b0d213ca0bd94aa30bc23b240d65081627","modified":1566368909628},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"b2f0d247b213e4cf8de47af6a304d98070cc7256","modified":1566368909630},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1566368909631},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a8c7f9ca7c605d039a1f3bf4e4d3183700a3dd62","modified":1566368909630},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"9e3d133ac5bcc6cb51702c83b2611a49811abad1","modified":1566368909631},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1566368909632},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"9b84ab576982b2c3bb0291da49143bc77fba3cc6","modified":1566368909633},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"0a9cdd6958395fcdffc80ab60f0c6301b63664a5","modified":1566368909632},{"_id":"source/image/jvm/JDK自带工具/2.png","hash":"84811d8b1f8a23bdff290cc907b7e945b8213fb5","modified":1589949386318},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1566368909633},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1566368909634},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"ff947f3561b229bc528cb1837d4ca19612219411","modified":1566368909635},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"d9e2d9282f9be6e04eae105964abb81e512bffed","modified":1566368909631},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"71397a5823e8ec8aad3b68aace13150623b3e19d","modified":1566368909635},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"753d262911c27baf663fcaf199267133528656af","modified":1566368909635},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"a10b7f19d7b5725527514622899df413a34a89db","modified":1566368909636},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"16cb23818909f57dac1a5ada66869971c33d7bd8","modified":1566807516891},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"45f3f629c2aacc381095750e1c8649041a71a84b","modified":1566368909637},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"7d94845f96197d9d84a405fa5d4ede75fb81b225","modified":1566368909636},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b1e13df83fb2b1d5d513b30b7aa6158b0837daab","modified":1566368909637},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"ccc443b22bd4f8c7ac4145664686c756395b90e0","modified":1566368909637},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"5a8027328f060f965b3014060bebec1d7cf149c1","modified":1566368909638},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"8a399df90dadba5ad4e781445b58f4765aeb701e","modified":1566368909638},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"f9a1647a8f1866deeb94052d1f87a5df99cb1e70","modified":1566368909638},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b83a51bbe0f1e2ded9819070840b0ea145f003a6","modified":1566368909639},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"e6d10ee4fb70b3ae1cd37e9e36e000306734aa2e","modified":1566368909637},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"1600f340e0225361580c44890568dc07dbcf2c89","modified":1566368909639},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"4dcc3213c033994d342d02b800b6229295433d30","modified":1566368909639},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"af7f3e43cbdc4f88c13f101f0f341af96ace3383","modified":1566368909640},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"1c816b522b04842476d7f8379dd4e6850e292a0f","modified":1566824214430},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"9246162d4bc7e949ce1d12d135cbbaf5dc3024ec","modified":1566368909641},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"4c501ea0b9c494181eb3c607c5526a5754e7fbd8","modified":1566368909639},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"3b713ce08a22cb4d7371efa97988bc2550bea001","modified":1566824919250},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4050553d44ba1396174161c9a6bb0f89fa779eca","modified":1566368909641},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"7e65ff8fe586cd655b0e9d1ad2912663ff9bd36c","modified":1566368909641},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"34599633658f3b0ffb487728b7766e1c7b551f5a","modified":1566368909644},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"07f7da320689f828f6e36a6123807964a45157a0","modified":1566368909675},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1566368909645},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"7896c3ee107e1a8b9108b6019f1c070600a1e8cc","modified":1566368909675},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"d8c98938719284fa06492c114d99a1904652a555","modified":1566368909645},{"_id":"source/image/mysql/mysql_InnoDB.png","hash":"5585358b025e5782c656dc8bea4997d3a3b679f7","modified":1589793854775},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"3403fdd8efde1a0afd11ae8a5a97673f5903087f","modified":1566368909674},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"58e7dd5947817d9fc30770712fc39b2f52230d1e","modified":1566368909683},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"a25408534f8fe6e321db4bbf9dd03335d648fe17","modified":1566368909683},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0e55cbd93852dc3f8ccb44df74d35d9918f847e0","modified":1566368909676},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"93479642fd076a1257fecc25fcf5d20ccdefe509","modified":1566368909645},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4069f918ccc312da86db6c51205fc6c6eaabb116","modified":1566368909684},{"_id":"themes/next/source/js/src/affix.js","hash":"1b509c3b5b290a6f4607f0f06461a0c33acb69b1","modified":1566368909696},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"0289031200c3d4c2bdd801ee10fff13bb2c353e4","modified":1566368909697},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"cb431b54ba9c692165a1f5a12e4c564a560f8058","modified":1566368909696},{"_id":"themes/next/source/css/_variables/base.styl","hash":"b1f6ea881a4938a54603d68282b0f8efb4d7915d","modified":1566368909684},{"_id":"themes/next/source/js/src/exturl.js","hash":"a2a0f0de07e46211f74942a468f42ee270aa555c","modified":1566368909697},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"b35a7dc47b634197b93487cea8671a40a9fdffce","modified":1566368909697},{"_id":"themes/next/source/js/src/motion.js","hash":"885176ed51d468f662fbf0fc09611f45c7e5a3b1","modified":1566368909703},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"1512c751d219577d338ac0780fb2bbd9075d5298","modified":1566368909697},{"_id":"themes/next/source/js/src/post-details.js","hash":"93a18271b4123dd8f94f09d1439b47c3c19a8712","modified":1566368909704},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"b7657be25fc52ec67c75ab5481bdcb483573338b","modified":1566368909705},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"02cf91514e41200bc9df5d8bdbeb58575ec06074","modified":1566368909704},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1566368909714},{"_id":"themes/next/source/js/src/utils.js","hash":"b3e9eca64aba59403334f3fa821f100d98d40337","modified":1566368909705},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1566368909710},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"672d3b5767e0eacd83bb41b188c913f2cf754793","modified":1566368909715},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"9be892a4e14e0da18ff9cb962c9ef71f163b1b22","modified":1566368909715},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"b02737510e9b89aeed6b54f89f602a9c24b06ff2","modified":1566368909714},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"bf3eef9d647cd7c9b62feda3bc708c6cdd7c0877","modified":1566368909773},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1566368909774},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"03ddbf76c1dd1afb93eed0b670d2eee747472ef1","modified":1566368909786},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1566368909774},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"b4aefc910578d76b267e86dfffdd5121c8db9aec","modified":1566368909786},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"c31ff06a740955e44edd4403902e653ccabfd4db","modified":1566368909786},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1566368909787},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1566368909774},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1566368909787},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"865d6c1328ab209a4376b9d2b7a7824369565f28","modified":1566368909825},{"_id":"themes/next/source/lib/gitalk/gitalk.css","hash":"99f6725b386bdb0f52d15b0dd7877eaf1ad4c918","modified":1566824427619},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"14264a210bf94232d58d7599ea2ba93bfa4fb458","modified":1566368909850},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"e33aa8fa48b6639d8d8b937d13261597dd473b3a","modified":1566368909850},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"90fa628f156d8045357ff11eaf32e61abacf10e8","modified":1566368909826},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1566368909827},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"2ce5f3bf15c523b9bfc97720d8884bb22602a454","modified":1566368909850},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1566368909827},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1566368909827},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1566368909851},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1566368909849},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1566368909851},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1566368909827},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1566368909852},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1566368909851},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1566368909872},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1566368909873},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1566368909873},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1566368909873},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1566368909873},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1566368909874},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1566368909874},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1566368909874},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1566368909875},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"8aaa675f577d5501f5f22d5ccb07c2b76310b690","modified":1566368909875},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"2d9a9f38c493fdf7c0b833bb9184b6a1645c11b2","modified":1566368909876},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"46a50b91c98b639c9a2b9265c5a1e66a5c656881","modified":1566368909908},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"63da5e80ebb61bb66a2794d5936315ca44231f0c","modified":1566368909913},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1566368909913},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"8148492dd49aa876d32bb7d5b728d3f5bf6f5074","modified":1566368909909},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1566368909915},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1566368909915},{"_id":"source/image/jvm/GC/GC_02.jpg","hash":"252e1800e3e7df95c1f5327a8f3705320eef7068","modified":1589960505022},{"_id":"source/image/jvm/GC/GC_03.jpg","hash":"259ca90a25f0479ca10685472443d4ea881f6d54","modified":1589960552962},{"_id":"source/image/jvm/GC/GC_06.jpg","hash":"7ae98d3184515e11dc0e3739c088128aceb8fc5e","modified":1589960743525},{"_id":"source/image/jvm/JDK自带工具/1.png","hash":"cc35f00f73d2215f3b61828783ba20b2fda0ab9a","modified":1589949381938},{"_id":"source/image/jvm/JDK自带工具/14.png","hash":"f028305deedb7aa79dbad871d86dff6fa4c1e92e","modified":1589949564570},{"_id":"source/image/jvm/JDK自带工具/17.png","hash":"3851771022408820f280df12a6eea93593115ac1","modified":1589949591217},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1566368909916},{"_id":"source/image/jvm/JDK自带工具/18.png","hash":"2f7db8f0bf1a16ac71ba7430f7f4cdf9e57cf74b","modified":1589949609649},{"_id":"source/image/jvm/JDK自带工具/13.png","hash":"1c775569352a16e99154aada40467994487556d7","modified":1589949541958},{"_id":"themes/next/source/images/reward/alipay_reward.jpg","hash":"f1bb3c47e49dd912ffaa97cde916b39a25b6c199","modified":1566814648061},{"_id":"source/image/ElasticSearch/elasticsearch04.png","hash":"480c3dc1725d3e2e510dfdc875c3023928dd2b92","modified":1575790210259},{"_id":"source/image/jvm/GC/GC_04.jpg","hash":"0dd0abd3ed27c44c0474fa14a371a825610dac95","modified":1589960653351},{"_id":"source/image/jvm/profile_03.png","hash":"86bb4d445d1796455cc128d11f4694cab3eeacac","modified":1589697514975},{"_id":"themes/next/source/images/reward/wechatpay_reward.jpg","hash":"12f6630ecb07d878ab216e6a6b61041ee63f260e","modified":1566814632707},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"218cc936ba3518a3591b2c9eda46bc701edf7710","modified":1566368909644},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"2530de0f3125a912756f6c0e9090cd012134a4c5","modified":1566368909644},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"12662536c7a07fff548abe94171f34b768dd610f","modified":1566368909672},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"8f86f694c0749a18ab3ad6f6df75466ca137a4bc","modified":1566368909652},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"237d185ac62ec9877e300947fa0109c44fb8db19","modified":1566368909653},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1566368909653},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"8b32928686c327151e13d3ab100157f9a03cd59f","modified":1566368909653},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"7ad4081466b397e2a6204141bb7768b7c01bd93c","modified":1566368909653},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1566368909666},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"4f2801fc4cf3f31bf2069f41db8c6ce0e3da9e39","modified":1566368909658},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"24ee4b356ff55fc6e58f26a929fa07750002cf29","modified":1566368909673},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"1da5c800d025345f212a3bf1be035060f4e5e6ed","modified":1566368909673},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"91ca75492cd51f2553f4d294ed2f48239fcd55eb","modified":1566368909673},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1566368909674},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"ea9069645696f86c5df64208490876fe150c8cae","modified":1566368909674},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"25d5e45a355ee2093f3b8b8eeac125ebf3905026","modified":1566368909677},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a17e2b871a335f290afb392a08f94fd35f59c715","modified":1566368909674},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"d0bfd1bef988c76f7d7dd72d88af6f0908a8b0db","modified":1566368909677},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"60fa84aa7731760f05f52dd7d8f79b5f74ac478d","modified":1566368909676},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"9c99034f8e00d47e978b3959f51eb4a9ded0fcc8","modified":1566368909678},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1566368909677},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"26666c1f472bf5f3fb9bc62081cca22b4de15ccb","modified":1566368909677},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1566368909678},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9b913b73d31d21f057f97115ffab93cfa578b884","modified":1566368909679},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1566368909680},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"31127dcbf4c7b4ada53ffbf1638b5fe325b7cbc0","modified":1566368909680},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1566368909681},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"e695e58f714129ca292c2e54cd62c251aca7f7fe","modified":1566368909680},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"bce344d3a665b4c55230d2a91eac2ad16d6f32fd","modified":1566368909682},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"5dbc0d0c897e46760e5dbee416530d485c747bba","modified":1566368909681},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"416988dca389e6e2fdfa51fa7f4ee07eb53f82fb","modified":1566368909682},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"1f6e2ce674735269599acc6d77b3ea18d31967fc","modified":1566368909682},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"4642e30010af8b2b037f5b43146b10a934941958","modified":1566368909682},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"86197902dfd3bededba10ba62b8f9f22e0420bde","modified":1566368909683},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"ad2dcedf393ed1f3f5afd2508d24969c916d02fc","modified":1566368909683},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"f1d0b5d7af32c423eaa8bb93ab6a0b45655645dc","modified":1566368909704},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"6d586bfcfb7ae48f1b12f76eec82d3ad31947501","modified":1566368909710},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1566368909715},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1566368909715},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1566368909716},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1566368909716},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1566368909716},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1566368909763},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1566368909772},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"16b03db23a52623348f37c04544f2792032c1fb6","modified":1566368909710},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1566368909773},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1566368909775},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"3655f1fdf1e584c4d8e8d39026093ca306a5a341","modified":1566368909787},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1566368909775},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1566368909788},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1566368909788},{"_id":"themes/next/source/lib/gitalk/gitalk.min.js","hash":"266500948447c95aeea95ef6760f192afc96fd5e","modified":1566824439489},{"_id":"themes/next/source/lib/jquery/index.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1566368909826},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"41ea797c68dbcff2f6fb3aba1d1043a22e7cc0f6","modified":1566368909912},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"a817b6c158cbc5bab3582713de9fe18a18a80552","modified":1566368909912},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"6c26cdb36687d4f0a11dabf5290a909c3506be5c","modified":1566368909708},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1566368909772},{"_id":"source/image/jvm/profile_01.png","hash":"17942c86b54260d8b5c371fbd2ce8b5884304465","modified":1589697468954},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1566368909799},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1566368909825},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"9f73c4696f0907aa451a855444f88fc0698fa472","modified":1566368909654},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"53cde051e0337f4bf42fb8d6d7a79fa3fa6d4ef2","modified":1566368909655},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"167986d0f649516671ddf7193eebba7b421cd115","modified":1566368909656},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"50450d9fdc8a2b2be8cfca51e3e1a01ffd636c0b","modified":1566368909656},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d63e0cacc53dd375fcc113465a4328c59ff5f2c1","modified":1566368909655},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"0656e753f182c9f47fef7304c847b7587a85ef0d","modified":1566368909655},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"1727702eac5d326b5c81a667944a245016668231","modified":1566368909656},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"1a0d059799a298fe17c49a44298d32cebde93785","modified":1566368909655},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"b6f3a06a94a6ee5470c956663164d58eda818a64","modified":1566368909657},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"7fb593f90d74a99c21840679933b9ef6fdc16a61","modified":1566368909657},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"7fe4d4d656e86276c17cb4e48a560cb6a4def703","modified":1566368909657},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"f9760ecf186954cee3ba4a149be334e9ba296b89","modified":1566368909658},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1566368909658},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"62fbbd32cf5a99ae550c45c763a2c4813a138d01","modified":1566368909659},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"8cf318644acc8b4978537c263290363e21c7f5af","modified":1566368909658},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"a200c0a1c5a895ac9dc41e0641a5dfcd766be99b","modified":1566368909659},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"caf263d1928496688c0e1419801eafd7e6919ce5","modified":1566368909659},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"875cbe88d5c7f6248990e2beb97c9828920e7e24","modified":1566368909659},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1566368909660},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"a6c6eb8adba0a090ad1f4b9124e866887f20d10d","modified":1566368909660},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d0d7a5c90d62b685520d2b47fea8ba6019ff5402","modified":1566368909661},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"27deb3d3a243d30022055dac7dad851024099a8b","modified":1566368909661},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5a982d8ef3b3623ea5f59e63728990f5623c1b57","modified":1566368909662},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"01567edaea6978628aa5521a122a85434c418bfd","modified":1566368909662},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"b2495ae5e04dcca610aacadc47881d9e716cd440","modified":1566368909662},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"7968343e41f8b94b318c36289dff1196c3eb1791","modified":1566368909663},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"ccb34c52be8adba5996c6b94f9e723bd07d34c16","modified":1566368909662},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"89d6c3b697efc63de42afd2e89194b1be14152af","modified":1566368909663},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"bdcd8e4acbc6e51f28fa95d8a02f65fd1c80f242","modified":1566870024103},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"761eba9811b050b25d548cc0854de4824b41eb08","modified":1566368909663},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"39f04c4c7237a4e10acd3002331992b79945d241","modified":1566368909663},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"8dd9a1c6f4f6baa00c2cf01837e7617120cf9660","modified":1566368909664},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"61f8cea3c01acd600e90e1bc2a07def405503748","modified":1566368909664},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"1153bb71edf253765145559674390e16dd67c633","modified":1566368909665},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"11c22f0fb3f6beb13e5a425ec064a4ff974c13b7","modified":1566368909664},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a1521d48bb06d8d703753f52a198baa197af7da2","modified":1566368909665},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"5ef6343835f484a2c0770bd1eb9cc443609e4c39","modified":1566368909665},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"a3bdd71237afc112b2aa255f278cab6baeb25351","modified":1566368909667},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"e71652d3216e289c8548b1ea2357822c1476a425","modified":1566368909666},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1566368909666},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"c8fe49a4bc014c24dead05b782a7082411a4abc5","modified":1566368909665},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"f825da191816eef69ea8efb498a7f756d5ebb498","modified":1566368909667},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"2ab1322fe52ab5aafd49e68f5bd890e8380ee927","modified":1566368909667},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"b7076e58d647265ee0ad2b461fe8ce72c9373bc5","modified":1566368909668},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"b80604868e4f5cf20fccafd7ee415c20c804f700","modified":1566368909669},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"2ad1a2a9bbf6742d1b0762c4c623b68113d1e0fe","modified":1566368909667},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"154a87a32d2fead480d5e909c37f6c476671c5e6","modified":1566368909668},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"5dbeed535d63a50265d96b396a5440f9bb31e4ba","modified":1566368909669},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"9a409b798decdefdaf7a23f0b11004a8c27e82f3","modified":1566368909668},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"bba4f3bdb7517cd85376df3e1209b570c0548c69","modified":1566368909669},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"a6e7d698702c2e383dde3fde2abde27951679084","modified":1566368909670},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"10599e16414a8b7a76c4e79e6617b5fe3d4d1adf","modified":1566368909671},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"874278147115601d2abf15987f5f7a84ada1ac6b","modified":1566368909670},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1566368909671},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"717cc7f82be9cc151e23a7678601ff2fd3a7fa1d","modified":1566368909670},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"a01484e350ad5fc9b1fdfbfafb2ddd9687ad4d20","modified":1566824278988},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"16087276945fa038f199692e3eabb1c52b8ea633","modified":1566368909671},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"87e34d2992f77251ba59045c087db560fc53ad9b","modified":1566824322157},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"a07aa12cc36ac5c819670c2a3c17d07ed7a08986","modified":1566368909679},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"28825ae15fa20ae3942cdaa7bcc1f3523ce59acc","modified":1566368909672},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1566368909679},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1566368909681},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1566368909706},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1566368909706},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1566368909707},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1566368909763},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1566368909708},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1566368909707},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1566368909764},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1566368909764},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1566368909795},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1566368909764},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"4ac683b2bc8531c84d98f51b86957be0e6f830f3","modified":1566368909709},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1566368909764},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1566368909796},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1566368909914},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1566368909799},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1566368909772},{"_id":"themes/next/source/images/new_favicon_source_02.jpg","hash":"02bf3653b9b95c71ec9958239396f5fe8b29b4d5","modified":1566887474113},{"_id":"themes/next/source/lib/three/three.min.js","hash":"26273b1cb4914850a89529b48091dc584f2c57b8","modified":1566368909911},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1566368909798},{"_id":"source/image/springboot/springboot_01.png","hash":"fdaae0ba0585f7efcffd88b9a640c3fd31d088c1","modified":1588749896401},{"_id":"source/image/jvm/JVM_栈.png","hash":"6779b3f4671ca431523246fce9c4ca85ab2fbfe1","modified":1589886837944},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"90a1b22129efc172e2dfcceeeb76bff58bc3192f","modified":1566368909713},{"_id":"source/image/jvm/执行引擎.png","hash":"d67defa5f80a72a064778ddbd1bf1da86222de61","modified":1589889245059},{"_id":"public/404.html","hash":"d4692aaee40e20a5d6ae4a3643ed53b5ca4a8380","modified":1590134446733},{"_id":"public/categories/index.html","hash":"be1bdb75a65627cda46e597cb957be3f444e1786","modified":1590134446734},{"_id":"public/about/index.html","hash":"cb14a222b9beefc2fbca6891dd59b2eb04fbd6a1","modified":1590134446734},{"_id":"public/tags/index.html","hash":"eb0d0f765ebe60e9ee67e9d28b9852753925c03a","modified":1590134446734},{"_id":"public/categories/Java/page/2/index.html","hash":"578d277852c8adf946ebd027185743a7a0b4b29c","modified":1590134446734},{"_id":"public/categories/DevOps/page/2/index.html","hash":"4ed6ef55afa51ffec026ca3f8eb39427217b8410","modified":1590134446734},{"_id":"public/categories/Elastic-Stack/index.html","hash":"337124eccc3a979201e8b83b988fc46c7c39c9b1","modified":1590134446734},{"_id":"public/categories/其他/index.html","hash":"f55938be5ee1c84b54738b70a4542ffa4cebe033","modified":1590134446734},{"_id":"public/categories/Linux/index.html","hash":"ad7f604cb3bed0fa62b05f03623c4351e43bea76","modified":1590134446735},{"_id":"public/categories/中间件/index.html","hash":"1b7c14c8f027455d7ab3a4bf5de0a3852d7c154b","modified":1590134446735},{"_id":"public/categories/分布式/index.html","hash":"75e36ed26b8f226adb682781d94b8baaea1eba4f","modified":1590134446735},{"_id":"public/categories/数据库/index.html","hash":"51051269e86db744a56509ae7b29bc55c185d5f2","modified":1590134446735},{"_id":"public/categories/前端/index.html","hash":"9d0446366217e7e8c1f272d55edf7e72286981c9","modified":1590134446735},{"_id":"public/categories/设计模式/index.html","hash":"b480fd2aae98643c2e7ba35fce4d71af8d2214b5","modified":1590134446735},{"_id":"public/archives/2018/01/index.html","hash":"1ec4ed7bd3e1da2ee6460781aa430b31e57a80ec","modified":1590134446735},{"_id":"public/archives/2018/09/index.html","hash":"7586c3559b3515a476217af0ef149bba1735c0bc","modified":1590134446735},{"_id":"public/archives/2018/10/index.html","hash":"42fe60da45ea23641fb9436baea7a08959d684c9","modified":1590134446735},{"_id":"public/archives/2018/11/index.html","hash":"2932aaee95bd7677d8e132089c555d02f5d4650e","modified":1590134446735},{"_id":"public/archives/2018/12/index.html","hash":"5400a90ec53281bfdc9d0941c3b4e5366b20bb4c","modified":1590134446735},{"_id":"public/archives/2019/01/index.html","hash":"572e7bebf2ef5ee034594cd6c300aab33543ba15","modified":1590134446735},{"_id":"public/archives/2019/02/index.html","hash":"8458a19d1483f4b594dded6fcdbe5c08b1f57d7f","modified":1590134446736},{"_id":"public/archives/2019/04/index.html","hash":"3f48233ffa9a00c0a820743bbc815933c84d6df4","modified":1590134446736},{"_id":"public/archives/2019/05/index.html","hash":"872392a9340ba01cb06dab299689d9f297268532","modified":1590134446736},{"_id":"public/archives/2019/06/index.html","hash":"30d71a6ac19f1f740b923fb47ab730c5218e1aef","modified":1590134446736},{"_id":"public/archives/2019/07/index.html","hash":"e7bbe2a0c5080c0ac73783310052435017eaa0e3","modified":1590134446736},{"_id":"public/archives/2019/09/index.html","hash":"f78694e514952ce663194f25b952bee65bdb0c8a","modified":1590134446736},{"_id":"public/archives/2019/12/index.html","hash":"308d8eab1e629ad88adcb1fe54593681d47daf23","modified":1590134446736},{"_id":"public/archives/2020/page/2/index.html","hash":"61c8c5bead9d3c3f4da78829374c11c3a7ad1dce","modified":1590134446736},{"_id":"public/archives/2020/01/index.html","hash":"79469f351fddf262862a25cf33149ef6a0a02e5f","modified":1590134446736},{"_id":"public/archives/2020/02/index.html","hash":"245080aede5ae18d6c2a09e5ddfc5447a5e4f502","modified":1590134446736},{"_id":"public/archives/2020/03/index.html","hash":"1012a91e6368d232e094c58df22e56aed9777b76","modified":1590134446737},{"_id":"public/archives/2020/05/index.html","hash":"d16a47bc9bb22b17081980dd0bea6281e9d82034","modified":1590134446737},{"_id":"public/tags/JVM/index.html","hash":"6b201e70d7dd9a7d5baab334255fdfc1d8d41db1","modified":1590134446737},{"_id":"public/tags/docker/page/2/index.html","hash":"adcbf33ef925333ff6bbab60ebbe1c69d7bc16d7","modified":1590134446737},{"_id":"public/tags/ElasticSearch/index.html","hash":"035afe2adcfa03c880fff6c9f4727b159ff1b6fb","modified":1590134446737},{"_id":"public/tags/hexo/index.html","hash":"884e9c30e5891c9c9006d965a9c1acbdee037dfb","modified":1590134446737},{"_id":"public/tags/Lock/index.html","hash":"dfea82bb786be96cdae88baf3d343d873cf8b237","modified":1590134446737},{"_id":"public/tags/Linux/index.html","hash":"f7f3666a56340685f794e67c7a55558cfe8f8835","modified":1590134446737},{"_id":"public/tags/redis/index.html","hash":"73222a09eecee14d942835e97c8c32df9f511447","modified":1590134446737},{"_id":"public/tags/mybatis/index.html","hash":"3abca71307f32c1ad862fc719c45467ae9056426","modified":1590134446737},{"_id":"public/tags/事务/index.html","hash":"2255738a902e73a762a7d10509d9c1adaba2696b","modified":1590134446738},{"_id":"public/tags/分布式ID/index.html","hash":"236ed0da788eeadead153f470bf36eb99161b0eb","modified":1590134446738},{"_id":"public/tags/数据库/index.html","hash":"12d313513eb06b587903742ce2dbdb24a44b18b6","modified":1590134446738},{"_id":"public/tags/前端/index.html","hash":"486a42c82edeb235a835c9ac452ef2efa07bf839","modified":1590134446738},{"_id":"public/tags/redisson/index.html","hash":"9817b487812581e74c857b3ccc737d73297066b5","modified":1590134446738},{"_id":"public/tags/负载均衡/index.html","hash":"09e1fad946ca6501132fd88aa718ede1afb106e2","modified":1590134446738},{"_id":"public/tags/MySQL/index.html","hash":"8dfd8ac3bb6fba19c7bb55f3337e83f9a9ad6aee","modified":1590134446738},{"_id":"public/tags/设计模式/index.html","hash":"51385f104cd1a1353b29c801335cb48e55d9bbed","modified":1590134446738},{"_id":"public/tags/rabbitMQ/index.html","hash":"6085b76e35f83568b169acd351f429726bc3e061","modified":1590134446739},{"_id":"public/tags/性能优化/index.html","hash":"82148dfcf897809964cf5a5aa70af9b2b2aaa820","modified":1590134446739},{"_id":"public/tags/网络IO模型/index.html","hash":"d683df3dedfd5e3ae30b42862e665bc717c6ccb7","modified":1590134446739},{"_id":"public/2020/05/03/GC调优参数/index.html","hash":"7fa7a3832bee5c9aef43fd38ff82d77a4a3a583c","modified":1590134446739},{"_id":"public/2020/05/02/GC收集器与算法/index.html","hash":"54834941147995762d8ebf566501c3d0c5ba7a6d","modified":1590134446739},{"_id":"public/2020/05/01/JDK自带性能调优相关工具/index.html","hash":"15e73f8a07654bf5978d14f42c8c235e11232bb2","modified":1590134446739},{"_id":"public/2020/03/21/JVM内存模型/index.html","hash":"47be6121c829dfde41d3c14d628d72795e43da20","modified":1590134446739},{"_id":"public/2020/03/13/redis_03_客户端源码/index.html","hash":"3ff9a37b2cb00c2c44c4c922ffe443955ed5c58f","modified":1590134446739},{"_id":"public/2020/03/12/redis_02_进阶基础/index.html","hash":"c91550a47b32f5d77375f70ff38a7b2b89d127a8","modified":1590134446739},{"_id":"public/2020/02/08/redisson/index.html","hash":"53c7eca433d9731bcbcf1b407983cdfb91304f27","modified":1590134446739},{"_id":"public/2020/02/08/rabbitMQ知识点整理/index.html","hash":"dc238c8524136bacd2fdd086647c4809e80e7202","modified":1590134446739},{"_id":"public/2020/01/30/SpringBoot自动装配原理/index.html","hash":"4aa000c9c398ed26bbdce3ac029695ab2de34d80","modified":1590134446740},{"_id":"public/2020/01/15/mysql性能优化学习笔记/index.html","hash":"1262468ccfb1e109bec858e566db68cfb6e8c24a","modified":1590134446740},{"_id":"public/2020/01/09/分布式ID/index.html","hash":"095c53b9d8773e00cf720fe4b0a9d21801e053a0","modified":1590134446740},{"_id":"public/2020/01/01/CAS/index.html","hash":"fac820999451d2d4e1e93eb889c1ffb7a6e85407","modified":1590134446740},{"_id":"public/2019/12/09/elasticsearch_04_基础RESTfulAPI/index.html","hash":"d2ab1bae463af5e13a9aedeb55d6feb01155ad62","modified":1590134446740},{"_id":"public/2019/12/09/elasticsearch_03_基础概念/index.html","hash":"519384d5a58d441e9bb20dab904f006a30337b4c","modified":1590134446740},{"_id":"public/2019/09/24/docker_10_dockerfile/index.html","hash":"48ae997048bac5d843e507c223ab11dd8079c3e8","modified":1590134446740},{"_id":"public/2019/08/28/docker_07_网络/index.html","hash":"0342c0397518168614993c4c825ef85173c2f1e2","modified":1590134446740},{"_id":"public/2019/09/05/docker_09_ElasticSearch/index.html","hash":"0b77a801939c822971a416cef163f2f28214269b","modified":1590134446740},{"_id":"public/2019/08/28/docker_08_存储/index.html","hash":"5a4fd462c6715edcb3df222d1adcdf8c6a4b026a","modified":1590134446741},{"_id":"public/2019/08/26/docker_06_架构/index.html","hash":"87394ec6bfe0e138af6df3d3ba5b74e97f019abf","modified":1590134446741},{"_id":"public/2019/08/22/docker_06_mysql/index.html","hash":"b4de8c1324264131da3a419b6d3be4b13eac8cac","modified":1590134446741},{"_id":"public/2019/08/22/前端性能优化/index.html","hash":"bea3abe08b5412580fcccf76f9b5e092860d5cf7","modified":1590134446741},{"_id":"public/2019/08/21/docker_04_基础指令/index.html","hash":"9873f73a3da0a462d924c13d5a8197a8f038fb05","modified":1590134446741},{"_id":"public/2019/08/21/docker_05_容器的使用/index.html","hash":"2d5cefe18cf9d1d769d5c1f7545586f79d2a898b","modified":1590134446741},{"_id":"public/2019/08/21/docker_03_HelloWorld/index.html","hash":"77988ebfa57e8a580c6b6101730118730fe889d5","modified":1590134446741},{"_id":"public/2019/07/17/elasticsearch_02_安装/index.html","hash":"41e916cdb4f018b7f806c36ffca501a703e59e2d","modified":1590134446741},{"_id":"public/2019/06/20/elasticsearch_01_简介/index.html","hash":"40716804baf39c1ef1b834c5e023b48d7f0f617b","modified":1590134446741},{"_id":"public/2019/05/11/lock/index.html","hash":"ffd447c7307e0b22836394c4030e98290a38887a","modified":1590134446742},{"_id":"public/2019/05/10/网络IO模型/index.html","hash":"a4ddd5c07172ebcfa798fedb2a7d8c8295286509","modified":1590134446742},{"_id":"public/2019/04/26/parallelStream/index.html","hash":"94e44bbc42ad79173d70c77df7105848291c1ac7","modified":1590134446742},{"_id":"public/2019/04/26/数据库三范式/index.html","hash":"cb742653dd39b9a1e585d308f43e8cb8b2798238","modified":1590134446742},{"_id":"public/2019/03/22/docker_02_安装/index.html","hash":"3b3e9594b2061bf42456a05a22decc705525c712","modified":1590134446742},{"_id":"public/2019/04/25/压测调优/index.html","hash":"05a99f1f1614a48d614ffa8e802d81e46e89c0d6","modified":1590134446742},{"_id":"public/2019/03/21/docker_01_简介/index.html","hash":"2fa67dd87ba8af477308feda7301241bd65924ee","modified":1590134446742},{"_id":"public/2019/03/20/mybatis_01/index.html","hash":"f9a7541c0039b9d5e1e6e6fe32ad3bb26eefce31","modified":1590134446743},{"_id":"public/2019/03/20/linux命令笔记/index.html","hash":"a8913487f96c2c2dbcfb0016cf63edeb61fd07e8","modified":1590134446743},{"_id":"public/2019/03/11/redis_01_基础指令/index.html","hash":"7d67a1168bcbcd26196ffadb6761835b2138d519","modified":1590134446743},{"_id":"public/2019/03/10/缓存应用基础知识/index.html","hash":"55dec1ab04b13dcb6ca5b866e5cb54a9a143ca5b","modified":1590134446743},{"_id":"public/2019/03/06/事务相关基本概念/index.html","hash":"90ea74138402cacbbd65871b7e2c936c87b62bd1","modified":1590134446743},{"_id":"public/2019/02/01/集合容器框架笔记/index.html","hash":"f05cb6f9b0ace74740b0a092ab7cef5e8987bc8c","modified":1590134446743},{"_id":"public/2019/01/16/pattern/index.html","hash":"8932cdd85a7379eecd908304fc3e52d85c5d7b76","modified":1590134446743},{"_id":"public/2018/12/14/JAVA程序常见问题与JVM内存模型关系/index.html","hash":"766ac84b8bb16fd6e043fed4cc6c6c8633216499","modified":1590134446744},{"_id":"public/2018/12/12/proxy_pattern/index.html","hash":"84b708a1413682e4e7e512e0e8f470841a3678cb","modified":1590134446744},{"_id":"public/2018/11/28/对象创建及类的加载机制/index.html","hash":"3bc935a8575b3f7ab20edff2427c5bee111d8630","modified":1590134446744},{"_id":"public/2018/11/28/thread/index.html","hash":"298a88ed4476f20d1da1580ab8fef417612842f9","modified":1590134446745},{"_id":"public/2018/11/21/lambda、函数式接口、引用表达式/index.html","hash":"ce1bfb0a24c292868a202bf23fc439bbb67cc2a3","modified":1590134446745},{"_id":"public/2018/11/19/Stream/index.html","hash":"4e224dc24f5243080e7bac7af80db0fed297ae0b","modified":1590134446746},{"_id":"public/2018/10/31/线程模型/index.html","hash":"90bf0cdfd9aab0d623f91eace70ab5e9557bf08d","modified":1590134446746},{"_id":"public/2018/09/04/hexo/index.html","hash":"56a19e3a7b6d31ed7685434b2367c98d07a8ab5d","modified":1590134446746},{"_id":"public/2018/09/04/load-balancing/index.html","hash":"ae38661225ae6e507b70e976296425b2436099fb","modified":1590134446746},{"_id":"public/2018/01/01/hello-world/index.html","hash":"3ed18b54adcf00af59f68a2cbd6ddc42ca9102ec","modified":1590134446746},{"_id":"public/categories/Java/index.html","hash":"30966b9d0c65c1dc4f27b86620db329c558ea9dc","modified":1590134446746},{"_id":"public/categories/DevOps/index.html","hash":"75b08c6eef73d37c857ca3f03b8b13e4cb6bc4fc","modified":1590134446747},{"_id":"public/archives/index.html","hash":"166b73c4bd1654b593759f5c9f4e96029b0f571b","modified":1590134446747},{"_id":"public/archives/page/2/index.html","hash":"01d8309aea11118bd71f258b04bd23650106711d","modified":1590134446747},{"_id":"public/archives/page/3/index.html","hash":"043b768850a3087bb2054dad532240e758011644","modified":1590134446747},{"_id":"public/archives/page/4/index.html","hash":"713f962bf54499dd7fe53775ea6156d102b2b6b4","modified":1590134446747},{"_id":"public/archives/page/5/index.html","hash":"8ec659f33458d8183ddf08428f41503f227745a4","modified":1590134446747},{"_id":"public/archives/2018/index.html","hash":"3808d5595ed42ea280596bfc80bee274503a7815","modified":1590134446747},{"_id":"public/archives/2019/index.html","hash":"dfd0a2520c1c7a9aea546139033dfd0d6ea1177c","modified":1590134446747},{"_id":"public/archives/2019/page/2/index.html","hash":"6ec16c53f2565a7195268677219d5904d2d86236","modified":1590134446747},{"_id":"public/archives/2019/page/3/index.html","hash":"96fe0440458f2fba0268c81db13ae4f5c4489614","modified":1590134446747},{"_id":"public/archives/2019/03/index.html","hash":"2383536cc0fa453dcddc44b53a305f521968cc8e","modified":1590134446747},{"_id":"public/archives/2019/08/index.html","hash":"9b9771e8837088e889d719c88177ea6f70093ec2","modified":1590134446747},{"_id":"public/archives/2020/index.html","hash":"329f25434c5fba747418dfc69420d3c51924142c","modified":1590134446747},{"_id":"public/tags/Java/index.html","hash":"a5c9931dc44396d576b404646fc6ff95e3df6a61","modified":1590134446747},{"_id":"public/tags/docker/index.html","hash":"4509fda445d931e53e4d18e5772b5217616c5fd0","modified":1590134446748},{"_id":"public/index.html","hash":"19f15a8b68c4ee909fd198753adfee79bbbc3818","modified":1590134446748},{"_id":"public/page/2/index.html","hash":"2743acc1e624588193618025a9d7c3efdc5cba16","modified":1590134446748},{"_id":"public/page/3/index.html","hash":"ba278c0a55efd82c093d7e81280df51b74599d7b","modified":1590134446748},{"_id":"public/page/4/index.html","hash":"9d69b04ece4f32a5d78dc0be624c0d0a14501faa","modified":1590134446748},{"_id":"public/page/5/index.html","hash":"2c15bcfb7328ae4d38503df7fefe2bfe30760ae6","modified":1590134446748},{"_id":"public/image/Nginx-Keepalived.png","hash":"923d679f2510aeea93a0d4a6c5432b73ef84903d","modified":1590134446772},{"_id":"public/image/classloader01.png","hash":"dd269bacf46fd036e7c35d045585d2b7b3639ca4","modified":1590134446772},{"_id":"public/image/W3sDesign_Proxy_Design_Pattern_UML.jpg","hash":"10f7d521589ae9eba96c10864c3f33ec334ecc35","modified":1590134446772},{"_id":"public/image/classloader02.jpg","hash":"a68b6b7788076ab406f4ff3c6e14ee5923db2c1c","modified":1590134446772},{"_id":"public/image/压测性能调优_01.png","hash":"7fcdb4dd074e4e983dc3ed481bcf58e62ddee911","modified":1590134446772},{"_id":"public/image/DevOps/docker_01.png","hash":"41837cb220654a047c4443349c67b7d29b839680","modified":1590134446772},{"_id":"public/image/IO/IO模型00.png","hash":"a981beb53424b9596621c2712d84ec506b876c1d","modified":1590134446772},{"_id":"public/image/ElasticSearch/elasticsearch02.png","hash":"11406ccacb1ec05ee555260842152ba90e9f559b","modified":1590134446772},{"_id":"public/image/IO/IO模型02.png","hash":"fac1afaa31e87e5233256644b82e929fda8b1725","modified":1590134446773},{"_id":"public/image/IO/IO模型04.png","hash":"5cf87c0c389e166f12ee1549d3714777c14e8988","modified":1590134446773},{"_id":"public/image/IO/IO模型00.jpg","hash":"6bc777f242fe23977ca0aad870a377acbae3ac2e","modified":1590134446773},{"_id":"public/image/IO/IO模型03.png","hash":"80df24f058bfb673aca10d6ec8c318c0bfe10d51","modified":1590134446773},{"_id":"public/image/jvm/JVM7内存模型.png","hash":"f66718f8bf704bc1c45de4c4237d243c3c95357e","modified":1590134446773},{"_id":"public/image/IO/IO模型05.png","hash":"a085f584d6158ae62fecbf0cb1bc9e10f0e11ae5","modified":1590134446773},{"_id":"public/image/IO/IO模型07.png","hash":"1e18dcf011abf42ae491ca4bac8e2b9573c4bd82","modified":1590134446773},{"_id":"public/image/jvm/GC.png","hash":"a406ddce2996d580430deee2ee5f431c0a19b4cf","modified":1590134446773},{"_id":"public/image/jvm/JVM8内存模型.png","hash":"0a53190fc445b3638eaa56ea9923bc7033aba5b4","modified":1590134446773},{"_id":"public/image/loadbalancing/Nginx-Keepalived.png","hash":"923d679f2510aeea93a0d4a6c5432b73ef84903d","modified":1590134446773},{"_id":"public/image/loadbalancing/loadbalancing_layer4&7.jpeg","hash":"3c6b85cd80d1c3dbedcab17a47a86734bb95d615","modified":1590134446773},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1590134446774},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1590134446774},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1590134446774},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1590134446774},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1590134446774},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1590134446774},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1590134446774},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1590134446774},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1590134446775},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1590134446775},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1590134446775},{"_id":"public/images/new_favicon_source_01_16x16.jpg","hash":"4d7c034b33affc22b4bc0cabbc4ee4a0d8a5bf09","modified":1590134446775},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1590134446775},{"_id":"public/images/new_favicon_source_01.jpg","hash":"00b1b4e06e6149410d859dedf17915037e3f6102","modified":1590134446775},{"_id":"public/images/new_favicon_source_01_180x180.jpg","hash":"ab6bdc8bf1a37f8618729d3dcb0d19af948f486b","modified":1590134446775},{"_id":"public/images/new_favicon_source_01_32x32.jpg","hash":"41f44eba6a21e1a19b84e7a688b57e76baa40f62","modified":1590134446776},{"_id":"public/images/new_favicon_source_02_16x16.jpg","hash":"d3bcc57f2bc33dbaa8e42932d634c5c160f3b049","modified":1590134446776},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1590134446776},{"_id":"public/images/new_favicon_source_02_32x32.jpg","hash":"66544564cf229c08cdccb4b731e249cc3a63d25c","modified":1590134446776},{"_id":"public/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1590134446776},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1590134446777},{"_id":"public/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1590134446777},{"_id":"public/image/IO/IO模型06.png","hash":"3c642b0acc0db2f56464a5f98e944770b78616cd","modified":1590134446777},{"_id":"public/image/QRcode/wechat_qrcode.jpg","hash":"c146b58898b62459ac3e5b8d76d2e5574ed6dabe","modified":1590134446777},{"_id":"public/images/1571293259.jpg","hash":"6043ba07ec23006de18aba3a3603add0d849db17","modified":1590134446777},{"_id":"public/image/jvm/GC/GC_05.jpg","hash":"a6f860e433033115518d50cfbfce08412983543f","modified":1590134446777},{"_id":"public/image/jvm/GC/GC_01.jpg","hash":"f09c1820e7313e64327e986fa8da4b2cf8b86dc1","modified":1590134446777},{"_id":"public/image/jvm/GC/GC_08.jpg","hash":"51fa9cb8f737071b474653fdfc609715ec8c6692","modified":1590134446777},{"_id":"public/image/jvm/GC/GC_07.jpg","hash":"cec9a5ef1ae4c0dac292e8dbe1892b4a77389f54","modified":1590134446778},{"_id":"public/image/jvm/GC/GC_09.jpg","hash":"51fa9cb8f737071b474653fdfc609715ec8c6692","modified":1590134446778},{"_id":"public/image/jvm/GC/GC_11.jpg","hash":"13cb4d1e217b65037bd73e48a8d9d6bb155ed892","modified":1590134446778},{"_id":"public/image/jvm/GC/GC_10.jpg","hash":"e10b34d12340d98529a33f787923355a316fabbd","modified":1590134446778},{"_id":"public/image/jvm/GC/GC_12.jpg","hash":"0afbb21825dbabd67eb4e2899898afbbc8ebe226","modified":1590134446778},{"_id":"public/image/jvm/GC/GC_14.jpg","hash":"dc622c024b7fe89e285912d329e430016fb10491","modified":1590134446778},{"_id":"public/image/jvm/GC/GC_13.jpg","hash":"5271b7f65e4674f7b29035e411e07e6c5d2f8cd0","modified":1590134446778},{"_id":"public/image/jvm/JDK自带工具/11.png","hash":"e9ff7b13f8220a9975a6ef7a5ceac453ab97e352","modified":1590134446778},{"_id":"public/image/jvm/JDK自带工具/10.png","hash":"70fd183a8f70ef25b0d5ac3d72ed7aa471461423","modified":1590134446779},{"_id":"public/image/jvm/JDK自带工具/15.png","hash":"9db5ec681d44be07b558c2243bacb603a60ac82e","modified":1590134446779},{"_id":"public/image/jvm/JDK自带工具/12.png","hash":"5dac6c3f492cc13bed3bb6fb922922f3f9f2bfeb","modified":1590134446784},{"_id":"public/image/jvm/JDK自带工具/16.png","hash":"8fec11e572ad0c208bca7e837a515fbbb989555c","modified":1590134446784},{"_id":"public/image/jvm/JDK自带工具/19.png","hash":"c1e79e8d80547bf2f2eacc357da2665b8a8d20ae","modified":1590134446785},{"_id":"public/image/jvm/JDK自带工具/3.png","hash":"54ead790a520b3274d492f74b4e8a7ccf5fcd987","modified":1590134446785},{"_id":"public/image/jvm/JDK自带工具/5.png","hash":"73756814c0f04b8e6f7fba8af7e0c91bfa74e4d4","modified":1590134446785},{"_id":"public/image/jvm/JDK自带工具/7.png","hash":"0527550487488e03dd09b3c0a7b58e2311d2b7c0","modified":1590134446785},{"_id":"public/image/jvm/JDK自带工具/6.png","hash":"5c47f5344dbd8302bb92d903b4f0337cf8cf042a","modified":1590134446785},{"_id":"public/image/jvm/JDK自带工具/8.png","hash":"d19496cc5605bd61b16d29f04211227bf557e05c","modified":1590134446785},{"_id":"public/image/jvm/JDK自带工具/9.png","hash":"7c94ea854905eeef926f8b4ab58ba9900c780756","modified":1590134446785},{"_id":"public/image/jvm/JDK自带工具/4.png","hash":"c4446d0c55ad712f80d419cf8622b0f20a983fb4","modified":1590134446785},{"_id":"public/image/jvm/JDK自带工具/2.png","hash":"84811d8b1f8a23bdff290cc907b7e945b8213fb5","modified":1590134446785},{"_id":"public/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1590134446786},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1590134446786},{"_id":"public/image/jvm/GC/GC_02.jpg","hash":"252e1800e3e7df95c1f5327a8f3705320eef7068","modified":1590134446786},{"_id":"public/image/jvm/GC/GC_03.jpg","hash":"259ca90a25f0479ca10685472443d4ea881f6d54","modified":1590134446786},{"_id":"public/image/jvm/GC/GC_06.jpg","hash":"7ae98d3184515e11dc0e3739c088128aceb8fc5e","modified":1590134446786},{"_id":"public/image/jvm/GC/GC_04.jpg","hash":"0dd0abd3ed27c44c0474fa14a371a825610dac95","modified":1590134446786},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1590134446787},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1590134446787},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1590134446787},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1590134446787},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1590134446787},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1590134446787},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1590134446787},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1590134446787},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1590134446787},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1590134446787},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1590134446787},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1590134446788},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1590134446788},{"_id":"public/live2dw/assets/koharu.model.json","hash":"ceccdefd776b7c9475a29cff0842796e4f58b7e9","modified":1590134448921},{"_id":"public/live2dw/assets/koharu.physics.json","hash":"2fbf886979212357ba293bd35884f2cb5b26b6a6","modified":1590134448921},{"_id":"public/live2dw/assets/mtn/01.mtn","hash":"61d7d590d9feb71b32fd6bd142b59410d75bc1fa","modified":1590134448923},{"_id":"public/live2dw/assets/mtn/03.mtn","hash":"a72b697a92a7cff40d15774b143b465b34cee5e6","modified":1590134448923},{"_id":"public/live2dw/assets/mtn/04.mtn","hash":"32c888667455a3ff6f1b04f910c1a5cc4de30af0","modified":1590134448923},{"_id":"public/live2dw/assets/mtn/05.mtn","hash":"637e00442da4042cd4b0ed2cc62ffb1559881814","modified":1590134448923},{"_id":"public/live2dw/assets/mtn/07.mtn","hash":"d8c9410135c81604eba665b59808089808e0851a","modified":1590134448923},{"_id":"public/live2dw/assets/mtn/06.mtn","hash":"df10cc1d333c96da1296a4853c1ddbd44d8a11f3","modified":1590134448924},{"_id":"public/live2dw/assets/mtn/02.mtn","hash":"efc99efdff39c93372cff0f6d62c4e748e1a5593","modified":1590134448924},{"_id":"public/live2dw/assets/mtn/idle.mtn","hash":"058d4628ab04bf42c279501ba4fa37116d384e41","modified":1590134448924},{"_id":"public/image/snowflake.png","hash":"1591b3be2074040b1bb52515e36724695359db48","modified":1590134448924},{"_id":"public/image/F5_ISH_WAS.png","hash":"7824635a6200e4508c13614509c83f67f8e418d8","modified":1590134448924},{"_id":"public/image/parallelStream_01.png","hash":"711c09f534b932c435e23c6741b0bb5252c949b8","modified":1590134448924},{"_id":"public/image/JVM内存模型01.png","hash":"031731ca514cd5e7f1d82542334d973af9f6b3f2","modified":1590134448924},{"_id":"public/image/performance_optimization_02.jpg","hash":"be2b6262818bc1a6648639dffe78ce462738db9f","modified":1590134448924},{"_id":"public/image/performance_optimization_01.jpeg","hash":"f9c3c12ab74f2e1403080efda8c5fb5933676a91","modified":1590134448924},{"_id":"public/image/JVM内存模型02.png","hash":"bf03d26339f5965963476c6c08b5daf674d283ed","modified":1590134448924},{"_id":"public/image/ElasticSearch/elasticsearch01.jpg","hash":"24ac6a944e50e03bd021afacf49f6cd63ff88450","modified":1590134448924},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1590134448925},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1590134448925},{"_id":"public/images/new_favicon_source_02_180x180.jpg","hash":"5473f097e8f00bf613c261d47acfdf3c644533ea","modified":1590134448925},{"_id":"public/image/ElasticSearch/elastic_stack01.jpg.jpg","hash":"6638d06bfe1f5b7f50ad855064a2d1168e648ff6","modified":1590134448925},{"_id":"public/image/IO/IO模型01.png","hash":"583c12dc702d3d39f9eaa7dbfc2c3ca3aa82ae47","modified":1590134448925},{"_id":"public/image/loadbalancing/DNS.png","hash":"9c4690ed18ee0d68f18323c7fb52e6a2c1e56bfc","modified":1590134448925},{"_id":"public/image/loadbalancing/IP.png","hash":"b40e4c7e4d44d90300c9a436e76ba0c8e7f96ffa","modified":1590134448925},{"_id":"public/image/loadbalancing/F5_ISH_WAS.png","hash":"7824635a6200e4508c13614509c83f67f8e418d8","modified":1590134448925},{"_id":"public/image/loadbalancing/LVS.png","hash":"8938245784788e780d2f3d6d297cbef3cfcf0562","modified":1590134448925},{"_id":"public/image/mysql/btree.png","hash":"21956a89ec21bf63cb1809143b637729b54f07dd","modified":1590134448925},{"_id":"public/image/mysql/b+tree.png","hash":"56218025c67b7f0575e1e534d7a79ff6db5e343b","modified":1590134448925},{"_id":"public/image/mysql/mysql_index.png","hash":"41d377228d34dd990da08ffaea6d7a1f319ef580","modified":1590134448925},{"_id":"public/image/mysql/mysql_myISAM.png","hash":"12c121ea998f0f7df2f25f2a0dbeefced2d33711","modified":1590134448925},{"_id":"public/image/jvm/JDK自带工具/14.png","hash":"f028305deedb7aa79dbad871d86dff6fa4c1e92e","modified":1590134448926},{"_id":"public/image/jvm/JDK自带工具/1.png","hash":"cc35f00f73d2215f3b61828783ba20b2fda0ab9a","modified":1590134448926},{"_id":"public/image/jvm/JDK自带工具/17.png","hash":"3851771022408820f280df12a6eea93593115ac1","modified":1590134448926},{"_id":"public/image/jvm/JDK自带工具/18.png","hash":"2f7db8f0bf1a16ac71ba7430f7f4cdf9e57cf74b","modified":1590134448926},{"_id":"public/image/jvm/JDK自带工具/13.png","hash":"1c775569352a16e99154aada40467994487556d7","modified":1590134448926},{"_id":"public/images/reward/alipay_reward.jpg","hash":"f1bb3c47e49dd912ffaa97cde916b39a25b6c199","modified":1590134448926},{"_id":"public/images/reward/wechatpay_reward.jpg","hash":"12f6630ecb07d878ab216e6a6b61041ee63f260e","modified":1590134448926},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1590134448926},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1590134448926},{"_id":"public/live2dw/assets/mtn/09.mtn","hash":"ecf1283b72e1c4b7e3a97343cd97726813f18790","modified":1590134448926},{"_id":"public/live2dw/assets/mtn/08.mtn","hash":"9b95ef8548b979d1fca557c74f8d66fb15b34578","modified":1590134448927},{"_id":"public/live2dw/lib/L2Dwidget.min.js","hash":"5f1a807437cc723bcadc3791d37add5ceed566a2","modified":1590134448927},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1590134448942},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1590134448942},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1590134448942},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1590134448943},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1590134448943},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1590134448943},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1590134448943},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1590134448943},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1590134448943},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1590134448943},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1590134448943},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1590134448943},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1590134448943},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1590134448943},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1590134448943},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1590134448943},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1590134448943},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1590134448944},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1590134448944},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1590134448944},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1590134448944},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1590134448944},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1590134448944},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1590134448944},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1590134448944},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1590134448944},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1590134448944},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1590134448944},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1590134448944},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1590134448944},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1590134448944},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1590134448944},{"_id":"public/css/main.css","hash":"79c144e129edf7c2f614a628cddbf47d7edcf45d","modified":1590134448944},{"_id":"public/image/cglib_callback.png","hash":"60cec8f262884a716ae070b08113e23e1aa0be8c","modified":1590134448944},{"_id":"public/image/DevOps/docker_02.png","hash":"fed79dae1f6d4ab915f0c5c44babbdcdb24aca12","modified":1590134448944},{"_id":"public/image/volatile.png","hash":"4f1fae3fdeb807a6030b0b62b9742abc0c5baaa1","modified":1590134448944},{"_id":"public/image/ElasticSearch/elasticsearch03.png","hash":"c46376bf637361cb14523d096b764a24cc80047d","modified":1590134448944},{"_id":"public/image/jvm/profile_02.png","hash":"c75703a59138e8d3fa4b7ea61a14e6d5cc1f4c95","modified":1590134448945},{"_id":"public/image/mysql/mysql_InnoDB.png","hash":"5585358b025e5782c656dc8bea4997d3a3b679f7","modified":1590134448945},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1590134448945},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1590134448945},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1590134448945},{"_id":"public/live2dw/lib/L2Dwidget.min.js.map","hash":"3290fe2df45f065b51a1cd7b24ec325cbf9bb5ce","modified":1590134448945},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1590134448956},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1590134448956},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1590134448956},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1590134448956},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1590134448956},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1590134448956},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1590134448956},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1590134448956},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js","hash":"35bb5b588b6de25c9be2dd51d3fd331feafac02d","modified":1590134448956},{"_id":"public/lib/gitalk/gitalk.css","hash":"99f6725b386bdb0f52d15b0dd7877eaf1ad4c918","modified":1590134448964},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1590134448964},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1590134448965},{"_id":"public/image/jvm/profile_03.png","hash":"86bb4d445d1796455cc128d11f4694cab3eeacac","modified":1590134448965},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1590134448970},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1590134448970},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1590134448972},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1590134448972},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1590134448972},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1590134448972},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1590134448972},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1590134448972},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1590134448972},{"_id":"public/image/ElasticSearch/elasticsearch04.png","hash":"480c3dc1725d3e2e510dfdc875c3023928dd2b92","modified":1590134448996},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1590134449000},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1590134449000},{"_id":"public/live2dw/assets/moc/koharu.moc","hash":"5eec3fba21444dd6f774b913510b5955e2c0605b","modified":1590134449027},{"_id":"public/images/new_favicon_source_02.jpg","hash":"02bf3653b9b95c71ec9958239396f5fe8b29b4d5","modified":1590134449027},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1590134449031},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1590134449031},{"_id":"public/live2dw/assets/moc/koharu.2048/texture_00.png","hash":"0879b61b745084781722636bba9f278f31ce5fc1","modified":1590134449031},{"_id":"public/image/jvm/profile_01.png","hash":"17942c86b54260d8b5c371fbd2ce8b5884304465","modified":1590134449336},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1590134449338},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1590134449575},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1590134449575},{"_id":"public/image/springboot/springboot_01.png","hash":"fdaae0ba0585f7efcffd88b9a640c3fd31d088c1","modified":1590134450009},{"_id":"public/image/jvm/JVM_栈.png","hash":"6779b3f4671ca431523246fce9c4ca85ab2fbfe1","modified":1590134450009},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js.map","hash":"35e71cc2a130199efb167b9a06939576602f0d75","modified":1590134450054},{"_id":"public/lib/gitalk/gitalk.min.js","hash":"266500948447c95aeea95ef6760f192afc96fd5e","modified":1590134450078},{"_id":"public/image/jvm/执行引擎.png","hash":"d67defa5f80a72a064778ddbd1bf1da86222de61","modified":1590134450078},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1590134450084},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1590134450101},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1590134450128}],"Category":[{"name":"Java","_id":"ckahwzkzb0005qotnw51e4mbi"},{"name":"DevOps","_id":"ckahwzkzx000mqotnej2e74ci"},{"name":"Elastic Stack","_id":"ckahwzl0p001oqotnso8ckjg7"},{"name":"其他","_id":"ckahwzl13002bqotnixpj37jw"},{"name":"Linux","_id":"ckahwzl1a002pqotn5kxusich"},{"name":"中间件","_id":"ckahwzl1e002xqotnkcpsezqu"},{"name":"分布式","_id":"ckahwzl1k0039qotnahrla5wb"},{"name":"数据库","_id":"ckahwzl1m003eqotnomd8bcoi"},{"name":"前端","_id":"ckahwzl1o003iqotn0a54tmgc"},{"name":"设计模式","_id":"ckahwzl43004qqotnq9imgw1c"}],"Data":[],"Page":[{"_content":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\">\n</head>\n<body>\n  <script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\"\n          charset=\"utf-8\" homePageUrl=\"/\"\n          homePageName=\"回到我的主页\">\n  </script>\n  <script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"></script>\n  <script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"></script>\n</body>\n</html>","source":"404.html","raw":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\">\n</head>\n<body>\n  <script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\"\n          charset=\"utf-8\" homePageUrl=\"/\"\n          homePageName=\"回到我的主页\">\n  </script>\n  <script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"></script>\n  <script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"></script>\n</body>\n</html>","date":"2019-08-26T07:18:46.639Z","updated":"2019-08-26T07:18:46.639Z","path":"404.html","title":"","comments":1,"layout":"page","_id":"ckahwzkgd0000qotn2uz6x8d7","content":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n  <meta name=\"robots\" content=\"all\">\n  <meta name=\"robots\" content=\"index,follow\">\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\">\n</head>\n<body>\n  <script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homepageurl=\"/\" homepagename=\"回到我的主页\">\n  </script>\n  <script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"></script>\n  <script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"></script>\n<script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script><script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/koharu.model.json\"},\"mobile\":{\"show\":true,\"scale\":0.5},\"log\":false});</script></body>\n</html>","site":{"data":{}},"excerpt":"","more":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\">\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n  <meta name=\"robots\" content=\"all\">\n  <meta name=\"robots\" content=\"index,follow\">\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://qzone.qq.com/gy/404/style/404style.css\">\n</head>\n<body>\n  <script type=\"text/plain\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homepageurl=\"/\" homepagename=\"回到我的主页\">\n  </script>\n  <script src=\"https://qzone.qq.com/gy/404/data.js\" charset=\"utf-8\"></script>\n  <script src=\"https://qzone.qq.com/gy/404/page.js\" charset=\"utf-8\"></script>\n<script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script><script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/koharu.model.json\"},\"mobile\":{\"show\":true,\"scale\":0.5},\"log\":false});</script></body>\n</html>"},{"title":"分类","date":"2018-09-05T01:01:35.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2018-09-05 09:01:35\ntype: \"categories\"\n---\n","updated":"2019-08-26T07:59:09.070Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ckahwzkz60002qotntfhfwy29","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"关于我","date":"2019-08-26T01:00:00.000Z","type":"about","_content":"\n> *** 欢迎造访个人小站，本站仅记录和分享个人学习过程。 ***\n\n96后，热爱优秀的电子游戏、科幻电影、小说，喜欢动漫、插画、古典乐，偶尔玩玩雕像手办。\n\n2016年开始从事软件编程工作，主要从事JAVA后端开发。精简主义，有一丢丢极客精神，追求简洁高效的代码\n\n个人WeChat，欢迎沟通交流。\n\n![WeChat_QRcode](/image/QRcode/wechat_qrcode.jpg)\n\n另外，现在文末增加了**打赏（恰饭）**功能，欢迎并感谢社会各界好心人士对本中下贫码农投食。\n\n> Speak Thy Desire","source":"about/index.md","raw":"---\ntitle: 关于我\ndate: 2019-08-26 09:00:00\ntype: \"about\"\n---\n\n> *** 欢迎造访个人小站，本站仅记录和分享个人学习过程。 ***\n\n96后，热爱优秀的电子游戏、科幻电影、小说，喜欢动漫、插画、古典乐，偶尔玩玩雕像手办。\n\n2016年开始从事软件编程工作，主要从事JAVA后端开发。精简主义，有一丢丢极客精神，追求简洁高效的代码\n\n个人WeChat，欢迎沟通交流。\n\n![WeChat_QRcode](/image/QRcode/wechat_qrcode.jpg)\n\n另外，现在文末增加了**打赏（恰饭）**功能，欢迎并感谢社会各界好心人士对本中下贫码农投食。\n\n> Speak Thy Desire","updated":"2020-05-08T09:57:29.891Z","path":"about/index.html","comments":1,"layout":"page","_id":"ckahwzkz90004qotnogr86mzl","content":"<blockquote>\n<p><strong><em> 欢迎造访个人小站，本站仅记录和分享个人学习过程。 </em></strong></p>\n</blockquote>\n<p>96后，热爱优秀的电子游戏、科幻电影、小说，喜欢动漫、插画、古典乐，偶尔玩玩雕像手办。</p>\n<p>2016年开始从事软件编程工作，主要从事JAVA后端开发。精简主义，有一丢丢极客精神，追求简洁高效的代码</p>\n<p>个人WeChat，欢迎沟通交流。</p>\n<p><img src=\"/image/QRcode/wechat_qrcode.jpg\" alt=\"WeChat_QRcode\"></p>\n<p>另外，现在文末增加了<strong>打赏（恰饭）</strong>功能，欢迎并感谢社会各界好心人士对本中下贫码农投食。</p>\n<blockquote>\n<p>Speak Thy Desire</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p><strong><em> 欢迎造访个人小站，本站仅记录和分享个人学习过程。 </em></strong></p>\n</blockquote>\n<p>96后，热爱优秀的电子游戏、科幻电影、小说，喜欢动漫、插画、古典乐，偶尔玩玩雕像手办。</p>\n<p>2016年开始从事软件编程工作，主要从事JAVA后端开发。精简主义，有一丢丢极客精神，追求简洁高效的代码</p>\n<p>个人WeChat，欢迎沟通交流。</p>\n<p><img src=\"/image/QRcode/wechat_qrcode.jpg\" alt=\"WeChat_QRcode\"></p>\n<p>另外，现在文末增加了<strong>打赏（恰饭）</strong>功能，欢迎并感谢社会各界好心人士对本中下贫码农投食。</p>\n<blockquote>\n<p>Speak Thy Desire</p>\n</blockquote>\n"},{"title":"标签","date":"2019-08-26T01:00:00.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2019-08-26 09:00:00\ntype: \"tags\"\n---","updated":"2019-08-26T08:00:41.812Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ckahwzkzf0008qotn050jteso","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"GC调优参数","date":"2020-05-03T02:00:00.000Z","_content":"\n记录下学习GC的各个收集器对应的相关调优参数\n\n<!-- more -->\n# 调优的两个指标\n- 停顿时间: 垃圾收集器做垃圾回收中断应用执行的时间。-XX:MaxGCPauseMillis\n- 吞吐量: 花在垃圾收集的时间和花在应用时间的占比 -XX:GCTimeRatio=<n>,垃圾收集时间占比：1/(1+n)\n\n# GC调优步骤\n打印GC日志\n```\n-XX:+PrintGCDetails  -XX:+PrintGCTimeStamps  -XX:+PrintGCDateStamps  -Xloggc:./gc.log\n```\n- 分析日志得到关键性指标\n- 分析GC原因，调优JVM参数\n## 可视化分析\n### GCeasy \n一个可以对GC日志进行可视化分析的网站\n\nhttps://www.gceasy.io/\n\n### GCViewer \n\n# Parallel Scavenge收集器(默认)\n设置了该收集器后，年轻代默认为Parallel Scavenge，老年代则为Parallel Old\n\n分析parallel-gc.log\n- 第一次调优，设置Metaspace大小：增大元空间大小-XX:MetaspaceSize=64M  -XX:MaxMetaspaceSize=64M\n- 第二次调优，添加吞吐量和停顿时间参数：-XX:MaxGCPauseMillis=100   -XX:GCTimeRatio=99\n- 第三次调优，修改动态扩容增量：-XX:YoungGenerationSizeIncrement=30\n\n# 配置CMS收集器\n设置了老年代收集器为CMS后，年轻代默认为ParNew收集器\n```\n-XX:+UseConcMarkSweepGC\n```\n\n分析cms-gc.log\n\n# 配置G1收集器\n```\n-XX:+UseG1GC\n```\n分析g1-gc.log \n查看发生MixedGC的阈值：jinfo -flag InitiatingHeapOccupancyPercent 进程id\n\n分析工具：gceasy，GCViewer \n\n## G1调优常用参数\n- -XX:+UseG1GC 开启G1\n- -XX:G1HeapRegionSize=n,region的大小，1-32M，2048个\n- -XX:MaxGCPauseMillis=200 最大停顿时间\n- -XX:G1NewSizePercent   -XX:G1MaxNewSizePercent\n- -XX:G1ReservePercent=10 保留防止to space溢出（）\n- -XX:ParallelGCThreads=n SWT线程数（停止应用程序）\n- -XX:ConcGCThreads=n 并发线程数=1/4*并行\n\n# 总结\n- 年轻代大小：避免使用-Xmn、-XX:NewRatio等显示设置Young区大小，会覆盖暂停时间目标（常用参数3）\n- 暂停时间目标：暂停时间不要太严苛，其吞吐量目标是90%的应用程序时间和10%的垃圾回收时间，太严苛会直接影响到吞吐量\n\n## 是否需要切换到G1\n- 50%以上的堆被存活对象占用\n- 对象分配和晋升的速度变化非常大\n- 垃圾回收时间特别长，超过1秒\n\n## G1调优目标\n- 6GB以上内存\n- 停顿时间是500ms以内\n- 吞吐量是90%以上\n\n# GC常用参数汇总\n## 堆栈设置\n- -Xss:每个线程的栈大小\n- -Xms:初始堆大小，默认物理内存的1/64\n- -Xmx:最大堆大小，默认物理内存的1/4\n- -Xmn:新生代大小\n- -XX:NewSize:设置新生代初始大小\n- -XX:NewRatio:默认2表示新生代占年老代的1/2，占整个堆内存的1/3。\n- -XX:SurvivorRatio:默认8表示一个survivor区占用1/8的Eden内存，即1/10的新生代内存。\n- -XX:MetaspaceSize:设置元空间大小\n- -XX:MaxMetaspaceSize:设置元空间最大允许大小，默认不受限制，JVM Metaspace会进行动态扩展。\n## 垃圾回收统计信息\n- -XX:+PrintGC\n- -XX:+PrintGCDetails\n- -XX:+PrintGCTimeStamps \n- -Xloggc:filename\n## 收集器设置\n- -XX:+UseSerialGC:设置串行收集器\n- -XX:+UseParallelGC:设置并行收集器\n- -XX:+UseParallelOldGC:老年代使用并行回收收集器\n- -XX:+UseParNewGC:在新生代使用并行收集器\n- -XX:+UseParalledlOldGC:设置并行老年代收集器\n- -XX:+UseConcMarkSweepGC:设置CMS并发收集器\n- -XX:+UseG1GC:设置G1收集器\n- -XX:ParallelGCThreads:设置用于垃圾回收的线程数\n## 并行收集器设置\n- -XX:ParallelGCThreads:设置并行收集器收集时使用的CPU数。并行收集线程数。\n- -XX:MaxGCPauseMillis:设置并行收集最大暂停时间\n- -XX:GCTimeRatio:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)\n## CMS收集器设置\n- -XX:+UseConcMarkSweepGC:设置CMS并发收集器\n- -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。\n- -XX:ParallelGCThreads:设置并发收集器新生代收集方式为并行收集时，使用的CPU数。并行收集线程数。\n- -XX:CMSFullGCsBeforeCompaction:设定进行多少次CMS垃圾回收后，进行一次内存压缩\n- -XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收\n- -XX:UseCMSInitiatingOccupancyOnly:表示只在到达阀值的时候，才进行CMS回收\n- -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况\n- -XX:ParallelCMSThreads:设定CMS的线程数量\n- -XX:CMSInitiatingOccupancyFraction:设置CMS收集器在老年代空间被使用多少后触发\n- -XX:+UseCMSCompactAtFullCollection:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片的整理\t\n## G1收集器设置 \n- -XX:+UseG1GC:使用G1收集器\n- -XX:ParallelGCThreads:指定GC工作的线程数量\n- -XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区\n- -XX:GCTimeRatio:吞吐量大小，0-100的整数(默认9)，值为n则系统将花费不超过1/(1+n)的时间用于垃圾收集\n- -XX:MaxGCPauseMillis:目标暂停时间(默认200ms)\n- -XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%)\n- -XX:G1MaxNewSizePercent:新生代内存最大空间\n- -XX:TargetSurvivorRatio:Survivor填充容量(默认50%)\n- -XX:MaxTenuringThreshold:最大任期阈值(默认15)\n- -XX:InitiatingHeapOccupancyPercen:老年代占用空间超过整堆比IHOP阈值(默认45%),超过则执行混合收集\n- -XX:G1HeapWastePercent:堆废物百分比(默认5%)\n- -XX:G1MixedGCCountTarget:参数混合周期的最大总次数(默认8)","source":"_posts/GC调优参数.md","raw":"---\ntitle: GC调优参数\ndate: 2020-05-03 10:00:00\ntags: JVM\ncategories: Java\n---\n\n记录下学习GC的各个收集器对应的相关调优参数\n\n<!-- more -->\n# 调优的两个指标\n- 停顿时间: 垃圾收集器做垃圾回收中断应用执行的时间。-XX:MaxGCPauseMillis\n- 吞吐量: 花在垃圾收集的时间和花在应用时间的占比 -XX:GCTimeRatio=<n>,垃圾收集时间占比：1/(1+n)\n\n# GC调优步骤\n打印GC日志\n```\n-XX:+PrintGCDetails  -XX:+PrintGCTimeStamps  -XX:+PrintGCDateStamps  -Xloggc:./gc.log\n```\n- 分析日志得到关键性指标\n- 分析GC原因，调优JVM参数\n## 可视化分析\n### GCeasy \n一个可以对GC日志进行可视化分析的网站\n\nhttps://www.gceasy.io/\n\n### GCViewer \n\n# Parallel Scavenge收集器(默认)\n设置了该收集器后，年轻代默认为Parallel Scavenge，老年代则为Parallel Old\n\n分析parallel-gc.log\n- 第一次调优，设置Metaspace大小：增大元空间大小-XX:MetaspaceSize=64M  -XX:MaxMetaspaceSize=64M\n- 第二次调优，添加吞吐量和停顿时间参数：-XX:MaxGCPauseMillis=100   -XX:GCTimeRatio=99\n- 第三次调优，修改动态扩容增量：-XX:YoungGenerationSizeIncrement=30\n\n# 配置CMS收集器\n设置了老年代收集器为CMS后，年轻代默认为ParNew收集器\n```\n-XX:+UseConcMarkSweepGC\n```\n\n分析cms-gc.log\n\n# 配置G1收集器\n```\n-XX:+UseG1GC\n```\n分析g1-gc.log \n查看发生MixedGC的阈值：jinfo -flag InitiatingHeapOccupancyPercent 进程id\n\n分析工具：gceasy，GCViewer \n\n## G1调优常用参数\n- -XX:+UseG1GC 开启G1\n- -XX:G1HeapRegionSize=n,region的大小，1-32M，2048个\n- -XX:MaxGCPauseMillis=200 最大停顿时间\n- -XX:G1NewSizePercent   -XX:G1MaxNewSizePercent\n- -XX:G1ReservePercent=10 保留防止to space溢出（）\n- -XX:ParallelGCThreads=n SWT线程数（停止应用程序）\n- -XX:ConcGCThreads=n 并发线程数=1/4*并行\n\n# 总结\n- 年轻代大小：避免使用-Xmn、-XX:NewRatio等显示设置Young区大小，会覆盖暂停时间目标（常用参数3）\n- 暂停时间目标：暂停时间不要太严苛，其吞吐量目标是90%的应用程序时间和10%的垃圾回收时间，太严苛会直接影响到吞吐量\n\n## 是否需要切换到G1\n- 50%以上的堆被存活对象占用\n- 对象分配和晋升的速度变化非常大\n- 垃圾回收时间特别长，超过1秒\n\n## G1调优目标\n- 6GB以上内存\n- 停顿时间是500ms以内\n- 吞吐量是90%以上\n\n# GC常用参数汇总\n## 堆栈设置\n- -Xss:每个线程的栈大小\n- -Xms:初始堆大小，默认物理内存的1/64\n- -Xmx:最大堆大小，默认物理内存的1/4\n- -Xmn:新生代大小\n- -XX:NewSize:设置新生代初始大小\n- -XX:NewRatio:默认2表示新生代占年老代的1/2，占整个堆内存的1/3。\n- -XX:SurvivorRatio:默认8表示一个survivor区占用1/8的Eden内存，即1/10的新生代内存。\n- -XX:MetaspaceSize:设置元空间大小\n- -XX:MaxMetaspaceSize:设置元空间最大允许大小，默认不受限制，JVM Metaspace会进行动态扩展。\n## 垃圾回收统计信息\n- -XX:+PrintGC\n- -XX:+PrintGCDetails\n- -XX:+PrintGCTimeStamps \n- -Xloggc:filename\n## 收集器设置\n- -XX:+UseSerialGC:设置串行收集器\n- -XX:+UseParallelGC:设置并行收集器\n- -XX:+UseParallelOldGC:老年代使用并行回收收集器\n- -XX:+UseParNewGC:在新生代使用并行收集器\n- -XX:+UseParalledlOldGC:设置并行老年代收集器\n- -XX:+UseConcMarkSweepGC:设置CMS并发收集器\n- -XX:+UseG1GC:设置G1收集器\n- -XX:ParallelGCThreads:设置用于垃圾回收的线程数\n## 并行收集器设置\n- -XX:ParallelGCThreads:设置并行收集器收集时使用的CPU数。并行收集线程数。\n- -XX:MaxGCPauseMillis:设置并行收集最大暂停时间\n- -XX:GCTimeRatio:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)\n## CMS收集器设置\n- -XX:+UseConcMarkSweepGC:设置CMS并发收集器\n- -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。\n- -XX:ParallelGCThreads:设置并发收集器新生代收集方式为并行收集时，使用的CPU数。并行收集线程数。\n- -XX:CMSFullGCsBeforeCompaction:设定进行多少次CMS垃圾回收后，进行一次内存压缩\n- -XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收\n- -XX:UseCMSInitiatingOccupancyOnly:表示只在到达阀值的时候，才进行CMS回收\n- -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况\n- -XX:ParallelCMSThreads:设定CMS的线程数量\n- -XX:CMSInitiatingOccupancyFraction:设置CMS收集器在老年代空间被使用多少后触发\n- -XX:+UseCMSCompactAtFullCollection:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片的整理\t\n## G1收集器设置 \n- -XX:+UseG1GC:使用G1收集器\n- -XX:ParallelGCThreads:指定GC工作的线程数量\n- -XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区\n- -XX:GCTimeRatio:吞吐量大小，0-100的整数(默认9)，值为n则系统将花费不超过1/(1+n)的时间用于垃圾收集\n- -XX:MaxGCPauseMillis:目标暂停时间(默认200ms)\n- -XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%)\n- -XX:G1MaxNewSizePercent:新生代内存最大空间\n- -XX:TargetSurvivorRatio:Survivor填充容量(默认50%)\n- -XX:MaxTenuringThreshold:最大任期阈值(默认15)\n- -XX:InitiatingHeapOccupancyPercen:老年代占用空间超过整堆比IHOP阈值(默认45%),超过则执行混合收集\n- -XX:G1HeapWastePercent:堆废物百分比(默认5%)\n- -XX:G1MixedGCCountTarget:参数混合周期的最大总次数(默认8)","slug":"GC调优参数","published":1,"updated":"2020-05-22T07:59:10.528Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkz10001qotnts9d2c8p","content":"<p>记录下学习GC的各个收集器对应的相关调优参数</p>\n<a id=\"more\"></a>\n<h1 id=\"调优的两个指标\"><a href=\"#调优的两个指标\" class=\"headerlink\" title=\"调优的两个指标\"></a>调优的两个指标</h1><ul>\n<li>停顿时间: 垃圾收集器做垃圾回收中断应用执行的时间。-XX:MaxGCPauseMillis</li>\n<li>吞吐量: 花在垃圾收集的时间和花在应用时间的占比 -XX:GCTimeRatio=<n>,垃圾收集时间占比：1/(1+n)</n></li>\n</ul>\n<h1 id=\"GC调优步骤\"><a href=\"#GC调优步骤\" class=\"headerlink\" title=\"GC调优步骤\"></a>GC调优步骤</h1><p>打印GC日志<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-XX:+PrintGCDetails  -XX:+PrintGCTimeStamps  -XX:+PrintGCDateStamps  -Xloggc:./gc.log</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>分析日志得到关键性指标</li>\n<li>分析GC原因，调优JVM参数<h2 id=\"可视化分析\"><a href=\"#可视化分析\" class=\"headerlink\" title=\"可视化分析\"></a>可视化分析</h2><h3 id=\"GCeasy\"><a href=\"#GCeasy\" class=\"headerlink\" title=\"GCeasy\"></a>GCeasy</h3>一个可以对GC日志进行可视化分析的网站</li>\n</ul>\n<p><a href=\"https://www.gceasy.io/\" target=\"_blank\" rel=\"noopener\">https://www.gceasy.io/</a></p>\n<h3 id=\"GCViewer\"><a href=\"#GCViewer\" class=\"headerlink\" title=\"GCViewer\"></a>GCViewer</h3><h1 id=\"Parallel-Scavenge收集器-默认\"><a href=\"#Parallel-Scavenge收集器-默认\" class=\"headerlink\" title=\"Parallel Scavenge收集器(默认)\"></a>Parallel Scavenge收集器(默认)</h1><p>设置了该收集器后，年轻代默认为Parallel Scavenge，老年代则为Parallel Old</p>\n<p>分析parallel-gc.log</p>\n<ul>\n<li>第一次调优，设置Metaspace大小：增大元空间大小-XX:MetaspaceSize=64M  -XX:MaxMetaspaceSize=64M</li>\n<li>第二次调优，添加吞吐量和停顿时间参数：-XX:MaxGCPauseMillis=100   -XX:GCTimeRatio=99</li>\n<li>第三次调优，修改动态扩容增量：-XX:YoungGenerationSizeIncrement=30</li>\n</ul>\n<h1 id=\"配置CMS收集器\"><a href=\"#配置CMS收集器\" class=\"headerlink\" title=\"配置CMS收集器\"></a>配置CMS收集器</h1><p>设置了老年代收集器为CMS后，年轻代默认为ParNew收集器<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-XX:+UseConcMarkSweepGC</span><br></pre></td></tr></table></figure></p>\n<p>分析cms-gc.log</p>\n<h1 id=\"配置G1收集器\"><a href=\"#配置G1收集器\" class=\"headerlink\" title=\"配置G1收集器\"></a>配置G1收集器</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-XX:+UseG1GC</span><br></pre></td></tr></table></figure>\n<p>分析g1-gc.log<br>查看发生MixedGC的阈值：jinfo -flag InitiatingHeapOccupancyPercent 进程id</p>\n<p>分析工具：gceasy，GCViewer </p>\n<h2 id=\"G1调优常用参数\"><a href=\"#G1调优常用参数\" class=\"headerlink\" title=\"G1调优常用参数\"></a>G1调优常用参数</h2><ul>\n<li>-XX:+UseG1GC 开启G1</li>\n<li>-XX:G1HeapRegionSize=n,region的大小，1-32M，2048个</li>\n<li>-XX:MaxGCPauseMillis=200 最大停顿时间</li>\n<li>-XX:G1NewSizePercent   -XX:G1MaxNewSizePercent</li>\n<li>-XX:G1ReservePercent=10 保留防止to space溢出（）</li>\n<li>-XX:ParallelGCThreads=n SWT线程数（停止应用程序）</li>\n<li>-XX:ConcGCThreads=n 并发线程数=1/4*并行</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>年轻代大小：避免使用-Xmn、-XX:NewRatio等显示设置Young区大小，会覆盖暂停时间目标（常用参数3）</li>\n<li>暂停时间目标：暂停时间不要太严苛，其吞吐量目标是90%的应用程序时间和10%的垃圾回收时间，太严苛会直接影响到吞吐量</li>\n</ul>\n<h2 id=\"是否需要切换到G1\"><a href=\"#是否需要切换到G1\" class=\"headerlink\" title=\"是否需要切换到G1\"></a>是否需要切换到G1</h2><ul>\n<li>50%以上的堆被存活对象占用</li>\n<li>对象分配和晋升的速度变化非常大</li>\n<li>垃圾回收时间特别长，超过1秒</li>\n</ul>\n<h2 id=\"G1调优目标\"><a href=\"#G1调优目标\" class=\"headerlink\" title=\"G1调优目标\"></a>G1调优目标</h2><ul>\n<li>6GB以上内存</li>\n<li>停顿时间是500ms以内</li>\n<li>吞吐量是90%以上</li>\n</ul>\n<h1 id=\"GC常用参数汇总\"><a href=\"#GC常用参数汇总\" class=\"headerlink\" title=\"GC常用参数汇总\"></a>GC常用参数汇总</h1><h2 id=\"堆栈设置\"><a href=\"#堆栈设置\" class=\"headerlink\" title=\"堆栈设置\"></a>堆栈设置</h2><ul>\n<li>-Xss:每个线程的栈大小</li>\n<li>-Xms:初始堆大小，默认物理内存的1/64</li>\n<li>-Xmx:最大堆大小，默认物理内存的1/4</li>\n<li>-Xmn:新生代大小</li>\n<li>-XX:NewSize:设置新生代初始大小</li>\n<li>-XX:NewRatio:默认2表示新生代占年老代的1/2，占整个堆内存的1/3。</li>\n<li>-XX:SurvivorRatio:默认8表示一个survivor区占用1/8的Eden内存，即1/10的新生代内存。</li>\n<li>-XX:MetaspaceSize:设置元空间大小</li>\n<li>-XX:MaxMetaspaceSize:设置元空间最大允许大小，默认不受限制，JVM Metaspace会进行动态扩展。<h2 id=\"垃圾回收统计信息\"><a href=\"#垃圾回收统计信息\" class=\"headerlink\" title=\"垃圾回收统计信息\"></a>垃圾回收统计信息</h2></li>\n<li>-XX:+PrintGC</li>\n<li>-XX:+PrintGCDetails</li>\n<li>-XX:+PrintGCTimeStamps </li>\n<li>-Xloggc:filename<h2 id=\"收集器设置\"><a href=\"#收集器设置\" class=\"headerlink\" title=\"收集器设置\"></a>收集器设置</h2></li>\n<li>-XX:+UseSerialGC:设置串行收集器</li>\n<li>-XX:+UseParallelGC:设置并行收集器</li>\n<li>-XX:+UseParallelOldGC:老年代使用并行回收收集器</li>\n<li>-XX:+UseParNewGC:在新生代使用并行收集器</li>\n<li>-XX:+UseParalledlOldGC:设置并行老年代收集器</li>\n<li>-XX:+UseConcMarkSweepGC:设置CMS并发收集器</li>\n<li>-XX:+UseG1GC:设置G1收集器</li>\n<li>-XX:ParallelGCThreads:设置用于垃圾回收的线程数<h2 id=\"并行收集器设置\"><a href=\"#并行收集器设置\" class=\"headerlink\" title=\"并行收集器设置\"></a>并行收集器设置</h2></li>\n<li>-XX:ParallelGCThreads:设置并行收集器收集时使用的CPU数。并行收集线程数。</li>\n<li>-XX:MaxGCPauseMillis:设置并行收集最大暂停时间</li>\n<li>-XX:GCTimeRatio:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)<h2 id=\"CMS收集器设置\"><a href=\"#CMS收集器设置\" class=\"headerlink\" title=\"CMS收集器设置\"></a>CMS收集器设置</h2></li>\n<li>-XX:+UseConcMarkSweepGC:设置CMS并发收集器</li>\n<li>-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。</li>\n<li>-XX:ParallelGCThreads:设置并发收集器新生代收集方式为并行收集时，使用的CPU数。并行收集线程数。</li>\n<li>-XX:CMSFullGCsBeforeCompaction:设定进行多少次CMS垃圾回收后，进行一次内存压缩</li>\n<li>-XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收</li>\n<li>-XX:UseCMSInitiatingOccupancyOnly:表示只在到达阀值的时候，才进行CMS回收</li>\n<li>-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况</li>\n<li>-XX:ParallelCMSThreads:设定CMS的线程数量</li>\n<li>-XX:CMSInitiatingOccupancyFraction:设置CMS收集器在老年代空间被使用多少后触发</li>\n<li>-XX:+UseCMSCompactAtFullCollection:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片的整理    <h2 id=\"G1收集器设置\"><a href=\"#G1收集器设置\" class=\"headerlink\" title=\"G1收集器设置\"></a>G1收集器设置</h2></li>\n<li>-XX:+UseG1GC:使用G1收集器</li>\n<li>-XX:ParallelGCThreads:指定GC工作的线程数量</li>\n<li>-XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区</li>\n<li>-XX:GCTimeRatio:吞吐量大小，0-100的整数(默认9)，值为n则系统将花费不超过1/(1+n)的时间用于垃圾收集</li>\n<li>-XX:MaxGCPauseMillis:目标暂停时间(默认200ms)</li>\n<li>-XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%)</li>\n<li>-XX:G1MaxNewSizePercent:新生代内存最大空间</li>\n<li>-XX:TargetSurvivorRatio:Survivor填充容量(默认50%)</li>\n<li>-XX:MaxTenuringThreshold:最大任期阈值(默认15)</li>\n<li>-XX:InitiatingHeapOccupancyPercen:老年代占用空间超过整堆比IHOP阈值(默认45%),超过则执行混合收集</li>\n<li>-XX:G1HeapWastePercent:堆废物百分比(默认5%)</li>\n<li>-XX:G1MixedGCCountTarget:参数混合周期的最大总次数(默认8)</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>记录下学习GC的各个收集器对应的相关调优参数</p>","more":"<h1 id=\"调优的两个指标\"><a href=\"#调优的两个指标\" class=\"headerlink\" title=\"调优的两个指标\"></a>调优的两个指标</h1><ul>\n<li>停顿时间: 垃圾收集器做垃圾回收中断应用执行的时间。-XX:MaxGCPauseMillis</li>\n<li>吞吐量: 花在垃圾收集的时间和花在应用时间的占比 -XX:GCTimeRatio=<n>,垃圾收集时间占比：1/(1+n)</n></li>\n</ul>\n<h1 id=\"GC调优步骤\"><a href=\"#GC调优步骤\" class=\"headerlink\" title=\"GC调优步骤\"></a>GC调优步骤</h1><p>打印GC日志<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-XX:+PrintGCDetails  -XX:+PrintGCTimeStamps  -XX:+PrintGCDateStamps  -Xloggc:./gc.log</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>分析日志得到关键性指标</li>\n<li>分析GC原因，调优JVM参数<h2 id=\"可视化分析\"><a href=\"#可视化分析\" class=\"headerlink\" title=\"可视化分析\"></a>可视化分析</h2><h3 id=\"GCeasy\"><a href=\"#GCeasy\" class=\"headerlink\" title=\"GCeasy\"></a>GCeasy</h3>一个可以对GC日志进行可视化分析的网站</li>\n</ul>\n<p><a href=\"https://www.gceasy.io/\" target=\"_blank\" rel=\"noopener\">https://www.gceasy.io/</a></p>\n<h3 id=\"GCViewer\"><a href=\"#GCViewer\" class=\"headerlink\" title=\"GCViewer\"></a>GCViewer</h3><h1 id=\"Parallel-Scavenge收集器-默认\"><a href=\"#Parallel-Scavenge收集器-默认\" class=\"headerlink\" title=\"Parallel Scavenge收集器(默认)\"></a>Parallel Scavenge收集器(默认)</h1><p>设置了该收集器后，年轻代默认为Parallel Scavenge，老年代则为Parallel Old</p>\n<p>分析parallel-gc.log</p>\n<ul>\n<li>第一次调优，设置Metaspace大小：增大元空间大小-XX:MetaspaceSize=64M  -XX:MaxMetaspaceSize=64M</li>\n<li>第二次调优，添加吞吐量和停顿时间参数：-XX:MaxGCPauseMillis=100   -XX:GCTimeRatio=99</li>\n<li>第三次调优，修改动态扩容增量：-XX:YoungGenerationSizeIncrement=30</li>\n</ul>\n<h1 id=\"配置CMS收集器\"><a href=\"#配置CMS收集器\" class=\"headerlink\" title=\"配置CMS收集器\"></a>配置CMS收集器</h1><p>设置了老年代收集器为CMS后，年轻代默认为ParNew收集器<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-XX:+UseConcMarkSweepGC</span><br></pre></td></tr></table></figure></p>\n<p>分析cms-gc.log</p>\n<h1 id=\"配置G1收集器\"><a href=\"#配置G1收集器\" class=\"headerlink\" title=\"配置G1收集器\"></a>配置G1收集器</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-XX:+UseG1GC</span><br></pre></td></tr></table></figure>\n<p>分析g1-gc.log<br>查看发生MixedGC的阈值：jinfo -flag InitiatingHeapOccupancyPercent 进程id</p>\n<p>分析工具：gceasy，GCViewer </p>\n<h2 id=\"G1调优常用参数\"><a href=\"#G1调优常用参数\" class=\"headerlink\" title=\"G1调优常用参数\"></a>G1调优常用参数</h2><ul>\n<li>-XX:+UseG1GC 开启G1</li>\n<li>-XX:G1HeapRegionSize=n,region的大小，1-32M，2048个</li>\n<li>-XX:MaxGCPauseMillis=200 最大停顿时间</li>\n<li>-XX:G1NewSizePercent   -XX:G1MaxNewSizePercent</li>\n<li>-XX:G1ReservePercent=10 保留防止to space溢出（）</li>\n<li>-XX:ParallelGCThreads=n SWT线程数（停止应用程序）</li>\n<li>-XX:ConcGCThreads=n 并发线程数=1/4*并行</li>\n</ul>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><ul>\n<li>年轻代大小：避免使用-Xmn、-XX:NewRatio等显示设置Young区大小，会覆盖暂停时间目标（常用参数3）</li>\n<li>暂停时间目标：暂停时间不要太严苛，其吞吐量目标是90%的应用程序时间和10%的垃圾回收时间，太严苛会直接影响到吞吐量</li>\n</ul>\n<h2 id=\"是否需要切换到G1\"><a href=\"#是否需要切换到G1\" class=\"headerlink\" title=\"是否需要切换到G1\"></a>是否需要切换到G1</h2><ul>\n<li>50%以上的堆被存活对象占用</li>\n<li>对象分配和晋升的速度变化非常大</li>\n<li>垃圾回收时间特别长，超过1秒</li>\n</ul>\n<h2 id=\"G1调优目标\"><a href=\"#G1调优目标\" class=\"headerlink\" title=\"G1调优目标\"></a>G1调优目标</h2><ul>\n<li>6GB以上内存</li>\n<li>停顿时间是500ms以内</li>\n<li>吞吐量是90%以上</li>\n</ul>\n<h1 id=\"GC常用参数汇总\"><a href=\"#GC常用参数汇总\" class=\"headerlink\" title=\"GC常用参数汇总\"></a>GC常用参数汇总</h1><h2 id=\"堆栈设置\"><a href=\"#堆栈设置\" class=\"headerlink\" title=\"堆栈设置\"></a>堆栈设置</h2><ul>\n<li>-Xss:每个线程的栈大小</li>\n<li>-Xms:初始堆大小，默认物理内存的1/64</li>\n<li>-Xmx:最大堆大小，默认物理内存的1/4</li>\n<li>-Xmn:新生代大小</li>\n<li>-XX:NewSize:设置新生代初始大小</li>\n<li>-XX:NewRatio:默认2表示新生代占年老代的1/2，占整个堆内存的1/3。</li>\n<li>-XX:SurvivorRatio:默认8表示一个survivor区占用1/8的Eden内存，即1/10的新生代内存。</li>\n<li>-XX:MetaspaceSize:设置元空间大小</li>\n<li>-XX:MaxMetaspaceSize:设置元空间最大允许大小，默认不受限制，JVM Metaspace会进行动态扩展。<h2 id=\"垃圾回收统计信息\"><a href=\"#垃圾回收统计信息\" class=\"headerlink\" title=\"垃圾回收统计信息\"></a>垃圾回收统计信息</h2></li>\n<li>-XX:+PrintGC</li>\n<li>-XX:+PrintGCDetails</li>\n<li>-XX:+PrintGCTimeStamps </li>\n<li>-Xloggc:filename<h2 id=\"收集器设置\"><a href=\"#收集器设置\" class=\"headerlink\" title=\"收集器设置\"></a>收集器设置</h2></li>\n<li>-XX:+UseSerialGC:设置串行收集器</li>\n<li>-XX:+UseParallelGC:设置并行收集器</li>\n<li>-XX:+UseParallelOldGC:老年代使用并行回收收集器</li>\n<li>-XX:+UseParNewGC:在新生代使用并行收集器</li>\n<li>-XX:+UseParalledlOldGC:设置并行老年代收集器</li>\n<li>-XX:+UseConcMarkSweepGC:设置CMS并发收集器</li>\n<li>-XX:+UseG1GC:设置G1收集器</li>\n<li>-XX:ParallelGCThreads:设置用于垃圾回收的线程数<h2 id=\"并行收集器设置\"><a href=\"#并行收集器设置\" class=\"headerlink\" title=\"并行收集器设置\"></a>并行收集器设置</h2></li>\n<li>-XX:ParallelGCThreads:设置并行收集器收集时使用的CPU数。并行收集线程数。</li>\n<li>-XX:MaxGCPauseMillis:设置并行收集最大暂停时间</li>\n<li>-XX:GCTimeRatio:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)<h2 id=\"CMS收集器设置\"><a href=\"#CMS收集器设置\" class=\"headerlink\" title=\"CMS收集器设置\"></a>CMS收集器设置</h2></li>\n<li>-XX:+UseConcMarkSweepGC:设置CMS并发收集器</li>\n<li>-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。</li>\n<li>-XX:ParallelGCThreads:设置并发收集器新生代收集方式为并行收集时，使用的CPU数。并行收集线程数。</li>\n<li>-XX:CMSFullGCsBeforeCompaction:设定进行多少次CMS垃圾回收后，进行一次内存压缩</li>\n<li>-XX:+CMSClassUnloadingEnabled:允许对类元数据进行回收</li>\n<li>-XX:UseCMSInitiatingOccupancyOnly:表示只在到达阀值的时候，才进行CMS回收</li>\n<li>-XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况</li>\n<li>-XX:ParallelCMSThreads:设定CMS的线程数量</li>\n<li>-XX:CMSInitiatingOccupancyFraction:设置CMS收集器在老年代空间被使用多少后触发</li>\n<li>-XX:+UseCMSCompactAtFullCollection:设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片的整理    <h2 id=\"G1收集器设置\"><a href=\"#G1收集器设置\" class=\"headerlink\" title=\"G1收集器设置\"></a>G1收集器设置</h2></li>\n<li>-XX:+UseG1GC:使用G1收集器</li>\n<li>-XX:ParallelGCThreads:指定GC工作的线程数量</li>\n<li>-XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区</li>\n<li>-XX:GCTimeRatio:吞吐量大小，0-100的整数(默认9)，值为n则系统将花费不超过1/(1+n)的时间用于垃圾收集</li>\n<li>-XX:MaxGCPauseMillis:目标暂停时间(默认200ms)</li>\n<li>-XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%)</li>\n<li>-XX:G1MaxNewSizePercent:新生代内存最大空间</li>\n<li>-XX:TargetSurvivorRatio:Survivor填充容量(默认50%)</li>\n<li>-XX:MaxTenuringThreshold:最大任期阈值(默认15)</li>\n<li>-XX:InitiatingHeapOccupancyPercen:老年代占用空间超过整堆比IHOP阈值(默认45%),超过则执行混合收集</li>\n<li>-XX:G1HeapWastePercent:堆废物百分比(默认5%)</li>\n<li>-XX:G1MixedGCCountTarget:参数混合周期的最大总次数(默认8)</li>\n</ul>"},{"title":"JDK自带性能调优相关工具","date":"2020-05-01T02:00:00.000Z","_content":"\n内容比较多，所以单独来记录一些JDK自带的工具和相关的说明\n\n<!-- more -->\n\n# Jinfo\n查看正在运行的Java应用程序的扩展参数\n查看jvm的参数\n![photo-1](/image/jvm/JDK自带工具/1.png)\n\n查看java系统参数\n![photo-2](/image/jvm/JDK自带工具/2.png)\n\n\n# Jstat\njstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下：\n```\njstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数]\n```\n注意：使用的jdk版本是jdk8.\n\n## 类加载统计\n\n![photo-3](/image/jvm/JDK自带工具/3.png)\n\n- Loaded：加载class的数量\n- Bytes：所占用空间大小\n- Unloaded：未加载数量\n- Bytes:未加载占用空间\n- Time：时间\n\n## 垃圾回收统计\n\n![photo-4](/image/jvm/JDK自带工具/4.png)\n\n- S0C：第一个幸存区的大小\n- S1C：第二个幸存区的大小\n- S0U：第一个幸存区的使用大小\n- S1U：第二个幸存区的使用大小\n- EC：伊甸园区的大小\n- EU：伊甸园区的使用大小\n- OC：老年代大小\n- OU：老年代使用大小\n- MC：方法区大小(元空间)\n- MU：方法区使用大小\n- CCSC:压缩类空间大小\n- CCSU:压缩类空间使用大小\n- YGC：年轻代垃圾回收次数\n- YGCT：年轻代垃圾回收消耗时间\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n\n## 堆内存统计\n\n![photo-5](/image/jvm/JDK自带工具/5.png)\n\n- NGCMN：新生代最小容量\n- NGCMX：新生代最大容量\n- NGC：当前新生代容量\n- S0C：第一个幸存区大小\n- S1C：第二个幸存区的大小\n- EC：伊甸园区的大小\n- OGCMN：老年代最小容量\n- OGCMX：老年代最大容量\n- OGC：当前老年代大小\n- OC:当前老年代大小\n- MCMN:最小元数据容量\n- MCMX：最大元数据容量\n- MC：当前元数据空间大小\n- CCSMN：最小压缩类空间大小\n- CCSMX：最大压缩类空间大小\n- CCSC：当前压缩类空间大小\n- YGC：年轻代gc次数\n- FGC：老年代GC次数\n\n## 新生代垃圾回收统计\n\n![photo-6](/image/jvm/JDK自带工具/6.png)\n\n- S0C：第一个幸存区的大小\n- S1C：第二个幸存区的大小\n- S0U：第一个幸存区的使用大小\n- S1U：第二个幸存区的使用大小\n- TT:对象在新生代存活的次数\n- MTT:对象在新生代存活的最大次数\n- DSS:期望的幸存区大小\n- EC：伊甸园区的大小\n- EU：伊甸园区的使用大小\n- YGC：年轻代垃圾回收次数\n- YGCT：年轻代垃圾回收消耗时间\n\n## 新生代内存统计\n\n![photo-7](/image/jvm/JDK自带工具/7.png)\n\n- NGCMN：新生代最小容量\n- NGCMX：新生代最大容量\n- NGC：当前新生代容量\n- S0CMX：最大幸存1区大小\n- S0C：当前幸存1区大小\n- S1CMX：最大幸存2区大小\n- S1C：当前幸存2区大小\n- ECMX：最大伊甸园区大小\n- EC：当前伊甸园区大小\n- YGC：年轻代垃圾回收次数\n- FGC：老年代回收次数\n\n## 老年代垃圾回收统计\n\n![photo-8](/image/jvm/JDK自带工具/8.png)\n\n- MC：方法区大小\n- MU：方法区使用大小\n- CCSC:压缩类空间大小\n- CCSU:压缩类空间使用大小\n- OC：老年代大小\n- OU：老年代使用大小\n- YGC：年轻代垃圾回收次数\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n\n\n## 老年代内存统计\n\n![photo-9](/image/jvm/JDK自带工具/9.png)\n\n- OGCMN：老年代最小容量\n- OGCMX：老年代最大容量\n- OGC：当前老年代大小\n- OC：老年代大小\n- YGC：年轻代垃圾回收次数\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n\n## 元数据空间统计\n\n![photo-10](/image/jvm/JDK自带工具/10.png)\n\n- MCMN:最小元数据容量\n- MCMX：最大元数据容量\n- MC：当前元数据空间大小\n- CCSMN：最小压缩类空间大小\n- CCSMX：最大压缩类空间大小\n- CCSC：当前压缩类空间大小\n- YGC：年轻代垃圾回收次数\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n \n![photo-11](/image/jvm/JDK自带工具/11.png)\n\n- S0：幸存1区当前使用比例\n- S1：幸存2区当前使用比例\n- E：伊甸园区使用比例\n- O：老年代使用比例\n- M：元数据区使用比例\n- CCS：压缩使用比例\n- YGC：年轻代垃圾回收次数\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n\n\n# Jmap\n此命令可以用来查看内存信息。\n\n## 实例个数以及占用内存大小\n\n![photo-12](/image/jvm/JDK自带工具/12.png)\n\n打开log.txt，文件内容如下：\n\n![photo-13](/image/jvm/JDK自带工具/13.png)\n\n- num：序号\n- instances：实例数量\n- bytes：占用空间大小\n- class name：类名称\n\n## 堆信息\n\n![photo-14](/image/jvm/JDK自带工具/14.png)\n\n\n## 堆内存dump\n\n![photo-15](/image/jvm/JDK自带工具/15.png)\n\n也可以设置内存溢出自动导出dump文件(内存很大的时候，可能会导不出来)\n1. -XX:+HeapDumpOnOutOfMemoryError\n2. -XX:HeapDumpPath=./   （路径）\n\n![photo-16](/image/jvm/JDK自带工具/16.png)\n\n可以用jvisualvm命令工具导入该dump文件分析\n\n![photo-17](/image/jvm/JDK自带工具/17.png)\n\n# Jstack\n\n![photo-18](/image/jvm/JDK自带工具/18.png)\n\n用jstack查找死锁，见如下示例，也可以用jvisualvm查看死锁\n\n![photo-19](/image/jvm/JDK自带工具/19.png)\n \n## 远程连接jvisualvm\n启动普通的jar程序JMX端口配置：\n```\njava -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar xxx.jar\n```\n\ntomcat的JMX配置\n```\nJAVA_OPTS=-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false\n```\n\njvisualvm远程连接服务需要在远程服务器上配置host(连接ip 主机名)，并且要关闭防火墙\n\n## jstack找出占用cpu最高的堆栈信息\n1. 使用命令top -p <pid> ，显示你的java进程的内存情况，pid是你的java进程号，比如4977\n2. 按H，获取每个线程的内存情况 \n3. 找到内存和cpu占用最高的线程tid，比如4977 \n4. 转为十六进制得到 0x1371 ,此为线程id的十六进制表示\n5. 执行 jstack 4977|grep -A 10 1371，得到线程堆栈信息中1371这个线程所在行的后面10行 \n6. 查看对应的堆栈信息找出可能存在问题的代码","source":"_posts/JDK自带性能调优相关工具.md","raw":"---\ntitle: JDK自带性能调优相关工具\ndate: 2020-05-01 10:00:00\ntags: JVM\ncategories: Java\n---\n\n内容比较多，所以单独来记录一些JDK自带的工具和相关的说明\n\n<!-- more -->\n\n# Jinfo\n查看正在运行的Java应用程序的扩展参数\n查看jvm的参数\n![photo-1](/image/jvm/JDK自带工具/1.png)\n\n查看java系统参数\n![photo-2](/image/jvm/JDK自带工具/2.png)\n\n\n# Jstat\njstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下：\n```\njstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数]\n```\n注意：使用的jdk版本是jdk8.\n\n## 类加载统计\n\n![photo-3](/image/jvm/JDK自带工具/3.png)\n\n- Loaded：加载class的数量\n- Bytes：所占用空间大小\n- Unloaded：未加载数量\n- Bytes:未加载占用空间\n- Time：时间\n\n## 垃圾回收统计\n\n![photo-4](/image/jvm/JDK自带工具/4.png)\n\n- S0C：第一个幸存区的大小\n- S1C：第二个幸存区的大小\n- S0U：第一个幸存区的使用大小\n- S1U：第二个幸存区的使用大小\n- EC：伊甸园区的大小\n- EU：伊甸园区的使用大小\n- OC：老年代大小\n- OU：老年代使用大小\n- MC：方法区大小(元空间)\n- MU：方法区使用大小\n- CCSC:压缩类空间大小\n- CCSU:压缩类空间使用大小\n- YGC：年轻代垃圾回收次数\n- YGCT：年轻代垃圾回收消耗时间\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n\n## 堆内存统计\n\n![photo-5](/image/jvm/JDK自带工具/5.png)\n\n- NGCMN：新生代最小容量\n- NGCMX：新生代最大容量\n- NGC：当前新生代容量\n- S0C：第一个幸存区大小\n- S1C：第二个幸存区的大小\n- EC：伊甸园区的大小\n- OGCMN：老年代最小容量\n- OGCMX：老年代最大容量\n- OGC：当前老年代大小\n- OC:当前老年代大小\n- MCMN:最小元数据容量\n- MCMX：最大元数据容量\n- MC：当前元数据空间大小\n- CCSMN：最小压缩类空间大小\n- CCSMX：最大压缩类空间大小\n- CCSC：当前压缩类空间大小\n- YGC：年轻代gc次数\n- FGC：老年代GC次数\n\n## 新生代垃圾回收统计\n\n![photo-6](/image/jvm/JDK自带工具/6.png)\n\n- S0C：第一个幸存区的大小\n- S1C：第二个幸存区的大小\n- S0U：第一个幸存区的使用大小\n- S1U：第二个幸存区的使用大小\n- TT:对象在新生代存活的次数\n- MTT:对象在新生代存活的最大次数\n- DSS:期望的幸存区大小\n- EC：伊甸园区的大小\n- EU：伊甸园区的使用大小\n- YGC：年轻代垃圾回收次数\n- YGCT：年轻代垃圾回收消耗时间\n\n## 新生代内存统计\n\n![photo-7](/image/jvm/JDK自带工具/7.png)\n\n- NGCMN：新生代最小容量\n- NGCMX：新生代最大容量\n- NGC：当前新生代容量\n- S0CMX：最大幸存1区大小\n- S0C：当前幸存1区大小\n- S1CMX：最大幸存2区大小\n- S1C：当前幸存2区大小\n- ECMX：最大伊甸园区大小\n- EC：当前伊甸园区大小\n- YGC：年轻代垃圾回收次数\n- FGC：老年代回收次数\n\n## 老年代垃圾回收统计\n\n![photo-8](/image/jvm/JDK自带工具/8.png)\n\n- MC：方法区大小\n- MU：方法区使用大小\n- CCSC:压缩类空间大小\n- CCSU:压缩类空间使用大小\n- OC：老年代大小\n- OU：老年代使用大小\n- YGC：年轻代垃圾回收次数\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n\n\n## 老年代内存统计\n\n![photo-9](/image/jvm/JDK自带工具/9.png)\n\n- OGCMN：老年代最小容量\n- OGCMX：老年代最大容量\n- OGC：当前老年代大小\n- OC：老年代大小\n- YGC：年轻代垃圾回收次数\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n\n## 元数据空间统计\n\n![photo-10](/image/jvm/JDK自带工具/10.png)\n\n- MCMN:最小元数据容量\n- MCMX：最大元数据容量\n- MC：当前元数据空间大小\n- CCSMN：最小压缩类空间大小\n- CCSMX：最大压缩类空间大小\n- CCSC：当前压缩类空间大小\n- YGC：年轻代垃圾回收次数\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n \n![photo-11](/image/jvm/JDK自带工具/11.png)\n\n- S0：幸存1区当前使用比例\n- S1：幸存2区当前使用比例\n- E：伊甸园区使用比例\n- O：老年代使用比例\n- M：元数据区使用比例\n- CCS：压缩使用比例\n- YGC：年轻代垃圾回收次数\n- FGC：老年代垃圾回收次数\n- FGCT：老年代垃圾回收消耗时间\n- GCT：垃圾回收消耗总时间\n\n\n# Jmap\n此命令可以用来查看内存信息。\n\n## 实例个数以及占用内存大小\n\n![photo-12](/image/jvm/JDK自带工具/12.png)\n\n打开log.txt，文件内容如下：\n\n![photo-13](/image/jvm/JDK自带工具/13.png)\n\n- num：序号\n- instances：实例数量\n- bytes：占用空间大小\n- class name：类名称\n\n## 堆信息\n\n![photo-14](/image/jvm/JDK自带工具/14.png)\n\n\n## 堆内存dump\n\n![photo-15](/image/jvm/JDK自带工具/15.png)\n\n也可以设置内存溢出自动导出dump文件(内存很大的时候，可能会导不出来)\n1. -XX:+HeapDumpOnOutOfMemoryError\n2. -XX:HeapDumpPath=./   （路径）\n\n![photo-16](/image/jvm/JDK自带工具/16.png)\n\n可以用jvisualvm命令工具导入该dump文件分析\n\n![photo-17](/image/jvm/JDK自带工具/17.png)\n\n# Jstack\n\n![photo-18](/image/jvm/JDK自带工具/18.png)\n\n用jstack查找死锁，见如下示例，也可以用jvisualvm查看死锁\n\n![photo-19](/image/jvm/JDK自带工具/19.png)\n \n## 远程连接jvisualvm\n启动普通的jar程序JMX端口配置：\n```\njava -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar xxx.jar\n```\n\ntomcat的JMX配置\n```\nJAVA_OPTS=-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false\n```\n\njvisualvm远程连接服务需要在远程服务器上配置host(连接ip 主机名)，并且要关闭防火墙\n\n## jstack找出占用cpu最高的堆栈信息\n1. 使用命令top -p <pid> ，显示你的java进程的内存情况，pid是你的java进程号，比如4977\n2. 按H，获取每个线程的内存情况 \n3. 找到内存和cpu占用最高的线程tid，比如4977 \n4. 转为十六进制得到 0x1371 ,此为线程id的十六进制表示\n5. 执行 jstack 4977|grep -A 10 1371，得到线程堆栈信息中1371这个线程所在行的后面10行 \n6. 查看对应的堆栈信息找出可能存在问题的代码","slug":"JDK自带性能调优相关工具","published":1,"updated":"2020-05-20T16:04:56.737Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkz70003qotn4cna0mhb","content":"<p>内容比较多，所以单独来记录一些JDK自带的工具和相关的说明</p>\n<a id=\"more\"></a>\n<h1 id=\"Jinfo\"><a href=\"#Jinfo\" class=\"headerlink\" title=\"Jinfo\"></a>Jinfo</h1><p>查看正在运行的Java应用程序的扩展参数<br>查看jvm的参数<br><img src=\"/image/jvm/JDK自带工具/1.png\" alt=\"photo-1\"></p>\n<p>查看java系统参数<br><img src=\"/image/jvm/JDK自带工具/2.png\" alt=\"photo-2\"></p>\n<h1 id=\"Jstat\"><a href=\"#Jstat\" class=\"headerlink\" title=\"Jstat\"></a>Jstat</h1><p>jstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数]</span><br></pre></td></tr></table></figure></p>\n<p>注意：使用的jdk版本是jdk8.</p>\n<h2 id=\"类加载统计\"><a href=\"#类加载统计\" class=\"headerlink\" title=\"类加载统计\"></a>类加载统计</h2><p><img src=\"/image/jvm/JDK自带工具/3.png\" alt=\"photo-3\"></p>\n<ul>\n<li>Loaded：加载class的数量</li>\n<li>Bytes：所占用空间大小</li>\n<li>Unloaded：未加载数量</li>\n<li>Bytes:未加载占用空间</li>\n<li>Time：时间</li>\n</ul>\n<h2 id=\"垃圾回收统计\"><a href=\"#垃圾回收统计\" class=\"headerlink\" title=\"垃圾回收统计\"></a>垃圾回收统计</h2><p><img src=\"/image/jvm/JDK自带工具/4.png\" alt=\"photo-4\"></p>\n<ul>\n<li>S0C：第一个幸存区的大小</li>\n<li>S1C：第二个幸存区的大小</li>\n<li>S0U：第一个幸存区的使用大小</li>\n<li>S1U：第二个幸存区的使用大小</li>\n<li>EC：伊甸园区的大小</li>\n<li>EU：伊甸园区的使用大小</li>\n<li>OC：老年代大小</li>\n<li>OU：老年代使用大小</li>\n<li>MC：方法区大小(元空间)</li>\n<li>MU：方法区使用大小</li>\n<li>CCSC:压缩类空间大小</li>\n<li>CCSU:压缩类空间使用大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>YGCT：年轻代垃圾回收消耗时间</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<h2 id=\"堆内存统计\"><a href=\"#堆内存统计\" class=\"headerlink\" title=\"堆内存统计\"></a>堆内存统计</h2><p><img src=\"/image/jvm/JDK自带工具/5.png\" alt=\"photo-5\"></p>\n<ul>\n<li>NGCMN：新生代最小容量</li>\n<li>NGCMX：新生代最大容量</li>\n<li>NGC：当前新生代容量</li>\n<li>S0C：第一个幸存区大小</li>\n<li>S1C：第二个幸存区的大小</li>\n<li>EC：伊甸园区的大小</li>\n<li>OGCMN：老年代最小容量</li>\n<li>OGCMX：老年代最大容量</li>\n<li>OGC：当前老年代大小</li>\n<li>OC:当前老年代大小</li>\n<li>MCMN:最小元数据容量</li>\n<li>MCMX：最大元数据容量</li>\n<li>MC：当前元数据空间大小</li>\n<li>CCSMN：最小压缩类空间大小</li>\n<li>CCSMX：最大压缩类空间大小</li>\n<li>CCSC：当前压缩类空间大小</li>\n<li>YGC：年轻代gc次数</li>\n<li>FGC：老年代GC次数</li>\n</ul>\n<h2 id=\"新生代垃圾回收统计\"><a href=\"#新生代垃圾回收统计\" class=\"headerlink\" title=\"新生代垃圾回收统计\"></a>新生代垃圾回收统计</h2><p><img src=\"/image/jvm/JDK自带工具/6.png\" alt=\"photo-6\"></p>\n<ul>\n<li>S0C：第一个幸存区的大小</li>\n<li>S1C：第二个幸存区的大小</li>\n<li>S0U：第一个幸存区的使用大小</li>\n<li>S1U：第二个幸存区的使用大小</li>\n<li>TT:对象在新生代存活的次数</li>\n<li>MTT:对象在新生代存活的最大次数</li>\n<li>DSS:期望的幸存区大小</li>\n<li>EC：伊甸园区的大小</li>\n<li>EU：伊甸园区的使用大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>YGCT：年轻代垃圾回收消耗时间</li>\n</ul>\n<h2 id=\"新生代内存统计\"><a href=\"#新生代内存统计\" class=\"headerlink\" title=\"新生代内存统计\"></a>新生代内存统计</h2><p><img src=\"/image/jvm/JDK自带工具/7.png\" alt=\"photo-7\"></p>\n<ul>\n<li>NGCMN：新生代最小容量</li>\n<li>NGCMX：新生代最大容量</li>\n<li>NGC：当前新生代容量</li>\n<li>S0CMX：最大幸存1区大小</li>\n<li>S0C：当前幸存1区大小</li>\n<li>S1CMX：最大幸存2区大小</li>\n<li>S1C：当前幸存2区大小</li>\n<li>ECMX：最大伊甸园区大小</li>\n<li>EC：当前伊甸园区大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代回收次数</li>\n</ul>\n<h2 id=\"老年代垃圾回收统计\"><a href=\"#老年代垃圾回收统计\" class=\"headerlink\" title=\"老年代垃圾回收统计\"></a>老年代垃圾回收统计</h2><p><img src=\"/image/jvm/JDK自带工具/8.png\" alt=\"photo-8\"></p>\n<ul>\n<li>MC：方法区大小</li>\n<li>MU：方法区使用大小</li>\n<li>CCSC:压缩类空间大小</li>\n<li>CCSU:压缩类空间使用大小</li>\n<li>OC：老年代大小</li>\n<li>OU：老年代使用大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<h2 id=\"老年代内存统计\"><a href=\"#老年代内存统计\" class=\"headerlink\" title=\"老年代内存统计\"></a>老年代内存统计</h2><p><img src=\"/image/jvm/JDK自带工具/9.png\" alt=\"photo-9\"></p>\n<ul>\n<li>OGCMN：老年代最小容量</li>\n<li>OGCMX：老年代最大容量</li>\n<li>OGC：当前老年代大小</li>\n<li>OC：老年代大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<h2 id=\"元数据空间统计\"><a href=\"#元数据空间统计\" class=\"headerlink\" title=\"元数据空间统计\"></a>元数据空间统计</h2><p><img src=\"/image/jvm/JDK自带工具/10.png\" alt=\"photo-10\"></p>\n<ul>\n<li>MCMN:最小元数据容量</li>\n<li>MCMX：最大元数据容量</li>\n<li>MC：当前元数据空间大小</li>\n<li>CCSMN：最小压缩类空间大小</li>\n<li>CCSMX：最大压缩类空间大小</li>\n<li>CCSC：当前压缩类空间大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<p><img src=\"/image/jvm/JDK自带工具/11.png\" alt=\"photo-11\"></p>\n<ul>\n<li>S0：幸存1区当前使用比例</li>\n<li>S1：幸存2区当前使用比例</li>\n<li>E：伊甸园区使用比例</li>\n<li>O：老年代使用比例</li>\n<li>M：元数据区使用比例</li>\n<li>CCS：压缩使用比例</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<h1 id=\"Jmap\"><a href=\"#Jmap\" class=\"headerlink\" title=\"Jmap\"></a>Jmap</h1><p>此命令可以用来查看内存信息。</p>\n<h2 id=\"实例个数以及占用内存大小\"><a href=\"#实例个数以及占用内存大小\" class=\"headerlink\" title=\"实例个数以及占用内存大小\"></a>实例个数以及占用内存大小</h2><p><img src=\"/image/jvm/JDK自带工具/12.png\" alt=\"photo-12\"></p>\n<p>打开log.txt，文件内容如下：</p>\n<p><img src=\"/image/jvm/JDK自带工具/13.png\" alt=\"photo-13\"></p>\n<ul>\n<li>num：序号</li>\n<li>instances：实例数量</li>\n<li>bytes：占用空间大小</li>\n<li>class name：类名称</li>\n</ul>\n<h2 id=\"堆信息\"><a href=\"#堆信息\" class=\"headerlink\" title=\"堆信息\"></a>堆信息</h2><p><img src=\"/image/jvm/JDK自带工具/14.png\" alt=\"photo-14\"></p>\n<h2 id=\"堆内存dump\"><a href=\"#堆内存dump\" class=\"headerlink\" title=\"堆内存dump\"></a>堆内存dump</h2><p><img src=\"/image/jvm/JDK自带工具/15.png\" alt=\"photo-15\"></p>\n<p>也可以设置内存溢出自动导出dump文件(内存很大的时候，可能会导不出来)</p>\n<ol>\n<li>-XX:+HeapDumpOnOutOfMemoryError</li>\n<li>-XX:HeapDumpPath=./   （路径）</li>\n</ol>\n<p><img src=\"/image/jvm/JDK自带工具/16.png\" alt=\"photo-16\"></p>\n<p>可以用jvisualvm命令工具导入该dump文件分析</p>\n<p><img src=\"/image/jvm/JDK自带工具/17.png\" alt=\"photo-17\"></p>\n<h1 id=\"Jstack\"><a href=\"#Jstack\" class=\"headerlink\" title=\"Jstack\"></a>Jstack</h1><p><img src=\"/image/jvm/JDK自带工具/18.png\" alt=\"photo-18\"></p>\n<p>用jstack查找死锁，见如下示例，也可以用jvisualvm查看死锁</p>\n<p><img src=\"/image/jvm/JDK自带工具/19.png\" alt=\"photo-19\"></p>\n<h2 id=\"远程连接jvisualvm\"><a href=\"#远程连接jvisualvm\" class=\"headerlink\" title=\"远程连接jvisualvm\"></a>远程连接jvisualvm</h2><p>启动普通的jar程序JMX端口配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">java -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar xxx.jar</span><br></pre></td></tr></table></figure></p>\n<p>tomcat的JMX配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_OPTS=-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false</span><br></pre></td></tr></table></figure></p>\n<p>jvisualvm远程连接服务需要在远程服务器上配置host(连接ip 主机名)，并且要关闭防火墙</p>\n<h2 id=\"jstack找出占用cpu最高的堆栈信息\"><a href=\"#jstack找出占用cpu最高的堆栈信息\" class=\"headerlink\" title=\"jstack找出占用cpu最高的堆栈信息\"></a>jstack找出占用cpu最高的堆栈信息</h2><ol>\n<li>使用命令top -p <pid> ，显示你的java进程的内存情况，pid是你的java进程号，比如4977</pid></li>\n<li>按H，获取每个线程的内存情况 </li>\n<li>找到内存和cpu占用最高的线程tid，比如4977 </li>\n<li>转为十六进制得到 0x1371 ,此为线程id的十六进制表示</li>\n<li>执行 jstack 4977|grep -A 10 1371，得到线程堆栈信息中1371这个线程所在行的后面10行 </li>\n<li>查看对应的堆栈信息找出可能存在问题的代码</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>内容比较多，所以单独来记录一些JDK自带的工具和相关的说明</p>","more":"<h1 id=\"Jinfo\"><a href=\"#Jinfo\" class=\"headerlink\" title=\"Jinfo\"></a>Jinfo</h1><p>查看正在运行的Java应用程序的扩展参数<br>查看jvm的参数<br><img src=\"/image/jvm/JDK自带工具/1.png\" alt=\"photo-1\"></p>\n<p>查看java系统参数<br><img src=\"/image/jvm/JDK自带工具/2.png\" alt=\"photo-2\"></p>\n<h1 id=\"Jstat\"><a href=\"#Jstat\" class=\"headerlink\" title=\"Jstat\"></a>Jstat</h1><p>jstat命令可以查看堆内存各部分的使用量，以及加载类的数量。命令的格式如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jstat [-命令选项] [vmid] [间隔时间/毫秒] [查询次数]</span><br></pre></td></tr></table></figure></p>\n<p>注意：使用的jdk版本是jdk8.</p>\n<h2 id=\"类加载统计\"><a href=\"#类加载统计\" class=\"headerlink\" title=\"类加载统计\"></a>类加载统计</h2><p><img src=\"/image/jvm/JDK自带工具/3.png\" alt=\"photo-3\"></p>\n<ul>\n<li>Loaded：加载class的数量</li>\n<li>Bytes：所占用空间大小</li>\n<li>Unloaded：未加载数量</li>\n<li>Bytes:未加载占用空间</li>\n<li>Time：时间</li>\n</ul>\n<h2 id=\"垃圾回收统计\"><a href=\"#垃圾回收统计\" class=\"headerlink\" title=\"垃圾回收统计\"></a>垃圾回收统计</h2><p><img src=\"/image/jvm/JDK自带工具/4.png\" alt=\"photo-4\"></p>\n<ul>\n<li>S0C：第一个幸存区的大小</li>\n<li>S1C：第二个幸存区的大小</li>\n<li>S0U：第一个幸存区的使用大小</li>\n<li>S1U：第二个幸存区的使用大小</li>\n<li>EC：伊甸园区的大小</li>\n<li>EU：伊甸园区的使用大小</li>\n<li>OC：老年代大小</li>\n<li>OU：老年代使用大小</li>\n<li>MC：方法区大小(元空间)</li>\n<li>MU：方法区使用大小</li>\n<li>CCSC:压缩类空间大小</li>\n<li>CCSU:压缩类空间使用大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>YGCT：年轻代垃圾回收消耗时间</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<h2 id=\"堆内存统计\"><a href=\"#堆内存统计\" class=\"headerlink\" title=\"堆内存统计\"></a>堆内存统计</h2><p><img src=\"/image/jvm/JDK自带工具/5.png\" alt=\"photo-5\"></p>\n<ul>\n<li>NGCMN：新生代最小容量</li>\n<li>NGCMX：新生代最大容量</li>\n<li>NGC：当前新生代容量</li>\n<li>S0C：第一个幸存区大小</li>\n<li>S1C：第二个幸存区的大小</li>\n<li>EC：伊甸园区的大小</li>\n<li>OGCMN：老年代最小容量</li>\n<li>OGCMX：老年代最大容量</li>\n<li>OGC：当前老年代大小</li>\n<li>OC:当前老年代大小</li>\n<li>MCMN:最小元数据容量</li>\n<li>MCMX：最大元数据容量</li>\n<li>MC：当前元数据空间大小</li>\n<li>CCSMN：最小压缩类空间大小</li>\n<li>CCSMX：最大压缩类空间大小</li>\n<li>CCSC：当前压缩类空间大小</li>\n<li>YGC：年轻代gc次数</li>\n<li>FGC：老年代GC次数</li>\n</ul>\n<h2 id=\"新生代垃圾回收统计\"><a href=\"#新生代垃圾回收统计\" class=\"headerlink\" title=\"新生代垃圾回收统计\"></a>新生代垃圾回收统计</h2><p><img src=\"/image/jvm/JDK自带工具/6.png\" alt=\"photo-6\"></p>\n<ul>\n<li>S0C：第一个幸存区的大小</li>\n<li>S1C：第二个幸存区的大小</li>\n<li>S0U：第一个幸存区的使用大小</li>\n<li>S1U：第二个幸存区的使用大小</li>\n<li>TT:对象在新生代存活的次数</li>\n<li>MTT:对象在新生代存活的最大次数</li>\n<li>DSS:期望的幸存区大小</li>\n<li>EC：伊甸园区的大小</li>\n<li>EU：伊甸园区的使用大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>YGCT：年轻代垃圾回收消耗时间</li>\n</ul>\n<h2 id=\"新生代内存统计\"><a href=\"#新生代内存统计\" class=\"headerlink\" title=\"新生代内存统计\"></a>新生代内存统计</h2><p><img src=\"/image/jvm/JDK自带工具/7.png\" alt=\"photo-7\"></p>\n<ul>\n<li>NGCMN：新生代最小容量</li>\n<li>NGCMX：新生代最大容量</li>\n<li>NGC：当前新生代容量</li>\n<li>S0CMX：最大幸存1区大小</li>\n<li>S0C：当前幸存1区大小</li>\n<li>S1CMX：最大幸存2区大小</li>\n<li>S1C：当前幸存2区大小</li>\n<li>ECMX：最大伊甸园区大小</li>\n<li>EC：当前伊甸园区大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代回收次数</li>\n</ul>\n<h2 id=\"老年代垃圾回收统计\"><a href=\"#老年代垃圾回收统计\" class=\"headerlink\" title=\"老年代垃圾回收统计\"></a>老年代垃圾回收统计</h2><p><img src=\"/image/jvm/JDK自带工具/8.png\" alt=\"photo-8\"></p>\n<ul>\n<li>MC：方法区大小</li>\n<li>MU：方法区使用大小</li>\n<li>CCSC:压缩类空间大小</li>\n<li>CCSU:压缩类空间使用大小</li>\n<li>OC：老年代大小</li>\n<li>OU：老年代使用大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<h2 id=\"老年代内存统计\"><a href=\"#老年代内存统计\" class=\"headerlink\" title=\"老年代内存统计\"></a>老年代内存统计</h2><p><img src=\"/image/jvm/JDK自带工具/9.png\" alt=\"photo-9\"></p>\n<ul>\n<li>OGCMN：老年代最小容量</li>\n<li>OGCMX：老年代最大容量</li>\n<li>OGC：当前老年代大小</li>\n<li>OC：老年代大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<h2 id=\"元数据空间统计\"><a href=\"#元数据空间统计\" class=\"headerlink\" title=\"元数据空间统计\"></a>元数据空间统计</h2><p><img src=\"/image/jvm/JDK自带工具/10.png\" alt=\"photo-10\"></p>\n<ul>\n<li>MCMN:最小元数据容量</li>\n<li>MCMX：最大元数据容量</li>\n<li>MC：当前元数据空间大小</li>\n<li>CCSMN：最小压缩类空间大小</li>\n<li>CCSMX：最大压缩类空间大小</li>\n<li>CCSC：当前压缩类空间大小</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<p><img src=\"/image/jvm/JDK自带工具/11.png\" alt=\"photo-11\"></p>\n<ul>\n<li>S0：幸存1区当前使用比例</li>\n<li>S1：幸存2区当前使用比例</li>\n<li>E：伊甸园区使用比例</li>\n<li>O：老年代使用比例</li>\n<li>M：元数据区使用比例</li>\n<li>CCS：压缩使用比例</li>\n<li>YGC：年轻代垃圾回收次数</li>\n<li>FGC：老年代垃圾回收次数</li>\n<li>FGCT：老年代垃圾回收消耗时间</li>\n<li>GCT：垃圾回收消耗总时间</li>\n</ul>\n<h1 id=\"Jmap\"><a href=\"#Jmap\" class=\"headerlink\" title=\"Jmap\"></a>Jmap</h1><p>此命令可以用来查看内存信息。</p>\n<h2 id=\"实例个数以及占用内存大小\"><a href=\"#实例个数以及占用内存大小\" class=\"headerlink\" title=\"实例个数以及占用内存大小\"></a>实例个数以及占用内存大小</h2><p><img src=\"/image/jvm/JDK自带工具/12.png\" alt=\"photo-12\"></p>\n<p>打开log.txt，文件内容如下：</p>\n<p><img src=\"/image/jvm/JDK自带工具/13.png\" alt=\"photo-13\"></p>\n<ul>\n<li>num：序号</li>\n<li>instances：实例数量</li>\n<li>bytes：占用空间大小</li>\n<li>class name：类名称</li>\n</ul>\n<h2 id=\"堆信息\"><a href=\"#堆信息\" class=\"headerlink\" title=\"堆信息\"></a>堆信息</h2><p><img src=\"/image/jvm/JDK自带工具/14.png\" alt=\"photo-14\"></p>\n<h2 id=\"堆内存dump\"><a href=\"#堆内存dump\" class=\"headerlink\" title=\"堆内存dump\"></a>堆内存dump</h2><p><img src=\"/image/jvm/JDK自带工具/15.png\" alt=\"photo-15\"></p>\n<p>也可以设置内存溢出自动导出dump文件(内存很大的时候，可能会导不出来)</p>\n<ol>\n<li>-XX:+HeapDumpOnOutOfMemoryError</li>\n<li>-XX:HeapDumpPath=./   （路径）</li>\n</ol>\n<p><img src=\"/image/jvm/JDK自带工具/16.png\" alt=\"photo-16\"></p>\n<p>可以用jvisualvm命令工具导入该dump文件分析</p>\n<p><img src=\"/image/jvm/JDK自带工具/17.png\" alt=\"photo-17\"></p>\n<h1 id=\"Jstack\"><a href=\"#Jstack\" class=\"headerlink\" title=\"Jstack\"></a>Jstack</h1><p><img src=\"/image/jvm/JDK自带工具/18.png\" alt=\"photo-18\"></p>\n<p>用jstack查找死锁，见如下示例，也可以用jvisualvm查看死锁</p>\n<p><img src=\"/image/jvm/JDK自带工具/19.png\" alt=\"photo-19\"></p>\n<h2 id=\"远程连接jvisualvm\"><a href=\"#远程连接jvisualvm\" class=\"headerlink\" title=\"远程连接jvisualvm\"></a>远程连接jvisualvm</h2><p>启动普通的jar程序JMX端口配置：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">java -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar xxx.jar</span><br></pre></td></tr></table></figure></p>\n<p>tomcat的JMX配置<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_OPTS=-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false</span><br></pre></td></tr></table></figure></p>\n<p>jvisualvm远程连接服务需要在远程服务器上配置host(连接ip 主机名)，并且要关闭防火墙</p>\n<h2 id=\"jstack找出占用cpu最高的堆栈信息\"><a href=\"#jstack找出占用cpu最高的堆栈信息\" class=\"headerlink\" title=\"jstack找出占用cpu最高的堆栈信息\"></a>jstack找出占用cpu最高的堆栈信息</h2><ol>\n<li>使用命令top -p <pid> ，显示你的java进程的内存情况，pid是你的java进程号，比如4977</pid></li>\n<li>按H，获取每个线程的内存情况 </li>\n<li>找到内存和cpu占用最高的线程tid，比如4977 </li>\n<li>转为十六进制得到 0x1371 ,此为线程id的十六进制表示</li>\n<li>执行 jstack 4977|grep -A 10 1371，得到线程堆栈信息中1371这个线程所在行的后面10行 </li>\n<li>查看对应的堆栈信息找出可能存在问题的代码</li>\n</ol>"},{"title":"JAVA程序常见问题与JVM内存模型关系","date":"2018-12-14T02:00:00.000Z","_content":"\n> 本文是前段时间公司培训讲到的内容，个人做了笔记进行了总结。通过各类JAVA程序的OOM问题，结合JVM内存模型进行定位以及调优，具体调试的工具以及内容后续会进行补充。\n\n<!-- more -->\n\n# OOM\n\n## 内存模型\n![JVM内存模型01-photo](/image/JVM内存模型01.png)\n\n![JVM内存模型02-photo](/image/JVM内存模型02.png)\n\n## 非堆内存\n\n## 调优参数\n-XX:MaxPremSize=256MB\n* jdk1.7 持久代 使用的虚拟机内存\n* jdk1.8之后 源空间 使用的是本地内存\n### 对应OOM错误信息\nPremGen Space\n### 问题处理\n1. 调大PermSize\n2. 是否有动态加载Groovy脚本\n3. 是否有大量动态生成类的逻辑，如字节码框、或动态代理的使用。\n\n## 堆内存\n### 调优参数\n-Xmx2G\n* 年轻代：Eden Survior -XX:NewSize=30m\n* 老年代\n### 对应OOM错误信息\nJava heap space/GC overhead limit exceeded\n### 问题处理\n1. 产生heapdump \n\n    1) 启动参数-XX:+HeapDumpOnOutOfMemoryError XX:HeapDumpPath=\n\n    2) jmap -dump:format=b,file=文件名 [pid] \n2. 使用mat工具分析heapdump\n3. 确定内存占用的代码进行优化\n4. 如果内存占用不多\n\n    1) 可能是创建了一个大对象导致，根据日志分析何时会创建大对象。\n\n    2) 死循环，jstack分析。\n\n## 栈内存\n### 调优参数\n-Xss128，默认2m\n* 使用的是操作系统的剩余内存，与其他JVM内存区域无关\n### 对应OOM错误信息\nStackOverflowError,unable to create new native thread\n### 问题处理\n1. 调大-Xss，使每个线程栈的内存增大\n2. 调小-Xmx 等参数，给栈留更多内存空间\n3. 分析是否代码中有不合理的递归\n\n## 堆外内存\n### 调优参数\n-XX:MaxDirectMemorySize=1G\n* DiectBuffer\n* 如netty直接缓冲区，io操作不需要进行内存的拷贝，性能较优\n### 对应OOM错误信息\ndirect buffer memory\n### 问题处理\n1. 默认占用-Xmx相同内存，可以通过增加参数XX:MaxDirectMemorySize=1G设定\n2. 络通信使用Netty但是未限流\n3. 分析代码中是否使用DirectBuffer未合理控制\n\n## 最终占用内存=MaxPermSize+Xmx+MaxDirectMemorySize+n*xss\n\n## OutofMemory-Out of swap space解决方案\n### 问题处理\n1. 地址空间不够，调整系统为64位\n2. 物理内存不足\n\n    1) jmap -histo:live pid，如果内存明显减少说明是DirectBuffer问题，通过设置-XX:MaxDirectMemorySize=1G设定\n\n    2) btrace Inflater/Deflater\n\n## OutofMemory- unable to create new native thread解决方\n1. 线程数超过ulimit限制\n\n    1) ulimit -a 查看max user process\n    \n    2) 临时调大ulimit -u unlimited\n\n    3) 永久增加 \n        a. * vi /etc/security/limits.conf # 添加如下的行\n\n        b. * soft noproc 11000\n\n        c. * hard noproc 11000\n\n        d. * soft nofile 4100\n\n        e. * hard nofile 4100\n\n2. 线程数超过kernel.pid_max\n\n    1) /proc/sys/kernel/pid_max #操作系统线程数限制\n\n    2) /proc/sys/vm/max_map_count #单进程mmap的限制会影响当个进程可创建的线程数\n\n3. 线程创建太多\n\n    1) jstack、pstree查看线程数量，排查谁创建过多线程\n\n    2) 调小-xss，使每个栈内存占用变小\n\n## OutofMemory-补充\n1. 只有heap或Perm区满，才会产生heapDump，其他oom不会产生\n2. 如何分析定位问题\n\n    1) Jvm监控工具（JavaMelody）\n\n    2) 其他工具 \n\n        a. Greys https://github.com/oldmanpushcart/greys-anatomy\n\n        b. TProfile https://github.com/alibaba/TProfiler\n\n# Java进程退出\n\n# CPU占用高\n\n# 应用无响应\n\n# 环境变量异常\n\n# 调用超时\n","source":"_posts/JAVA程序常见问题与JVM内存模型关系.md","raw":"---\ntitle: JAVA程序常见问题与JVM内存模型关系\ndate: 2018-12-14 10:00:00\ntags: Java\ncategories: Java\n---\n\n> 本文是前段时间公司培训讲到的内容，个人做了笔记进行了总结。通过各类JAVA程序的OOM问题，结合JVM内存模型进行定位以及调优，具体调试的工具以及内容后续会进行补充。\n\n<!-- more -->\n\n# OOM\n\n## 内存模型\n![JVM内存模型01-photo](/image/JVM内存模型01.png)\n\n![JVM内存模型02-photo](/image/JVM内存模型02.png)\n\n## 非堆内存\n\n## 调优参数\n-XX:MaxPremSize=256MB\n* jdk1.7 持久代 使用的虚拟机内存\n* jdk1.8之后 源空间 使用的是本地内存\n### 对应OOM错误信息\nPremGen Space\n### 问题处理\n1. 调大PermSize\n2. 是否有动态加载Groovy脚本\n3. 是否有大量动态生成类的逻辑，如字节码框、或动态代理的使用。\n\n## 堆内存\n### 调优参数\n-Xmx2G\n* 年轻代：Eden Survior -XX:NewSize=30m\n* 老年代\n### 对应OOM错误信息\nJava heap space/GC overhead limit exceeded\n### 问题处理\n1. 产生heapdump \n\n    1) 启动参数-XX:+HeapDumpOnOutOfMemoryError XX:HeapDumpPath=\n\n    2) jmap -dump:format=b,file=文件名 [pid] \n2. 使用mat工具分析heapdump\n3. 确定内存占用的代码进行优化\n4. 如果内存占用不多\n\n    1) 可能是创建了一个大对象导致，根据日志分析何时会创建大对象。\n\n    2) 死循环，jstack分析。\n\n## 栈内存\n### 调优参数\n-Xss128，默认2m\n* 使用的是操作系统的剩余内存，与其他JVM内存区域无关\n### 对应OOM错误信息\nStackOverflowError,unable to create new native thread\n### 问题处理\n1. 调大-Xss，使每个线程栈的内存增大\n2. 调小-Xmx 等参数，给栈留更多内存空间\n3. 分析是否代码中有不合理的递归\n\n## 堆外内存\n### 调优参数\n-XX:MaxDirectMemorySize=1G\n* DiectBuffer\n* 如netty直接缓冲区，io操作不需要进行内存的拷贝，性能较优\n### 对应OOM错误信息\ndirect buffer memory\n### 问题处理\n1. 默认占用-Xmx相同内存，可以通过增加参数XX:MaxDirectMemorySize=1G设定\n2. 络通信使用Netty但是未限流\n3. 分析代码中是否使用DirectBuffer未合理控制\n\n## 最终占用内存=MaxPermSize+Xmx+MaxDirectMemorySize+n*xss\n\n## OutofMemory-Out of swap space解决方案\n### 问题处理\n1. 地址空间不够，调整系统为64位\n2. 物理内存不足\n\n    1) jmap -histo:live pid，如果内存明显减少说明是DirectBuffer问题，通过设置-XX:MaxDirectMemorySize=1G设定\n\n    2) btrace Inflater/Deflater\n\n## OutofMemory- unable to create new native thread解决方\n1. 线程数超过ulimit限制\n\n    1) ulimit -a 查看max user process\n    \n    2) 临时调大ulimit -u unlimited\n\n    3) 永久增加 \n        a. * vi /etc/security/limits.conf # 添加如下的行\n\n        b. * soft noproc 11000\n\n        c. * hard noproc 11000\n\n        d. * soft nofile 4100\n\n        e. * hard nofile 4100\n\n2. 线程数超过kernel.pid_max\n\n    1) /proc/sys/kernel/pid_max #操作系统线程数限制\n\n    2) /proc/sys/vm/max_map_count #单进程mmap的限制会影响当个进程可创建的线程数\n\n3. 线程创建太多\n\n    1) jstack、pstree查看线程数量，排查谁创建过多线程\n\n    2) 调小-xss，使每个栈内存占用变小\n\n## OutofMemory-补充\n1. 只有heap或Perm区满，才会产生heapDump，其他oom不会产生\n2. 如何分析定位问题\n\n    1) Jvm监控工具（JavaMelody）\n\n    2) 其他工具 \n\n        a. Greys https://github.com/oldmanpushcart/greys-anatomy\n\n        b. TProfile https://github.com/alibaba/TProfiler\n\n# Java进程退出\n\n# CPU占用高\n\n# 应用无响应\n\n# 环境变量异常\n\n# 调用超时\n","slug":"JAVA程序常见问题与JVM内存模型关系","published":1,"updated":"2019-09-07T07:22:36.934Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkze0007qotn9116clkv","content":"<blockquote>\n<p>本文是前段时间公司培训讲到的内容，个人做了笔记进行了总结。通过各类JAVA程序的OOM问题，结合JVM内存模型进行定位以及调优，具体调试的工具以及内容后续会进行补充。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"OOM\"><a href=\"#OOM\" class=\"headerlink\" title=\"OOM\"></a>OOM</h1><h2 id=\"内存模型\"><a href=\"#内存模型\" class=\"headerlink\" title=\"内存模型\"></a>内存模型</h2><p><img src=\"/image/JVM内存模型01.png\" alt=\"JVM内存模型01-photo\"></p>\n<p><img src=\"/image/JVM内存模型02.png\" alt=\"JVM内存模型02-photo\"></p>\n<h2 id=\"非堆内存\"><a href=\"#非堆内存\" class=\"headerlink\" title=\"非堆内存\"></a>非堆内存</h2><h2 id=\"调优参数\"><a href=\"#调优参数\" class=\"headerlink\" title=\"调优参数\"></a>调优参数</h2><p>-XX:MaxPremSize=256MB</p>\n<ul>\n<li>jdk1.7 持久代 使用的虚拟机内存</li>\n<li>jdk1.8之后 源空间 使用的是本地内存<h3 id=\"对应OOM错误信息\"><a href=\"#对应OOM错误信息\" class=\"headerlink\" title=\"对应OOM错误信息\"></a>对应OOM错误信息</h3>PremGen Space<h3 id=\"问题处理\"><a href=\"#问题处理\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3></li>\n</ul>\n<ol>\n<li>调大PermSize</li>\n<li>是否有动态加载Groovy脚本</li>\n<li>是否有大量动态生成类的逻辑，如字节码框、或动态代理的使用。</li>\n</ol>\n<h2 id=\"堆内存\"><a href=\"#堆内存\" class=\"headerlink\" title=\"堆内存\"></a>堆内存</h2><h3 id=\"调优参数-1\"><a href=\"#调优参数-1\" class=\"headerlink\" title=\"调优参数\"></a>调优参数</h3><p>-Xmx2G</p>\n<ul>\n<li>年轻代：Eden Survior -XX:NewSize=30m</li>\n<li>老年代<h3 id=\"对应OOM错误信息-1\"><a href=\"#对应OOM错误信息-1\" class=\"headerlink\" title=\"对应OOM错误信息\"></a>对应OOM错误信息</h3>Java heap space/GC overhead limit exceeded<h3 id=\"问题处理-1\"><a href=\"#问题处理-1\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3></li>\n</ul>\n<ol>\n<li><p>产生heapdump </p>\n<p> 1) 启动参数-XX:+HeapDumpOnOutOfMemoryError XX:HeapDumpPath=</p>\n<p> 2) jmap -dump:format=b,file=文件名 [pid] </p>\n</li>\n<li>使用mat工具分析heapdump</li>\n<li>确定内存占用的代码进行优化</li>\n<li><p>如果内存占用不多</p>\n<p> 1) 可能是创建了一个大对象导致，根据日志分析何时会创建大对象。</p>\n<p> 2) 死循环，jstack分析。</p>\n</li>\n</ol>\n<h2 id=\"栈内存\"><a href=\"#栈内存\" class=\"headerlink\" title=\"栈内存\"></a>栈内存</h2><h3 id=\"调优参数-2\"><a href=\"#调优参数-2\" class=\"headerlink\" title=\"调优参数\"></a>调优参数</h3><p>-Xss128，默认2m</p>\n<ul>\n<li>使用的是操作系统的剩余内存，与其他JVM内存区域无关<h3 id=\"对应OOM错误信息-2\"><a href=\"#对应OOM错误信息-2\" class=\"headerlink\" title=\"对应OOM错误信息\"></a>对应OOM错误信息</h3>StackOverflowError,unable to create new native thread<h3 id=\"问题处理-2\"><a href=\"#问题处理-2\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3></li>\n</ul>\n<ol>\n<li>调大-Xss，使每个线程栈的内存增大</li>\n<li>调小-Xmx 等参数，给栈留更多内存空间</li>\n<li>分析是否代码中有不合理的递归</li>\n</ol>\n<h2 id=\"堆外内存\"><a href=\"#堆外内存\" class=\"headerlink\" title=\"堆外内存\"></a>堆外内存</h2><h3 id=\"调优参数-3\"><a href=\"#调优参数-3\" class=\"headerlink\" title=\"调优参数\"></a>调优参数</h3><p>-XX:MaxDirectMemorySize=1G</p>\n<ul>\n<li>DiectBuffer</li>\n<li>如netty直接缓冲区，io操作不需要进行内存的拷贝，性能较优<h3 id=\"对应OOM错误信息-3\"><a href=\"#对应OOM错误信息-3\" class=\"headerlink\" title=\"对应OOM错误信息\"></a>对应OOM错误信息</h3>direct buffer memory<h3 id=\"问题处理-3\"><a href=\"#问题处理-3\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3></li>\n</ul>\n<ol>\n<li>默认占用-Xmx相同内存，可以通过增加参数XX:MaxDirectMemorySize=1G设定</li>\n<li>络通信使用Netty但是未限流</li>\n<li>分析代码中是否使用DirectBuffer未合理控制</li>\n</ol>\n<h2 id=\"最终占用内存-MaxPermSize-Xmx-MaxDirectMemorySize-n-xss\"><a href=\"#最终占用内存-MaxPermSize-Xmx-MaxDirectMemorySize-n-xss\" class=\"headerlink\" title=\"最终占用内存=MaxPermSize+Xmx+MaxDirectMemorySize+n*xss\"></a>最终占用内存=MaxPermSize+Xmx+MaxDirectMemorySize+n*xss</h2><h2 id=\"OutofMemory-Out-of-swap-space解决方案\"><a href=\"#OutofMemory-Out-of-swap-space解决方案\" class=\"headerlink\" title=\"OutofMemory-Out of swap space解决方案\"></a>OutofMemory-Out of swap space解决方案</h2><h3 id=\"问题处理-4\"><a href=\"#问题处理-4\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3><ol>\n<li>地址空间不够，调整系统为64位</li>\n<li><p>物理内存不足</p>\n<p> 1) jmap -histo:live pid，如果内存明显减少说明是DirectBuffer问题，通过设置-XX:MaxDirectMemorySize=1G设定</p>\n<p> 2) btrace Inflater/Deflater</p>\n</li>\n</ol>\n<h2 id=\"OutofMemory-unable-to-create-new-native-thread解决方\"><a href=\"#OutofMemory-unable-to-create-new-native-thread解决方\" class=\"headerlink\" title=\"OutofMemory- unable to create new native thread解决方\"></a>OutofMemory- unable to create new native thread解决方</h2><ol>\n<li><p>线程数超过ulimit限制</p>\n<p> 1) ulimit -a 查看max user process</p>\n<p> 2) 临时调大ulimit -u unlimited</p>\n<p> 3) 永久增加 </p>\n<pre><code>a. * vi /etc/security/limits.conf # 添加如下的行\n\nb. * soft noproc 11000\n\nc. * hard noproc 11000\n\nd. * soft nofile 4100\n\ne. * hard nofile 4100\n</code></pre></li>\n<li><p>线程数超过kernel.pid_max</p>\n<p> 1) /proc/sys/kernel/pid_max #操作系统线程数限制</p>\n<p> 2) /proc/sys/vm/max_map_count #单进程mmap的限制会影响当个进程可创建的线程数</p>\n</li>\n<li><p>线程创建太多</p>\n<p> 1) jstack、pstree查看线程数量，排查谁创建过多线程</p>\n<p> 2) 调小-xss，使每个栈内存占用变小</p>\n</li>\n</ol>\n<h2 id=\"OutofMemory-补充\"><a href=\"#OutofMemory-补充\" class=\"headerlink\" title=\"OutofMemory-补充\"></a>OutofMemory-补充</h2><ol>\n<li>只有heap或Perm区满，才会产生heapDump，其他oom不会产生</li>\n<li><p>如何分析定位问题</p>\n<p> 1) Jvm监控工具（JavaMelody）</p>\n<p> 2) 其他工具 </p>\n<pre><code>a. Greys https://github.com/oldmanpushcart/greys-anatomy\n\nb. TProfile https://github.com/alibaba/TProfiler\n</code></pre></li>\n</ol>\n<h1 id=\"Java进程退出\"><a href=\"#Java进程退出\" class=\"headerlink\" title=\"Java进程退出\"></a>Java进程退出</h1><h1 id=\"CPU占用高\"><a href=\"#CPU占用高\" class=\"headerlink\" title=\"CPU占用高\"></a>CPU占用高</h1><h1 id=\"应用无响应\"><a href=\"#应用无响应\" class=\"headerlink\" title=\"应用无响应\"></a>应用无响应</h1><h1 id=\"环境变量异常\"><a href=\"#环境变量异常\" class=\"headerlink\" title=\"环境变量异常\"></a>环境变量异常</h1><h1 id=\"调用超时\"><a href=\"#调用超时\" class=\"headerlink\" title=\"调用超时\"></a>调用超时</h1>","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文是前段时间公司培训讲到的内容，个人做了笔记进行了总结。通过各类JAVA程序的OOM问题，结合JVM内存模型进行定位以及调优，具体调试的工具以及内容后续会进行补充。</p>\n</blockquote>","more":"<h1 id=\"OOM\"><a href=\"#OOM\" class=\"headerlink\" title=\"OOM\"></a>OOM</h1><h2 id=\"内存模型\"><a href=\"#内存模型\" class=\"headerlink\" title=\"内存模型\"></a>内存模型</h2><p><img src=\"/image/JVM内存模型01.png\" alt=\"JVM内存模型01-photo\"></p>\n<p><img src=\"/image/JVM内存模型02.png\" alt=\"JVM内存模型02-photo\"></p>\n<h2 id=\"非堆内存\"><a href=\"#非堆内存\" class=\"headerlink\" title=\"非堆内存\"></a>非堆内存</h2><h2 id=\"调优参数\"><a href=\"#调优参数\" class=\"headerlink\" title=\"调优参数\"></a>调优参数</h2><p>-XX:MaxPremSize=256MB</p>\n<ul>\n<li>jdk1.7 持久代 使用的虚拟机内存</li>\n<li>jdk1.8之后 源空间 使用的是本地内存<h3 id=\"对应OOM错误信息\"><a href=\"#对应OOM错误信息\" class=\"headerlink\" title=\"对应OOM错误信息\"></a>对应OOM错误信息</h3>PremGen Space<h3 id=\"问题处理\"><a href=\"#问题处理\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3></li>\n</ul>\n<ol>\n<li>调大PermSize</li>\n<li>是否有动态加载Groovy脚本</li>\n<li>是否有大量动态生成类的逻辑，如字节码框、或动态代理的使用。</li>\n</ol>\n<h2 id=\"堆内存\"><a href=\"#堆内存\" class=\"headerlink\" title=\"堆内存\"></a>堆内存</h2><h3 id=\"调优参数-1\"><a href=\"#调优参数-1\" class=\"headerlink\" title=\"调优参数\"></a>调优参数</h3><p>-Xmx2G</p>\n<ul>\n<li>年轻代：Eden Survior -XX:NewSize=30m</li>\n<li>老年代<h3 id=\"对应OOM错误信息-1\"><a href=\"#对应OOM错误信息-1\" class=\"headerlink\" title=\"对应OOM错误信息\"></a>对应OOM错误信息</h3>Java heap space/GC overhead limit exceeded<h3 id=\"问题处理-1\"><a href=\"#问题处理-1\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3></li>\n</ul>\n<ol>\n<li><p>产生heapdump </p>\n<p> 1) 启动参数-XX:+HeapDumpOnOutOfMemoryError XX:HeapDumpPath=</p>\n<p> 2) jmap -dump:format=b,file=文件名 [pid] </p>\n</li>\n<li>使用mat工具分析heapdump</li>\n<li>确定内存占用的代码进行优化</li>\n<li><p>如果内存占用不多</p>\n<p> 1) 可能是创建了一个大对象导致，根据日志分析何时会创建大对象。</p>\n<p> 2) 死循环，jstack分析。</p>\n</li>\n</ol>\n<h2 id=\"栈内存\"><a href=\"#栈内存\" class=\"headerlink\" title=\"栈内存\"></a>栈内存</h2><h3 id=\"调优参数-2\"><a href=\"#调优参数-2\" class=\"headerlink\" title=\"调优参数\"></a>调优参数</h3><p>-Xss128，默认2m</p>\n<ul>\n<li>使用的是操作系统的剩余内存，与其他JVM内存区域无关<h3 id=\"对应OOM错误信息-2\"><a href=\"#对应OOM错误信息-2\" class=\"headerlink\" title=\"对应OOM错误信息\"></a>对应OOM错误信息</h3>StackOverflowError,unable to create new native thread<h3 id=\"问题处理-2\"><a href=\"#问题处理-2\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3></li>\n</ul>\n<ol>\n<li>调大-Xss，使每个线程栈的内存增大</li>\n<li>调小-Xmx 等参数，给栈留更多内存空间</li>\n<li>分析是否代码中有不合理的递归</li>\n</ol>\n<h2 id=\"堆外内存\"><a href=\"#堆外内存\" class=\"headerlink\" title=\"堆外内存\"></a>堆外内存</h2><h3 id=\"调优参数-3\"><a href=\"#调优参数-3\" class=\"headerlink\" title=\"调优参数\"></a>调优参数</h3><p>-XX:MaxDirectMemorySize=1G</p>\n<ul>\n<li>DiectBuffer</li>\n<li>如netty直接缓冲区，io操作不需要进行内存的拷贝，性能较优<h3 id=\"对应OOM错误信息-3\"><a href=\"#对应OOM错误信息-3\" class=\"headerlink\" title=\"对应OOM错误信息\"></a>对应OOM错误信息</h3>direct buffer memory<h3 id=\"问题处理-3\"><a href=\"#问题处理-3\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3></li>\n</ul>\n<ol>\n<li>默认占用-Xmx相同内存，可以通过增加参数XX:MaxDirectMemorySize=1G设定</li>\n<li>络通信使用Netty但是未限流</li>\n<li>分析代码中是否使用DirectBuffer未合理控制</li>\n</ol>\n<h2 id=\"最终占用内存-MaxPermSize-Xmx-MaxDirectMemorySize-n-xss\"><a href=\"#最终占用内存-MaxPermSize-Xmx-MaxDirectMemorySize-n-xss\" class=\"headerlink\" title=\"最终占用内存=MaxPermSize+Xmx+MaxDirectMemorySize+n*xss\"></a>最终占用内存=MaxPermSize+Xmx+MaxDirectMemorySize+n*xss</h2><h2 id=\"OutofMemory-Out-of-swap-space解决方案\"><a href=\"#OutofMemory-Out-of-swap-space解决方案\" class=\"headerlink\" title=\"OutofMemory-Out of swap space解决方案\"></a>OutofMemory-Out of swap space解决方案</h2><h3 id=\"问题处理-4\"><a href=\"#问题处理-4\" class=\"headerlink\" title=\"问题处理\"></a>问题处理</h3><ol>\n<li>地址空间不够，调整系统为64位</li>\n<li><p>物理内存不足</p>\n<p> 1) jmap -histo:live pid，如果内存明显减少说明是DirectBuffer问题，通过设置-XX:MaxDirectMemorySize=1G设定</p>\n<p> 2) btrace Inflater/Deflater</p>\n</li>\n</ol>\n<h2 id=\"OutofMemory-unable-to-create-new-native-thread解决方\"><a href=\"#OutofMemory-unable-to-create-new-native-thread解决方\" class=\"headerlink\" title=\"OutofMemory- unable to create new native thread解决方\"></a>OutofMemory- unable to create new native thread解决方</h2><ol>\n<li><p>线程数超过ulimit限制</p>\n<p> 1) ulimit -a 查看max user process</p>\n<p> 2) 临时调大ulimit -u unlimited</p>\n<p> 3) 永久增加 </p>\n<pre><code>a. * vi /etc/security/limits.conf # 添加如下的行\n\nb. * soft noproc 11000\n\nc. * hard noproc 11000\n\nd. * soft nofile 4100\n\ne. * hard nofile 4100\n</code></pre></li>\n<li><p>线程数超过kernel.pid_max</p>\n<p> 1) /proc/sys/kernel/pid_max #操作系统线程数限制</p>\n<p> 2) /proc/sys/vm/max_map_count #单进程mmap的限制会影响当个进程可创建的线程数</p>\n</li>\n<li><p>线程创建太多</p>\n<p> 1) jstack、pstree查看线程数量，排查谁创建过多线程</p>\n<p> 2) 调小-xss，使每个栈内存占用变小</p>\n</li>\n</ol>\n<h2 id=\"OutofMemory-补充\"><a href=\"#OutofMemory-补充\" class=\"headerlink\" title=\"OutofMemory-补充\"></a>OutofMemory-补充</h2><ol>\n<li>只有heap或Perm区满，才会产生heapDump，其他oom不会产生</li>\n<li><p>如何分析定位问题</p>\n<p> 1) Jvm监控工具（JavaMelody）</p>\n<p> 2) 其他工具 </p>\n<pre><code>a. Greys https://github.com/oldmanpushcart/greys-anatomy\n\nb. TProfile https://github.com/alibaba/TProfiler\n</code></pre></li>\n</ol>\n<h1 id=\"Java进程退出\"><a href=\"#Java进程退出\" class=\"headerlink\" title=\"Java进程退出\"></a>Java进程退出</h1><h1 id=\"CPU占用高\"><a href=\"#CPU占用高\" class=\"headerlink\" title=\"CPU占用高\"></a>CPU占用高</h1><h1 id=\"应用无响应\"><a href=\"#应用无响应\" class=\"headerlink\" title=\"应用无响应\"></a>应用无响应</h1><h1 id=\"环境变量异常\"><a href=\"#环境变量异常\" class=\"headerlink\" title=\"环境变量异常\"></a>环境变量异常</h1><h1 id=\"调用超时\"><a href=\"#调用超时\" class=\"headerlink\" title=\"调用超时\"></a>调用超时</h1>"},{"title":"docker 安装","date":"2019-03-22T02:00:00.000Z","_content":"\n> \n\n<!-- more -->\nDocker目前可以在红帽企业版7(Red Hat Enterprise Linux 7)版本下面安装。\n\nDocker需要一个64位系统的红帽系统，内核的版本必须大于3.10。\n\n\n我用的是阿里云的云服务器，CentOS系统。\n\n先更新现有的yum包\n``` linux\n$ sudo yum update\n```\n\n## 安装docker\ndocker其实有很多种安装方式，看下执行docker安装脚本\n``` linux\n$ curl -sSL http://get.docker.com/ | sh\n```\n安装后可以先用\n``` linux\n$ docker version\n```\n可以看到docker服务已经安装好了，但是还未启动\n``` linux\nClient:\n Version:           18.09.4\n API version:       1.39\n Go version:        go1.10.8\n Git commit:        d14af54266\n Built:             Wed Mar 27 18:34:51 2019\n OS/Arch:           linux/amd64\n Experimental:      false\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n```\n\n## Hello World\n我第一次尝试的时候，是按照docker中文网的教程进行的，直接运行了helloworld\n``` linux\n$ docker run hello-world\n```\n``` linux\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n1b930d010525: Pull complete\nDigest: sha256:2557e3c07ed1e38f26e389462d03ed943586f744621577a99efb77324b0fe535\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n\n```\n其实是可以看到，提示未找到hello-world:latest的镜像在本地，docker默认进行了pulling from library/hello-world的操作，pull image完成后，进行了docker run。\n\n如果需要单独获取镜像的话\n``` linux\n$ docker pull library/hello-world\n```\n上面就是获取image的命令，library/hello-world是image在仓库中的位置，其中library是image文件所在的组，hello-world是image文件的名字。\n\n获取成功后，就可以在宿主机（本机）看到这个image了。\n``` linux\n[root@iZwz91w0kp029z0dmueicoZ /root]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nhello-world         latest              fce289e99eb9        3 months ago        1.84kB\n```\n## 卸载docker\n再简单说下卸载docker\n``` linux\n$ sudo yum remove docker\n```\n\n卸载docker后，/var/lib/docker/目录下会保留原docker的镜像、网络、存储卷等文件，如果需要安装全新的docker，还需要删除/var/lib/docker/目录。\n``` linux\n$ rm -fr /var/lib/docker/\n```\n\n## 好东西\n如果没有主机的，或者觉得安装虚拟机太麻烦的朋友，可以再daocloud.io玩下胶囊机，虽然只能用120分钟，但是简单入门玩下还是ok的。\n\n## 参考资源\n* http://tech.meituan.com/\n","source":"_posts/docker_02_安装.md","raw":"---\ntitle: docker 安装\ndate: 2019-03-22 10:00:00\ntags: docker\ncategories: DevOps\n---\n\n> \n\n<!-- more -->\nDocker目前可以在红帽企业版7(Red Hat Enterprise Linux 7)版本下面安装。\n\nDocker需要一个64位系统的红帽系统，内核的版本必须大于3.10。\n\n\n我用的是阿里云的云服务器，CentOS系统。\n\n先更新现有的yum包\n``` linux\n$ sudo yum update\n```\n\n## 安装docker\ndocker其实有很多种安装方式，看下执行docker安装脚本\n``` linux\n$ curl -sSL http://get.docker.com/ | sh\n```\n安装后可以先用\n``` linux\n$ docker version\n```\n可以看到docker服务已经安装好了，但是还未启动\n``` linux\nClient:\n Version:           18.09.4\n API version:       1.39\n Go version:        go1.10.8\n Git commit:        d14af54266\n Built:             Wed Mar 27 18:34:51 2019\n OS/Arch:           linux/amd64\n Experimental:      false\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n```\n\n## Hello World\n我第一次尝试的时候，是按照docker中文网的教程进行的，直接运行了helloworld\n``` linux\n$ docker run hello-world\n```\n``` linux\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n1b930d010525: Pull complete\nDigest: sha256:2557e3c07ed1e38f26e389462d03ed943586f744621577a99efb77324b0fe535\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n\n```\n其实是可以看到，提示未找到hello-world:latest的镜像在本地，docker默认进行了pulling from library/hello-world的操作，pull image完成后，进行了docker run。\n\n如果需要单独获取镜像的话\n``` linux\n$ docker pull library/hello-world\n```\n上面就是获取image的命令，library/hello-world是image在仓库中的位置，其中library是image文件所在的组，hello-world是image文件的名字。\n\n获取成功后，就可以在宿主机（本机）看到这个image了。\n``` linux\n[root@iZwz91w0kp029z0dmueicoZ /root]# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nhello-world         latest              fce289e99eb9        3 months ago        1.84kB\n```\n## 卸载docker\n再简单说下卸载docker\n``` linux\n$ sudo yum remove docker\n```\n\n卸载docker后，/var/lib/docker/目录下会保留原docker的镜像、网络、存储卷等文件，如果需要安装全新的docker，还需要删除/var/lib/docker/目录。\n``` linux\n$ rm -fr /var/lib/docker/\n```\n\n## 好东西\n如果没有主机的，或者觉得安装虚拟机太麻烦的朋友，可以再daocloud.io玩下胶囊机，虽然只能用120分钟，但是简单入门玩下还是ok的。\n\n## 参考资源\n* http://tech.meituan.com/\n","slug":"docker_02_安装","published":1,"updated":"2019-08-26T07:50:35.066Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkzg0009qotn3h6ow8nt","content":"<blockquote>\n</blockquote>\n<a id=\"more\"></a>\n<p>Docker目前可以在红帽企业版7(Red Hat Enterprise Linux 7)版本下面安装。</p>\n<p>Docker需要一个64位系统的红帽系统，内核的版本必须大于3.10。</p>\n<p>我用的是阿里云的云服务器，CentOS系统。</p>\n<p>先更新现有的yum包<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum update</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"安装docker\"><a href=\"#安装docker\" class=\"headerlink\" title=\"安装docker\"></a>安装docker</h2><p>docker其实有很多种安装方式，看下执行docker安装脚本<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -sSL http://get.docker.com/ | sh</span><br></pre></td></tr></table></figure></p>\n<p>安装后可以先用<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker version</span><br></pre></td></tr></table></figure></p>\n<p>可以看到docker服务已经安装好了，但是还未启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Client:</span><br><span class=\"line\"> Version:           18.09.4</span><br><span class=\"line\"> API version:       1.39</span><br><span class=\"line\"> Go version:        go1.10.8</span><br><span class=\"line\"> Git commit:        d14af54266</span><br><span class=\"line\"> Built:             Wed Mar 27 18:34:51 2019</span><br><span class=\"line\"> OS/Arch:           linux/amd64</span><br><span class=\"line\"> Experimental:      false</span><br><span class=\"line\">Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Hello-World\"><a href=\"#Hello-World\" class=\"headerlink\" title=\"Hello World\"></a>Hello World</h2><p>我第一次尝试的时候，是按照docker中文网的教程进行的，直接运行了helloworld<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run hello-world</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Unable to find image &apos;hello-world:latest&apos; locally</span><br><span class=\"line\">latest: Pulling from library/hello-world</span><br><span class=\"line\">1b930d010525: Pull complete</span><br><span class=\"line\">Digest: sha256:2557e3c07ed1e38f26e389462d03ed943586f744621577a99efb77324b0fe535</span><br><span class=\"line\">Status: Downloaded newer image for hello-world:latest</span><br><span class=\"line\"></span><br><span class=\"line\">Hello from Docker!</span><br><span class=\"line\">This message shows that your installation appears to be working correctly.</span><br><span class=\"line\"></span><br><span class=\"line\">To generate this message, Docker took the following steps:</span><br><span class=\"line\"> 1. The Docker client contacted the Docker daemon.</span><br><span class=\"line\"> 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub.</span><br><span class=\"line\">    (amd64)</span><br><span class=\"line\"> 3. The Docker daemon created a new container from that image which runs the</span><br><span class=\"line\">    executable that produces the output you are currently reading.</span><br><span class=\"line\"> 4. The Docker daemon streamed that output to the Docker client, which sent it</span><br><span class=\"line\">    to your terminal.</span><br><span class=\"line\"></span><br><span class=\"line\">To try something more ambitious, you can run an Ubuntu container with:</span><br><span class=\"line\"> $ docker run -it ubuntu bash</span><br><span class=\"line\"></span><br><span class=\"line\">Share images, automate workflows, and more with a free Docker ID:</span><br><span class=\"line\"> https://hub.docker.com/</span><br><span class=\"line\"></span><br><span class=\"line\">For more examples and ideas, visit:</span><br><span class=\"line\"> https://docs.docker.com/get-started/</span><br></pre></td></tr></table></figure>\n<p>其实是可以看到，提示未找到hello-world:latest的镜像在本地，docker默认进行了pulling from library/hello-world的操作，pull image完成后，进行了docker run。</p>\n<p>如果需要单独获取镜像的话<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker pull library/hello-world</span><br></pre></td></tr></table></figure></p>\n<p>上面就是获取image的命令，library/hello-world是image在仓库中的位置，其中library是image文件所在的组，hello-world是image文件的名字。</p>\n<p>获取成功后，就可以在宿主机（本机）看到这个image了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]# docker images</span><br><span class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">hello-world         latest              fce289e99eb9        3 months ago        1.84kB</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"卸载docker\"><a href=\"#卸载docker\" class=\"headerlink\" title=\"卸载docker\"></a>卸载docker</h2><p>再简单说下卸载docker<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum remove docker</span><br></pre></td></tr></table></figure></p>\n<p>卸载docker后，/var/lib/docker/目录下会保留原docker的镜像、网络、存储卷等文件，如果需要安装全新的docker，还需要删除/var/lib/docker/目录。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -fr /var/lib/docker/</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"好东西\"><a href=\"#好东西\" class=\"headerlink\" title=\"好东西\"></a>好东西</h2><p>如果没有主机的，或者觉得安装虚拟机太麻烦的朋友，可以再daocloud.io玩下胶囊机，虽然只能用120分钟，但是简单入门玩下还是ok的。</p>\n<h2 id=\"参考资源\"><a href=\"#参考资源\" class=\"headerlink\" title=\"参考资源\"></a>参考资源</h2><ul>\n<li><a href=\"http://tech.meituan.com/\" target=\"_blank\" rel=\"noopener\">http://tech.meituan.com/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n</blockquote>","more":"<p>Docker目前可以在红帽企业版7(Red Hat Enterprise Linux 7)版本下面安装。</p>\n<p>Docker需要一个64位系统的红帽系统，内核的版本必须大于3.10。</p>\n<p>我用的是阿里云的云服务器，CentOS系统。</p>\n<p>先更新现有的yum包<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum update</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"安装docker\"><a href=\"#安装docker\" class=\"headerlink\" title=\"安装docker\"></a>安装docker</h2><p>docker其实有很多种安装方式，看下执行docker安装脚本<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -sSL http://get.docker.com/ | sh</span><br></pre></td></tr></table></figure></p>\n<p>安装后可以先用<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker version</span><br></pre></td></tr></table></figure></p>\n<p>可以看到docker服务已经安装好了，但是还未启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Client:</span><br><span class=\"line\"> Version:           18.09.4</span><br><span class=\"line\"> API version:       1.39</span><br><span class=\"line\"> Go version:        go1.10.8</span><br><span class=\"line\"> Git commit:        d14af54266</span><br><span class=\"line\"> Built:             Wed Mar 27 18:34:51 2019</span><br><span class=\"line\"> OS/Arch:           linux/amd64</span><br><span class=\"line\"> Experimental:      false</span><br><span class=\"line\">Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Hello-World\"><a href=\"#Hello-World\" class=\"headerlink\" title=\"Hello World\"></a>Hello World</h2><p>我第一次尝试的时候，是按照docker中文网的教程进行的，直接运行了helloworld<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run hello-world</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Unable to find image &apos;hello-world:latest&apos; locally</span><br><span class=\"line\">latest: Pulling from library/hello-world</span><br><span class=\"line\">1b930d010525: Pull complete</span><br><span class=\"line\">Digest: sha256:2557e3c07ed1e38f26e389462d03ed943586f744621577a99efb77324b0fe535</span><br><span class=\"line\">Status: Downloaded newer image for hello-world:latest</span><br><span class=\"line\"></span><br><span class=\"line\">Hello from Docker!</span><br><span class=\"line\">This message shows that your installation appears to be working correctly.</span><br><span class=\"line\"></span><br><span class=\"line\">To generate this message, Docker took the following steps:</span><br><span class=\"line\"> 1. The Docker client contacted the Docker daemon.</span><br><span class=\"line\"> 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub.</span><br><span class=\"line\">    (amd64)</span><br><span class=\"line\"> 3. The Docker daemon created a new container from that image which runs the</span><br><span class=\"line\">    executable that produces the output you are currently reading.</span><br><span class=\"line\"> 4. The Docker daemon streamed that output to the Docker client, which sent it</span><br><span class=\"line\">    to your terminal.</span><br><span class=\"line\"></span><br><span class=\"line\">To try something more ambitious, you can run an Ubuntu container with:</span><br><span class=\"line\"> $ docker run -it ubuntu bash</span><br><span class=\"line\"></span><br><span class=\"line\">Share images, automate workflows, and more with a free Docker ID:</span><br><span class=\"line\"> https://hub.docker.com/</span><br><span class=\"line\"></span><br><span class=\"line\">For more examples and ideas, visit:</span><br><span class=\"line\"> https://docs.docker.com/get-started/</span><br></pre></td></tr></table></figure>\n<p>其实是可以看到，提示未找到hello-world:latest的镜像在本地，docker默认进行了pulling from library/hello-world的操作，pull image完成后，进行了docker run。</p>\n<p>如果需要单独获取镜像的话<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker pull library/hello-world</span><br></pre></td></tr></table></figure></p>\n<p>上面就是获取image的命令，library/hello-world是image在仓库中的位置，其中library是image文件所在的组，hello-world是image文件的名字。</p>\n<p>获取成功后，就可以在宿主机（本机）看到这个image了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]# docker images</span><br><span class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">hello-world         latest              fce289e99eb9        3 months ago        1.84kB</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"卸载docker\"><a href=\"#卸载docker\" class=\"headerlink\" title=\"卸载docker\"></a>卸载docker</h2><p>再简单说下卸载docker<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum remove docker</span><br></pre></td></tr></table></figure></p>\n<p>卸载docker后，/var/lib/docker/目录下会保留原docker的镜像、网络、存储卷等文件，如果需要安装全新的docker，还需要删除/var/lib/docker/目录。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm -fr /var/lib/docker/</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"好东西\"><a href=\"#好东西\" class=\"headerlink\" title=\"好东西\"></a>好东西</h2><p>如果没有主机的，或者觉得安装虚拟机太麻烦的朋友，可以再daocloud.io玩下胶囊机，虽然只能用120分钟，但是简单入门玩下还是ok的。</p>\n<h2 id=\"参考资源\"><a href=\"#参考资源\" class=\"headerlink\" title=\"参考资源\"></a>参考资源</h2><ul>\n<li><a href=\"http://tech.meituan.com/\" target=\"_blank\" rel=\"noopener\">http://tech.meituan.com/</a></li>\n</ul>"},{"title":"docker 容器使用","date":"2019-08-21T09:00:00.000Z","_content":"\n>\n\n<!-- more -->\n\n# 运行WEB应用\n## 拉取测试镜像\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker pull training/webapp\nUsing default tag: latest\nlatest: Pulling from training/webapp\ne190868d63f8: Pull complete\n909cd34c6fd7: Pull complete\n0b9bfabab7c1: Pull complete\na3ed95caeb02: Pull complete\n10bbbc0fc0ff: Pull complete\nfca59b508e9f: Pull complete\ne7ae2541b15b: Pull complete\n9dd97ef58ce9: Pull complete\na4c1b0cb7af7: Pull complete\nDigest: sha256:06e9c1983bd6d5db5fba376ccd63bfa529e8d02f23d5079b8f74a616308fb11d\nStatus: Downloaded newer image for training/webapp:latest\n```\n\n## 运行镜像\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -P training/webapp python app.py\n76fd8c2738182275dc0d6ff1a8b7c72caa0d7acc96fa640375d1f967cce3b0d1\n```\n- -d: 让容器在后台运行\n- -P: 将容器内部使用的网络端口映射到我们使用的主机上\n\n## 查看运行中的容器\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES\n76fd8c273818        training/webapp     \"python app.py\"     16 minutes ago      Up 16 minutes       0.0.0.0:32768->5000/tcp   dreamy_burnell\n```\n- PORTS 0.0.0.0:32768->5000/tcp，5000是容器监听的端口，映射到宿主机的32768端口。\n\n这时候通过docker宿主机的ip:32768就可以直接访问了\n\n## 运行镜像并修改监听端口\n也可以通过-p参数设置不同的端口\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -p 5000:5000 training/webapp python app.py\n1d7a7e33cdf674a0374e908613f1bd0ebe08a649d2b681e2afab6d25550ca6ba\n```\n\n再查看下\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES\n1d7a7e33cdf6        training/webapp     \"python app.py\"     5 seconds ago       Up 4 seconds        0.0.0.0:5000->5000/tcp    vigorous_murdock\n76fd8c273818        training/webapp     \"python app.py\"     31 minutes ago      Up 31 minutes       0.0.0.0:32768->5000/tcp   dreamy_burnell\n```\n\n这时候通过ip:5000也是可以访问的\n\n## 观察容器状态\n### 网络端口\n这时候可以先查下网络端口映射\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker port 1d7a7e33cdf6\n0.0.0.0:5000->5000/tcp\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker port 76fd8c273818\n0.0.0.0:32768->5000/tcp\n```\n\n### 应用程序日志\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs 006fdd129e49\n * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n```\n也可以加参数-f追踪查看最新打印的日志。\n\n### 查看容器进程\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker top 006fdd129e49\nUID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD\nroot                30384               30366               0                   10:15               ?                   00:00:00            python app.py\n```\n\n## 停止容器\n我们可以通过docker stop container_id来停止指定的容器。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker stop 1d7a7e33cdf6\n```\n这时再通过docker ps发现5000端口的webapp的容器已经没有了。","source":"_posts/docker_05_容器的使用.md","raw":"---\ntitle: docker 容器使用\ndate: 2019-08-21 17:00:00\ntags: docker\ncategories: DevOps\n---\n\n>\n\n<!-- more -->\n\n# 运行WEB应用\n## 拉取测试镜像\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker pull training/webapp\nUsing default tag: latest\nlatest: Pulling from training/webapp\ne190868d63f8: Pull complete\n909cd34c6fd7: Pull complete\n0b9bfabab7c1: Pull complete\na3ed95caeb02: Pull complete\n10bbbc0fc0ff: Pull complete\nfca59b508e9f: Pull complete\ne7ae2541b15b: Pull complete\n9dd97ef58ce9: Pull complete\na4c1b0cb7af7: Pull complete\nDigest: sha256:06e9c1983bd6d5db5fba376ccd63bfa529e8d02f23d5079b8f74a616308fb11d\nStatus: Downloaded newer image for training/webapp:latest\n```\n\n## 运行镜像\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -P training/webapp python app.py\n76fd8c2738182275dc0d6ff1a8b7c72caa0d7acc96fa640375d1f967cce3b0d1\n```\n- -d: 让容器在后台运行\n- -P: 将容器内部使用的网络端口映射到我们使用的主机上\n\n## 查看运行中的容器\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES\n76fd8c273818        training/webapp     \"python app.py\"     16 minutes ago      Up 16 minutes       0.0.0.0:32768->5000/tcp   dreamy_burnell\n```\n- PORTS 0.0.0.0:32768->5000/tcp，5000是容器监听的端口，映射到宿主机的32768端口。\n\n这时候通过docker宿主机的ip:32768就可以直接访问了\n\n## 运行镜像并修改监听端口\n也可以通过-p参数设置不同的端口\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -p 5000:5000 training/webapp python app.py\n1d7a7e33cdf674a0374e908613f1bd0ebe08a649d2b681e2afab6d25550ca6ba\n```\n\n再查看下\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES\n1d7a7e33cdf6        training/webapp     \"python app.py\"     5 seconds ago       Up 4 seconds        0.0.0.0:5000->5000/tcp    vigorous_murdock\n76fd8c273818        training/webapp     \"python app.py\"     31 minutes ago      Up 31 minutes       0.0.0.0:32768->5000/tcp   dreamy_burnell\n```\n\n这时候通过ip:5000也是可以访问的\n\n## 观察容器状态\n### 网络端口\n这时候可以先查下网络端口映射\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker port 1d7a7e33cdf6\n0.0.0.0:5000->5000/tcp\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker port 76fd8c273818\n0.0.0.0:32768->5000/tcp\n```\n\n### 应用程序日志\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs 006fdd129e49\n * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n```\n也可以加参数-f追踪查看最新打印的日志。\n\n### 查看容器进程\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker top 006fdd129e49\nUID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD\nroot                30384               30366               0                   10:15               ?                   00:00:00            python app.py\n```\n\n## 停止容器\n我们可以通过docker stop container_id来停止指定的容器。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker stop 1d7a7e33cdf6\n```\n这时再通过docker ps发现5000端口的webapp的容器已经没有了。","slug":"docker_05_容器的使用","published":1,"updated":"2019-08-26T07:50:50.678Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkzj000aqotnrz093ln8","content":"<blockquote>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"运行WEB应用\"><a href=\"#运行WEB应用\" class=\"headerlink\" title=\"运行WEB应用\"></a>运行WEB应用</h1><h2 id=\"拉取测试镜像\"><a href=\"#拉取测试镜像\" class=\"headerlink\" title=\"拉取测试镜像\"></a>拉取测试镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker pull training/webapp</span><br><span class=\"line\">Using default tag: latest</span><br><span class=\"line\">latest: Pulling from training/webapp</span><br><span class=\"line\">e190868d63f8: Pull complete</span><br><span class=\"line\">909cd34c6fd7: Pull complete</span><br><span class=\"line\">0b9bfabab7c1: Pull complete</span><br><span class=\"line\">a3ed95caeb02: Pull complete</span><br><span class=\"line\">10bbbc0fc0ff: Pull complete</span><br><span class=\"line\">fca59b508e9f: Pull complete</span><br><span class=\"line\">e7ae2541b15b: Pull complete</span><br><span class=\"line\">9dd97ef58ce9: Pull complete</span><br><span class=\"line\">a4c1b0cb7af7: Pull complete</span><br><span class=\"line\">Digest: sha256:06e9c1983bd6d5db5fba376ccd63bfa529e8d02f23d5079b8f74a616308fb11d</span><br><span class=\"line\">Status: Downloaded newer image for training/webapp:latest</span><br></pre></td></tr></table></figure>\n<h2 id=\"运行镜像\"><a href=\"#运行镜像\" class=\"headerlink\" title=\"运行镜像\"></a>运行镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -P training/webapp python app.py</span><br><span class=\"line\">76fd8c2738182275dc0d6ff1a8b7c72caa0d7acc96fa640375d1f967cce3b0d1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>-d: 让容器在后台运行</li>\n<li>-P: 将容器内部使用的网络端口映射到我们使用的主机上</li>\n</ul>\n<h2 id=\"查看运行中的容器\"><a href=\"#查看运行中的容器\" class=\"headerlink\" title=\"查看运行中的容器\"></a>查看运行中的容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class=\"line\">76fd8c273818        training/webapp     &quot;python app.py&quot;     16 minutes ago      Up 16 minutes       0.0.0.0:32768-&gt;5000/tcp   dreamy_burnell</span><br></pre></td></tr></table></figure>\n<ul>\n<li>PORTS 0.0.0.0:32768-&gt;5000/tcp，5000是容器监听的端口，映射到宿主机的32768端口。</li>\n</ul>\n<p>这时候通过docker宿主机的ip:32768就可以直接访问了</p>\n<h2 id=\"运行镜像并修改监听端口\"><a href=\"#运行镜像并修改监听端口\" class=\"headerlink\" title=\"运行镜像并修改监听端口\"></a>运行镜像并修改监听端口</h2><p>也可以通过-p参数设置不同的端口<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -p 5000:5000 training/webapp python app.py</span><br><span class=\"line\">1d7a7e33cdf674a0374e908613f1bd0ebe08a649d2b681e2afab6d25550ca6ba</span><br></pre></td></tr></table></figure></p>\n<p>再查看下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class=\"line\">1d7a7e33cdf6        training/webapp     &quot;python app.py&quot;     5 seconds ago       Up 4 seconds        0.0.0.0:5000-&gt;5000/tcp    vigorous_murdock</span><br><span class=\"line\">76fd8c273818        training/webapp     &quot;python app.py&quot;     31 minutes ago      Up 31 minutes       0.0.0.0:32768-&gt;5000/tcp   dreamy_burnell</span><br></pre></td></tr></table></figure></p>\n<p>这时候通过ip:5000也是可以访问的</p>\n<h2 id=\"观察容器状态\"><a href=\"#观察容器状态\" class=\"headerlink\" title=\"观察容器状态\"></a>观察容器状态</h2><h3 id=\"网络端口\"><a href=\"#网络端口\" class=\"headerlink\" title=\"网络端口\"></a>网络端口</h3><p>这时候可以先查下网络端口映射<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker port 1d7a7e33cdf6</span><br><span class=\"line\">0.0.0.0:5000-&gt;5000/tcp</span><br><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker port 76fd8c273818</span><br><span class=\"line\">0.0.0.0:32768-&gt;5000/tcp</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"应用程序日志\"><a href=\"#应用程序日志\" class=\"headerlink\" title=\"应用程序日志\"></a>应用程序日志</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs 006fdd129e49</span><br><span class=\"line\"> * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure>\n<p>也可以加参数-f追踪查看最新打印的日志。</p>\n<h3 id=\"查看容器进程\"><a href=\"#查看容器进程\" class=\"headerlink\" title=\"查看容器进程\"></a>查看容器进程</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker top 006fdd129e49</span><br><span class=\"line\">UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD</span><br><span class=\"line\">root                30384               30366               0                   10:15               ?                   00:00:00            python app.py</span><br></pre></td></tr></table></figure>\n<h2 id=\"停止容器\"><a href=\"#停止容器\" class=\"headerlink\" title=\"停止容器\"></a>停止容器</h2><p>我们可以通过docker stop container_id来停止指定的容器。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker stop 1d7a7e33cdf6</span><br></pre></td></tr></table></figure></p>\n<p>这时再通过docker ps发现5000端口的webapp的容器已经没有了。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n</blockquote>","more":"<h1 id=\"运行WEB应用\"><a href=\"#运行WEB应用\" class=\"headerlink\" title=\"运行WEB应用\"></a>运行WEB应用</h1><h2 id=\"拉取测试镜像\"><a href=\"#拉取测试镜像\" class=\"headerlink\" title=\"拉取测试镜像\"></a>拉取测试镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker pull training/webapp</span><br><span class=\"line\">Using default tag: latest</span><br><span class=\"line\">latest: Pulling from training/webapp</span><br><span class=\"line\">e190868d63f8: Pull complete</span><br><span class=\"line\">909cd34c6fd7: Pull complete</span><br><span class=\"line\">0b9bfabab7c1: Pull complete</span><br><span class=\"line\">a3ed95caeb02: Pull complete</span><br><span class=\"line\">10bbbc0fc0ff: Pull complete</span><br><span class=\"line\">fca59b508e9f: Pull complete</span><br><span class=\"line\">e7ae2541b15b: Pull complete</span><br><span class=\"line\">9dd97ef58ce9: Pull complete</span><br><span class=\"line\">a4c1b0cb7af7: Pull complete</span><br><span class=\"line\">Digest: sha256:06e9c1983bd6d5db5fba376ccd63bfa529e8d02f23d5079b8f74a616308fb11d</span><br><span class=\"line\">Status: Downloaded newer image for training/webapp:latest</span><br></pre></td></tr></table></figure>\n<h2 id=\"运行镜像\"><a href=\"#运行镜像\" class=\"headerlink\" title=\"运行镜像\"></a>运行镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -P training/webapp python app.py</span><br><span class=\"line\">76fd8c2738182275dc0d6ff1a8b7c72caa0d7acc96fa640375d1f967cce3b0d1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>-d: 让容器在后台运行</li>\n<li>-P: 将容器内部使用的网络端口映射到我们使用的主机上</li>\n</ul>\n<h2 id=\"查看运行中的容器\"><a href=\"#查看运行中的容器\" class=\"headerlink\" title=\"查看运行中的容器\"></a>查看运行中的容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class=\"line\">76fd8c273818        training/webapp     &quot;python app.py&quot;     16 minutes ago      Up 16 minutes       0.0.0.0:32768-&gt;5000/tcp   dreamy_burnell</span><br></pre></td></tr></table></figure>\n<ul>\n<li>PORTS 0.0.0.0:32768-&gt;5000/tcp，5000是容器监听的端口，映射到宿主机的32768端口。</li>\n</ul>\n<p>这时候通过docker宿主机的ip:32768就可以直接访问了</p>\n<h2 id=\"运行镜像并修改监听端口\"><a href=\"#运行镜像并修改监听端口\" class=\"headerlink\" title=\"运行镜像并修改监听端口\"></a>运行镜像并修改监听端口</h2><p>也可以通过-p参数设置不同的端口<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -p 5000:5000 training/webapp python app.py</span><br><span class=\"line\">1d7a7e33cdf674a0374e908613f1bd0ebe08a649d2b681e2afab6d25550ca6ba</span><br></pre></td></tr></table></figure></p>\n<p>再查看下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                     NAMES</span><br><span class=\"line\">1d7a7e33cdf6        training/webapp     &quot;python app.py&quot;     5 seconds ago       Up 4 seconds        0.0.0.0:5000-&gt;5000/tcp    vigorous_murdock</span><br><span class=\"line\">76fd8c273818        training/webapp     &quot;python app.py&quot;     31 minutes ago      Up 31 minutes       0.0.0.0:32768-&gt;5000/tcp   dreamy_burnell</span><br></pre></td></tr></table></figure></p>\n<p>这时候通过ip:5000也是可以访问的</p>\n<h2 id=\"观察容器状态\"><a href=\"#观察容器状态\" class=\"headerlink\" title=\"观察容器状态\"></a>观察容器状态</h2><h3 id=\"网络端口\"><a href=\"#网络端口\" class=\"headerlink\" title=\"网络端口\"></a>网络端口</h3><p>这时候可以先查下网络端口映射<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker port 1d7a7e33cdf6</span><br><span class=\"line\">0.0.0.0:5000-&gt;5000/tcp</span><br><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker port 76fd8c273818</span><br><span class=\"line\">0.0.0.0:32768-&gt;5000/tcp</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"应用程序日志\"><a href=\"#应用程序日志\" class=\"headerlink\" title=\"应用程序日志\"></a>应用程序日志</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs 006fdd129e49</span><br><span class=\"line\"> * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure>\n<p>也可以加参数-f追踪查看最新打印的日志。</p>\n<h3 id=\"查看容器进程\"><a href=\"#查看容器进程\" class=\"headerlink\" title=\"查看容器进程\"></a>查看容器进程</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker top 006fdd129e49</span><br><span class=\"line\">UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD</span><br><span class=\"line\">root                30384               30366               0                   10:15               ?                   00:00:00            python app.py</span><br></pre></td></tr></table></figure>\n<h2 id=\"停止容器\"><a href=\"#停止容器\" class=\"headerlink\" title=\"停止容器\"></a>停止容器</h2><p>我们可以通过docker stop container_id来停止指定的容器。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker stop 1d7a7e33cdf6</span><br></pre></td></tr></table></figure></p>\n<p>这时再通过docker ps发现5000端口的webapp的容器已经没有了。</p>"},{"title":"docker 简介","date":"2019-03-21T02:00:00.000Z","_content":"\n> 大概一年前接触微服务后就听说过容器化、docker这些名词了，草草了解了之后一直没有实践开始学习过，对于DevOps而言，容器化、以及容器编排都是非常重要的技术，现在开始着手学习并且记录下学习的笔记。\n\n<!-- more -->\n## 什么是Docker\nDcoker是一个开源的应用容器引擎，基于Go语言并遵从Apache2.0协议开源。\n\nDocker可以轻松的为任何应用创建一个轻量的、可移植的、自给自足的容器。开发者进行编写后测试通过的容器，可以批量的在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack集群和其他基础应用平台。\n\n## 什么是容器\n其实容器是一种虚拟化的方案。容器是完全使用沙箱机制，相互之间不会有任何接口，最重要的是容器的性能开销相比传统的虚拟机性能开销低。\n\n## Docker的好处\n1. 更快的交付和部署\n\n    对于开发、运维人员来说，最希望的就是一次创建和配置，可以在任意环境运行。\n\n    开发人员可以构建标准的镜像，开发完成后，运维人员可以直接使用这个镜像启动一个应用容器。Docker可以快速创建容器，快速迭代应用程序，大量的节省了开发、测试、运维部署的时间。\n\n2. 更高效的虚拟化\n\n    Docker容器的运行不需要额外的Hypervisor支持，他是内核级的虚拟化，因此可以实现更高的性能和效率。\n\n## 相关概念\nDocker是CS架构的应用，主要以下几种组成：\n* Docker daemon： 运行再宿主机上，Docker的守护进程，用户通过Docker client（docker命令行）进行交互\n* Docker client：Docker的命令行工具，是用户使用Docker的主要途径，Docker client也可以通过socket或者RESTful api访问远程的Docker deamon\n* Docker image：Docker镜像，是只读的，镜像中包含有需要运行的文件，通过镜像来创建container，一个镜像可以运行多个container；镜像可以通过Dockerfile创建，也可以通过Docker hub/registry下载官方或者个人创建好的镜像。\n* Docker container：容器是docker运行的组件，也是一个程序的最小单元。容器是一个隔离的环境，多个容器之间不会互相影响，来保证容器中的程序运行在一个相对安全独立的环境中\n* Docker hub/registry：共享和管理Docker镜像，用户可以上传或者下载镜像，官方地址位https://registry.hub.docker.com/，也可以搭建私有的Docker registry\n\n总结：镜像就相当于打包好的应用，镜像启动了之后运行在容器中，而通过dockerfile制作或者下载docker镜像后可以放在仓库中存储。\n\n\n## 参考资料\n* http://www.runoob.com/docker/docker-tutorial.html\n* http://www.docker.org.cn/","source":"_posts/docker_01_简介.md","raw":"---\ntitle: docker 简介\ndate: 2019-03-21 10:00:00\ntags: docker\ncategories: DevOps\n---\n\n> 大概一年前接触微服务后就听说过容器化、docker这些名词了，草草了解了之后一直没有实践开始学习过，对于DevOps而言，容器化、以及容器编排都是非常重要的技术，现在开始着手学习并且记录下学习的笔记。\n\n<!-- more -->\n## 什么是Docker\nDcoker是一个开源的应用容器引擎，基于Go语言并遵从Apache2.0协议开源。\n\nDocker可以轻松的为任何应用创建一个轻量的、可移植的、自给自足的容器。开发者进行编写后测试通过的容器，可以批量的在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack集群和其他基础应用平台。\n\n## 什么是容器\n其实容器是一种虚拟化的方案。容器是完全使用沙箱机制，相互之间不会有任何接口，最重要的是容器的性能开销相比传统的虚拟机性能开销低。\n\n## Docker的好处\n1. 更快的交付和部署\n\n    对于开发、运维人员来说，最希望的就是一次创建和配置，可以在任意环境运行。\n\n    开发人员可以构建标准的镜像，开发完成后，运维人员可以直接使用这个镜像启动一个应用容器。Docker可以快速创建容器，快速迭代应用程序，大量的节省了开发、测试、运维部署的时间。\n\n2. 更高效的虚拟化\n\n    Docker容器的运行不需要额外的Hypervisor支持，他是内核级的虚拟化，因此可以实现更高的性能和效率。\n\n## 相关概念\nDocker是CS架构的应用，主要以下几种组成：\n* Docker daemon： 运行再宿主机上，Docker的守护进程，用户通过Docker client（docker命令行）进行交互\n* Docker client：Docker的命令行工具，是用户使用Docker的主要途径，Docker client也可以通过socket或者RESTful api访问远程的Docker deamon\n* Docker image：Docker镜像，是只读的，镜像中包含有需要运行的文件，通过镜像来创建container，一个镜像可以运行多个container；镜像可以通过Dockerfile创建，也可以通过Docker hub/registry下载官方或者个人创建好的镜像。\n* Docker container：容器是docker运行的组件，也是一个程序的最小单元。容器是一个隔离的环境，多个容器之间不会互相影响，来保证容器中的程序运行在一个相对安全独立的环境中\n* Docker hub/registry：共享和管理Docker镜像，用户可以上传或者下载镜像，官方地址位https://registry.hub.docker.com/，也可以搭建私有的Docker registry\n\n总结：镜像就相当于打包好的应用，镜像启动了之后运行在容器中，而通过dockerfile制作或者下载docker镜像后可以放在仓库中存储。\n\n\n## 参考资料\n* http://www.runoob.com/docker/docker-tutorial.html\n* http://www.docker.org.cn/","slug":"docker_01_简介","published":1,"updated":"2019-08-26T07:50:30.477Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkzn000eqotnqbg61t16","content":"<blockquote>\n<p>大概一年前接触微服务后就听说过容器化、docker这些名词了，草草了解了之后一直没有实践开始学习过，对于DevOps而言，容器化、以及容器编排都是非常重要的技术，现在开始着手学习并且记录下学习的笔记。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"什么是Docker\"><a href=\"#什么是Docker\" class=\"headerlink\" title=\"什么是Docker\"></a>什么是Docker</h2><p>Dcoker是一个开源的应用容器引擎，基于Go语言并遵从Apache2.0协议开源。</p>\n<p>Docker可以轻松的为任何应用创建一个轻量的、可移植的、自给自足的容器。开发者进行编写后测试通过的容器，可以批量的在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack集群和其他基础应用平台。</p>\n<h2 id=\"什么是容器\"><a href=\"#什么是容器\" class=\"headerlink\" title=\"什么是容器\"></a>什么是容器</h2><p>其实容器是一种虚拟化的方案。容器是完全使用沙箱机制，相互之间不会有任何接口，最重要的是容器的性能开销相比传统的虚拟机性能开销低。</p>\n<h2 id=\"Docker的好处\"><a href=\"#Docker的好处\" class=\"headerlink\" title=\"Docker的好处\"></a>Docker的好处</h2><ol>\n<li><p>更快的交付和部署</p>\n<p> 对于开发、运维人员来说，最希望的就是一次创建和配置，可以在任意环境运行。</p>\n<p> 开发人员可以构建标准的镜像，开发完成后，运维人员可以直接使用这个镜像启动一个应用容器。Docker可以快速创建容器，快速迭代应用程序，大量的节省了开发、测试、运维部署的时间。</p>\n</li>\n<li><p>更高效的虚拟化</p>\n<p> Docker容器的运行不需要额外的Hypervisor支持，他是内核级的虚拟化，因此可以实现更高的性能和效率。</p>\n</li>\n</ol>\n<h2 id=\"相关概念\"><a href=\"#相关概念\" class=\"headerlink\" title=\"相关概念\"></a>相关概念</h2><p>Docker是CS架构的应用，主要以下几种组成：</p>\n<ul>\n<li>Docker daemon： 运行再宿主机上，Docker的守护进程，用户通过Docker client（docker命令行）进行交互</li>\n<li>Docker client：Docker的命令行工具，是用户使用Docker的主要途径，Docker client也可以通过socket或者RESTful api访问远程的Docker deamon</li>\n<li>Docker image：Docker镜像，是只读的，镜像中包含有需要运行的文件，通过镜像来创建container，一个镜像可以运行多个container；镜像可以通过Dockerfile创建，也可以通过Docker hub/registry下载官方或者个人创建好的镜像。</li>\n<li>Docker container：容器是docker运行的组件，也是一个程序的最小单元。容器是一个隔离的环境，多个容器之间不会互相影响，来保证容器中的程序运行在一个相对安全独立的环境中</li>\n<li>Docker hub/registry：共享和管理Docker镜像，用户可以上传或者下载镜像，官方地址位<a href=\"https://registry.hub.docker.com/，也可以搭建私有的Docker\" target=\"_blank\" rel=\"noopener\">https://registry.hub.docker.com/，也可以搭建私有的Docker</a> registry</li>\n</ul>\n<p>总结：镜像就相当于打包好的应用，镜像启动了之后运行在容器中，而通过dockerfile制作或者下载docker镜像后可以放在仓库中存储。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"http://www.runoob.com/docker/docker-tutorial.html\" target=\"_blank\" rel=\"noopener\">http://www.runoob.com/docker/docker-tutorial.html</a></li>\n<li><a href=\"http://www.docker.org.cn/\" target=\"_blank\" rel=\"noopener\">http://www.docker.org.cn/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>大概一年前接触微服务后就听说过容器化、docker这些名词了，草草了解了之后一直没有实践开始学习过，对于DevOps而言，容器化、以及容器编排都是非常重要的技术，现在开始着手学习并且记录下学习的笔记。</p>\n</blockquote>","more":"<h2 id=\"什么是Docker\"><a href=\"#什么是Docker\" class=\"headerlink\" title=\"什么是Docker\"></a>什么是Docker</h2><p>Dcoker是一个开源的应用容器引擎，基于Go语言并遵从Apache2.0协议开源。</p>\n<p>Docker可以轻松的为任何应用创建一个轻量的、可移植的、自给自足的容器。开发者进行编写后测试通过的容器，可以批量的在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack集群和其他基础应用平台。</p>\n<h2 id=\"什么是容器\"><a href=\"#什么是容器\" class=\"headerlink\" title=\"什么是容器\"></a>什么是容器</h2><p>其实容器是一种虚拟化的方案。容器是完全使用沙箱机制，相互之间不会有任何接口，最重要的是容器的性能开销相比传统的虚拟机性能开销低。</p>\n<h2 id=\"Docker的好处\"><a href=\"#Docker的好处\" class=\"headerlink\" title=\"Docker的好处\"></a>Docker的好处</h2><ol>\n<li><p>更快的交付和部署</p>\n<p> 对于开发、运维人员来说，最希望的就是一次创建和配置，可以在任意环境运行。</p>\n<p> 开发人员可以构建标准的镜像，开发完成后，运维人员可以直接使用这个镜像启动一个应用容器。Docker可以快速创建容器，快速迭代应用程序，大量的节省了开发、测试、运维部署的时间。</p>\n</li>\n<li><p>更高效的虚拟化</p>\n<p> Docker容器的运行不需要额外的Hypervisor支持，他是内核级的虚拟化，因此可以实现更高的性能和效率。</p>\n</li>\n</ol>\n<h2 id=\"相关概念\"><a href=\"#相关概念\" class=\"headerlink\" title=\"相关概念\"></a>相关概念</h2><p>Docker是CS架构的应用，主要以下几种组成：</p>\n<ul>\n<li>Docker daemon： 运行再宿主机上，Docker的守护进程，用户通过Docker client（docker命令行）进行交互</li>\n<li>Docker client：Docker的命令行工具，是用户使用Docker的主要途径，Docker client也可以通过socket或者RESTful api访问远程的Docker deamon</li>\n<li>Docker image：Docker镜像，是只读的，镜像中包含有需要运行的文件，通过镜像来创建container，一个镜像可以运行多个container；镜像可以通过Dockerfile创建，也可以通过Docker hub/registry下载官方或者个人创建好的镜像。</li>\n<li>Docker container：容器是docker运行的组件，也是一个程序的最小单元。容器是一个隔离的环境，多个容器之间不会互相影响，来保证容器中的程序运行在一个相对安全独立的环境中</li>\n<li>Docker hub/registry：共享和管理Docker镜像，用户可以上传或者下载镜像，官方地址位<a href=\"https://registry.hub.docker.com/，也可以搭建私有的Docker\" target=\"_blank\" rel=\"noopener\">https://registry.hub.docker.com/，也可以搭建私有的Docker</a> registry</li>\n</ul>\n<p>总结：镜像就相当于打包好的应用，镜像启动了之后运行在容器中，而通过dockerfile制作或者下载docker镜像后可以放在仓库中存储。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"http://www.runoob.com/docker/docker-tutorial.html\" target=\"_blank\" rel=\"noopener\">http://www.runoob.com/docker/docker-tutorial.html</a></li>\n<li><a href=\"http://www.docker.org.cn/\" target=\"_blank\" rel=\"noopener\">http://www.docker.org.cn/</a></li>\n</ul>"},{"title":"docker Hello World","date":"2019-08-21T02:00:00.000Z","_content":"\n有段时间没更新了，前段时间出去玩了一圈，回来接着学习docker。\n\n上一节有简单的讲到docker run运行hellVo world，这次详细的讲解下docker的一些基础命令\n\n<!-- more -->\n# Hello World\n上次是直接使用了docker run hello-world运行了hello world，但这仅仅是打印了hello world字符串。这次我们换种方式。\n\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run ubuntu:15.10 /bin/echo \"Hello world\"\nUnable to find image 'ubuntu:15.10' locally\n15.10: Pulling from library/ubuntu\n7dcf5a444392: Pull complete\n759aa75f3cee: Pull complete\n3fa871dc8a2b: Pull complete\n224c42ae46e7: Pull complete\nDigest: sha256:02521a2d079595241c6793b2044f02eecf294034f31d6e235ac4b2b54ffc41f3\nStatus: Downloaded newer image for ubuntu:15.10\nHello world\n```\n这里逐个参数的讲解：\n- docker: Docker 的二进制执行文件。\n- run: 与前面的 docker 组合来运行一个容器。\n- ubuntu:15.10 指定要运行的镜像，Docker首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。\n- /bin/echo \"Hello world\": 在启动的容器里执行的命令\n\n这里完整的执行逻辑是：Docker以ubuntu15.10镜像创建一个新容器，仓库中不存在镜像，提示了\"Unable to find image 'ubuntu:15.10' locally\"，所以先pull了镜像，然后在容器里执行 bin/echo \"Hello world\"，然后输出结果。\n\n# 与容器进行交互\n我们通过docker的两个参数 -i -t，让docker运行的容器实现\"对话\"的能力\n\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -i -t ubuntu:15.10 /bin/bash\nroot@61124b8b51b1:/#\n```\n- -t: 在新容器内指定一个伪终端或终端。\n- -i: 允许你对容器内的标准输入 (STDIN) 进行交互。\n\n此时我们就相当于进入了一个ubuntu15.10系统的容器内部的控制台。这时候我们可以使用一些命令来查看容器的情况，如ls、cat /proc/version\n\n```\nroot@61124b8b51b1:/# cat /proc/version\nLinux version 3.10.0-693.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat #1 SMP Tue Sep 12 22:26:13 UTC 2017\nroot@61124b8b51b1:/# ls -lrt\ntotal 64\n```\n\n# 后台运行容器\n我们用下面这条命令创建一个容器\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d ubuntu:15.10 /bin/sh -c \"while true; do echo hello world;sleep 1; done\"\n4d8f66bb1369a8d0b74b9b23bb6dcc86bc85fd638eb9801f21e99734747f4ab1\n```\n这里并没有响应Hello world，而是返回了一堆字符串，其实这个字符串是这个正在运行的容器ID，我们可以通过容器的ID对该容器做一些列的操作。\n\n这里同上面一样，运行了一个ubuntu:15.10的容器，并且运行了shell脚本，循环打印hello world，保持容器一直是有事情做的。\n\n# 查看容器\n我们可以使用docker ps来查看当面在运行的容器列表\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES\n4d8f66bb1369        ubuntu:15.10        \"/bin/sh -c 'while t…\"   3 seconds ago       Up 2 seconds                            modest_chatelet\n```\n- CONTAINER ID: 容器ID\n- NAMES: 自动生成的容器别名\n\n我们可以通过container id和names来控制某个容器\n\n## 查看容器日志\n通过container id来查看\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs 4d8f66bb1369\nhello world\nhello world\nhello world\nhello world\nhello world\n```\n\n通过names来查看\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs modest_chatelet\nhello world\nhello world\nhello world\nhello world\n```\n\n# 停止容器\n我们可以使用docker stop来停止容器，同样通过容器id或别名。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker stop modest_chatelet\nmodest_chatelet\n```\n然后我们再查看一次容器的列表\n\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n[root@iZwz91w0kp029z0dmueicoZ /root]#\n```\n列表列现在已经没有了任何正在运行的容器\n\n我们可以重复上面的操作再创建一个容器，然后使用容器ID停止一次，也是可以的。\n\n# 参考资料\n* https://www.runoob.com/docker/docker-hello-world.html","source":"_posts/docker_03_HelloWorld.md","raw":"---\ntitle: docker Hello World\ndate: 2019-08-21 10:00:00\ntags: docker\ncategories: DevOps\n---\n\n有段时间没更新了，前段时间出去玩了一圈，回来接着学习docker。\n\n上一节有简单的讲到docker run运行hellVo world，这次详细的讲解下docker的一些基础命令\n\n<!-- more -->\n# Hello World\n上次是直接使用了docker run hello-world运行了hello world，但这仅仅是打印了hello world字符串。这次我们换种方式。\n\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run ubuntu:15.10 /bin/echo \"Hello world\"\nUnable to find image 'ubuntu:15.10' locally\n15.10: Pulling from library/ubuntu\n7dcf5a444392: Pull complete\n759aa75f3cee: Pull complete\n3fa871dc8a2b: Pull complete\n224c42ae46e7: Pull complete\nDigest: sha256:02521a2d079595241c6793b2044f02eecf294034f31d6e235ac4b2b54ffc41f3\nStatus: Downloaded newer image for ubuntu:15.10\nHello world\n```\n这里逐个参数的讲解：\n- docker: Docker 的二进制执行文件。\n- run: 与前面的 docker 组合来运行一个容器。\n- ubuntu:15.10 指定要运行的镜像，Docker首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。\n- /bin/echo \"Hello world\": 在启动的容器里执行的命令\n\n这里完整的执行逻辑是：Docker以ubuntu15.10镜像创建一个新容器，仓库中不存在镜像，提示了\"Unable to find image 'ubuntu:15.10' locally\"，所以先pull了镜像，然后在容器里执行 bin/echo \"Hello world\"，然后输出结果。\n\n# 与容器进行交互\n我们通过docker的两个参数 -i -t，让docker运行的容器实现\"对话\"的能力\n\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -i -t ubuntu:15.10 /bin/bash\nroot@61124b8b51b1:/#\n```\n- -t: 在新容器内指定一个伪终端或终端。\n- -i: 允许你对容器内的标准输入 (STDIN) 进行交互。\n\n此时我们就相当于进入了一个ubuntu15.10系统的容器内部的控制台。这时候我们可以使用一些命令来查看容器的情况，如ls、cat /proc/version\n\n```\nroot@61124b8b51b1:/# cat /proc/version\nLinux version 3.10.0-693.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat #1 SMP Tue Sep 12 22:26:13 UTC 2017\nroot@61124b8b51b1:/# ls -lrt\ntotal 64\n```\n\n# 后台运行容器\n我们用下面这条命令创建一个容器\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d ubuntu:15.10 /bin/sh -c \"while true; do echo hello world;sleep 1; done\"\n4d8f66bb1369a8d0b74b9b23bb6dcc86bc85fd638eb9801f21e99734747f4ab1\n```\n这里并没有响应Hello world，而是返回了一堆字符串，其实这个字符串是这个正在运行的容器ID，我们可以通过容器的ID对该容器做一些列的操作。\n\n这里同上面一样，运行了一个ubuntu:15.10的容器，并且运行了shell脚本，循环打印hello world，保持容器一直是有事情做的。\n\n# 查看容器\n我们可以使用docker ps来查看当面在运行的容器列表\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES\n4d8f66bb1369        ubuntu:15.10        \"/bin/sh -c 'while t…\"   3 seconds ago       Up 2 seconds                            modest_chatelet\n```\n- CONTAINER ID: 容器ID\n- NAMES: 自动生成的容器别名\n\n我们可以通过container id和names来控制某个容器\n\n## 查看容器日志\n通过container id来查看\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs 4d8f66bb1369\nhello world\nhello world\nhello world\nhello world\nhello world\n```\n\n通过names来查看\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs modest_chatelet\nhello world\nhello world\nhello world\nhello world\n```\n\n# 停止容器\n我们可以使用docker stop来停止容器，同样通过容器id或别名。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker stop modest_chatelet\nmodest_chatelet\n```\n然后我们再查看一次容器的列表\n\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n[root@iZwz91w0kp029z0dmueicoZ /root]#\n```\n列表列现在已经没有了任何正在运行的容器\n\n我们可以重复上面的操作再创建一个容器，然后使用容器ID停止一次，也是可以的。\n\n# 参考资料\n* https://www.runoob.com/docker/docker-hello-world.html","slug":"docker_03_HelloWorld","published":1,"updated":"2019-08-26T07:50:41.910Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkzq000fqotniba6fcp6","content":"<p>有段时间没更新了，前段时间出去玩了一圈，回来接着学习docker。</p>\n<p>上一节有简单的讲到docker run运行hellVo world，这次详细的讲解下docker的一些基础命令</p>\n<a id=\"more\"></a>\n<h1 id=\"Hello-World\"><a href=\"#Hello-World\" class=\"headerlink\" title=\"Hello World\"></a>Hello World</h1><p>上次是直接使用了docker run hello-world运行了hello world，但这仅仅是打印了hello world字符串。这次我们换种方式。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run ubuntu:15.10 /bin/echo &quot;Hello world&quot;</span><br><span class=\"line\">Unable to find image &apos;ubuntu:15.10&apos; locally</span><br><span class=\"line\">15.10: Pulling from library/ubuntu</span><br><span class=\"line\">7dcf5a444392: Pull complete</span><br><span class=\"line\">759aa75f3cee: Pull complete</span><br><span class=\"line\">3fa871dc8a2b: Pull complete</span><br><span class=\"line\">224c42ae46e7: Pull complete</span><br><span class=\"line\">Digest: sha256:02521a2d079595241c6793b2044f02eecf294034f31d6e235ac4b2b54ffc41f3</span><br><span class=\"line\">Status: Downloaded newer image for ubuntu:15.10</span><br><span class=\"line\">Hello world</span><br></pre></td></tr></table></figure>\n<p>这里逐个参数的讲解：</p>\n<ul>\n<li>docker: Docker 的二进制执行文件。</li>\n<li>run: 与前面的 docker 组合来运行一个容器。</li>\n<li>ubuntu:15.10 指定要运行的镜像，Docker首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。</li>\n<li>/bin/echo “Hello world”: 在启动的容器里执行的命令</li>\n</ul>\n<p>这里完整的执行逻辑是：Docker以ubuntu15.10镜像创建一个新容器，仓库中不存在镜像，提示了”Unable to find image ‘ubuntu:15.10’ locally”，所以先pull了镜像，然后在容器里执行 bin/echo “Hello world”，然后输出结果。</p>\n<h1 id=\"与容器进行交互\"><a href=\"#与容器进行交互\" class=\"headerlink\" title=\"与容器进行交互\"></a>与容器进行交互</h1><p>我们通过docker的两个参数 -i -t，让docker运行的容器实现”对话”的能力</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -i -t ubuntu:15.10 /bin/bash</span><br><span class=\"line\">root@61124b8b51b1:/#</span><br></pre></td></tr></table></figure>\n<ul>\n<li>-t: 在新容器内指定一个伪终端或终端。</li>\n<li>-i: 允许你对容器内的标准输入 (STDIN) 进行交互。</li>\n</ul>\n<p>此时我们就相当于进入了一个ubuntu15.10系统的容器内部的控制台。这时候我们可以使用一些命令来查看容器的情况，如ls、cat /proc/version</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@61124b8b51b1:/# cat /proc/version</span><br><span class=\"line\">Linux version 3.10.0-693.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat #1 SMP Tue Sep 12 22:26:13 UTC 2017</span><br><span class=\"line\">root@61124b8b51b1:/# ls -lrt</span><br><span class=\"line\">total 64</span><br></pre></td></tr></table></figure>\n<h1 id=\"后台运行容器\"><a href=\"#后台运行容器\" class=\"headerlink\" title=\"后台运行容器\"></a>后台运行容器</h1><p>我们用下面这条命令创建一个容器<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d ubuntu:15.10 /bin/sh -c &quot;while true; do echo hello world;sleep 1; done&quot;</span><br><span class=\"line\">4d8f66bb1369a8d0b74b9b23bb6dcc86bc85fd638eb9801f21e99734747f4ab1</span><br></pre></td></tr></table></figure></p>\n<p>这里并没有响应Hello world，而是返回了一堆字符串，其实这个字符串是这个正在运行的容器ID，我们可以通过容器的ID对该容器做一些列的操作。</p>\n<p>这里同上面一样，运行了一个ubuntu:15.10的容器，并且运行了shell脚本，循环打印hello world，保持容器一直是有事情做的。</p>\n<h1 id=\"查看容器\"><a href=\"#查看容器\" class=\"headerlink\" title=\"查看容器\"></a>查看容器</h1><p>我们可以使用docker ps来查看当面在运行的容器列表<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class=\"line\">4d8f66bb1369        ubuntu:15.10        &quot;/bin/sh -c &apos;while t…&quot;   3 seconds ago       Up 2 seconds                            modest_chatelet</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>CONTAINER ID: 容器ID</li>\n<li>NAMES: 自动生成的容器别名</li>\n</ul>\n<p>我们可以通过container id和names来控制某个容器</p>\n<h2 id=\"查看容器日志\"><a href=\"#查看容器日志\" class=\"headerlink\" title=\"查看容器日志\"></a>查看容器日志</h2><p>通过container id来查看<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs 4d8f66bb1369</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br></pre></td></tr></table></figure></p>\n<p>通过names来查看<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs modest_chatelet</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"停止容器\"><a href=\"#停止容器\" class=\"headerlink\" title=\"停止容器\"></a>停止容器</h1><p>我们可以使用docker stop来停止容器，同样通过容器id或别名。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker stop modest_chatelet</span><br><span class=\"line\">modest_chatelet</span><br></pre></td></tr></table></figure></p>\n<p>然后我们再查看一次容器的列表</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#</span><br></pre></td></tr></table></figure>\n<p>列表列现在已经没有了任何正在运行的容器</p>\n<p>我们可以重复上面的操作再创建一个容器，然后使用容器ID停止一次，也是可以的。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://www.runoob.com/docker/docker-hello-world.html\" target=\"_blank\" rel=\"noopener\">https://www.runoob.com/docker/docker-hello-world.html</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>有段时间没更新了，前段时间出去玩了一圈，回来接着学习docker。</p>\n<p>上一节有简单的讲到docker run运行hellVo world，这次详细的讲解下docker的一些基础命令</p>","more":"<h1 id=\"Hello-World\"><a href=\"#Hello-World\" class=\"headerlink\" title=\"Hello World\"></a>Hello World</h1><p>上次是直接使用了docker run hello-world运行了hello world，但这仅仅是打印了hello world字符串。这次我们换种方式。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run ubuntu:15.10 /bin/echo &quot;Hello world&quot;</span><br><span class=\"line\">Unable to find image &apos;ubuntu:15.10&apos; locally</span><br><span class=\"line\">15.10: Pulling from library/ubuntu</span><br><span class=\"line\">7dcf5a444392: Pull complete</span><br><span class=\"line\">759aa75f3cee: Pull complete</span><br><span class=\"line\">3fa871dc8a2b: Pull complete</span><br><span class=\"line\">224c42ae46e7: Pull complete</span><br><span class=\"line\">Digest: sha256:02521a2d079595241c6793b2044f02eecf294034f31d6e235ac4b2b54ffc41f3</span><br><span class=\"line\">Status: Downloaded newer image for ubuntu:15.10</span><br><span class=\"line\">Hello world</span><br></pre></td></tr></table></figure>\n<p>这里逐个参数的讲解：</p>\n<ul>\n<li>docker: Docker 的二进制执行文件。</li>\n<li>run: 与前面的 docker 组合来运行一个容器。</li>\n<li>ubuntu:15.10 指定要运行的镜像，Docker首先从本地主机上查找镜像是否存在，如果不存在，Docker 就会从镜像仓库 Docker Hub 下载公共镜像。</li>\n<li>/bin/echo “Hello world”: 在启动的容器里执行的命令</li>\n</ul>\n<p>这里完整的执行逻辑是：Docker以ubuntu15.10镜像创建一个新容器，仓库中不存在镜像，提示了”Unable to find image ‘ubuntu:15.10’ locally”，所以先pull了镜像，然后在容器里执行 bin/echo “Hello world”，然后输出结果。</p>\n<h1 id=\"与容器进行交互\"><a href=\"#与容器进行交互\" class=\"headerlink\" title=\"与容器进行交互\"></a>与容器进行交互</h1><p>我们通过docker的两个参数 -i -t，让docker运行的容器实现”对话”的能力</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -i -t ubuntu:15.10 /bin/bash</span><br><span class=\"line\">root@61124b8b51b1:/#</span><br></pre></td></tr></table></figure>\n<ul>\n<li>-t: 在新容器内指定一个伪终端或终端。</li>\n<li>-i: 允许你对容器内的标准输入 (STDIN) 进行交互。</li>\n</ul>\n<p>此时我们就相当于进入了一个ubuntu15.10系统的容器内部的控制台。这时候我们可以使用一些命令来查看容器的情况，如ls、cat /proc/version</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@61124b8b51b1:/# cat /proc/version</span><br><span class=\"line\">Linux version 3.10.0-693.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat #1 SMP Tue Sep 12 22:26:13 UTC 2017</span><br><span class=\"line\">root@61124b8b51b1:/# ls -lrt</span><br><span class=\"line\">total 64</span><br></pre></td></tr></table></figure>\n<h1 id=\"后台运行容器\"><a href=\"#后台运行容器\" class=\"headerlink\" title=\"后台运行容器\"></a>后台运行容器</h1><p>我们用下面这条命令创建一个容器<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d ubuntu:15.10 /bin/sh -c &quot;while true; do echo hello world;sleep 1; done&quot;</span><br><span class=\"line\">4d8f66bb1369a8d0b74b9b23bb6dcc86bc85fd638eb9801f21e99734747f4ab1</span><br></pre></td></tr></table></figure></p>\n<p>这里并没有响应Hello world，而是返回了一堆字符串，其实这个字符串是这个正在运行的容器ID，我们可以通过容器的ID对该容器做一些列的操作。</p>\n<p>这里同上面一样，运行了一个ubuntu:15.10的容器，并且运行了shell脚本，循环打印hello world，保持容器一直是有事情做的。</p>\n<h1 id=\"查看容器\"><a href=\"#查看容器\" class=\"headerlink\" title=\"查看容器\"></a>查看容器</h1><p>我们可以使用docker ps来查看当面在运行的容器列表<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class=\"line\">4d8f66bb1369        ubuntu:15.10        &quot;/bin/sh -c &apos;while t…&quot;   3 seconds ago       Up 2 seconds                            modest_chatelet</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>CONTAINER ID: 容器ID</li>\n<li>NAMES: 自动生成的容器别名</li>\n</ul>\n<p>我们可以通过container id和names来控制某个容器</p>\n<h2 id=\"查看容器日志\"><a href=\"#查看容器日志\" class=\"headerlink\" title=\"查看容器日志\"></a>查看容器日志</h2><p>通过container id来查看<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs 4d8f66bb1369</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br></pre></td></tr></table></figure></p>\n<p>通过names来查看<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker logs modest_chatelet</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br><span class=\"line\">hello world</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"停止容器\"><a href=\"#停止容器\" class=\"headerlink\" title=\"停止容器\"></a>停止容器</h1><p>我们可以使用docker stop来停止容器，同样通过容器id或别名。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker stop modest_chatelet</span><br><span class=\"line\">modest_chatelet</span><br></pre></td></tr></table></figure></p>\n<p>然后我们再查看一次容器的列表</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#</span><br></pre></td></tr></table></figure>\n<p>列表列现在已经没有了任何正在运行的容器</p>\n<p>我们可以重复上面的操作再创建一个容器，然后使用容器ID停止一次，也是可以的。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://www.runoob.com/docker/docker-hello-world.html\" target=\"_blank\" rel=\"noopener\">https://www.runoob.com/docker/docker-hello-world.html</a></li>\n</ul>"},{"title":"docker 网络模式","date":"2019-08-28T02:41:00.000Z","_content":"\n> 上一篇分享的文章中有简单的讲到docker内部的网络模式，但很多点并没有讲的很详细，这篇就专门讨论学习一下docker的网络模式。\n\n<!-- more -->\n\n这里提到的docker的网络模式，指的是docker deamon与docker启动的容器实例的网络模式。不是docker与宿主机的网络模式。\n## docker network\n首先我们可以通过docker network了解下相关指令有什么东西。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker network COMMAND --help\n\nUsage:  docker network COMMAND\n\nManage networks\n\nCommands:\n  connect     Connect a container to a network\n  create      Create a network\n  disconnect  Disconnect a container from a network\n  inspect     Display detailed information on one or more networks\n  ls          List networks\n  prune       Remove all unused networks\n  rm          Remove one or more networks\n\n```\n其实这里都有解释每一个指令的\n- connect: 建立容器网络链接\n- disconnect: 断开容器网络链接\n- create: 创建一个自定义网\n- inspect: 查看网络详情\n- ls: 列出网络信息\n- prune: 移除全部未使用的网络\n- rm: 移除一个或多个网络\n\n### ls\n先看下docker network ls\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\ndd3610923996        bridge              bridge              local\n2499a5d8180c        host                host                local\n68083386230a        none                null                local\n```\n","source":"_posts/docker_07_网络.md","raw":"---\ntitle: docker 网络模式\ndate: 2019-08-28 10:41:00\ntags: docker\ncategories: DevOps\n---\n\n> 上一篇分享的文章中有简单的讲到docker内部的网络模式，但很多点并没有讲的很详细，这篇就专门讨论学习一下docker的网络模式。\n\n<!-- more -->\n\n这里提到的docker的网络模式，指的是docker deamon与docker启动的容器实例的网络模式。不是docker与宿主机的网络模式。\n## docker network\n首先我们可以通过docker network了解下相关指令有什么东西。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker network COMMAND --help\n\nUsage:  docker network COMMAND\n\nManage networks\n\nCommands:\n  connect     Connect a container to a network\n  create      Create a network\n  disconnect  Disconnect a container from a network\n  inspect     Display detailed information on one or more networks\n  ls          List networks\n  prune       Remove all unused networks\n  rm          Remove one or more networks\n\n```\n其实这里都有解释每一个指令的\n- connect: 建立容器网络链接\n- disconnect: 断开容器网络链接\n- create: 创建一个自定义网\n- inspect: 查看网络详情\n- ls: 列出网络信息\n- prune: 移除全部未使用的网络\n- rm: 移除一个或多个网络\n\n### ls\n先看下docker network ls\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\ndd3610923996        bridge              bridge              local\n2499a5d8180c        host                host                local\n68083386230a        none                null                local\n```\n","slug":"docker_07_网络","published":1,"updated":"2019-09-05T09:20:20.992Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkzt000kqotnbmhw2n0f","content":"<blockquote>\n<p>上一篇分享的文章中有简单的讲到docker内部的网络模式，但很多点并没有讲的很详细，这篇就专门讨论学习一下docker的网络模式。</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>这里提到的docker的网络模式，指的是docker deamon与docker启动的容器实例的网络模式。不是docker与宿主机的网络模式。</p>\n<h2 id=\"docker-network\"><a href=\"#docker-network\" class=\"headerlink\" title=\"docker network\"></a>docker network</h2><p>首先我们可以通过docker network了解下相关指令有什么东西。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker network COMMAND --help</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:  docker network COMMAND</span><br><span class=\"line\"></span><br><span class=\"line\">Manage networks</span><br><span class=\"line\"></span><br><span class=\"line\">Commands:</span><br><span class=\"line\">  connect     Connect a container to a network</span><br><span class=\"line\">  create      Create a network</span><br><span class=\"line\">  disconnect  Disconnect a container from a network</span><br><span class=\"line\">  inspect     Display detailed information on one or more networks</span><br><span class=\"line\">  ls          List networks</span><br><span class=\"line\">  prune       Remove all unused networks</span><br><span class=\"line\">  rm          Remove one or more networks</span><br></pre></td></tr></table></figure></p>\n<p>其实这里都有解释每一个指令的</p>\n<ul>\n<li>connect: 建立容器网络链接</li>\n<li>disconnect: 断开容器网络链接</li>\n<li>create: 创建一个自定义网</li>\n<li>inspect: 查看网络详情</li>\n<li>ls: 列出网络信息</li>\n<li>prune: 移除全部未使用的网络</li>\n<li>rm: 移除一个或多个网络</li>\n</ul>\n<h3 id=\"ls\"><a href=\"#ls\" class=\"headerlink\" title=\"ls\"></a>ls</h3><p>先看下docker network ls<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class=\"line\">dd3610923996        bridge              bridge              local</span><br><span class=\"line\">2499a5d8180c        host                host                local</span><br><span class=\"line\">68083386230a        none                null                local</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>上一篇分享的文章中有简单的讲到docker内部的网络模式，但很多点并没有讲的很详细，这篇就专门讨论学习一下docker的网络模式。</p>\n</blockquote>","more":"<p>这里提到的docker的网络模式，指的是docker deamon与docker启动的容器实例的网络模式。不是docker与宿主机的网络模式。</p>\n<h2 id=\"docker-network\"><a href=\"#docker-network\" class=\"headerlink\" title=\"docker network\"></a>docker network</h2><p>首先我们可以通过docker network了解下相关指令有什么东西。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker network COMMAND --help</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:  docker network COMMAND</span><br><span class=\"line\"></span><br><span class=\"line\">Manage networks</span><br><span class=\"line\"></span><br><span class=\"line\">Commands:</span><br><span class=\"line\">  connect     Connect a container to a network</span><br><span class=\"line\">  create      Create a network</span><br><span class=\"line\">  disconnect  Disconnect a container from a network</span><br><span class=\"line\">  inspect     Display detailed information on one or more networks</span><br><span class=\"line\">  ls          List networks</span><br><span class=\"line\">  prune       Remove all unused networks</span><br><span class=\"line\">  rm          Remove one or more networks</span><br></pre></td></tr></table></figure></p>\n<p>其实这里都有解释每一个指令的</p>\n<ul>\n<li>connect: 建立容器网络链接</li>\n<li>disconnect: 断开容器网络链接</li>\n<li>create: 创建一个自定义网</li>\n<li>inspect: 查看网络详情</li>\n<li>ls: 列出网络信息</li>\n<li>prune: 移除全部未使用的网络</li>\n<li>rm: 移除一个或多个网络</li>\n</ul>\n<h3 id=\"ls\"><a href=\"#ls\" class=\"headerlink\" title=\"ls\"></a>ls</h3><p>先看下docker network ls<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class=\"line\">dd3610923996        bridge              bridge              local</span><br><span class=\"line\">2499a5d8180c        host                host                local</span><br><span class=\"line\">68083386230a        none                null                local</span><br></pre></td></tr></table></figure></p>"},{"title":"docker ElasticSearch","date":"2019-09-05T04:00:00.000Z","_content":"\n> 最近公司项目组要使用ElasticSearch，自己先学习一下，记录通过docker搭建的过程。\n\n<!-- more -->\n\nelasticsearch官方镜像会暴露9200 9300两个默认的http端口，可以通过此端口进行访问\n- 9200: 对外提供服务的api使用端口\n- 9300: 内部通信端口，包括心跳、集群内部信息同步\n\n使用数据卷挂载自定义配置文件，以及进行存储数据持久化。分别挂载至：\n- 配置文件: /usr/share/elasticsearch/config\n- 存储数据: /usr/share/elasticsearch/data\n\n# elasticsearch目录结构\n```\nbin：可执行文件，运行es的命令\nconfig：配置文件目录\n config/elasticsearch.yml：ES启动基础配置\n config/jvm.options：ES启动时JVM配置\n config/log4j2.properties：ES日志输出配置文件\nlib：依赖的jar\nlogs：日志文件夹\nmodules：es模块\nplugins：可以自己开发的插件\ndata：我们自己创建的，存放es存储文件\n```\n## 配置文件\n所以我们挂载的elasticsearch主要有一下几个配置文件：\n* config/elasticsearch.yml   主配置文件\n* config/jvm.options         jvm参数配置文件\n* cofnig/log4j2.properties   日志配置文件\n\n## 运行elasticsearch镜像\n我是直接拉取了最新的elasticsearch:7.2.0\n```\n[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#docker run -d -p 9200:9200 -p 9300:9300 --name es -v $PWD/config:/usr/share/elasticsearch/config -v $PWD/data:/usr/share/elasticsearch/data elasticsearch:7.2.0\nf22048b5909fe4ddb4c1a72bc30c375def5595c075eedcf8801bfd13bc06fae3\n[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#docker ps -a\nCONTAINER ID        IMAGE                                                 COMMAND                  CREATED             STATUS                       PORTS                    NAMES\nf22048b5909f        elasticsearch:7.2.0                                   \"/usr/local/bin/dock…\"   44 seconds ago      Exited (1) 42 seconds ago                             es\n```\n\n直接run发现没有启动成功，这时候需要查看下启动日志\n```\nERROR: [1] bootstrap checks failed\n[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured\n```\n大概的意思就是：默认发现设置不适合生产使用； 必须配置[discovery.seed_hosts，discovery.seed_providers，cluster.initial_master_nodes]中的至少一个。\n\n* discovery.seed_hosts\n* discovery.seed_providers\n* cluster.initial_master_nodes","source":"_posts/docker_09_ElasticSearch.md","raw":"---\ntitle: docker ElasticSearch\ndate: 2019-09-05 12:00:00\ntags: docker\ncategories: DevOps\n---\n\n> 最近公司项目组要使用ElasticSearch，自己先学习一下，记录通过docker搭建的过程。\n\n<!-- more -->\n\nelasticsearch官方镜像会暴露9200 9300两个默认的http端口，可以通过此端口进行访问\n- 9200: 对外提供服务的api使用端口\n- 9300: 内部通信端口，包括心跳、集群内部信息同步\n\n使用数据卷挂载自定义配置文件，以及进行存储数据持久化。分别挂载至：\n- 配置文件: /usr/share/elasticsearch/config\n- 存储数据: /usr/share/elasticsearch/data\n\n# elasticsearch目录结构\n```\nbin：可执行文件，运行es的命令\nconfig：配置文件目录\n config/elasticsearch.yml：ES启动基础配置\n config/jvm.options：ES启动时JVM配置\n config/log4j2.properties：ES日志输出配置文件\nlib：依赖的jar\nlogs：日志文件夹\nmodules：es模块\nplugins：可以自己开发的插件\ndata：我们自己创建的，存放es存储文件\n```\n## 配置文件\n所以我们挂载的elasticsearch主要有一下几个配置文件：\n* config/elasticsearch.yml   主配置文件\n* config/jvm.options         jvm参数配置文件\n* cofnig/log4j2.properties   日志配置文件\n\n## 运行elasticsearch镜像\n我是直接拉取了最新的elasticsearch:7.2.0\n```\n[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#docker run -d -p 9200:9200 -p 9300:9300 --name es -v $PWD/config:/usr/share/elasticsearch/config -v $PWD/data:/usr/share/elasticsearch/data elasticsearch:7.2.0\nf22048b5909fe4ddb4c1a72bc30c375def5595c075eedcf8801bfd13bc06fae3\n[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#docker ps -a\nCONTAINER ID        IMAGE                                                 COMMAND                  CREATED             STATUS                       PORTS                    NAMES\nf22048b5909f        elasticsearch:7.2.0                                   \"/usr/local/bin/dock…\"   44 seconds ago      Exited (1) 42 seconds ago                             es\n```\n\n直接run发现没有启动成功，这时候需要查看下启动日志\n```\nERROR: [1] bootstrap checks failed\n[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured\n```\n大概的意思就是：默认发现设置不适合生产使用； 必须配置[discovery.seed_hosts，discovery.seed_providers，cluster.initial_master_nodes]中的至少一个。\n\n* discovery.seed_hosts\n* discovery.seed_providers\n* cluster.initial_master_nodes","slug":"docker_09_ElasticSearch","published":1,"updated":"2019-09-25T01:05:38.567Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkzw000lqotnf9cg7h2n","content":"<blockquote>\n<p>最近公司项目组要使用ElasticSearch，自己先学习一下，记录通过docker搭建的过程。</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>elasticsearch官方镜像会暴露9200 9300两个默认的http端口，可以通过此端口进行访问</p>\n<ul>\n<li>9200: 对外提供服务的api使用端口</li>\n<li>9300: 内部通信端口，包括心跳、集群内部信息同步</li>\n</ul>\n<p>使用数据卷挂载自定义配置文件，以及进行存储数据持久化。分别挂载至：</p>\n<ul>\n<li>配置文件: /usr/share/elasticsearch/config</li>\n<li>存储数据: /usr/share/elasticsearch/data</li>\n</ul>\n<h1 id=\"elasticsearch目录结构\"><a href=\"#elasticsearch目录结构\" class=\"headerlink\" title=\"elasticsearch目录结构\"></a>elasticsearch目录结构</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin：可执行文件，运行es的命令</span><br><span class=\"line\">config：配置文件目录</span><br><span class=\"line\"> config/elasticsearch.yml：ES启动基础配置</span><br><span class=\"line\"> config/jvm.options：ES启动时JVM配置</span><br><span class=\"line\"> config/log4j2.properties：ES日志输出配置文件</span><br><span class=\"line\">lib：依赖的jar</span><br><span class=\"line\">logs：日志文件夹</span><br><span class=\"line\">modules：es模块</span><br><span class=\"line\">plugins：可以自己开发的插件</span><br><span class=\"line\">data：我们自己创建的，存放es存储文件</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置文件\"><a href=\"#配置文件\" class=\"headerlink\" title=\"配置文件\"></a>配置文件</h2><p>所以我们挂载的elasticsearch主要有一下几个配置文件：</p>\n<ul>\n<li>config/elasticsearch.yml   主配置文件</li>\n<li>config/jvm.options         jvm参数配置文件</li>\n<li>cofnig/log4j2.properties   日志配置文件</li>\n</ul>\n<h2 id=\"运行elasticsearch镜像\"><a href=\"#运行elasticsearch镜像\" class=\"headerlink\" title=\"运行elasticsearch镜像\"></a>运行elasticsearch镜像</h2><p>我是直接拉取了最新的elasticsearch:7.2.0<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#docker run -d -p 9200:9200 -p 9300:9300 --name es -v $PWD/config:/usr/share/elasticsearch/config -v $PWD/data:/usr/share/elasticsearch/data elasticsearch:7.2.0</span><br><span class=\"line\">f22048b5909fe4ddb4c1a72bc30c375def5595c075eedcf8801bfd13bc06fae3</span><br><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#docker ps -a</span><br><span class=\"line\">CONTAINER ID        IMAGE                                                 COMMAND                  CREATED             STATUS                       PORTS                    NAMES</span><br><span class=\"line\">f22048b5909f        elasticsearch:7.2.0                                   &quot;/usr/local/bin/dock…&quot;   44 seconds ago      Exited (1) 42 seconds ago                             es</span><br></pre></td></tr></table></figure></p>\n<p>直接run发现没有启动成功，这时候需要查看下启动日志<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ERROR: [1] bootstrap checks failed</span><br><span class=\"line\">[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured</span><br></pre></td></tr></table></figure></p>\n<p>大概的意思就是：默认发现设置不适合生产使用； 必须配置[discovery.seed_hosts，discovery.seed_providers，cluster.initial_master_nodes]中的至少一个。</p>\n<ul>\n<li>discovery.seed_hosts</li>\n<li>discovery.seed_providers</li>\n<li>cluster.initial_master_nodes</li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>最近公司项目组要使用ElasticSearch，自己先学习一下，记录通过docker搭建的过程。</p>\n</blockquote>","more":"<p>elasticsearch官方镜像会暴露9200 9300两个默认的http端口，可以通过此端口进行访问</p>\n<ul>\n<li>9200: 对外提供服务的api使用端口</li>\n<li>9300: 内部通信端口，包括心跳、集群内部信息同步</li>\n</ul>\n<p>使用数据卷挂载自定义配置文件，以及进行存储数据持久化。分别挂载至：</p>\n<ul>\n<li>配置文件: /usr/share/elasticsearch/config</li>\n<li>存储数据: /usr/share/elasticsearch/data</li>\n</ul>\n<h1 id=\"elasticsearch目录结构\"><a href=\"#elasticsearch目录结构\" class=\"headerlink\" title=\"elasticsearch目录结构\"></a>elasticsearch目录结构</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin：可执行文件，运行es的命令</span><br><span class=\"line\">config：配置文件目录</span><br><span class=\"line\"> config/elasticsearch.yml：ES启动基础配置</span><br><span class=\"line\"> config/jvm.options：ES启动时JVM配置</span><br><span class=\"line\"> config/log4j2.properties：ES日志输出配置文件</span><br><span class=\"line\">lib：依赖的jar</span><br><span class=\"line\">logs：日志文件夹</span><br><span class=\"line\">modules：es模块</span><br><span class=\"line\">plugins：可以自己开发的插件</span><br><span class=\"line\">data：我们自己创建的，存放es存储文件</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置文件\"><a href=\"#配置文件\" class=\"headerlink\" title=\"配置文件\"></a>配置文件</h2><p>所以我们挂载的elasticsearch主要有一下几个配置文件：</p>\n<ul>\n<li>config/elasticsearch.yml   主配置文件</li>\n<li>config/jvm.options         jvm参数配置文件</li>\n<li>cofnig/log4j2.properties   日志配置文件</li>\n</ul>\n<h2 id=\"运行elasticsearch镜像\"><a href=\"#运行elasticsearch镜像\" class=\"headerlink\" title=\"运行elasticsearch镜像\"></a>运行elasticsearch镜像</h2><p>我是直接拉取了最新的elasticsearch:7.2.0<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#docker run -d -p 9200:9200 -p 9300:9300 --name es -v $PWD/config:/usr/share/elasticsearch/config -v $PWD/data:/usr/share/elasticsearch/data elasticsearch:7.2.0</span><br><span class=\"line\">f22048b5909fe4ddb4c1a72bc30c375def5595c075eedcf8801bfd13bc06fae3</span><br><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#docker ps -a</span><br><span class=\"line\">CONTAINER ID        IMAGE                                                 COMMAND                  CREATED             STATUS                       PORTS                    NAMES</span><br><span class=\"line\">f22048b5909f        elasticsearch:7.2.0                                   &quot;/usr/local/bin/dock…&quot;   44 seconds ago      Exited (1) 42 seconds ago                             es</span><br></pre></td></tr></table></figure></p>\n<p>直接run发现没有启动成功，这时候需要查看下启动日志<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ERROR: [1] bootstrap checks failed</span><br><span class=\"line\">[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured</span><br></pre></td></tr></table></figure></p>\n<p>大概的意思就是：默认发现设置不适合生产使用； 必须配置[discovery.seed_hosts，discovery.seed_providers，cluster.initial_master_nodes]中的至少一个。</p>\n<ul>\n<li>discovery.seed_hosts</li>\n<li>discovery.seed_providers</li>\n<li>cluster.initial_master_nodes</li>\n</ul>"},{"title":"docker 基础指令","date":"2019-08-21T10:00:00.000Z","_content":"\n> 列举一些学习过程中常用到的指令\n\n<!-- more -->\n想要一次全记住很困难，而且每个指令都有很多的参数，可以再之后使用的时候强化记忆，这里暂时先列出一些常用到的指令，具体的参数可以通过--help了解。如docker run的详细参数\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run --help\nUsage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\nRun a command in a new container\nOptions:\n      --add-host list                  Add a custom host-to-IP mapping (host:ip)\n  -a, --attach list                    Attach to STDIN, STDOUT or STDERR\n      --blkio-weight uint16            Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)\n      --blkio-weight-device list       Block IO weight (relative device weight) (default [])\n      --cap-add list                   Add Linux capabilities\n      --cap-drop list                  Drop Linux capabilities\n      --cgroup-parent string           Optional parent cgroup for the container\n      --cidfile string                 Write the container ID to the file\n      --cpu-period int                 Limit CPU CFS (Completely Fair Scheduler) period\n      --cpu-quota int                  Limit CPU CFS (Completely Fair Scheduler) quota\n      --cpu-rt-period int              Limit CPU real-time period in microseconds\n      --cpu-rt-runtime int             Limit CPU real-time runtime in microseconds\n  -c, --cpu-shares int                 CPU shares (relative weight)\n      --cpus decimal                   Number of CPUs\n      --cpuset-cpus string             CPUs in which to allow execution (0-3, 0,1)\n      --cpuset-mems string             MEMs in which to allow execution (0-3, 0,1)\n...\n```\n这里就不详细赘述每一个指令的详细参数了，如果想了解可以参考https://www.runoob.com/docker/docker-command-manual.html\n\n# 操作镜像\n## 查看镜像仓库\n```\ndocker images\n```\n## 拉取镜像\n```\ndocker pull\n```\n## 运行镜像\n```\ndocker run\n```\n## 删除镜像\n```\ndocker rmi\n```\n## 镜像仓库\n### 查询镜像\n```\ndocker search\n```\n# 操作容器\n## 运行容器\n```\ndocker run\n```\n## 查看运行中的容器\n```\ndocker ps\n```\n## 查看全部容器\n```\ndocker ps -a\n```\n## 停止容器\n```\ndocker stop container_id/names\n```\n## 启动容器\n已经停止的容器可以重新启动\n```\ndocker start container_id/names\n```\n也可以直接重启\n```\ndocker restart \n```\n\n## 删除容器\n```\ndocker rm container_id/names\n```\n## 查看容器端口\n```\ndocker port container_id/names\n```\n## 查看容器日志\n```\ndocker logs [-f] container_id/names\n```\n## 查看容器进程\n```\ndocker top container_id/names\n```\n\n## 查看容器/镜像 元数据\n会返回一个JSON文件记录着Docker容器的配置和状态信息。\n```\ndocker inspect container_id/names\n```\n\n\n# 镜像仓库加速\n我是直接使用的阿里云的镜像仓库，如果你有阿里云账号的话，直接登录阿里云控制台，搜索“容器镜像服务”，最下面有一个镜像加速。\n\n里面是有介绍各个操作系统的步骤的，我的是CentOS。\n\n打开/etc/docker/daemon.json文件，如果没有的话可以先创建。\n```\nsudo mkdir -p /etc/docker\n```\n然后增加如下内容\n```\n{\n  \"registry-mirrors\": [\"https://ilisd4hk.mirror.aliyuncs.com\"]\n}\n```\n最后重启docker\n```\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```","source":"_posts/docker_04_基础指令.md","raw":"---\ntitle: docker 基础指令\ndate: 2019-08-21 18:00:00\ntags: docker\ncategories: DevOps\n---\n\n> 列举一些学习过程中常用到的指令\n\n<!-- more -->\n想要一次全记住很困难，而且每个指令都有很多的参数，可以再之后使用的时候强化记忆，这里暂时先列出一些常用到的指令，具体的参数可以通过--help了解。如docker run的详细参数\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run --help\nUsage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\nRun a command in a new container\nOptions:\n      --add-host list                  Add a custom host-to-IP mapping (host:ip)\n  -a, --attach list                    Attach to STDIN, STDOUT or STDERR\n      --blkio-weight uint16            Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)\n      --blkio-weight-device list       Block IO weight (relative device weight) (default [])\n      --cap-add list                   Add Linux capabilities\n      --cap-drop list                  Drop Linux capabilities\n      --cgroup-parent string           Optional parent cgroup for the container\n      --cidfile string                 Write the container ID to the file\n      --cpu-period int                 Limit CPU CFS (Completely Fair Scheduler) period\n      --cpu-quota int                  Limit CPU CFS (Completely Fair Scheduler) quota\n      --cpu-rt-period int              Limit CPU real-time period in microseconds\n      --cpu-rt-runtime int             Limit CPU real-time runtime in microseconds\n  -c, --cpu-shares int                 CPU shares (relative weight)\n      --cpus decimal                   Number of CPUs\n      --cpuset-cpus string             CPUs in which to allow execution (0-3, 0,1)\n      --cpuset-mems string             MEMs in which to allow execution (0-3, 0,1)\n...\n```\n这里就不详细赘述每一个指令的详细参数了，如果想了解可以参考https://www.runoob.com/docker/docker-command-manual.html\n\n# 操作镜像\n## 查看镜像仓库\n```\ndocker images\n```\n## 拉取镜像\n```\ndocker pull\n```\n## 运行镜像\n```\ndocker run\n```\n## 删除镜像\n```\ndocker rmi\n```\n## 镜像仓库\n### 查询镜像\n```\ndocker search\n```\n# 操作容器\n## 运行容器\n```\ndocker run\n```\n## 查看运行中的容器\n```\ndocker ps\n```\n## 查看全部容器\n```\ndocker ps -a\n```\n## 停止容器\n```\ndocker stop container_id/names\n```\n## 启动容器\n已经停止的容器可以重新启动\n```\ndocker start container_id/names\n```\n也可以直接重启\n```\ndocker restart \n```\n\n## 删除容器\n```\ndocker rm container_id/names\n```\n## 查看容器端口\n```\ndocker port container_id/names\n```\n## 查看容器日志\n```\ndocker logs [-f] container_id/names\n```\n## 查看容器进程\n```\ndocker top container_id/names\n```\n\n## 查看容器/镜像 元数据\n会返回一个JSON文件记录着Docker容器的配置和状态信息。\n```\ndocker inspect container_id/names\n```\n\n\n# 镜像仓库加速\n我是直接使用的阿里云的镜像仓库，如果你有阿里云账号的话，直接登录阿里云控制台，搜索“容器镜像服务”，最下面有一个镜像加速。\n\n里面是有介绍各个操作系统的步骤的，我的是CentOS。\n\n打开/etc/docker/daemon.json文件，如果没有的话可以先创建。\n```\nsudo mkdir -p /etc/docker\n```\n然后增加如下内容\n```\n{\n  \"registry-mirrors\": [\"https://ilisd4hk.mirror.aliyuncs.com\"]\n}\n```\n最后重启docker\n```\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```","slug":"docker_04_基础指令","published":1,"updated":"2019-08-26T07:50:46.214Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzkzz000pqotn51ki9xsy","content":"<blockquote>\n<p>列举一些学习过程中常用到的指令</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>想要一次全记住很困难，而且每个指令都有很多的参数，可以再之后使用的时候强化记忆，这里暂时先列出一些常用到的指令，具体的参数可以通过–help了解。如docker run的详细参数<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run --help</span><br><span class=\"line\">Usage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</span><br><span class=\"line\">Run a command in a new container</span><br><span class=\"line\">Options:</span><br><span class=\"line\">      --add-host list                  Add a custom host-to-IP mapping (host:ip)</span><br><span class=\"line\">  -a, --attach list                    Attach to STDIN, STDOUT or STDERR</span><br><span class=\"line\">      --blkio-weight uint16            Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)</span><br><span class=\"line\">      --blkio-weight-device list       Block IO weight (relative device weight) (default [])</span><br><span class=\"line\">      --cap-add list                   Add Linux capabilities</span><br><span class=\"line\">      --cap-drop list                  Drop Linux capabilities</span><br><span class=\"line\">      --cgroup-parent string           Optional parent cgroup for the container</span><br><span class=\"line\">      --cidfile string                 Write the container ID to the file</span><br><span class=\"line\">      --cpu-period int                 Limit CPU CFS (Completely Fair Scheduler) period</span><br><span class=\"line\">      --cpu-quota int                  Limit CPU CFS (Completely Fair Scheduler) quota</span><br><span class=\"line\">      --cpu-rt-period int              Limit CPU real-time period in microseconds</span><br><span class=\"line\">      --cpu-rt-runtime int             Limit CPU real-time runtime in microseconds</span><br><span class=\"line\">  -c, --cpu-shares int                 CPU shares (relative weight)</span><br><span class=\"line\">      --cpus decimal                   Number of CPUs</span><br><span class=\"line\">      --cpuset-cpus string             CPUs in which to allow execution (0-3, 0,1)</span><br><span class=\"line\">      --cpuset-mems string             MEMs in which to allow execution (0-3, 0,1)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>这里就不详细赘述每一个指令的详细参数了，如果想了解可以参考<a href=\"https://www.runoob.com/docker/docker-command-manual.html\" target=\"_blank\" rel=\"noopener\">https://www.runoob.com/docker/docker-command-manual.html</a></p>\n<h1 id=\"操作镜像\"><a href=\"#操作镜像\" class=\"headerlink\" title=\"操作镜像\"></a>操作镜像</h1><h2 id=\"查看镜像仓库\"><a href=\"#查看镜像仓库\" class=\"headerlink\" title=\"查看镜像仓库\"></a>查看镜像仓库</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker images</span><br></pre></td></tr></table></figure>\n<h2 id=\"拉取镜像\"><a href=\"#拉取镜像\" class=\"headerlink\" title=\"拉取镜像\"></a>拉取镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull</span><br></pre></td></tr></table></figure>\n<h2 id=\"运行镜像\"><a href=\"#运行镜像\" class=\"headerlink\" title=\"运行镜像\"></a>运行镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run</span><br></pre></td></tr></table></figure>\n<h2 id=\"删除镜像\"><a href=\"#删除镜像\" class=\"headerlink\" title=\"删除镜像\"></a>删除镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker rmi</span><br></pre></td></tr></table></figure>\n<h2 id=\"镜像仓库\"><a href=\"#镜像仓库\" class=\"headerlink\" title=\"镜像仓库\"></a>镜像仓库</h2><h3 id=\"查询镜像\"><a href=\"#查询镜像\" class=\"headerlink\" title=\"查询镜像\"></a>查询镜像</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker search</span><br></pre></td></tr></table></figure>\n<h1 id=\"操作容器\"><a href=\"#操作容器\" class=\"headerlink\" title=\"操作容器\"></a>操作容器</h1><h2 id=\"运行容器\"><a href=\"#运行容器\" class=\"headerlink\" title=\"运行容器\"></a>运行容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看运行中的容器\"><a href=\"#查看运行中的容器\" class=\"headerlink\" title=\"查看运行中的容器\"></a>查看运行中的容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker ps</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看全部容器\"><a href=\"#查看全部容器\" class=\"headerlink\" title=\"查看全部容器\"></a>查看全部容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker ps -a</span><br></pre></td></tr></table></figure>\n<h2 id=\"停止容器\"><a href=\"#停止容器\" class=\"headerlink\" title=\"停止容器\"></a>停止容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker stop container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动容器\"><a href=\"#启动容器\" class=\"headerlink\" title=\"启动容器\"></a>启动容器</h2><p>已经停止的容器可以重新启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker start container_id/names</span><br></pre></td></tr></table></figure></p>\n<p>也可以直接重启<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker restart</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"删除容器\"><a href=\"#删除容器\" class=\"headerlink\" title=\"删除容器\"></a>删除容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker rm container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看容器端口\"><a href=\"#查看容器端口\" class=\"headerlink\" title=\"查看容器端口\"></a>查看容器端口</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker port container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看容器日志\"><a href=\"#查看容器日志\" class=\"headerlink\" title=\"查看容器日志\"></a>查看容器日志</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker logs [-f] container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看容器进程\"><a href=\"#查看容器进程\" class=\"headerlink\" title=\"查看容器进程\"></a>查看容器进程</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker top container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看容器-镜像-元数据\"><a href=\"#查看容器-镜像-元数据\" class=\"headerlink\" title=\"查看容器/镜像 元数据\"></a>查看容器/镜像 元数据</h2><p>会返回一个JSON文件记录着Docker容器的配置和状态信息。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker inspect container_id/names</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"镜像仓库加速\"><a href=\"#镜像仓库加速\" class=\"headerlink\" title=\"镜像仓库加速\"></a>镜像仓库加速</h1><p>我是直接使用的阿里云的镜像仓库，如果你有阿里云账号的话，直接登录阿里云控制台，搜索“容器镜像服务”，最下面有一个镜像加速。</p>\n<p>里面是有介绍各个操作系统的步骤的，我的是CentOS。</p>\n<p>打开/etc/docker/daemon.json文件，如果没有的话可以先创建。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir -p /etc/docker</span><br></pre></td></tr></table></figure></p>\n<p>然后增加如下内容<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;registry-mirrors&quot;: [&quot;https://ilisd4hk.mirror.aliyuncs.com&quot;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>最后重启docker<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl daemon-reload</span><br><span class=\"line\">sudo systemctl restart docker</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>列举一些学习过程中常用到的指令</p>\n</blockquote>","more":"<p>想要一次全记住很困难，而且每个指令都有很多的参数，可以再之后使用的时候强化记忆，这里暂时先列出一些常用到的指令，具体的参数可以通过–help了解。如docker run的详细参数<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run --help</span><br><span class=\"line\">Usage:  docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</span><br><span class=\"line\">Run a command in a new container</span><br><span class=\"line\">Options:</span><br><span class=\"line\">      --add-host list                  Add a custom host-to-IP mapping (host:ip)</span><br><span class=\"line\">  -a, --attach list                    Attach to STDIN, STDOUT or STDERR</span><br><span class=\"line\">      --blkio-weight uint16            Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)</span><br><span class=\"line\">      --blkio-weight-device list       Block IO weight (relative device weight) (default [])</span><br><span class=\"line\">      --cap-add list                   Add Linux capabilities</span><br><span class=\"line\">      --cap-drop list                  Drop Linux capabilities</span><br><span class=\"line\">      --cgroup-parent string           Optional parent cgroup for the container</span><br><span class=\"line\">      --cidfile string                 Write the container ID to the file</span><br><span class=\"line\">      --cpu-period int                 Limit CPU CFS (Completely Fair Scheduler) period</span><br><span class=\"line\">      --cpu-quota int                  Limit CPU CFS (Completely Fair Scheduler) quota</span><br><span class=\"line\">      --cpu-rt-period int              Limit CPU real-time period in microseconds</span><br><span class=\"line\">      --cpu-rt-runtime int             Limit CPU real-time runtime in microseconds</span><br><span class=\"line\">  -c, --cpu-shares int                 CPU shares (relative weight)</span><br><span class=\"line\">      --cpus decimal                   Number of CPUs</span><br><span class=\"line\">      --cpuset-cpus string             CPUs in which to allow execution (0-3, 0,1)</span><br><span class=\"line\">      --cpuset-mems string             MEMs in which to allow execution (0-3, 0,1)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure></p>\n<p>这里就不详细赘述每一个指令的详细参数了，如果想了解可以参考<a href=\"https://www.runoob.com/docker/docker-command-manual.html\" target=\"_blank\" rel=\"noopener\">https://www.runoob.com/docker/docker-command-manual.html</a></p>\n<h1 id=\"操作镜像\"><a href=\"#操作镜像\" class=\"headerlink\" title=\"操作镜像\"></a>操作镜像</h1><h2 id=\"查看镜像仓库\"><a href=\"#查看镜像仓库\" class=\"headerlink\" title=\"查看镜像仓库\"></a>查看镜像仓库</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker images</span><br></pre></td></tr></table></figure>\n<h2 id=\"拉取镜像\"><a href=\"#拉取镜像\" class=\"headerlink\" title=\"拉取镜像\"></a>拉取镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull</span><br></pre></td></tr></table></figure>\n<h2 id=\"运行镜像\"><a href=\"#运行镜像\" class=\"headerlink\" title=\"运行镜像\"></a>运行镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run</span><br></pre></td></tr></table></figure>\n<h2 id=\"删除镜像\"><a href=\"#删除镜像\" class=\"headerlink\" title=\"删除镜像\"></a>删除镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker rmi</span><br></pre></td></tr></table></figure>\n<h2 id=\"镜像仓库\"><a href=\"#镜像仓库\" class=\"headerlink\" title=\"镜像仓库\"></a>镜像仓库</h2><h3 id=\"查询镜像\"><a href=\"#查询镜像\" class=\"headerlink\" title=\"查询镜像\"></a>查询镜像</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker search</span><br></pre></td></tr></table></figure>\n<h1 id=\"操作容器\"><a href=\"#操作容器\" class=\"headerlink\" title=\"操作容器\"></a>操作容器</h1><h2 id=\"运行容器\"><a href=\"#运行容器\" class=\"headerlink\" title=\"运行容器\"></a>运行容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看运行中的容器\"><a href=\"#查看运行中的容器\" class=\"headerlink\" title=\"查看运行中的容器\"></a>查看运行中的容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker ps</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看全部容器\"><a href=\"#查看全部容器\" class=\"headerlink\" title=\"查看全部容器\"></a>查看全部容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker ps -a</span><br></pre></td></tr></table></figure>\n<h2 id=\"停止容器\"><a href=\"#停止容器\" class=\"headerlink\" title=\"停止容器\"></a>停止容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker stop container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动容器\"><a href=\"#启动容器\" class=\"headerlink\" title=\"启动容器\"></a>启动容器</h2><p>已经停止的容器可以重新启动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker start container_id/names</span><br></pre></td></tr></table></figure></p>\n<p>也可以直接重启<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker restart</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"删除容器\"><a href=\"#删除容器\" class=\"headerlink\" title=\"删除容器\"></a>删除容器</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker rm container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看容器端口\"><a href=\"#查看容器端口\" class=\"headerlink\" title=\"查看容器端口\"></a>查看容器端口</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker port container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看容器日志\"><a href=\"#查看容器日志\" class=\"headerlink\" title=\"查看容器日志\"></a>查看容器日志</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker logs [-f] container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看容器进程\"><a href=\"#查看容器进程\" class=\"headerlink\" title=\"查看容器进程\"></a>查看容器进程</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker top container_id/names</span><br></pre></td></tr></table></figure>\n<h2 id=\"查看容器-镜像-元数据\"><a href=\"#查看容器-镜像-元数据\" class=\"headerlink\" title=\"查看容器/镜像 元数据\"></a>查看容器/镜像 元数据</h2><p>会返回一个JSON文件记录着Docker容器的配置和状态信息。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker inspect container_id/names</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"镜像仓库加速\"><a href=\"#镜像仓库加速\" class=\"headerlink\" title=\"镜像仓库加速\"></a>镜像仓库加速</h1><p>我是直接使用的阿里云的镜像仓库，如果你有阿里云账号的话，直接登录阿里云控制台，搜索“容器镜像服务”，最下面有一个镜像加速。</p>\n<p>里面是有介绍各个操作系统的步骤的，我的是CentOS。</p>\n<p>打开/etc/docker/daemon.json文件，如果没有的话可以先创建。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir -p /etc/docker</span><br></pre></td></tr></table></figure></p>\n<p>然后增加如下内容<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;registry-mirrors&quot;: [&quot;https://ilisd4hk.mirror.aliyuncs.com&quot;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>最后重启docker<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo systemctl daemon-reload</span><br><span class=\"line\">sudo systemctl restart docker</span><br></pre></td></tr></table></figure></p>"},{"title":"ElasticSearch入门简介","date":"2019-06-20T02:41:00.000Z","_content":"\n又开了一个坑，之前也只是对ES和ELK的使用和搭建只有简单的理解，没有系统的学习过，那趁着这段时间好好系统的学习下。\n\n<!-- more -->\n\nElasticSearch 基于JSON的开源分布式搜索分析引擎\n- Near Real Time 近实时\n- 分布式存储/搜索/分析引擎\n\n## 同类产品\n- solr(Apache开源项目)\n- splunk(商业上市公司)\n\n## Elastic Stack\n- Kibana 数据可视化\n- Logstash 动态数据收集管道\n- Beats 轻量型数据采集器\n\n## 起源\n### Lucene\n初创于1999年，Apache开源项目，基于JAVA语言开发\n- Lucene具有高性能、易扩展的优点\n- Lucene的局限性：\n    - 只能基于JAVA语言开发\n    - 类库的接口学习曲线陡峭\n    - 原生并不支持水品扩展\n\n### Elasticsearch的诞生\n- 2004年Shay Banon基于Lucene开发了Compass\n- 2010年Shay Banon对Compass进行了重写，更名为Elasticsearch\n    - 支持分布式、可水平扩展\n    - 提供Restful Api，降低全文检索的学习曲线。并且可接入任何语言应用。\n\n## Elasticsearch的分布式架构\n![es01](/image/ElasticSearch/elasticsearch01.jpg)\n- 集群规模可以从单个扩展至数百个节点\n- 高可用&水平扩展，从服务和数据两个维度\n- 支持设置不同的节点类型，支持Hot&Warm架构\n\n## 支持多种方式介接入\n- 多种语言接入类库\n- RESTful api & Transport Api\n- JDBC & ODBC\n\n## Elasticsearch主要功能\n- 海量数据的分布式存储以及集群管理\n    - 服务与数据的高可用、水平扩展\n- 近实时搜索，性能卓越\n    - 结构化/全文/地理位置/自动完成\n- 海量数据的近实时分析\n    - 聚合功能\n## 新特性\n### 5.x\n- Lucene 6.x，性能提升，默认打印机制从TF-IDF改为BM25\n- 支持Ingest节点/Painless Scripting/Completiion suggested支持/原生的Java REST客户端\n- Type标记成deprecated，支持了Keyword的类型\n- 性能优化\n    - 内部引擎移除了避免同一文档并发更新的竞争锁，带来了15%-20%的性能提升\n    - Instant aggregation，支持分片上的聚合的缓存\n    - 新增了Profile API\n\n### 6.x\n- Lucene 7.x\n- 新特性\n    - 跨集群复制（CCR）\n    - 索引生命周期管理\n    - SQL的支持\n- 更友好的升级以及数据迁移\n    - 在主要版本之间的迁移更加简化，体验升级\n    - 全新的基于操作的数据复制框架，可加快恢复数据\n- 性能优化\n    - 有效存储稀疏字段的新方法，降低了存储成本\n    - 在索引时进行排序，可加快排序的查询性能\n\n### 7.x\n- Lucene 8.0\n- 重大改进-正式废除单个索引下多Type的支持\n- 7.1开始，Security功能免费使用\n- ECK-Elasticsearch Operator on Kubernetes,可以将Elasticsearch部署至K8S的容器环境中\n- 新功能\n    - New Cluster coordinatio，新的分组协调\n    - Feature-Complete High Level REST Client，改进了高级REST客户端\n    - Script Score Query\n- 性能优化\n    - 默认的Primary Shard数由5改为1，避免over sharding\n    - 性能优化，更快的Top K\n\n## Elastic Stack生态圈\n![es02](/image/ElasticSearch/elastic_stack01.jpg)\n基于Elaticsearch、Logstash、Kibana等构建出一整套的生态系统，适合大量场景，向用户提供网站搜索、机器学习等服务。\n\n### Logstash 数据处理管道\n开源的服务端数据处理管道，支持从不同来源采集数据、转换数据，并将数据发送到不同的存储介质中。\n\nLogstash诞生于2009年，最初用作日志的的采集与处理，后再2013年被Elastic收购。\n\n#### 特性\n- 实时解析和转换数据\n    - 从IP地址破译出地理坐标\n    - 将PII数据匿名化，完全排除敏感字段\n- 可扩展\n    - 200多个插件（日志/数据库/Arcsigh/Netflow）\n- 可靠性安全性\n    - Logstash会通过持久化队列来保证至少将运行中的事件送达一次\n    - 数据传输加密\n- 监控\n\n### Kibana 可视化分析\nKibana = Kiwifruit（奇异果） + banana（香蕉）\n\n数据可视化工具，最初基于Logstash，2013年被Elastic公司收购。\n\n数据可视化分析，kibana可以提供一系列的可视化图表。也可以结合机器学习的技术做一些相关异常检测，提前发现可疑的问题。\n\n### Beats 轻量的数据采集器\nGo语言开发，运行速度快。\n- Filebeat：文件采集器\n- Packetbeat：网络数据抓包\n- functionbeat:对serveriess infrastructure提供数据抓取\n- winlogbeat\n- Metricbeat\n- Heartbeat\n- Auditbeat\n- Journalbeat\n\n### ELK应用场景\n- 网站搜索/垂直搜索/代码搜索\n- 日志管理与分析/安全指标监控/应用性能监控/WEB抓取舆情分析\n\n### 搜索场景\n#### ElasticSearch与数据库的集成\n![es03](/image/ElasticSearch/elasticsearch02.png)\n- 可以单独使用Elasticsearch进行单存储。但是当数据需要与现有数据集成、考虑事务性、数据频繁更新时，就需要与数据库进行同步数据了。\n\n### 指标分析/日志分析\n![es04](/image/ElasticSearch/elasticsearch03.png)\n1. Data Collection，收集数据。beats可以从不同的数据源中收集数据。对于特定的需求，可以通过代码实现数据收集。\n2. Buffering，缓冲。在真实的业务场景中，往往需要收集的数据量较大\n，需要引入消息、缓存中间件来作为数据采集的缓冲层。\n3. Data Aggregation&Processing，数据转化聚合后发送给ES。\n4. Indexing&Storage，索引和存储。\n5. Analysis&visualization，基于Elasticsearch可以搭建Kibana，也可以使用可Grafana进行数据分析，图形化展示。","source":"_posts/elasticsearch_01_简介.md","raw":"---\ntitle: ElasticSearch入门简介\ndate: 2019-06-20 10:41:00\ntags: ElasticSearch\ncategories: Elastic Stack\n---\n\n又开了一个坑，之前也只是对ES和ELK的使用和搭建只有简单的理解，没有系统的学习过，那趁着这段时间好好系统的学习下。\n\n<!-- more -->\n\nElasticSearch 基于JSON的开源分布式搜索分析引擎\n- Near Real Time 近实时\n- 分布式存储/搜索/分析引擎\n\n## 同类产品\n- solr(Apache开源项目)\n- splunk(商业上市公司)\n\n## Elastic Stack\n- Kibana 数据可视化\n- Logstash 动态数据收集管道\n- Beats 轻量型数据采集器\n\n## 起源\n### Lucene\n初创于1999年，Apache开源项目，基于JAVA语言开发\n- Lucene具有高性能、易扩展的优点\n- Lucene的局限性：\n    - 只能基于JAVA语言开发\n    - 类库的接口学习曲线陡峭\n    - 原生并不支持水品扩展\n\n### Elasticsearch的诞生\n- 2004年Shay Banon基于Lucene开发了Compass\n- 2010年Shay Banon对Compass进行了重写，更名为Elasticsearch\n    - 支持分布式、可水平扩展\n    - 提供Restful Api，降低全文检索的学习曲线。并且可接入任何语言应用。\n\n## Elasticsearch的分布式架构\n![es01](/image/ElasticSearch/elasticsearch01.jpg)\n- 集群规模可以从单个扩展至数百个节点\n- 高可用&水平扩展，从服务和数据两个维度\n- 支持设置不同的节点类型，支持Hot&Warm架构\n\n## 支持多种方式介接入\n- 多种语言接入类库\n- RESTful api & Transport Api\n- JDBC & ODBC\n\n## Elasticsearch主要功能\n- 海量数据的分布式存储以及集群管理\n    - 服务与数据的高可用、水平扩展\n- 近实时搜索，性能卓越\n    - 结构化/全文/地理位置/自动完成\n- 海量数据的近实时分析\n    - 聚合功能\n## 新特性\n### 5.x\n- Lucene 6.x，性能提升，默认打印机制从TF-IDF改为BM25\n- 支持Ingest节点/Painless Scripting/Completiion suggested支持/原生的Java REST客户端\n- Type标记成deprecated，支持了Keyword的类型\n- 性能优化\n    - 内部引擎移除了避免同一文档并发更新的竞争锁，带来了15%-20%的性能提升\n    - Instant aggregation，支持分片上的聚合的缓存\n    - 新增了Profile API\n\n### 6.x\n- Lucene 7.x\n- 新特性\n    - 跨集群复制（CCR）\n    - 索引生命周期管理\n    - SQL的支持\n- 更友好的升级以及数据迁移\n    - 在主要版本之间的迁移更加简化，体验升级\n    - 全新的基于操作的数据复制框架，可加快恢复数据\n- 性能优化\n    - 有效存储稀疏字段的新方法，降低了存储成本\n    - 在索引时进行排序，可加快排序的查询性能\n\n### 7.x\n- Lucene 8.0\n- 重大改进-正式废除单个索引下多Type的支持\n- 7.1开始，Security功能免费使用\n- ECK-Elasticsearch Operator on Kubernetes,可以将Elasticsearch部署至K8S的容器环境中\n- 新功能\n    - New Cluster coordinatio，新的分组协调\n    - Feature-Complete High Level REST Client，改进了高级REST客户端\n    - Script Score Query\n- 性能优化\n    - 默认的Primary Shard数由5改为1，避免over sharding\n    - 性能优化，更快的Top K\n\n## Elastic Stack生态圈\n![es02](/image/ElasticSearch/elastic_stack01.jpg)\n基于Elaticsearch、Logstash、Kibana等构建出一整套的生态系统，适合大量场景，向用户提供网站搜索、机器学习等服务。\n\n### Logstash 数据处理管道\n开源的服务端数据处理管道，支持从不同来源采集数据、转换数据，并将数据发送到不同的存储介质中。\n\nLogstash诞生于2009年，最初用作日志的的采集与处理，后再2013年被Elastic收购。\n\n#### 特性\n- 实时解析和转换数据\n    - 从IP地址破译出地理坐标\n    - 将PII数据匿名化，完全排除敏感字段\n- 可扩展\n    - 200多个插件（日志/数据库/Arcsigh/Netflow）\n- 可靠性安全性\n    - Logstash会通过持久化队列来保证至少将运行中的事件送达一次\n    - 数据传输加密\n- 监控\n\n### Kibana 可视化分析\nKibana = Kiwifruit（奇异果） + banana（香蕉）\n\n数据可视化工具，最初基于Logstash，2013年被Elastic公司收购。\n\n数据可视化分析，kibana可以提供一系列的可视化图表。也可以结合机器学习的技术做一些相关异常检测，提前发现可疑的问题。\n\n### Beats 轻量的数据采集器\nGo语言开发，运行速度快。\n- Filebeat：文件采集器\n- Packetbeat：网络数据抓包\n- functionbeat:对serveriess infrastructure提供数据抓取\n- winlogbeat\n- Metricbeat\n- Heartbeat\n- Auditbeat\n- Journalbeat\n\n### ELK应用场景\n- 网站搜索/垂直搜索/代码搜索\n- 日志管理与分析/安全指标监控/应用性能监控/WEB抓取舆情分析\n\n### 搜索场景\n#### ElasticSearch与数据库的集成\n![es03](/image/ElasticSearch/elasticsearch02.png)\n- 可以单独使用Elasticsearch进行单存储。但是当数据需要与现有数据集成、考虑事务性、数据频繁更新时，就需要与数据库进行同步数据了。\n\n### 指标分析/日志分析\n![es04](/image/ElasticSearch/elasticsearch03.png)\n1. Data Collection，收集数据。beats可以从不同的数据源中收集数据。对于特定的需求，可以通过代码实现数据收集。\n2. Buffering，缓冲。在真实的业务场景中，往往需要收集的数据量较大\n，需要引入消息、缓存中间件来作为数据采集的缓冲层。\n3. Data Aggregation&Processing，数据转化聚合后发送给ES。\n4. Indexing&Storage，索引和存储。\n5. Analysis&visualization，基于Elasticsearch可以搭建Kibana，也可以使用可Grafana进行数据分析，图形化展示。","slug":"elasticsearch_01_简介","published":1,"updated":"2019-08-26T07:51:20.118Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl01000rqotnf1ft3l5h","content":"<p>又开了一个坑，之前也只是对ES和ELK的使用和搭建只有简单的理解，没有系统的学习过，那趁着这段时间好好系统的学习下。</p>\n<a id=\"more\"></a>\n<p>ElasticSearch 基于JSON的开源分布式搜索分析引擎</p>\n<ul>\n<li>Near Real Time 近实时</li>\n<li>分布式存储/搜索/分析引擎</li>\n</ul>\n<h2 id=\"同类产品\"><a href=\"#同类产品\" class=\"headerlink\" title=\"同类产品\"></a>同类产品</h2><ul>\n<li>solr(Apache开源项目)</li>\n<li>splunk(商业上市公司)</li>\n</ul>\n<h2 id=\"Elastic-Stack\"><a href=\"#Elastic-Stack\" class=\"headerlink\" title=\"Elastic Stack\"></a>Elastic Stack</h2><ul>\n<li>Kibana 数据可视化</li>\n<li>Logstash 动态数据收集管道</li>\n<li>Beats 轻量型数据采集器</li>\n</ul>\n<h2 id=\"起源\"><a href=\"#起源\" class=\"headerlink\" title=\"起源\"></a>起源</h2><h3 id=\"Lucene\"><a href=\"#Lucene\" class=\"headerlink\" title=\"Lucene\"></a>Lucene</h3><p>初创于1999年，Apache开源项目，基于JAVA语言开发</p>\n<ul>\n<li>Lucene具有高性能、易扩展的优点</li>\n<li>Lucene的局限性：<ul>\n<li>只能基于JAVA语言开发</li>\n<li>类库的接口学习曲线陡峭</li>\n<li>原生并不支持水品扩展</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Elasticsearch的诞生\"><a href=\"#Elasticsearch的诞生\" class=\"headerlink\" title=\"Elasticsearch的诞生\"></a>Elasticsearch的诞生</h3><ul>\n<li>2004年Shay Banon基于Lucene开发了Compass</li>\n<li>2010年Shay Banon对Compass进行了重写，更名为Elasticsearch<ul>\n<li>支持分布式、可水平扩展</li>\n<li>提供Restful Api，降低全文检索的学习曲线。并且可接入任何语言应用。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Elasticsearch的分布式架构\"><a href=\"#Elasticsearch的分布式架构\" class=\"headerlink\" title=\"Elasticsearch的分布式架构\"></a>Elasticsearch的分布式架构</h2><p><img src=\"/image/ElasticSearch/elasticsearch01.jpg\" alt=\"es01\"></p>\n<ul>\n<li>集群规模可以从单个扩展至数百个节点</li>\n<li>高可用&amp;水平扩展，从服务和数据两个维度</li>\n<li>支持设置不同的节点类型，支持Hot&amp;Warm架构</li>\n</ul>\n<h2 id=\"支持多种方式介接入\"><a href=\"#支持多种方式介接入\" class=\"headerlink\" title=\"支持多种方式介接入\"></a>支持多种方式介接入</h2><ul>\n<li>多种语言接入类库</li>\n<li>RESTful api &amp; Transport Api</li>\n<li>JDBC &amp; ODBC</li>\n</ul>\n<h2 id=\"Elasticsearch主要功能\"><a href=\"#Elasticsearch主要功能\" class=\"headerlink\" title=\"Elasticsearch主要功能\"></a>Elasticsearch主要功能</h2><ul>\n<li>海量数据的分布式存储以及集群管理<ul>\n<li>服务与数据的高可用、水平扩展</li>\n</ul>\n</li>\n<li>近实时搜索，性能卓越<ul>\n<li>结构化/全文/地理位置/自动完成</li>\n</ul>\n</li>\n<li>海量数据的近实时分析<ul>\n<li>聚合功能<h2 id=\"新特性\"><a href=\"#新特性\" class=\"headerlink\" title=\"新特性\"></a>新特性</h2><h3 id=\"5-x\"><a href=\"#5-x\" class=\"headerlink\" title=\"5.x\"></a>5.x</h3></li>\n</ul>\n</li>\n<li>Lucene 6.x，性能提升，默认打印机制从TF-IDF改为BM25</li>\n<li>支持Ingest节点/Painless Scripting/Completiion suggested支持/原生的Java REST客户端</li>\n<li>Type标记成deprecated，支持了Keyword的类型</li>\n<li>性能优化<ul>\n<li>内部引擎移除了避免同一文档并发更新的竞争锁，带来了15%-20%的性能提升</li>\n<li>Instant aggregation，支持分片上的聚合的缓存</li>\n<li>新增了Profile API</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-x\"><a href=\"#6-x\" class=\"headerlink\" title=\"6.x\"></a>6.x</h3><ul>\n<li>Lucene 7.x</li>\n<li>新特性<ul>\n<li>跨集群复制（CCR）</li>\n<li>索引生命周期管理</li>\n<li>SQL的支持</li>\n</ul>\n</li>\n<li>更友好的升级以及数据迁移<ul>\n<li>在主要版本之间的迁移更加简化，体验升级</li>\n<li>全新的基于操作的数据复制框架，可加快恢复数据</li>\n</ul>\n</li>\n<li>性能优化<ul>\n<li>有效存储稀疏字段的新方法，降低了存储成本</li>\n<li>在索引时进行排序，可加快排序的查询性能</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"7-x\"><a href=\"#7-x\" class=\"headerlink\" title=\"7.x\"></a>7.x</h3><ul>\n<li>Lucene 8.0</li>\n<li>重大改进-正式废除单个索引下多Type的支持</li>\n<li>7.1开始，Security功能免费使用</li>\n<li>ECK-Elasticsearch Operator on Kubernetes,可以将Elasticsearch部署至K8S的容器环境中</li>\n<li>新功能<ul>\n<li>New Cluster coordinatio，新的分组协调</li>\n<li>Feature-Complete High Level REST Client，改进了高级REST客户端</li>\n<li>Script Score Query</li>\n</ul>\n</li>\n<li>性能优化<ul>\n<li>默认的Primary Shard数由5改为1，避免over sharding</li>\n<li>性能优化，更快的Top K</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Elastic-Stack生态圈\"><a href=\"#Elastic-Stack生态圈\" class=\"headerlink\" title=\"Elastic Stack生态圈\"></a>Elastic Stack生态圈</h2><p><img src=\"/image/ElasticSearch/elastic_stack01.jpg\" alt=\"es02\"><br>基于Elaticsearch、Logstash、Kibana等构建出一整套的生态系统，适合大量场景，向用户提供网站搜索、机器学习等服务。</p>\n<h3 id=\"Logstash-数据处理管道\"><a href=\"#Logstash-数据处理管道\" class=\"headerlink\" title=\"Logstash 数据处理管道\"></a>Logstash 数据处理管道</h3><p>开源的服务端数据处理管道，支持从不同来源采集数据、转换数据，并将数据发送到不同的存储介质中。</p>\n<p>Logstash诞生于2009年，最初用作日志的的采集与处理，后再2013年被Elastic收购。</p>\n<h4 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li>实时解析和转换数据<ul>\n<li>从IP地址破译出地理坐标</li>\n<li>将PII数据匿名化，完全排除敏感字段</li>\n</ul>\n</li>\n<li>可扩展<ul>\n<li>200多个插件（日志/数据库/Arcsigh/Netflow）</li>\n</ul>\n</li>\n<li>可靠性安全性<ul>\n<li>Logstash会通过持久化队列来保证至少将运行中的事件送达一次</li>\n<li>数据传输加密</li>\n</ul>\n</li>\n<li>监控</li>\n</ul>\n<h3 id=\"Kibana-可视化分析\"><a href=\"#Kibana-可视化分析\" class=\"headerlink\" title=\"Kibana 可视化分析\"></a>Kibana 可视化分析</h3><p>Kibana = Kiwifruit（奇异果） + banana（香蕉）</p>\n<p>数据可视化工具，最初基于Logstash，2013年被Elastic公司收购。</p>\n<p>数据可视化分析，kibana可以提供一系列的可视化图表。也可以结合机器学习的技术做一些相关异常检测，提前发现可疑的问题。</p>\n<h3 id=\"Beats-轻量的数据采集器\"><a href=\"#Beats-轻量的数据采集器\" class=\"headerlink\" title=\"Beats 轻量的数据采集器\"></a>Beats 轻量的数据采集器</h3><p>Go语言开发，运行速度快。</p>\n<ul>\n<li>Filebeat：文件采集器</li>\n<li>Packetbeat：网络数据抓包</li>\n<li>functionbeat:对serveriess infrastructure提供数据抓取</li>\n<li>winlogbeat</li>\n<li>Metricbeat</li>\n<li>Heartbeat</li>\n<li>Auditbeat</li>\n<li>Journalbeat</li>\n</ul>\n<h3 id=\"ELK应用场景\"><a href=\"#ELK应用场景\" class=\"headerlink\" title=\"ELK应用场景\"></a>ELK应用场景</h3><ul>\n<li>网站搜索/垂直搜索/代码搜索</li>\n<li>日志管理与分析/安全指标监控/应用性能监控/WEB抓取舆情分析</li>\n</ul>\n<h3 id=\"搜索场景\"><a href=\"#搜索场景\" class=\"headerlink\" title=\"搜索场景\"></a>搜索场景</h3><h4 id=\"ElasticSearch与数据库的集成\"><a href=\"#ElasticSearch与数据库的集成\" class=\"headerlink\" title=\"ElasticSearch与数据库的集成\"></a>ElasticSearch与数据库的集成</h4><p><img src=\"/image/ElasticSearch/elasticsearch02.png\" alt=\"es03\"></p>\n<ul>\n<li>可以单独使用Elasticsearch进行单存储。但是当数据需要与现有数据集成、考虑事务性、数据频繁更新时，就需要与数据库进行同步数据了。</li>\n</ul>\n<h3 id=\"指标分析-日志分析\"><a href=\"#指标分析-日志分析\" class=\"headerlink\" title=\"指标分析/日志分析\"></a>指标分析/日志分析</h3><p><img src=\"/image/ElasticSearch/elasticsearch03.png\" alt=\"es04\"></p>\n<ol>\n<li>Data Collection，收集数据。beats可以从不同的数据源中收集数据。对于特定的需求，可以通过代码实现数据收集。</li>\n<li>Buffering，缓冲。在真实的业务场景中，往往需要收集的数据量较大<br>，需要引入消息、缓存中间件来作为数据采集的缓冲层。</li>\n<li>Data Aggregation&amp;Processing，数据转化聚合后发送给ES。</li>\n<li>Indexing&amp;Storage，索引和存储。</li>\n<li>Analysis&amp;visualization，基于Elasticsearch可以搭建Kibana，也可以使用可Grafana进行数据分析，图形化展示。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>又开了一个坑，之前也只是对ES和ELK的使用和搭建只有简单的理解，没有系统的学习过，那趁着这段时间好好系统的学习下。</p>","more":"<p>ElasticSearch 基于JSON的开源分布式搜索分析引擎</p>\n<ul>\n<li>Near Real Time 近实时</li>\n<li>分布式存储/搜索/分析引擎</li>\n</ul>\n<h2 id=\"同类产品\"><a href=\"#同类产品\" class=\"headerlink\" title=\"同类产品\"></a>同类产品</h2><ul>\n<li>solr(Apache开源项目)</li>\n<li>splunk(商业上市公司)</li>\n</ul>\n<h2 id=\"Elastic-Stack\"><a href=\"#Elastic-Stack\" class=\"headerlink\" title=\"Elastic Stack\"></a>Elastic Stack</h2><ul>\n<li>Kibana 数据可视化</li>\n<li>Logstash 动态数据收集管道</li>\n<li>Beats 轻量型数据采集器</li>\n</ul>\n<h2 id=\"起源\"><a href=\"#起源\" class=\"headerlink\" title=\"起源\"></a>起源</h2><h3 id=\"Lucene\"><a href=\"#Lucene\" class=\"headerlink\" title=\"Lucene\"></a>Lucene</h3><p>初创于1999年，Apache开源项目，基于JAVA语言开发</p>\n<ul>\n<li>Lucene具有高性能、易扩展的优点</li>\n<li>Lucene的局限性：<ul>\n<li>只能基于JAVA语言开发</li>\n<li>类库的接口学习曲线陡峭</li>\n<li>原生并不支持水品扩展</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Elasticsearch的诞生\"><a href=\"#Elasticsearch的诞生\" class=\"headerlink\" title=\"Elasticsearch的诞生\"></a>Elasticsearch的诞生</h3><ul>\n<li>2004年Shay Banon基于Lucene开发了Compass</li>\n<li>2010年Shay Banon对Compass进行了重写，更名为Elasticsearch<ul>\n<li>支持分布式、可水平扩展</li>\n<li>提供Restful Api，降低全文检索的学习曲线。并且可接入任何语言应用。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Elasticsearch的分布式架构\"><a href=\"#Elasticsearch的分布式架构\" class=\"headerlink\" title=\"Elasticsearch的分布式架构\"></a>Elasticsearch的分布式架构</h2><p><img src=\"/image/ElasticSearch/elasticsearch01.jpg\" alt=\"es01\"></p>\n<ul>\n<li>集群规模可以从单个扩展至数百个节点</li>\n<li>高可用&amp;水平扩展，从服务和数据两个维度</li>\n<li>支持设置不同的节点类型，支持Hot&amp;Warm架构</li>\n</ul>\n<h2 id=\"支持多种方式介接入\"><a href=\"#支持多种方式介接入\" class=\"headerlink\" title=\"支持多种方式介接入\"></a>支持多种方式介接入</h2><ul>\n<li>多种语言接入类库</li>\n<li>RESTful api &amp; Transport Api</li>\n<li>JDBC &amp; ODBC</li>\n</ul>\n<h2 id=\"Elasticsearch主要功能\"><a href=\"#Elasticsearch主要功能\" class=\"headerlink\" title=\"Elasticsearch主要功能\"></a>Elasticsearch主要功能</h2><ul>\n<li>海量数据的分布式存储以及集群管理<ul>\n<li>服务与数据的高可用、水平扩展</li>\n</ul>\n</li>\n<li>近实时搜索，性能卓越<ul>\n<li>结构化/全文/地理位置/自动完成</li>\n</ul>\n</li>\n<li>海量数据的近实时分析<ul>\n<li>聚合功能<h2 id=\"新特性\"><a href=\"#新特性\" class=\"headerlink\" title=\"新特性\"></a>新特性</h2><h3 id=\"5-x\"><a href=\"#5-x\" class=\"headerlink\" title=\"5.x\"></a>5.x</h3></li>\n</ul>\n</li>\n<li>Lucene 6.x，性能提升，默认打印机制从TF-IDF改为BM25</li>\n<li>支持Ingest节点/Painless Scripting/Completiion suggested支持/原生的Java REST客户端</li>\n<li>Type标记成deprecated，支持了Keyword的类型</li>\n<li>性能优化<ul>\n<li>内部引擎移除了避免同一文档并发更新的竞争锁，带来了15%-20%的性能提升</li>\n<li>Instant aggregation，支持分片上的聚合的缓存</li>\n<li>新增了Profile API</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6-x\"><a href=\"#6-x\" class=\"headerlink\" title=\"6.x\"></a>6.x</h3><ul>\n<li>Lucene 7.x</li>\n<li>新特性<ul>\n<li>跨集群复制（CCR）</li>\n<li>索引生命周期管理</li>\n<li>SQL的支持</li>\n</ul>\n</li>\n<li>更友好的升级以及数据迁移<ul>\n<li>在主要版本之间的迁移更加简化，体验升级</li>\n<li>全新的基于操作的数据复制框架，可加快恢复数据</li>\n</ul>\n</li>\n<li>性能优化<ul>\n<li>有效存储稀疏字段的新方法，降低了存储成本</li>\n<li>在索引时进行排序，可加快排序的查询性能</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"7-x\"><a href=\"#7-x\" class=\"headerlink\" title=\"7.x\"></a>7.x</h3><ul>\n<li>Lucene 8.0</li>\n<li>重大改进-正式废除单个索引下多Type的支持</li>\n<li>7.1开始，Security功能免费使用</li>\n<li>ECK-Elasticsearch Operator on Kubernetes,可以将Elasticsearch部署至K8S的容器环境中</li>\n<li>新功能<ul>\n<li>New Cluster coordinatio，新的分组协调</li>\n<li>Feature-Complete High Level REST Client，改进了高级REST客户端</li>\n<li>Script Score Query</li>\n</ul>\n</li>\n<li>性能优化<ul>\n<li>默认的Primary Shard数由5改为1，避免over sharding</li>\n<li>性能优化，更快的Top K</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Elastic-Stack生态圈\"><a href=\"#Elastic-Stack生态圈\" class=\"headerlink\" title=\"Elastic Stack生态圈\"></a>Elastic Stack生态圈</h2><p><img src=\"/image/ElasticSearch/elastic_stack01.jpg\" alt=\"es02\"><br>基于Elaticsearch、Logstash、Kibana等构建出一整套的生态系统，适合大量场景，向用户提供网站搜索、机器学习等服务。</p>\n<h3 id=\"Logstash-数据处理管道\"><a href=\"#Logstash-数据处理管道\" class=\"headerlink\" title=\"Logstash 数据处理管道\"></a>Logstash 数据处理管道</h3><p>开源的服务端数据处理管道，支持从不同来源采集数据、转换数据，并将数据发送到不同的存储介质中。</p>\n<p>Logstash诞生于2009年，最初用作日志的的采集与处理，后再2013年被Elastic收购。</p>\n<h4 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li>实时解析和转换数据<ul>\n<li>从IP地址破译出地理坐标</li>\n<li>将PII数据匿名化，完全排除敏感字段</li>\n</ul>\n</li>\n<li>可扩展<ul>\n<li>200多个插件（日志/数据库/Arcsigh/Netflow）</li>\n</ul>\n</li>\n<li>可靠性安全性<ul>\n<li>Logstash会通过持久化队列来保证至少将运行中的事件送达一次</li>\n<li>数据传输加密</li>\n</ul>\n</li>\n<li>监控</li>\n</ul>\n<h3 id=\"Kibana-可视化分析\"><a href=\"#Kibana-可视化分析\" class=\"headerlink\" title=\"Kibana 可视化分析\"></a>Kibana 可视化分析</h3><p>Kibana = Kiwifruit（奇异果） + banana（香蕉）</p>\n<p>数据可视化工具，最初基于Logstash，2013年被Elastic公司收购。</p>\n<p>数据可视化分析，kibana可以提供一系列的可视化图表。也可以结合机器学习的技术做一些相关异常检测，提前发现可疑的问题。</p>\n<h3 id=\"Beats-轻量的数据采集器\"><a href=\"#Beats-轻量的数据采集器\" class=\"headerlink\" title=\"Beats 轻量的数据采集器\"></a>Beats 轻量的数据采集器</h3><p>Go语言开发，运行速度快。</p>\n<ul>\n<li>Filebeat：文件采集器</li>\n<li>Packetbeat：网络数据抓包</li>\n<li>functionbeat:对serveriess infrastructure提供数据抓取</li>\n<li>winlogbeat</li>\n<li>Metricbeat</li>\n<li>Heartbeat</li>\n<li>Auditbeat</li>\n<li>Journalbeat</li>\n</ul>\n<h3 id=\"ELK应用场景\"><a href=\"#ELK应用场景\" class=\"headerlink\" title=\"ELK应用场景\"></a>ELK应用场景</h3><ul>\n<li>网站搜索/垂直搜索/代码搜索</li>\n<li>日志管理与分析/安全指标监控/应用性能监控/WEB抓取舆情分析</li>\n</ul>\n<h3 id=\"搜索场景\"><a href=\"#搜索场景\" class=\"headerlink\" title=\"搜索场景\"></a>搜索场景</h3><h4 id=\"ElasticSearch与数据库的集成\"><a href=\"#ElasticSearch与数据库的集成\" class=\"headerlink\" title=\"ElasticSearch与数据库的集成\"></a>ElasticSearch与数据库的集成</h4><p><img src=\"/image/ElasticSearch/elasticsearch02.png\" alt=\"es03\"></p>\n<ul>\n<li>可以单独使用Elasticsearch进行单存储。但是当数据需要与现有数据集成、考虑事务性、数据频繁更新时，就需要与数据库进行同步数据了。</li>\n</ul>\n<h3 id=\"指标分析-日志分析\"><a href=\"#指标分析-日志分析\" class=\"headerlink\" title=\"指标分析/日志分析\"></a>指标分析/日志分析</h3><p><img src=\"/image/ElasticSearch/elasticsearch03.png\" alt=\"es04\"></p>\n<ol>\n<li>Data Collection，收集数据。beats可以从不同的数据源中收集数据。对于特定的需求，可以通过代码实现数据收集。</li>\n<li>Buffering，缓冲。在真实的业务场景中，往往需要收集的数据量较大<br>，需要引入消息、缓存中间件来作为数据采集的缓冲层。</li>\n<li>Data Aggregation&amp;Processing，数据转化聚合后发送给ES。</li>\n<li>Indexing&amp;Storage，索引和存储。</li>\n<li>Analysis&amp;visualization，基于Elasticsearch可以搭建Kibana，也可以使用可Grafana进行数据分析，图形化展示。</li>\n</ol>"},{"title":"ElasticSearch安装","date":"2019-07-17T09:00:00.000Z","_content":"\nElasticsearch的安装部署、以及简单配置。\n\n<!-- more -->\n\n## 运行环境\n- 安装并配置JDK，设置$JAVA_HOME。\n- 各个版本对Java的依赖\n    - Elasticsearch 5，需要Java8以上版本\n    - Elasticsearch 6.5开始支持Java11\n    - Elasticsearch 7.0开始，内置了Java环境\n\n## 安装\n可以直接访问[Elasticsearch官网](https://www.elastic.co/cn/downloads/elasticsearch)进行下载。同时，Elastic官方也提供docker镜像，通过docker进行快速部署。\n\n## Elasticsearch的文件目录结构\n目录 | 配置文件 | 描述\n-- | -- | --\nbin     |  | 脚本文件，包括启动elasticsearch，安装插件。运行统计数据等\nconfig  | elasticsearch.yml | 集群配置文件，user、role、based相关配置\nJDK     |  | Java运行环境\ndata    | path.data | 数据文件\nlib     |  | Java相关类库\nlogs    | path.log | 日志文件\nmodules |  | 包含所有ES模块\nplugins |  | 包含所有已安装插件\n\n## 安装错误解决方法汇总\n1. seccomp unavailable 错误\n解决方法：elasticsearch.yml 配置\n\nbootstrap.memory_lock: false\n\nbootstrap.system_call_filter: false\n\n2. max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]\n\n解决方法：修改 /etc/security/limits.conf，配置：\n\nhard nofile 80000\n\nsoft nofile 80000\n\n3. max virtual memory areas vm.max_map_count [65530] is too low\n\n解决方法：修改 /etc/sysctl.conf，添加 ：\n\nvm.max_map_count = 262144\n\n然后 sysctl -p 生效\n\n4. the default discovery settings are unsuitable...., last least one of [....] must be configured\n\n解决方法：elasticsearch.yml 开启配置：\n\nnode.name: node-1\n\ncluster.initial_master_nodes: [\"node-1\"]","source":"_posts/elasticsearch_02_安装.md","raw":"---\ntitle: ElasticSearch安装\ndate: 2019-07-17 17:00:00\ntags: ElasticSearch\ncategories: Elastic Stack\n---\n\nElasticsearch的安装部署、以及简单配置。\n\n<!-- more -->\n\n## 运行环境\n- 安装并配置JDK，设置$JAVA_HOME。\n- 各个版本对Java的依赖\n    - Elasticsearch 5，需要Java8以上版本\n    - Elasticsearch 6.5开始支持Java11\n    - Elasticsearch 7.0开始，内置了Java环境\n\n## 安装\n可以直接访问[Elasticsearch官网](https://www.elastic.co/cn/downloads/elasticsearch)进行下载。同时，Elastic官方也提供docker镜像，通过docker进行快速部署。\n\n## Elasticsearch的文件目录结构\n目录 | 配置文件 | 描述\n-- | -- | --\nbin     |  | 脚本文件，包括启动elasticsearch，安装插件。运行统计数据等\nconfig  | elasticsearch.yml | 集群配置文件，user、role、based相关配置\nJDK     |  | Java运行环境\ndata    | path.data | 数据文件\nlib     |  | Java相关类库\nlogs    | path.log | 日志文件\nmodules |  | 包含所有ES模块\nplugins |  | 包含所有已安装插件\n\n## 安装错误解决方法汇总\n1. seccomp unavailable 错误\n解决方法：elasticsearch.yml 配置\n\nbootstrap.memory_lock: false\n\nbootstrap.system_call_filter: false\n\n2. max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]\n\n解决方法：修改 /etc/security/limits.conf，配置：\n\nhard nofile 80000\n\nsoft nofile 80000\n\n3. max virtual memory areas vm.max_map_count [65530] is too low\n\n解决方法：修改 /etc/sysctl.conf，添加 ：\n\nvm.max_map_count = 262144\n\n然后 sysctl -p 生效\n\n4. the default discovery settings are unsuitable...., last least one of [....] must be configured\n\n解决方法：elasticsearch.yml 开启配置：\n\nnode.name: node-1\n\ncluster.initial_master_nodes: [\"node-1\"]","slug":"elasticsearch_02_安装","published":1,"updated":"2019-09-05T09:32:18.566Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl03000wqotnbt1ma8rg","content":"<p>Elasticsearch的安装部署、以及简单配置。</p>\n<a id=\"more\"></a>\n<h2 id=\"运行环境\"><a href=\"#运行环境\" class=\"headerlink\" title=\"运行环境\"></a>运行环境</h2><ul>\n<li>安装并配置JDK，设置$JAVA_HOME。</li>\n<li>各个版本对Java的依赖<ul>\n<li>Elasticsearch 5，需要Java8以上版本</li>\n<li>Elasticsearch 6.5开始支持Java11</li>\n<li>Elasticsearch 7.0开始，内置了Java环境</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>可以直接访问<a href=\"https://www.elastic.co/cn/downloads/elasticsearch\" target=\"_blank\" rel=\"noopener\">Elasticsearch官网</a>进行下载。同时，Elastic官方也提供docker镜像，通过docker进行快速部署。</p>\n<h2 id=\"Elasticsearch的文件目录结构\"><a href=\"#Elasticsearch的文件目录结构\" class=\"headerlink\" title=\"Elasticsearch的文件目录结构\"></a>Elasticsearch的文件目录结构</h2><table>\n<thead>\n<tr>\n<th>目录</th>\n<th>配置文件</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bin</td>\n<td></td>\n<td>脚本文件，包括启动elasticsearch，安装插件。运行统计数据等</td>\n</tr>\n<tr>\n<td>config</td>\n<td>elasticsearch.yml</td>\n<td>集群配置文件，user、role、based相关配置</td>\n</tr>\n<tr>\n<td>JDK</td>\n<td></td>\n<td>Java运行环境</td>\n</tr>\n<tr>\n<td>data</td>\n<td>path.data</td>\n<td>数据文件</td>\n</tr>\n<tr>\n<td>lib</td>\n<td></td>\n<td>Java相关类库</td>\n</tr>\n<tr>\n<td>logs</td>\n<td>path.log</td>\n<td>日志文件</td>\n</tr>\n<tr>\n<td>modules</td>\n<td></td>\n<td>包含所有ES模块</td>\n</tr>\n<tr>\n<td>plugins</td>\n<td></td>\n<td>包含所有已安装插件</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"安装错误解决方法汇总\"><a href=\"#安装错误解决方法汇总\" class=\"headerlink\" title=\"安装错误解决方法汇总\"></a>安装错误解决方法汇总</h2><ol>\n<li>seccomp unavailable 错误<br>解决方法：elasticsearch.yml 配置</li>\n</ol>\n<p>bootstrap.memory_lock: false</p>\n<p>bootstrap.system_call_filter: false</p>\n<ol start=\"2\">\n<li>max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]</li>\n</ol>\n<p>解决方法：修改 /etc/security/limits.conf，配置：</p>\n<p>hard nofile 80000</p>\n<p>soft nofile 80000</p>\n<ol start=\"3\">\n<li>max virtual memory areas vm.max_map_count [65530] is too low</li>\n</ol>\n<p>解决方法：修改 /etc/sysctl.conf，添加 ：</p>\n<p>vm.max_map_count = 262144</p>\n<p>然后 sysctl -p 生效</p>\n<ol start=\"4\">\n<li>the default discovery settings are unsuitable…., last least one of [….] must be configured</li>\n</ol>\n<p>解决方法：elasticsearch.yml 开启配置：</p>\n<p>node.name: node-1</p>\n<p>cluster.initial_master_nodes: [“node-1”]</p>\n","site":{"data":{}},"excerpt":"<p>Elasticsearch的安装部署、以及简单配置。</p>","more":"<h2 id=\"运行环境\"><a href=\"#运行环境\" class=\"headerlink\" title=\"运行环境\"></a>运行环境</h2><ul>\n<li>安装并配置JDK，设置$JAVA_HOME。</li>\n<li>各个版本对Java的依赖<ul>\n<li>Elasticsearch 5，需要Java8以上版本</li>\n<li>Elasticsearch 6.5开始支持Java11</li>\n<li>Elasticsearch 7.0开始，内置了Java环境</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>可以直接访问<a href=\"https://www.elastic.co/cn/downloads/elasticsearch\" target=\"_blank\" rel=\"noopener\">Elasticsearch官网</a>进行下载。同时，Elastic官方也提供docker镜像，通过docker进行快速部署。</p>\n<h2 id=\"Elasticsearch的文件目录结构\"><a href=\"#Elasticsearch的文件目录结构\" class=\"headerlink\" title=\"Elasticsearch的文件目录结构\"></a>Elasticsearch的文件目录结构</h2><table>\n<thead>\n<tr>\n<th>目录</th>\n<th>配置文件</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bin</td>\n<td></td>\n<td>脚本文件，包括启动elasticsearch，安装插件。运行统计数据等</td>\n</tr>\n<tr>\n<td>config</td>\n<td>elasticsearch.yml</td>\n<td>集群配置文件，user、role、based相关配置</td>\n</tr>\n<tr>\n<td>JDK</td>\n<td></td>\n<td>Java运行环境</td>\n</tr>\n<tr>\n<td>data</td>\n<td>path.data</td>\n<td>数据文件</td>\n</tr>\n<tr>\n<td>lib</td>\n<td></td>\n<td>Java相关类库</td>\n</tr>\n<tr>\n<td>logs</td>\n<td>path.log</td>\n<td>日志文件</td>\n</tr>\n<tr>\n<td>modules</td>\n<td></td>\n<td>包含所有ES模块</td>\n</tr>\n<tr>\n<td>plugins</td>\n<td></td>\n<td>包含所有已安装插件</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"安装错误解决方法汇总\"><a href=\"#安装错误解决方法汇总\" class=\"headerlink\" title=\"安装错误解决方法汇总\"></a>安装错误解决方法汇总</h2><ol>\n<li>seccomp unavailable 错误<br>解决方法：elasticsearch.yml 配置</li>\n</ol>\n<p>bootstrap.memory_lock: false</p>\n<p>bootstrap.system_call_filter: false</p>\n<ol start=\"2\">\n<li>max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]</li>\n</ol>\n<p>解决方法：修改 /etc/security/limits.conf，配置：</p>\n<p>hard nofile 80000</p>\n<p>soft nofile 80000</p>\n<ol start=\"3\">\n<li>max virtual memory areas vm.max_map_count [65530] is too low</li>\n</ol>\n<p>解决方法：修改 /etc/sysctl.conf，添加 ：</p>\n<p>vm.max_map_count = 262144</p>\n<p>然后 sysctl -p 生效</p>\n<ol start=\"4\">\n<li>the default discovery settings are unsuitable…., last least one of [….] must be configured</li>\n</ol>\n<p>解决方法：elasticsearch.yml 开启配置：</p>\n<p>node.name: node-1</p>\n<p>cluster.initial_master_nodes: [“node-1”]</p>"},{"title":"ElasticSearch相关基础概念","date":"2019-12-09T05:00:00.000Z","_content":"\n最近一直忙于工作、出差，一直没有更新内容，还是继续学习了一些Elasticsearch的知识，简单的记录一下\n\n<!-- more -->\n\n# 文档Document\nElasticsearch是面向文档的，文档是所有可搜索数据的最小单位\n\n那什么是文档，可以根据不同的业务场景进行划分，比如：\n- 日志文件中的日志项\n- 一部电影、一张唱片的详细信息\n- 一篇PDF文档的具体内容\n- 等等\n\n文档会被序列化为JSON格式，保存在Elasticsearch中\n- JSON对象格式\n- 每个JSON对象的属性都有对应的类型（数值、字符串、布尔类型、日期、数组等等\n\n每一个文档都会有一个Unique ID，生成方式有两种：\n- 指定文档ID\n- ES自动生成\n\n## JSON文档\n一篇文档包含一系列的字段，类似数据库表中的一行记录。\n\nJSON文档，格式灵活，不需要进行预先的格式定义。\n- 字段的类型可以指定，或者让ES进行自动推算\n- 支持数据、嵌套\n\n## 文档的元数据\n元数据，用于标注文档的相关基础信息。\n- _index 文档所属的索引名\n- _type 文档所属的类型名\n- _id 文档的唯一标识\n- _source 文档的原始JSON数据\n- _all 整合所有的字段内容（在之后的版本已经被废除，原本是用于对所有的文档进行检索\n- _version 版本号，用于解决多个相同文档的冲突问题\n- _score 相关性分数\n\n# 索引Index\n索引是文档的容器，是一类文档的结合\n- index体现了逻辑空间的概念：每个索引都有自己的Mapping定义，用于定义包含的文档的字段名和字段类型。\n- shard 体现了物理空间的概念：索引中的数据分散在shard上。\n\n可以对index设置mapping和setting\n- mapping 定义文档字段的类型\n- setting 定义不同的数据分布\n\n## 索引在Elasticsearch中的语义\n由于索引在不同的上下文中语义是不同的\n- 名词 在es的基础概念中，索引是类文档的集合\n- 动词 保存文档到es的过程也叫索引（indexing）\n抛开es的名词概念，通常我们谈论到索引，一般指的是B树索引、倒排索引等，与ES中的索引是不同的概念\n\n## Type\n在7.0版本之前，一个index可以设置多个Types。但是在6.0开始，Type已经被废除不被使用了。一个索引只能创建一个Type \"_doc\"。\n\n# 与RDBMS（关系型数据库）类比\n进行了一个大概的类比\n\nRDBMS | Elasticsearch\n-- | --\ntable | index(type)\nrow | document\ncolumn | field\nschema | mapping\nSQL | DSL\n\n与传统的关系型数据库的区别（待补充）：\n- ES用于高性能的全文检索，对搜索结果进行算分。\n- 关系型数据库更注重事务性\n\n# 分布式部署下的一些基础概念\n## 节点\n节点是一个Elasticsearch的实例，本质上是一个Java进程，所以可以通过JVM启动参数对配置进行修改。\n\n一台机器上可以运行多个es进程，但是一般生产环境一台机器上只运行一个es实例。\n\n每个节点在启动之后都会分配一个UID，保存在data目录下。\n### Master-eligible nodes和Master Node(合格主节点和主节点)\n每一个节点启动后，默认就是一个Master eligible节点，可以设置node.master: false禁止。\n\n- Master-eligible节点可以参加选主，成为Master节点。\n- 当第一个节点启动的时候，他会将自己选举成Master节点。\n- 每个节点上都保存了集群的状态，只有Master节点才能修改集群的状态信息。\n    - 集群状态(Cluster State)维护了一个集群中的必要信息\n        - 所有节点信息\n        - 所有索引和其相关的Mapping和Setting信息\n        - 分片的路由信息\n    - 任意节点修改信息都会导致数据的不一致性\n\n### Data Node和Corrdinating Node(数据节点和协调节点)\nData Node:\n- 保存数据的节点，负责保存分片的数据，在数据扩展上起到关键作用。\nCoordinating Node\n- 负责接收Clinet的请求，将请求分发到合适的节点，最终把结果汇集到一起\n- 每个节点都默认起到了Corrdinating Node的职责\n\n### Hot&Warm Node(冷/热节点)\n不同硬件配置的Data Node，用来实现冷热数据架构的，降低集群部署的成本。\n\n一般日志的case的时候，热节点用更高配置的机器，更高性能的CPU、更大存储的硬盘。冷节点用来存储旧数据，相对来讲就可以使用配置低一些的机器。\n\n\n### Machine Learning Node\nElasticsearch可以通过配置Machine Job自动的发现数据的一些异常，及时做出一些警报\n\n所以machine learning node负责跑机器学习的Job，用来做异常检测。\n\n### Tribe Node（已经被淘汰）\n5.3开始使用了Cross Cluster Search ，和Tribe Node一样，连接到不同的Elasticsearch集群，并且支持将这些集群当成一个单独的集群处理。\n\n## 配置节点类型\n- 开发环境中一个节点可以承担多种角色\n- 生产环境中应该设置单一角色的节点\n\n节点类型 | 配置参数 | 默认值\n-- | -- | --\nmaster eligible | node.master | true\ndata | node.data | true\ningest| node.ingest | true\ncoordinating only | 无 | 每个节点默认都是coordinating节点，设置其他类型全部为false\nmachine learning | node.ml | true(需enable x-pack)\n\n## 分片\n主分片(Primary Shard)，用于解决数据水平扩展的问题。通过主分片，可以将数据分布到集群内的所有节点上。\n- 一个分片是一个运行的lucene的实例\n- 主分片数在索引创建时指定，后续不允许修改，除非Reindex。\n\n副本分片(Replica Shard)，用于解决数据高可用问题，副本分片是主分片的拷贝。\n- 副本分片数可以动态调整\n- 增加副本数量，还可以一定程度上提高服务的可用性(独取的吞吐量)\n\n![es04](/image/ElasticSearch/elasticsearch04.png)\n\n## 集群\n不同的集群通过名字进行区分，默认是\"elasticsearch\"\n\n可以通过配置文件修改，或者启动命令行中增加\"-E cluster.name=xxxx\"指定名称。","source":"_posts/elasticsearch_03_基础概念.md","raw":"---\ntitle: ElasticSearch相关基础概念\ndate: 2019-12-09 13:00:00\ntags: ElasticSearch\ncategories: Elastic Stack\n---\n\n最近一直忙于工作、出差，一直没有更新内容，还是继续学习了一些Elasticsearch的知识，简单的记录一下\n\n<!-- more -->\n\n# 文档Document\nElasticsearch是面向文档的，文档是所有可搜索数据的最小单位\n\n那什么是文档，可以根据不同的业务场景进行划分，比如：\n- 日志文件中的日志项\n- 一部电影、一张唱片的详细信息\n- 一篇PDF文档的具体内容\n- 等等\n\n文档会被序列化为JSON格式，保存在Elasticsearch中\n- JSON对象格式\n- 每个JSON对象的属性都有对应的类型（数值、字符串、布尔类型、日期、数组等等\n\n每一个文档都会有一个Unique ID，生成方式有两种：\n- 指定文档ID\n- ES自动生成\n\n## JSON文档\n一篇文档包含一系列的字段，类似数据库表中的一行记录。\n\nJSON文档，格式灵活，不需要进行预先的格式定义。\n- 字段的类型可以指定，或者让ES进行自动推算\n- 支持数据、嵌套\n\n## 文档的元数据\n元数据，用于标注文档的相关基础信息。\n- _index 文档所属的索引名\n- _type 文档所属的类型名\n- _id 文档的唯一标识\n- _source 文档的原始JSON数据\n- _all 整合所有的字段内容（在之后的版本已经被废除，原本是用于对所有的文档进行检索\n- _version 版本号，用于解决多个相同文档的冲突问题\n- _score 相关性分数\n\n# 索引Index\n索引是文档的容器，是一类文档的结合\n- index体现了逻辑空间的概念：每个索引都有自己的Mapping定义，用于定义包含的文档的字段名和字段类型。\n- shard 体现了物理空间的概念：索引中的数据分散在shard上。\n\n可以对index设置mapping和setting\n- mapping 定义文档字段的类型\n- setting 定义不同的数据分布\n\n## 索引在Elasticsearch中的语义\n由于索引在不同的上下文中语义是不同的\n- 名词 在es的基础概念中，索引是类文档的集合\n- 动词 保存文档到es的过程也叫索引（indexing）\n抛开es的名词概念，通常我们谈论到索引，一般指的是B树索引、倒排索引等，与ES中的索引是不同的概念\n\n## Type\n在7.0版本之前，一个index可以设置多个Types。但是在6.0开始，Type已经被废除不被使用了。一个索引只能创建一个Type \"_doc\"。\n\n# 与RDBMS（关系型数据库）类比\n进行了一个大概的类比\n\nRDBMS | Elasticsearch\n-- | --\ntable | index(type)\nrow | document\ncolumn | field\nschema | mapping\nSQL | DSL\n\n与传统的关系型数据库的区别（待补充）：\n- ES用于高性能的全文检索，对搜索结果进行算分。\n- 关系型数据库更注重事务性\n\n# 分布式部署下的一些基础概念\n## 节点\n节点是一个Elasticsearch的实例，本质上是一个Java进程，所以可以通过JVM启动参数对配置进行修改。\n\n一台机器上可以运行多个es进程，但是一般生产环境一台机器上只运行一个es实例。\n\n每个节点在启动之后都会分配一个UID，保存在data目录下。\n### Master-eligible nodes和Master Node(合格主节点和主节点)\n每一个节点启动后，默认就是一个Master eligible节点，可以设置node.master: false禁止。\n\n- Master-eligible节点可以参加选主，成为Master节点。\n- 当第一个节点启动的时候，他会将自己选举成Master节点。\n- 每个节点上都保存了集群的状态，只有Master节点才能修改集群的状态信息。\n    - 集群状态(Cluster State)维护了一个集群中的必要信息\n        - 所有节点信息\n        - 所有索引和其相关的Mapping和Setting信息\n        - 分片的路由信息\n    - 任意节点修改信息都会导致数据的不一致性\n\n### Data Node和Corrdinating Node(数据节点和协调节点)\nData Node:\n- 保存数据的节点，负责保存分片的数据，在数据扩展上起到关键作用。\nCoordinating Node\n- 负责接收Clinet的请求，将请求分发到合适的节点，最终把结果汇集到一起\n- 每个节点都默认起到了Corrdinating Node的职责\n\n### Hot&Warm Node(冷/热节点)\n不同硬件配置的Data Node，用来实现冷热数据架构的，降低集群部署的成本。\n\n一般日志的case的时候，热节点用更高配置的机器，更高性能的CPU、更大存储的硬盘。冷节点用来存储旧数据，相对来讲就可以使用配置低一些的机器。\n\n\n### Machine Learning Node\nElasticsearch可以通过配置Machine Job自动的发现数据的一些异常，及时做出一些警报\n\n所以machine learning node负责跑机器学习的Job，用来做异常检测。\n\n### Tribe Node（已经被淘汰）\n5.3开始使用了Cross Cluster Search ，和Tribe Node一样，连接到不同的Elasticsearch集群，并且支持将这些集群当成一个单独的集群处理。\n\n## 配置节点类型\n- 开发环境中一个节点可以承担多种角色\n- 生产环境中应该设置单一角色的节点\n\n节点类型 | 配置参数 | 默认值\n-- | -- | --\nmaster eligible | node.master | true\ndata | node.data | true\ningest| node.ingest | true\ncoordinating only | 无 | 每个节点默认都是coordinating节点，设置其他类型全部为false\nmachine learning | node.ml | true(需enable x-pack)\n\n## 分片\n主分片(Primary Shard)，用于解决数据水平扩展的问题。通过主分片，可以将数据分布到集群内的所有节点上。\n- 一个分片是一个运行的lucene的实例\n- 主分片数在索引创建时指定，后续不允许修改，除非Reindex。\n\n副本分片(Replica Shard)，用于解决数据高可用问题，副本分片是主分片的拷贝。\n- 副本分片数可以动态调整\n- 增加副本数量，还可以一定程度上提高服务的可用性(独取的吞吐量)\n\n![es04](/image/ElasticSearch/elasticsearch04.png)\n\n## 集群\n不同的集群通过名字进行区分，默认是\"elasticsearch\"\n\n可以通过配置文件修改，或者启动命令行中增加\"-E cluster.name=xxxx\"指定名称。","slug":"elasticsearch_03_基础概念","published":1,"updated":"2019-12-08T08:50:46.029Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl05000yqotnltmya9vw","content":"<p>最近一直忙于工作、出差，一直没有更新内容，还是继续学习了一些Elasticsearch的知识，简单的记录一下</p>\n<a id=\"more\"></a>\n<h1 id=\"文档Document\"><a href=\"#文档Document\" class=\"headerlink\" title=\"文档Document\"></a>文档Document</h1><p>Elasticsearch是面向文档的，文档是所有可搜索数据的最小单位</p>\n<p>那什么是文档，可以根据不同的业务场景进行划分，比如：</p>\n<ul>\n<li>日志文件中的日志项</li>\n<li>一部电影、一张唱片的详细信息</li>\n<li>一篇PDF文档的具体内容</li>\n<li>等等</li>\n</ul>\n<p>文档会被序列化为JSON格式，保存在Elasticsearch中</p>\n<ul>\n<li>JSON对象格式</li>\n<li>每个JSON对象的属性都有对应的类型（数值、字符串、布尔类型、日期、数组等等</li>\n</ul>\n<p>每一个文档都会有一个Unique ID，生成方式有两种：</p>\n<ul>\n<li>指定文档ID</li>\n<li>ES自动生成</li>\n</ul>\n<h2 id=\"JSON文档\"><a href=\"#JSON文档\" class=\"headerlink\" title=\"JSON文档\"></a>JSON文档</h2><p>一篇文档包含一系列的字段，类似数据库表中的一行记录。</p>\n<p>JSON文档，格式灵活，不需要进行预先的格式定义。</p>\n<ul>\n<li>字段的类型可以指定，或者让ES进行自动推算</li>\n<li>支持数据、嵌套</li>\n</ul>\n<h2 id=\"文档的元数据\"><a href=\"#文档的元数据\" class=\"headerlink\" title=\"文档的元数据\"></a>文档的元数据</h2><p>元数据，用于标注文档的相关基础信息。</p>\n<ul>\n<li>_index 文档所属的索引名</li>\n<li>_type 文档所属的类型名</li>\n<li>_id 文档的唯一标识</li>\n<li>_source 文档的原始JSON数据</li>\n<li>_all 整合所有的字段内容（在之后的版本已经被废除，原本是用于对所有的文档进行检索</li>\n<li>_version 版本号，用于解决多个相同文档的冲突问题</li>\n<li>_score 相关性分数</li>\n</ul>\n<h1 id=\"索引Index\"><a href=\"#索引Index\" class=\"headerlink\" title=\"索引Index\"></a>索引Index</h1><p>索引是文档的容器，是一类文档的结合</p>\n<ul>\n<li>index体现了逻辑空间的概念：每个索引都有自己的Mapping定义，用于定义包含的文档的字段名和字段类型。</li>\n<li>shard 体现了物理空间的概念：索引中的数据分散在shard上。</li>\n</ul>\n<p>可以对index设置mapping和setting</p>\n<ul>\n<li>mapping 定义文档字段的类型</li>\n<li>setting 定义不同的数据分布</li>\n</ul>\n<h2 id=\"索引在Elasticsearch中的语义\"><a href=\"#索引在Elasticsearch中的语义\" class=\"headerlink\" title=\"索引在Elasticsearch中的语义\"></a>索引在Elasticsearch中的语义</h2><p>由于索引在不同的上下文中语义是不同的</p>\n<ul>\n<li>名词 在es的基础概念中，索引是类文档的集合</li>\n<li>动词 保存文档到es的过程也叫索引（indexing）<br>抛开es的名词概念，通常我们谈论到索引，一般指的是B树索引、倒排索引等，与ES中的索引是不同的概念</li>\n</ul>\n<h2 id=\"Type\"><a href=\"#Type\" class=\"headerlink\" title=\"Type\"></a>Type</h2><p>在7.0版本之前，一个index可以设置多个Types。但是在6.0开始，Type已经被废除不被使用了。一个索引只能创建一个Type “_doc”。</p>\n<h1 id=\"与RDBMS（关系型数据库）类比\"><a href=\"#与RDBMS（关系型数据库）类比\" class=\"headerlink\" title=\"与RDBMS（关系型数据库）类比\"></a>与RDBMS（关系型数据库）类比</h1><p>进行了一个大概的类比</p>\n<table>\n<thead>\n<tr>\n<th>RDBMS</th>\n<th>Elasticsearch</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>table</td>\n<td>index(type)</td>\n</tr>\n<tr>\n<td>row</td>\n<td>document</td>\n</tr>\n<tr>\n<td>column</td>\n<td>field</td>\n</tr>\n<tr>\n<td>schema</td>\n<td>mapping</td>\n</tr>\n<tr>\n<td>SQL</td>\n<td>DSL</td>\n</tr>\n</tbody>\n</table>\n<p>与传统的关系型数据库的区别（待补充）：</p>\n<ul>\n<li>ES用于高性能的全文检索，对搜索结果进行算分。</li>\n<li>关系型数据库更注重事务性</li>\n</ul>\n<h1 id=\"分布式部署下的一些基础概念\"><a href=\"#分布式部署下的一些基础概念\" class=\"headerlink\" title=\"分布式部署下的一些基础概念\"></a>分布式部署下的一些基础概念</h1><h2 id=\"节点\"><a href=\"#节点\" class=\"headerlink\" title=\"节点\"></a>节点</h2><p>节点是一个Elasticsearch的实例，本质上是一个Java进程，所以可以通过JVM启动参数对配置进行修改。</p>\n<p>一台机器上可以运行多个es进程，但是一般生产环境一台机器上只运行一个es实例。</p>\n<p>每个节点在启动之后都会分配一个UID，保存在data目录下。</p>\n<h3 id=\"Master-eligible-nodes和Master-Node-合格主节点和主节点\"><a href=\"#Master-eligible-nodes和Master-Node-合格主节点和主节点\" class=\"headerlink\" title=\"Master-eligible nodes和Master Node(合格主节点和主节点)\"></a>Master-eligible nodes和Master Node(合格主节点和主节点)</h3><p>每一个节点启动后，默认就是一个Master eligible节点，可以设置node.master: false禁止。</p>\n<ul>\n<li>Master-eligible节点可以参加选主，成为Master节点。</li>\n<li>当第一个节点启动的时候，他会将自己选举成Master节点。</li>\n<li>每个节点上都保存了集群的状态，只有Master节点才能修改集群的状态信息。<ul>\n<li>集群状态(Cluster State)维护了一个集群中的必要信息<ul>\n<li>所有节点信息</li>\n<li>所有索引和其相关的Mapping和Setting信息</li>\n<li>分片的路由信息</li>\n</ul>\n</li>\n<li>任意节点修改信息都会导致数据的不一致性</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Data-Node和Corrdinating-Node-数据节点和协调节点\"><a href=\"#Data-Node和Corrdinating-Node-数据节点和协调节点\" class=\"headerlink\" title=\"Data Node和Corrdinating Node(数据节点和协调节点)\"></a>Data Node和Corrdinating Node(数据节点和协调节点)</h3><p>Data Node:</p>\n<ul>\n<li>保存数据的节点，负责保存分片的数据，在数据扩展上起到关键作用。<br>Coordinating Node</li>\n<li>负责接收Clinet的请求，将请求分发到合适的节点，最终把结果汇集到一起</li>\n<li>每个节点都默认起到了Corrdinating Node的职责</li>\n</ul>\n<h3 id=\"Hot-amp-Warm-Node-冷-热节点\"><a href=\"#Hot-amp-Warm-Node-冷-热节点\" class=\"headerlink\" title=\"Hot&amp;Warm Node(冷/热节点)\"></a>Hot&amp;Warm Node(冷/热节点)</h3><p>不同硬件配置的Data Node，用来实现冷热数据架构的，降低集群部署的成本。</p>\n<p>一般日志的case的时候，热节点用更高配置的机器，更高性能的CPU、更大存储的硬盘。冷节点用来存储旧数据，相对来讲就可以使用配置低一些的机器。</p>\n<h3 id=\"Machine-Learning-Node\"><a href=\"#Machine-Learning-Node\" class=\"headerlink\" title=\"Machine Learning Node\"></a>Machine Learning Node</h3><p>Elasticsearch可以通过配置Machine Job自动的发现数据的一些异常，及时做出一些警报</p>\n<p>所以machine learning node负责跑机器学习的Job，用来做异常检测。</p>\n<h3 id=\"Tribe-Node（已经被淘汰）\"><a href=\"#Tribe-Node（已经被淘汰）\" class=\"headerlink\" title=\"Tribe Node（已经被淘汰）\"></a>Tribe Node（已经被淘汰）</h3><p>5.3开始使用了Cross Cluster Search ，和Tribe Node一样，连接到不同的Elasticsearch集群，并且支持将这些集群当成一个单独的集群处理。</p>\n<h2 id=\"配置节点类型\"><a href=\"#配置节点类型\" class=\"headerlink\" title=\"配置节点类型\"></a>配置节点类型</h2><ul>\n<li>开发环境中一个节点可以承担多种角色</li>\n<li>生产环境中应该设置单一角色的节点</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>节点类型</th>\n<th>配置参数</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>master eligible</td>\n<td>node.master</td>\n<td>true</td>\n</tr>\n<tr>\n<td>data</td>\n<td>node.data</td>\n<td>true</td>\n</tr>\n<tr>\n<td>ingest</td>\n<td>node.ingest</td>\n<td>true</td>\n</tr>\n<tr>\n<td>coordinating only</td>\n<td>无</td>\n<td>每个节点默认都是coordinating节点，设置其他类型全部为false</td>\n</tr>\n<tr>\n<td>machine learning</td>\n<td>node.ml</td>\n<td>true(需enable x-pack)</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"分片\"><a href=\"#分片\" class=\"headerlink\" title=\"分片\"></a>分片</h2><p>主分片(Primary Shard)，用于解决数据水平扩展的问题。通过主分片，可以将数据分布到集群内的所有节点上。</p>\n<ul>\n<li>一个分片是一个运行的lucene的实例</li>\n<li>主分片数在索引创建时指定，后续不允许修改，除非Reindex。</li>\n</ul>\n<p>副本分片(Replica Shard)，用于解决数据高可用问题，副本分片是主分片的拷贝。</p>\n<ul>\n<li>副本分片数可以动态调整</li>\n<li>增加副本数量，还可以一定程度上提高服务的可用性(独取的吞吐量)</li>\n</ul>\n<p><img src=\"/image/ElasticSearch/elasticsearch04.png\" alt=\"es04\"></p>\n<h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><p>不同的集群通过名字进行区分，默认是”elasticsearch”</p>\n<p>可以通过配置文件修改，或者启动命令行中增加”-E cluster.name=xxxx”指定名称。</p>\n","site":{"data":{}},"excerpt":"<p>最近一直忙于工作、出差，一直没有更新内容，还是继续学习了一些Elasticsearch的知识，简单的记录一下</p>","more":"<h1 id=\"文档Document\"><a href=\"#文档Document\" class=\"headerlink\" title=\"文档Document\"></a>文档Document</h1><p>Elasticsearch是面向文档的，文档是所有可搜索数据的最小单位</p>\n<p>那什么是文档，可以根据不同的业务场景进行划分，比如：</p>\n<ul>\n<li>日志文件中的日志项</li>\n<li>一部电影、一张唱片的详细信息</li>\n<li>一篇PDF文档的具体内容</li>\n<li>等等</li>\n</ul>\n<p>文档会被序列化为JSON格式，保存在Elasticsearch中</p>\n<ul>\n<li>JSON对象格式</li>\n<li>每个JSON对象的属性都有对应的类型（数值、字符串、布尔类型、日期、数组等等</li>\n</ul>\n<p>每一个文档都会有一个Unique ID，生成方式有两种：</p>\n<ul>\n<li>指定文档ID</li>\n<li>ES自动生成</li>\n</ul>\n<h2 id=\"JSON文档\"><a href=\"#JSON文档\" class=\"headerlink\" title=\"JSON文档\"></a>JSON文档</h2><p>一篇文档包含一系列的字段，类似数据库表中的一行记录。</p>\n<p>JSON文档，格式灵活，不需要进行预先的格式定义。</p>\n<ul>\n<li>字段的类型可以指定，或者让ES进行自动推算</li>\n<li>支持数据、嵌套</li>\n</ul>\n<h2 id=\"文档的元数据\"><a href=\"#文档的元数据\" class=\"headerlink\" title=\"文档的元数据\"></a>文档的元数据</h2><p>元数据，用于标注文档的相关基础信息。</p>\n<ul>\n<li>_index 文档所属的索引名</li>\n<li>_type 文档所属的类型名</li>\n<li>_id 文档的唯一标识</li>\n<li>_source 文档的原始JSON数据</li>\n<li>_all 整合所有的字段内容（在之后的版本已经被废除，原本是用于对所有的文档进行检索</li>\n<li>_version 版本号，用于解决多个相同文档的冲突问题</li>\n<li>_score 相关性分数</li>\n</ul>\n<h1 id=\"索引Index\"><a href=\"#索引Index\" class=\"headerlink\" title=\"索引Index\"></a>索引Index</h1><p>索引是文档的容器，是一类文档的结合</p>\n<ul>\n<li>index体现了逻辑空间的概念：每个索引都有自己的Mapping定义，用于定义包含的文档的字段名和字段类型。</li>\n<li>shard 体现了物理空间的概念：索引中的数据分散在shard上。</li>\n</ul>\n<p>可以对index设置mapping和setting</p>\n<ul>\n<li>mapping 定义文档字段的类型</li>\n<li>setting 定义不同的数据分布</li>\n</ul>\n<h2 id=\"索引在Elasticsearch中的语义\"><a href=\"#索引在Elasticsearch中的语义\" class=\"headerlink\" title=\"索引在Elasticsearch中的语义\"></a>索引在Elasticsearch中的语义</h2><p>由于索引在不同的上下文中语义是不同的</p>\n<ul>\n<li>名词 在es的基础概念中，索引是类文档的集合</li>\n<li>动词 保存文档到es的过程也叫索引（indexing）<br>抛开es的名词概念，通常我们谈论到索引，一般指的是B树索引、倒排索引等，与ES中的索引是不同的概念</li>\n</ul>\n<h2 id=\"Type\"><a href=\"#Type\" class=\"headerlink\" title=\"Type\"></a>Type</h2><p>在7.0版本之前，一个index可以设置多个Types。但是在6.0开始，Type已经被废除不被使用了。一个索引只能创建一个Type “_doc”。</p>\n<h1 id=\"与RDBMS（关系型数据库）类比\"><a href=\"#与RDBMS（关系型数据库）类比\" class=\"headerlink\" title=\"与RDBMS（关系型数据库）类比\"></a>与RDBMS（关系型数据库）类比</h1><p>进行了一个大概的类比</p>\n<table>\n<thead>\n<tr>\n<th>RDBMS</th>\n<th>Elasticsearch</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>table</td>\n<td>index(type)</td>\n</tr>\n<tr>\n<td>row</td>\n<td>document</td>\n</tr>\n<tr>\n<td>column</td>\n<td>field</td>\n</tr>\n<tr>\n<td>schema</td>\n<td>mapping</td>\n</tr>\n<tr>\n<td>SQL</td>\n<td>DSL</td>\n</tr>\n</tbody>\n</table>\n<p>与传统的关系型数据库的区别（待补充）：</p>\n<ul>\n<li>ES用于高性能的全文检索，对搜索结果进行算分。</li>\n<li>关系型数据库更注重事务性</li>\n</ul>\n<h1 id=\"分布式部署下的一些基础概念\"><a href=\"#分布式部署下的一些基础概念\" class=\"headerlink\" title=\"分布式部署下的一些基础概念\"></a>分布式部署下的一些基础概念</h1><h2 id=\"节点\"><a href=\"#节点\" class=\"headerlink\" title=\"节点\"></a>节点</h2><p>节点是一个Elasticsearch的实例，本质上是一个Java进程，所以可以通过JVM启动参数对配置进行修改。</p>\n<p>一台机器上可以运行多个es进程，但是一般生产环境一台机器上只运行一个es实例。</p>\n<p>每个节点在启动之后都会分配一个UID，保存在data目录下。</p>\n<h3 id=\"Master-eligible-nodes和Master-Node-合格主节点和主节点\"><a href=\"#Master-eligible-nodes和Master-Node-合格主节点和主节点\" class=\"headerlink\" title=\"Master-eligible nodes和Master Node(合格主节点和主节点)\"></a>Master-eligible nodes和Master Node(合格主节点和主节点)</h3><p>每一个节点启动后，默认就是一个Master eligible节点，可以设置node.master: false禁止。</p>\n<ul>\n<li>Master-eligible节点可以参加选主，成为Master节点。</li>\n<li>当第一个节点启动的时候，他会将自己选举成Master节点。</li>\n<li>每个节点上都保存了集群的状态，只有Master节点才能修改集群的状态信息。<ul>\n<li>集群状态(Cluster State)维护了一个集群中的必要信息<ul>\n<li>所有节点信息</li>\n<li>所有索引和其相关的Mapping和Setting信息</li>\n<li>分片的路由信息</li>\n</ul>\n</li>\n<li>任意节点修改信息都会导致数据的不一致性</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Data-Node和Corrdinating-Node-数据节点和协调节点\"><a href=\"#Data-Node和Corrdinating-Node-数据节点和协调节点\" class=\"headerlink\" title=\"Data Node和Corrdinating Node(数据节点和协调节点)\"></a>Data Node和Corrdinating Node(数据节点和协调节点)</h3><p>Data Node:</p>\n<ul>\n<li>保存数据的节点，负责保存分片的数据，在数据扩展上起到关键作用。<br>Coordinating Node</li>\n<li>负责接收Clinet的请求，将请求分发到合适的节点，最终把结果汇集到一起</li>\n<li>每个节点都默认起到了Corrdinating Node的职责</li>\n</ul>\n<h3 id=\"Hot-amp-Warm-Node-冷-热节点\"><a href=\"#Hot-amp-Warm-Node-冷-热节点\" class=\"headerlink\" title=\"Hot&amp;Warm Node(冷/热节点)\"></a>Hot&amp;Warm Node(冷/热节点)</h3><p>不同硬件配置的Data Node，用来实现冷热数据架构的，降低集群部署的成本。</p>\n<p>一般日志的case的时候，热节点用更高配置的机器，更高性能的CPU、更大存储的硬盘。冷节点用来存储旧数据，相对来讲就可以使用配置低一些的机器。</p>\n<h3 id=\"Machine-Learning-Node\"><a href=\"#Machine-Learning-Node\" class=\"headerlink\" title=\"Machine Learning Node\"></a>Machine Learning Node</h3><p>Elasticsearch可以通过配置Machine Job自动的发现数据的一些异常，及时做出一些警报</p>\n<p>所以machine learning node负责跑机器学习的Job，用来做异常检测。</p>\n<h3 id=\"Tribe-Node（已经被淘汰）\"><a href=\"#Tribe-Node（已经被淘汰）\" class=\"headerlink\" title=\"Tribe Node（已经被淘汰）\"></a>Tribe Node（已经被淘汰）</h3><p>5.3开始使用了Cross Cluster Search ，和Tribe Node一样，连接到不同的Elasticsearch集群，并且支持将这些集群当成一个单独的集群处理。</p>\n<h2 id=\"配置节点类型\"><a href=\"#配置节点类型\" class=\"headerlink\" title=\"配置节点类型\"></a>配置节点类型</h2><ul>\n<li>开发环境中一个节点可以承担多种角色</li>\n<li>生产环境中应该设置单一角色的节点</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>节点类型</th>\n<th>配置参数</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>master eligible</td>\n<td>node.master</td>\n<td>true</td>\n</tr>\n<tr>\n<td>data</td>\n<td>node.data</td>\n<td>true</td>\n</tr>\n<tr>\n<td>ingest</td>\n<td>node.ingest</td>\n<td>true</td>\n</tr>\n<tr>\n<td>coordinating only</td>\n<td>无</td>\n<td>每个节点默认都是coordinating节点，设置其他类型全部为false</td>\n</tr>\n<tr>\n<td>machine learning</td>\n<td>node.ml</td>\n<td>true(需enable x-pack)</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"分片\"><a href=\"#分片\" class=\"headerlink\" title=\"分片\"></a>分片</h2><p>主分片(Primary Shard)，用于解决数据水平扩展的问题。通过主分片，可以将数据分布到集群内的所有节点上。</p>\n<ul>\n<li>一个分片是一个运行的lucene的实例</li>\n<li>主分片数在索引创建时指定，后续不允许修改，除非Reindex。</li>\n</ul>\n<p>副本分片(Replica Shard)，用于解决数据高可用问题，副本分片是主分片的拷贝。</p>\n<ul>\n<li>副本分片数可以动态调整</li>\n<li>增加副本数量，还可以一定程度上提高服务的可用性(独取的吞吐量)</li>\n</ul>\n<p><img src=\"/image/ElasticSearch/elasticsearch04.png\" alt=\"es04\"></p>\n<h2 id=\"集群\"><a href=\"#集群\" class=\"headerlink\" title=\"集群\"></a>集群</h2><p>不同的集群通过名字进行区分，默认是”elasticsearch”</p>\n<p>可以通过配置文件修改，或者启动命令行中增加”-E cluster.name=xxxx”指定名称。</p>"},{"title":"Hello World","date":"2017-12-31T16:00:00.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ndate: 2018-01-01 00:00:00\ntags: hexo\ncategories: 其他\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"updated":"2019-08-26T07:56:29.057Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl080012qotnkzyzu09o","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n"},{"title":"hexo","date":"2018-09-04T07:12:28.000Z","_content":"\n# Hexo&GitHub Pages\n\n最初接触github pages之后，一直想尝试搭建一个属于自己的博客网站，根据朋友的博客网站搭建选择了jekyll，但由于选择的模板以及调试问题居多，最后放弃了。偶然间了解到了hexo和vuepress，了解了之后感觉vuepress的模板比较单一，再加上自己不是很了解vuejs（说的好像node.js自己就很懂一样），最后选择了hexo。\n\nhexo是基于node.js的高效的静态站点生成框架，通过Hexo可以轻松地使用Markdown编写文章，除了Markdown本身的语法之外，还可以使用Hexo提供的标签插件来快速的插入特定形式的内容。使用起来非常方便。\n\n从基于Ruby的jekyll，到hexo，再到vuepress。最后选择了hexo。真的是因为用起来简单，但是可能由于自己的电脑git出现了一些问题，导致不能使用hexo deploy，每次都要自己手动构建提交，这还是很麻烦的。\n\n关于如何在使用github pages搭建博客网站，这里就不抄写细节了，能找到一大堆教程，这篇文章主要是记录下我在学习hexo的一些常用命令。\n\ngithub pages是github提供的一个托管的公开网页，会自动将你id.github.io仓库的静态文件自动部署至：https://你的githubID.github.io/ 但由于是公开的仓库，所以大家要注意不要将敏感数据上传。\n\n由于hexo是基于NodeJS的，所以要先安装NodeJS，具体教程有很多，就不做表述了，下面记录了一些搭建博客过程中常用的命令。\n\n<!-- more -->\n\n# 常用指令\n## 清理\n``` linux\n$ hexo clean\n```\n\n## 构建服务\n``` linux\n$ hexo generate\n```\n也可以缩写为：\n``` linux\n$ hexo g\n```\n\n## 启动服务\n``` linux\n$ hexo server\n```\n缩写：\n``` linux\n$ hexo s\n```\n\n## 部署到远程站点\n``` linux\n$ hexo deploy\n```\n缩写：\n``` linux\n$ hexo d\n```\n\n## 新建博文\n``` linux\n$ hexo new \"post name\"\n```\n缩写：\n``` linux\n$ hexo n \"post name\"\n```\n\n之后会在source/\\_posts下面生成对应的post name.md的文件。\n\n## 创建新主页\n``` linux\n$ hexo new page \"page name\"\n```\n\n之后会在source/\\_posts/page name下面生成对应的page index.md的文件。如：tags、categories的主页，然后再标题头中添加type。\n\n\n# 选择主题\nhttps://hexo.io/themes/\n\n## 替换模板\ngithub上clone各类模板到/themes/xxx\n\n修改_config.yml中的theme: xxx\n\n我个人使用的Theme是NexT，他有三种模式，分别可以在模板的_config.yml中设置schemes。\n``` yml\n# Schemes\nscheme: Muse\n#scheme: Mist\n#scheme: Pisces\n#scheme: Gemini\n```\n\n\n## 安装hexo git配置插件\nnpm install hexo-deployer-git --save\n配置_config.yml中修改入下：\n``` yml\ndeploy:\n  type: git\n  repo: gti仓库https地址或SSH地址\n  branch: master\n```\n\n目前我是每一次generate之后，将构建好的文件从public中全部复制到本地仓库，然后再上传，其实嘛区别不大，就是自己打两个命令。","source":"_posts/hexo.md","raw":"---\ntitle: hexo\ndate: 2018-09-04 15:12:28\ntags: hexo\ncategories: 其他\n---\n\n# Hexo&GitHub Pages\n\n最初接触github pages之后，一直想尝试搭建一个属于自己的博客网站，根据朋友的博客网站搭建选择了jekyll，但由于选择的模板以及调试问题居多，最后放弃了。偶然间了解到了hexo和vuepress，了解了之后感觉vuepress的模板比较单一，再加上自己不是很了解vuejs（说的好像node.js自己就很懂一样），最后选择了hexo。\n\nhexo是基于node.js的高效的静态站点生成框架，通过Hexo可以轻松地使用Markdown编写文章，除了Markdown本身的语法之外，还可以使用Hexo提供的标签插件来快速的插入特定形式的内容。使用起来非常方便。\n\n从基于Ruby的jekyll，到hexo，再到vuepress。最后选择了hexo。真的是因为用起来简单，但是可能由于自己的电脑git出现了一些问题，导致不能使用hexo deploy，每次都要自己手动构建提交，这还是很麻烦的。\n\n关于如何在使用github pages搭建博客网站，这里就不抄写细节了，能找到一大堆教程，这篇文章主要是记录下我在学习hexo的一些常用命令。\n\ngithub pages是github提供的一个托管的公开网页，会自动将你id.github.io仓库的静态文件自动部署至：https://你的githubID.github.io/ 但由于是公开的仓库，所以大家要注意不要将敏感数据上传。\n\n由于hexo是基于NodeJS的，所以要先安装NodeJS，具体教程有很多，就不做表述了，下面记录了一些搭建博客过程中常用的命令。\n\n<!-- more -->\n\n# 常用指令\n## 清理\n``` linux\n$ hexo clean\n```\n\n## 构建服务\n``` linux\n$ hexo generate\n```\n也可以缩写为：\n``` linux\n$ hexo g\n```\n\n## 启动服务\n``` linux\n$ hexo server\n```\n缩写：\n``` linux\n$ hexo s\n```\n\n## 部署到远程站点\n``` linux\n$ hexo deploy\n```\n缩写：\n``` linux\n$ hexo d\n```\n\n## 新建博文\n``` linux\n$ hexo new \"post name\"\n```\n缩写：\n``` linux\n$ hexo n \"post name\"\n```\n\n之后会在source/\\_posts下面生成对应的post name.md的文件。\n\n## 创建新主页\n``` linux\n$ hexo new page \"page name\"\n```\n\n之后会在source/\\_posts/page name下面生成对应的page index.md的文件。如：tags、categories的主页，然后再标题头中添加type。\n\n\n# 选择主题\nhttps://hexo.io/themes/\n\n## 替换模板\ngithub上clone各类模板到/themes/xxx\n\n修改_config.yml中的theme: xxx\n\n我个人使用的Theme是NexT，他有三种模式，分别可以在模板的_config.yml中设置schemes。\n``` yml\n# Schemes\nscheme: Muse\n#scheme: Mist\n#scheme: Pisces\n#scheme: Gemini\n```\n\n\n## 安装hexo git配置插件\nnpm install hexo-deployer-git --save\n配置_config.yml中修改入下：\n``` yml\ndeploy:\n  type: git\n  repo: gti仓库https地址或SSH地址\n  branch: master\n```\n\n目前我是每一次generate之后，将构建好的文件从public中全部复制到本地仓库，然后再上传，其实嘛区别不大，就是自己打两个命令。","slug":"hexo","published":1,"updated":"2019-08-26T07:56:34.076Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0a0015qotn054y6p0v","content":"<h1 id=\"Hexo-amp-GitHub-Pages\"><a href=\"#Hexo-amp-GitHub-Pages\" class=\"headerlink\" title=\"Hexo&amp;GitHub Pages\"></a>Hexo&amp;GitHub Pages</h1><p>最初接触github pages之后，一直想尝试搭建一个属于自己的博客网站，根据朋友的博客网站搭建选择了jekyll，但由于选择的模板以及调试问题居多，最后放弃了。偶然间了解到了hexo和vuepress，了解了之后感觉vuepress的模板比较单一，再加上自己不是很了解vuejs（说的好像node.js自己就很懂一样），最后选择了hexo。</p>\n<p>hexo是基于node.js的高效的静态站点生成框架，通过Hexo可以轻松地使用Markdown编写文章，除了Markdown本身的语法之外，还可以使用Hexo提供的标签插件来快速的插入特定形式的内容。使用起来非常方便。</p>\n<p>从基于Ruby的jekyll，到hexo，再到vuepress。最后选择了hexo。真的是因为用起来简单，但是可能由于自己的电脑git出现了一些问题，导致不能使用hexo deploy，每次都要自己手动构建提交，这还是很麻烦的。</p>\n<p>关于如何在使用github pages搭建博客网站，这里就不抄写细节了，能找到一大堆教程，这篇文章主要是记录下我在学习hexo的一些常用命令。</p>\n<p>github pages是github提供的一个托管的公开网页，会自动将你id.github.io仓库的静态文件自动部署至：https://你的githubID.github.io/ 但由于是公开的仓库，所以大家要注意不要将敏感数据上传。</p>\n<p>由于hexo是基于NodeJS的，所以要先安装NodeJS，具体教程有很多，就不做表述了，下面记录了一些搭建博客过程中常用的命令。</p>\n<a id=\"more\"></a>\n<h1 id=\"常用指令\"><a href=\"#常用指令\" class=\"headerlink\" title=\"常用指令\"></a>常用指令</h1><h2 id=\"清理\"><a href=\"#清理\" class=\"headerlink\" title=\"清理\"></a>清理</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo clean</span><br></pre></td></tr></table></figure>\n<h2 id=\"构建服务\"><a href=\"#构建服务\" class=\"headerlink\" title=\"构建服务\"></a>构建服务</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>也可以缩写为：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo g</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a>启动服务</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>缩写：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo s</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"部署到远程站点\"><a href=\"#部署到远程站点\" class=\"headerlink\" title=\"部署到远程站点\"></a>部署到远程站点</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>缩写：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo d</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"新建博文\"><a href=\"#新建博文\" class=\"headerlink\" title=\"新建博文\"></a>新建博文</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new &quot;post name&quot;</span><br></pre></td></tr></table></figure>\n<p>缩写：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo n &quot;post name&quot;</span><br></pre></td></tr></table></figure></p>\n<p>之后会在source/_posts下面生成对应的post name.md的文件。</p>\n<h2 id=\"创建新主页\"><a href=\"#创建新主页\" class=\"headerlink\" title=\"创建新主页\"></a>创建新主页</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new page &quot;page name&quot;</span><br></pre></td></tr></table></figure>\n<p>之后会在source/_posts/page name下面生成对应的page index.md的文件。如：tags、categories的主页，然后再标题头中添加type。</p>\n<h1 id=\"选择主题\"><a href=\"#选择主题\" class=\"headerlink\" title=\"选择主题\"></a>选择主题</h1><p><a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"noopener\">https://hexo.io/themes/</a></p>\n<h2 id=\"替换模板\"><a href=\"#替换模板\" class=\"headerlink\" title=\"替换模板\"></a>替换模板</h2><p>github上clone各类模板到/themes/xxx</p>\n<p>修改_config.yml中的theme: xxx</p>\n<p>我个人使用的Theme是NexT，他有三种模式，分别可以在模板的_config.yml中设置schemes。<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Schemes</span></span><br><span class=\"line\"><span class=\"attr\">scheme:</span> <span class=\"string\">Muse</span></span><br><span class=\"line\"><span class=\"comment\">#scheme: Mist</span></span><br><span class=\"line\"><span class=\"comment\">#scheme: Pisces</span></span><br><span class=\"line\"><span class=\"comment\">#scheme: Gemini</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"安装hexo-git配置插件\"><a href=\"#安装hexo-git配置插件\" class=\"headerlink\" title=\"安装hexo git配置插件\"></a>安装hexo git配置插件</h2><p>npm install hexo-deployer-git –save<br>配置_config.yml中修改入下：<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">git</span></span><br><span class=\"line\"><span class=\"attr\">  repo:</span> <span class=\"string\">gti仓库https地址或SSH地址</span></span><br><span class=\"line\"><span class=\"attr\">  branch:</span> <span class=\"string\">master</span></span><br></pre></td></tr></table></figure></p>\n<p>目前我是每一次generate之后，将构建好的文件从public中全部复制到本地仓库，然后再上传，其实嘛区别不大，就是自己打两个命令。</p>\n","site":{"data":{}},"excerpt":"<h1 id=\"Hexo-amp-GitHub-Pages\"><a href=\"#Hexo-amp-GitHub-Pages\" class=\"headerlink\" title=\"Hexo&amp;GitHub Pages\"></a>Hexo&amp;GitHub Pages</h1><p>最初接触github pages之后，一直想尝试搭建一个属于自己的博客网站，根据朋友的博客网站搭建选择了jekyll，但由于选择的模板以及调试问题居多，最后放弃了。偶然间了解到了hexo和vuepress，了解了之后感觉vuepress的模板比较单一，再加上自己不是很了解vuejs（说的好像node.js自己就很懂一样），最后选择了hexo。</p>\n<p>hexo是基于node.js的高效的静态站点生成框架，通过Hexo可以轻松地使用Markdown编写文章，除了Markdown本身的语法之外，还可以使用Hexo提供的标签插件来快速的插入特定形式的内容。使用起来非常方便。</p>\n<p>从基于Ruby的jekyll，到hexo，再到vuepress。最后选择了hexo。真的是因为用起来简单，但是可能由于自己的电脑git出现了一些问题，导致不能使用hexo deploy，每次都要自己手动构建提交，这还是很麻烦的。</p>\n<p>关于如何在使用github pages搭建博客网站，这里就不抄写细节了，能找到一大堆教程，这篇文章主要是记录下我在学习hexo的一些常用命令。</p>\n<p>github pages是github提供的一个托管的公开网页，会自动将你id.github.io仓库的静态文件自动部署至：https://你的githubID.github.io/ 但由于是公开的仓库，所以大家要注意不要将敏感数据上传。</p>\n<p>由于hexo是基于NodeJS的，所以要先安装NodeJS，具体教程有很多，就不做表述了，下面记录了一些搭建博客过程中常用的命令。</p>","more":"<h1 id=\"常用指令\"><a href=\"#常用指令\" class=\"headerlink\" title=\"常用指令\"></a>常用指令</h1><h2 id=\"清理\"><a href=\"#清理\" class=\"headerlink\" title=\"清理\"></a>清理</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo clean</span><br></pre></td></tr></table></figure>\n<h2 id=\"构建服务\"><a href=\"#构建服务\" class=\"headerlink\" title=\"构建服务\"></a>构建服务</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>也可以缩写为：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo g</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"启动服务\"><a href=\"#启动服务\" class=\"headerlink\" title=\"启动服务\"></a>启动服务</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>缩写：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo s</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"部署到远程站点\"><a href=\"#部署到远程站点\" class=\"headerlink\" title=\"部署到远程站点\"></a>部署到远程站点</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>缩写：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo d</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"新建博文\"><a href=\"#新建博文\" class=\"headerlink\" title=\"新建博文\"></a>新建博文</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new &quot;post name&quot;</span><br></pre></td></tr></table></figure>\n<p>缩写：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo n &quot;post name&quot;</span><br></pre></td></tr></table></figure></p>\n<p>之后会在source/_posts下面生成对应的post name.md的文件。</p>\n<h2 id=\"创建新主页\"><a href=\"#创建新主页\" class=\"headerlink\" title=\"创建新主页\"></a>创建新主页</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new page &quot;page name&quot;</span><br></pre></td></tr></table></figure>\n<p>之后会在source/_posts/page name下面生成对应的page index.md的文件。如：tags、categories的主页，然后再标题头中添加type。</p>\n<h1 id=\"选择主题\"><a href=\"#选择主题\" class=\"headerlink\" title=\"选择主题\"></a>选择主题</h1><p><a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"noopener\">https://hexo.io/themes/</a></p>\n<h2 id=\"替换模板\"><a href=\"#替换模板\" class=\"headerlink\" title=\"替换模板\"></a>替换模板</h2><p>github上clone各类模板到/themes/xxx</p>\n<p>修改_config.yml中的theme: xxx</p>\n<p>我个人使用的Theme是NexT，他有三种模式，分别可以在模板的_config.yml中设置schemes。<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Schemes</span></span><br><span class=\"line\"><span class=\"attr\">scheme:</span> <span class=\"string\">Muse</span></span><br><span class=\"line\"><span class=\"comment\">#scheme: Mist</span></span><br><span class=\"line\"><span class=\"comment\">#scheme: Pisces</span></span><br><span class=\"line\"><span class=\"comment\">#scheme: Gemini</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"安装hexo-git配置插件\"><a href=\"#安装hexo-git配置插件\" class=\"headerlink\" title=\"安装hexo git配置插件\"></a>安装hexo git配置插件</h2><p>npm install hexo-deployer-git –save<br>配置_config.yml中修改入下：<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">git</span></span><br><span class=\"line\"><span class=\"attr\">  repo:</span> <span class=\"string\">gti仓库https地址或SSH地址</span></span><br><span class=\"line\"><span class=\"attr\">  branch:</span> <span class=\"string\">master</span></span><br></pre></td></tr></table></figure></p>\n<p>目前我是每一次generate之后，将构建好的文件从public中全部复制到本地仓库，然后再上传，其实嘛区别不大，就是自己打两个命令。</p>"},{"title":"锁的基础知识","date":"2019-05-11T03:37:00.000Z","_content":"\n之前已经温习了事务相关的基础知识和概念，在实现事务和关于线程安全等问题时，经常会用到锁，但是并没有对锁的基础知识和概念有一个系统的学习，本文是对锁的基础知识概念学习的一个总结。\n\n<!-- more -->\n锁的基础概念\n\n锁设计的点\n\n可重入性\n\n公平性\n\n锁的种类\n\n1. 公平锁/非公平锁\n2. 可重入锁\n3. 独享锁/共享锁\n4. 互斥锁/读写锁\n5. 乐观锁/悲观锁\n6. 分段锁\n7. 偏向锁/轻量级锁/重量级锁\n8. 自旋锁\n\n死锁\n\n如何避免死锁\n\n","source":"_posts/lock.md","raw":"---\ntitle: 锁的基础知识\ndate: 2019-05-11 11:37:00\ntags: Lock\ncategories: 其他\n---\n\n之前已经温习了事务相关的基础知识和概念，在实现事务和关于线程安全等问题时，经常会用到锁，但是并没有对锁的基础知识和概念有一个系统的学习，本文是对锁的基础知识概念学习的一个总结。\n\n<!-- more -->\n锁的基础概念\n\n锁设计的点\n\n可重入性\n\n公平性\n\n锁的种类\n\n1. 公平锁/非公平锁\n2. 可重入锁\n3. 独享锁/共享锁\n4. 互斥锁/读写锁\n5. 乐观锁/悲观锁\n6. 分段锁\n7. 偏向锁/轻量级锁/重量级锁\n8. 自旋锁\n\n死锁\n\n如何避免死锁\n\n","slug":"lock","published":1,"updated":"2019-08-26T07:56:50.157Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0d0019qotnjtynbbxw","content":"<p>之前已经温习了事务相关的基础知识和概念，在实现事务和关于线程安全等问题时，经常会用到锁，但是并没有对锁的基础知识和概念有一个系统的学习，本文是对锁的基础知识概念学习的一个总结。</p>\n<a id=\"more\"></a>\n<p>锁的基础概念</p>\n<p>锁设计的点</p>\n<p>可重入性</p>\n<p>公平性</p>\n<p>锁的种类</p>\n<ol>\n<li>公平锁/非公平锁</li>\n<li>可重入锁</li>\n<li>独享锁/共享锁</li>\n<li>互斥锁/读写锁</li>\n<li>乐观锁/悲观锁</li>\n<li>分段锁</li>\n<li>偏向锁/轻量级锁/重量级锁</li>\n<li>自旋锁</li>\n</ol>\n<p>死锁</p>\n<p>如何避免死锁</p>\n","site":{"data":{}},"excerpt":"<p>之前已经温习了事务相关的基础知识和概念，在实现事务和关于线程安全等问题时，经常会用到锁，但是并没有对锁的基础知识和概念有一个系统的学习，本文是对锁的基础知识概念学习的一个总结。</p>","more":"<p>锁的基础概念</p>\n<p>锁设计的点</p>\n<p>可重入性</p>\n<p>公平性</p>\n<p>锁的种类</p>\n<ol>\n<li>公平锁/非公平锁</li>\n<li>可重入锁</li>\n<li>独享锁/共享锁</li>\n<li>互斥锁/读写锁</li>\n<li>乐观锁/悲观锁</li>\n<li>分段锁</li>\n<li>偏向锁/轻量级锁/重量级锁</li>\n<li>自旋锁</li>\n</ol>\n<p>死锁</p>\n<p>如何避免死锁</p>"},{"title":"linux命令笔记","date":"2019-03-20T02:00:00.000Z","_content":"\n> 一直都在说要好好学习下linux命令，最近在学习docker的时候真的发现自己linux的能力太差了，基础也不行，暂时先记下学习docker过程中用到的一些命令行。\n\n<!-- more -->\n\n首先要先了解下自己的linux系统的操作版本，预防之后遇到的很多坑。\n\n## 查看Linux系统版本与内核版本\n* 查看内核版本的方式\n1. uname -a\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#uname -a\nLinux iZwz91w0kp029z0dmueicoZ 3.10.0-693.2.2.el7.x86_64 #1 SMP Tue Sep 12 22:26:13 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n```\n2. cat /proc/version\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#cat /proc/version\nLinux version 3.10.0-693.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) ) #1 SMP Tue Sep 12 22:26:13 UTC 2017\n```\n\n* 查看Linux系统版本命令\n1. lsb_release\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#lsb_release -a\nLSB Version:    :core-4.1-amd64:core-4.1-noarch\nDistributor ID: CentOS\nDescription:    CentOS Linux release 7.4.1708 (Core)\nRelease:        7.4.1708\nCodename:       Core\n```\n2. cat /etc/redhat-release\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#cat /etc/redhat-release\nCentOS Linux release 7.4.1708 (Core)\n```\n\n还查到了一个说是cat /etc/issue但是这个文件打开后没什么东西，不清楚是不是我这个系统有问题。。\n\n我这个是一个阿里云的服务器，系统内核是CentOS linux 7.4.1708 x86 64位，linux版本Linux version 3.10.0。\n\n\n## 用户\n今天在记笔记的时候，看到有的会是$ xxx的指令，而有的是# xxx，后来查了下才知道，原来root用户就会是#开头，而非root用户则是$开头。\n\n一直用root用户其实也是有一定风险的，当然个人使用的话是没问题的，但是如果有多人使用，root用户权限会非常大，并不安全。所以先学习了下如何创建用户，并且分配相关权限。\n\n## 网络\n在windows中是使用ipconfig查看IP网络信息的，但是在linux系统中会提示没有这个指令，那相同能力的指令是什么呢，其实是ifconfig。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#ifconfig\ndocker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        ether 02:42:f9:91:0c:70  txqueuelen 0  (Ethernet)\n        RX packets 3385  bytes 233447 (227.9 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 7300  bytes 448669 (438.1 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.18.149.46  netmask 255.255.240.0  broadcast 172.18.159.255\n        ether 00:16:3e:02:d1:f0  txqueuelen 1000  (Ethernet)\n        RX packets 5062352  bytes 1452046450 (1.3 GiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 3885791  bytes 441227116 (420.7 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        loop  txqueuelen 1  (Local Loopback)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nvethe8247e8: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        ether 76:33:08:8d:a1:f0  txqueuelen 0  (Ethernet)\n        RX packets 3204  bytes 265137 (258.9 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 7105  bytes 434120 (423.9 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nvethfcf581a: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        ether d6:5a:8c:29:23:7e  txqueuelen 0  (Ethernet)\n        RX packets 133  bytes 11230 (10.9 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 231  bytes 14338 (14.0 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n```\n\n### iptables\n防火墙配置规则\n\niptables --list-rules\n\n### brctl\n先引入工具包：yum install bridge-utils\n\nbrctl show\n\n### 查看端口占用情况\nnetstat -tunlp\n```\n[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#netstat -tunlp\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      31413/sshd\ntcp6       0      0 :::3306                 :::*                    LISTEN      28980/docker-proxy\nudp        0      0 0.0.0.0:25940           0.0.0.0:*                           724/dhclient\nudp        0      0 0.0.0.0:68              0.0.0.0:*                           724/dhclient\nudp        0      0 172.20.0.1:123          0.0.0.0:*                           7939/ntpd\nudp        0      0 172.19.0.1:123          0.0.0.0:*                           7939/ntpd\nudp        0      0 172.17.0.1:123          0.0.0.0:*                           7939/ntpd\nudp        0      0 172.18.149.46:123       0.0.0.0:*                           7939/ntpd\nudp        0      0 127.0.0.1:123           0.0.0.0:*                           7939/ntpd\nudp        0      0 0.0.0.0:123             0.0.0.0:*                           7939/ntpd\nudp6       0      0 :::50357                :::*                                724/dhclient\nudp6       0      0 :::123                  :::*                                7939/ntpd\n\n```\n## 硬盘使用情况\n> df [OPTION]... [FILE]...\n- -a, --all 包含所有的具有 0 Blocks 的文件系统\n- --block-size={SIZE} 使用 {SIZE} 大小的 Blocks\n- -h, --human-readable 使用人类可读的格式(预设值是不加这个选项的...)\n- -H, --si 很像 -h, 但是用 1000 为单位而不是用 1024\n- -i, --inodes 列出 inode 资讯，不列出已使用 block\n- -k, --kilobytes 就像是 --block-size=1024\n- -l, --local 限制列出的文件结构\n- -m, --megabytes 就像 --block-size=1048576\n- --no-sync 取得资讯前不 sync (预设值)\n- -P, --portability 使用 POSIX 输出格式\n- --sync 在取得资讯前 sync\n- -t, --type=TYPE 限制列出文件系统的 TYPE\n- -T, --print-type 显示文件系统的形式\n- -x, --exclude-type=TYPE 限制列出文件系统不要显示 TYPE\n- -v (忽略)\n- --help 显示这个帮手并且离开\n- --version 输出版本资讯并且离开\n```\n[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#df -hl\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/vda1        40G   16G   22G  43% /\ndevtmpfs        1.9G     0  1.9G   0% /dev\ntmpfs           1.9G     0  1.9G   0% /dev/shm\ntmpfs           1.9G  428K  1.9G   1% /run\ntmpfs           1.9G     0  1.9G   0% /sys/fs/cgroup\noverlay          40G   16G   22G  43% /var/lib/docker/overlay2/15c11eb5a1a871c9e41ce861b6fcd11063a2d5dec965b75985b1068cf05f9ce5/merged\nshm              64M     0   64M   0% /var/lib/docker/containers/1254821edc4c200cd6e899a70347623bb38276bde0db1591f7c9c4dbc208a692/mounts/shm\ntmpfs           380M     0  380M   0% /run/user/0\n```\n","source":"_posts/linux命令笔记.md","raw":"---\ntitle: linux命令笔记\ndate: 2019-03-20 10:00:00\ntags: Linux\ncategories: Linux\n---\n\n> 一直都在说要好好学习下linux命令，最近在学习docker的时候真的发现自己linux的能力太差了，基础也不行，暂时先记下学习docker过程中用到的一些命令行。\n\n<!-- more -->\n\n首先要先了解下自己的linux系统的操作版本，预防之后遇到的很多坑。\n\n## 查看Linux系统版本与内核版本\n* 查看内核版本的方式\n1. uname -a\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#uname -a\nLinux iZwz91w0kp029z0dmueicoZ 3.10.0-693.2.2.el7.x86_64 #1 SMP Tue Sep 12 22:26:13 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n```\n2. cat /proc/version\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#cat /proc/version\nLinux version 3.10.0-693.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) ) #1 SMP Tue Sep 12 22:26:13 UTC 2017\n```\n\n* 查看Linux系统版本命令\n1. lsb_release\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#lsb_release -a\nLSB Version:    :core-4.1-amd64:core-4.1-noarch\nDistributor ID: CentOS\nDescription:    CentOS Linux release 7.4.1708 (Core)\nRelease:        7.4.1708\nCodename:       Core\n```\n2. cat /etc/redhat-release\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#cat /etc/redhat-release\nCentOS Linux release 7.4.1708 (Core)\n```\n\n还查到了一个说是cat /etc/issue但是这个文件打开后没什么东西，不清楚是不是我这个系统有问题。。\n\n我这个是一个阿里云的服务器，系统内核是CentOS linux 7.4.1708 x86 64位，linux版本Linux version 3.10.0。\n\n\n## 用户\n今天在记笔记的时候，看到有的会是$ xxx的指令，而有的是# xxx，后来查了下才知道，原来root用户就会是#开头，而非root用户则是$开头。\n\n一直用root用户其实也是有一定风险的，当然个人使用的话是没问题的，但是如果有多人使用，root用户权限会非常大，并不安全。所以先学习了下如何创建用户，并且分配相关权限。\n\n## 网络\n在windows中是使用ipconfig查看IP网络信息的，但是在linux系统中会提示没有这个指令，那相同能力的指令是什么呢，其实是ifconfig。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#ifconfig\ndocker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n        ether 02:42:f9:91:0c:70  txqueuelen 0  (Ethernet)\n        RX packets 3385  bytes 233447 (227.9 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 7300  bytes 448669 (438.1 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 172.18.149.46  netmask 255.255.240.0  broadcast 172.18.159.255\n        ether 00:16:3e:02:d1:f0  txqueuelen 1000  (Ethernet)\n        RX packets 5062352  bytes 1452046450 (1.3 GiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 3885791  bytes 441227116 (420.7 MiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nlo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536\n        inet 127.0.0.1  netmask 255.0.0.0\n        loop  txqueuelen 1  (Local Loopback)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nvethe8247e8: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        ether 76:33:08:8d:a1:f0  txqueuelen 0  (Ethernet)\n        RX packets 3204  bytes 265137 (258.9 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 7105  bytes 434120 (423.9 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\nvethfcf581a: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        ether d6:5a:8c:29:23:7e  txqueuelen 0  (Ethernet)\n        RX packets 133  bytes 11230 (10.9 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 231  bytes 14338 (14.0 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n```\n\n### iptables\n防火墙配置规则\n\niptables --list-rules\n\n### brctl\n先引入工具包：yum install bridge-utils\n\nbrctl show\n\n### 查看端口占用情况\nnetstat -tunlp\n```\n[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#netstat -tunlp\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      31413/sshd\ntcp6       0      0 :::3306                 :::*                    LISTEN      28980/docker-proxy\nudp        0      0 0.0.0.0:25940           0.0.0.0:*                           724/dhclient\nudp        0      0 0.0.0.0:68              0.0.0.0:*                           724/dhclient\nudp        0      0 172.20.0.1:123          0.0.0.0:*                           7939/ntpd\nudp        0      0 172.19.0.1:123          0.0.0.0:*                           7939/ntpd\nudp        0      0 172.17.0.1:123          0.0.0.0:*                           7939/ntpd\nudp        0      0 172.18.149.46:123       0.0.0.0:*                           7939/ntpd\nudp        0      0 127.0.0.1:123           0.0.0.0:*                           7939/ntpd\nudp        0      0 0.0.0.0:123             0.0.0.0:*                           7939/ntpd\nudp6       0      0 :::50357                :::*                                724/dhclient\nudp6       0      0 :::123                  :::*                                7939/ntpd\n\n```\n## 硬盘使用情况\n> df [OPTION]... [FILE]...\n- -a, --all 包含所有的具有 0 Blocks 的文件系统\n- --block-size={SIZE} 使用 {SIZE} 大小的 Blocks\n- -h, --human-readable 使用人类可读的格式(预设值是不加这个选项的...)\n- -H, --si 很像 -h, 但是用 1000 为单位而不是用 1024\n- -i, --inodes 列出 inode 资讯，不列出已使用 block\n- -k, --kilobytes 就像是 --block-size=1024\n- -l, --local 限制列出的文件结构\n- -m, --megabytes 就像 --block-size=1048576\n- --no-sync 取得资讯前不 sync (预设值)\n- -P, --portability 使用 POSIX 输出格式\n- --sync 在取得资讯前 sync\n- -t, --type=TYPE 限制列出文件系统的 TYPE\n- -T, --print-type 显示文件系统的形式\n- -x, --exclude-type=TYPE 限制列出文件系统不要显示 TYPE\n- -v (忽略)\n- --help 显示这个帮手并且离开\n- --version 输出版本资讯并且离开\n```\n[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#df -hl\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/vda1        40G   16G   22G  43% /\ndevtmpfs        1.9G     0  1.9G   0% /dev\ntmpfs           1.9G     0  1.9G   0% /dev/shm\ntmpfs           1.9G  428K  1.9G   1% /run\ntmpfs           1.9G     0  1.9G   0% /sys/fs/cgroup\noverlay          40G   16G   22G  43% /var/lib/docker/overlay2/15c11eb5a1a871c9e41ce861b6fcd11063a2d5dec965b75985b1068cf05f9ce5/merged\nshm              64M     0   64M   0% /var/lib/docker/containers/1254821edc4c200cd6e899a70347623bb38276bde0db1591f7c9c4dbc208a692/mounts/shm\ntmpfs           380M     0  380M   0% /run/user/0\n```\n","slug":"linux命令笔记","published":1,"updated":"2019-09-24T08:31:16.108Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0f001bqotn3z71ee1v","content":"<blockquote>\n<p>一直都在说要好好学习下linux命令，最近在学习docker的时候真的发现自己linux的能力太差了，基础也不行，暂时先记下学习docker过程中用到的一些命令行。</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>首先要先了解下自己的linux系统的操作版本，预防之后遇到的很多坑。</p>\n<h2 id=\"查看Linux系统版本与内核版本\"><a href=\"#查看Linux系统版本与内核版本\" class=\"headerlink\" title=\"查看Linux系统版本与内核版本\"></a>查看Linux系统版本与内核版本</h2><ul>\n<li>查看内核版本的方式</li>\n</ul>\n<ol>\n<li><p>uname -a</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#uname -a</span><br><span class=\"line\">Linux iZwz91w0kp029z0dmueicoZ 3.10.0-693.2.2.el7.x86_64 #1 SMP Tue Sep 12 22:26:13 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>cat /proc/version</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#cat /proc/version</span><br><span class=\"line\">Linux version 3.10.0-693.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) ) #1 SMP Tue Sep 12 22:26:13 UTC 2017</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ul>\n<li>查看Linux系统版本命令</li>\n</ul>\n<ol>\n<li><p>lsb_release</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#lsb_release -a</span><br><span class=\"line\">LSB Version:    :core-4.1-amd64:core-4.1-noarch</span><br><span class=\"line\">Distributor ID: CentOS</span><br><span class=\"line\">Description:    CentOS Linux release 7.4.1708 (Core)</span><br><span class=\"line\">Release:        7.4.1708</span><br><span class=\"line\">Codename:       Core</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>cat /etc/redhat-release</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#cat /etc/redhat-release</span><br><span class=\"line\">CentOS Linux release 7.4.1708 (Core)</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>还查到了一个说是cat /etc/issue但是这个文件打开后没什么东西，不清楚是不是我这个系统有问题。。</p>\n<p>我这个是一个阿里云的服务器，系统内核是CentOS linux 7.4.1708 x86 64位，linux版本Linux version 3.10.0。</p>\n<h2 id=\"用户\"><a href=\"#用户\" class=\"headerlink\" title=\"用户\"></a>用户</h2><p>今天在记笔记的时候，看到有的会是$ xxx的指令，而有的是# xxx，后来查了下才知道，原来root用户就会是#开头，而非root用户则是$开头。</p>\n<p>一直用root用户其实也是有一定风险的，当然个人使用的话是没问题的，但是如果有多人使用，root用户权限会非常大，并不安全。所以先学习了下如何创建用户，并且分配相关权限。</p>\n<h2 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h2><p>在windows中是使用ipconfig查看IP网络信息的，但是在linux系统中会提示没有这个指令，那相同能力的指令是什么呢，其实是ifconfig。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#ifconfig</span><br><span class=\"line\">docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class=\"line\">        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255</span><br><span class=\"line\">        ether 02:42:f9:91:0c:70  txqueuelen 0  (Ethernet)</span><br><span class=\"line\">        RX packets 3385  bytes 233447 (227.9 KiB)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 7300  bytes 448669 (438.1 KiB)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class=\"line\"></span><br><span class=\"line\">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class=\"line\">        inet 172.18.149.46  netmask 255.255.240.0  broadcast 172.18.159.255</span><br><span class=\"line\">        ether 00:16:3e:02:d1:f0  txqueuelen 1000  (Ethernet)</span><br><span class=\"line\">        RX packets 5062352  bytes 1452046450 (1.3 GiB)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 3885791  bytes 441227116 (420.7 MiB)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class=\"line\"></span><br><span class=\"line\">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class=\"line\">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class=\"line\">        loop  txqueuelen 1  (Local Loopback)</span><br><span class=\"line\">        RX packets 0  bytes 0 (0.0 B)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 0  bytes 0 (0.0 B)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class=\"line\"></span><br><span class=\"line\">vethe8247e8: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class=\"line\">        ether 76:33:08:8d:a1:f0  txqueuelen 0  (Ethernet)</span><br><span class=\"line\">        RX packets 3204  bytes 265137 (258.9 KiB)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 7105  bytes 434120 (423.9 KiB)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class=\"line\"></span><br><span class=\"line\">vethfcf581a: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class=\"line\">        ether d6:5a:8c:29:23:7e  txqueuelen 0  (Ethernet)</span><br><span class=\"line\">        RX packets 133  bytes 11230 (10.9 KiB)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 231  bytes 14338 (14.0 KiB)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"iptables\"><a href=\"#iptables\" class=\"headerlink\" title=\"iptables\"></a>iptables</h3><p>防火墙配置规则</p>\n<p>iptables –list-rules</p>\n<h3 id=\"brctl\"><a href=\"#brctl\" class=\"headerlink\" title=\"brctl\"></a>brctl</h3><p>先引入工具包：yum install bridge-utils</p>\n<p>brctl show</p>\n<h3 id=\"查看端口占用情况\"><a href=\"#查看端口占用情况\" class=\"headerlink\" title=\"查看端口占用情况\"></a>查看端口占用情况</h3><p>netstat -tunlp<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#netstat -tunlp</span><br><span class=\"line\">Active Internet connections (only servers)</span><br><span class=\"line\">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</span><br><span class=\"line\">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      31413/sshd</span><br><span class=\"line\">tcp6       0      0 :::3306                 :::*                    LISTEN      28980/docker-proxy</span><br><span class=\"line\">udp        0      0 0.0.0.0:25940           0.0.0.0:*                           724/dhclient</span><br><span class=\"line\">udp        0      0 0.0.0.0:68              0.0.0.0:*                           724/dhclient</span><br><span class=\"line\">udp        0      0 172.20.0.1:123          0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 172.19.0.1:123          0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 172.17.0.1:123          0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 172.18.149.46:123       0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 127.0.0.1:123           0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 0.0.0.0:123             0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp6       0      0 :::50357                :::*                                724/dhclient</span><br><span class=\"line\">udp6       0      0 :::123                  :::*                                7939/ntpd</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"硬盘使用情况\"><a href=\"#硬盘使用情况\" class=\"headerlink\" title=\"硬盘使用情况\"></a>硬盘使用情况</h2><blockquote>\n<p>df [OPTION]… [FILE]…</p>\n<ul>\n<li>-a, –all 包含所有的具有 0 Blocks 的文件系统</li>\n<li>–block-size={SIZE} 使用 {SIZE} 大小的 Blocks</li>\n<li>-h, –human-readable 使用人类可读的格式(预设值是不加这个选项的…)</li>\n<li>-H, –si 很像 -h, 但是用 1000 为单位而不是用 1024</li>\n<li>-i, –inodes 列出 inode 资讯，不列出已使用 block</li>\n<li>-k, –kilobytes 就像是 –block-size=1024</li>\n<li>-l, –local 限制列出的文件结构</li>\n<li>-m, –megabytes 就像 –block-size=1048576</li>\n<li>–no-sync 取得资讯前不 sync (预设值)</li>\n<li>-P, –portability 使用 POSIX 输出格式</li>\n<li>–sync 在取得资讯前 sync</li>\n<li>-t, –type=TYPE 限制列出文件系统的 TYPE</li>\n<li>-T, –print-type 显示文件系统的形式</li>\n<li>-x, –exclude-type=TYPE 限制列出文件系统不要显示 TYPE</li>\n<li>-v (忽略)</li>\n<li>–help 显示这个帮手并且离开</li>\n<li>–version 输出版本资讯并且离开<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#df -hl</span><br><span class=\"line\">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class=\"line\">/dev/vda1        40G   16G   22G  43% /</span><br><span class=\"line\">devtmpfs        1.9G     0  1.9G   0% /dev</span><br><span class=\"line\">tmpfs           1.9G     0  1.9G   0% /dev/shm</span><br><span class=\"line\">tmpfs           1.9G  428K  1.9G   1% /run</span><br><span class=\"line\">tmpfs           1.9G     0  1.9G   0% /sys/fs/cgroup</span><br><span class=\"line\">overlay          40G   16G   22G  43% /var/lib/docker/overlay2/15c11eb5a1a871c9e41ce861b6fcd11063a2d5dec965b75985b1068cf05f9ce5/merged</span><br><span class=\"line\">shm              64M     0   64M   0% /var/lib/docker/containers/1254821edc4c200cd6e899a70347623bb38276bde0db1591f7c9c4dbc208a692/mounts/shm</span><br><span class=\"line\">tmpfs           380M     0  380M   0% /run/user/0</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</blockquote>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>一直都在说要好好学习下linux命令，最近在学习docker的时候真的发现自己linux的能力太差了，基础也不行，暂时先记下学习docker过程中用到的一些命令行。</p>\n</blockquote>","more":"<p>首先要先了解下自己的linux系统的操作版本，预防之后遇到的很多坑。</p>\n<h2 id=\"查看Linux系统版本与内核版本\"><a href=\"#查看Linux系统版本与内核版本\" class=\"headerlink\" title=\"查看Linux系统版本与内核版本\"></a>查看Linux系统版本与内核版本</h2><ul>\n<li>查看内核版本的方式</li>\n</ul>\n<ol>\n<li><p>uname -a</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#uname -a</span><br><span class=\"line\">Linux iZwz91w0kp029z0dmueicoZ 3.10.0-693.2.2.el7.x86_64 #1 SMP Tue Sep 12 22:26:13 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>cat /proc/version</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#cat /proc/version</span><br><span class=\"line\">Linux version 3.10.0-693.2.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) ) #1 SMP Tue Sep 12 22:26:13 UTC 2017</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ul>\n<li>查看Linux系统版本命令</li>\n</ul>\n<ol>\n<li><p>lsb_release</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#lsb_release -a</span><br><span class=\"line\">LSB Version:    :core-4.1-amd64:core-4.1-noarch</span><br><span class=\"line\">Distributor ID: CentOS</span><br><span class=\"line\">Description:    CentOS Linux release 7.4.1708 (Core)</span><br><span class=\"line\">Release:        7.4.1708</span><br><span class=\"line\">Codename:       Core</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>cat /etc/redhat-release</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#cat /etc/redhat-release</span><br><span class=\"line\">CentOS Linux release 7.4.1708 (Core)</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>还查到了一个说是cat /etc/issue但是这个文件打开后没什么东西，不清楚是不是我这个系统有问题。。</p>\n<p>我这个是一个阿里云的服务器，系统内核是CentOS linux 7.4.1708 x86 64位，linux版本Linux version 3.10.0。</p>\n<h2 id=\"用户\"><a href=\"#用户\" class=\"headerlink\" title=\"用户\"></a>用户</h2><p>今天在记笔记的时候，看到有的会是$ xxx的指令，而有的是# xxx，后来查了下才知道，原来root用户就会是#开头，而非root用户则是$开头。</p>\n<p>一直用root用户其实也是有一定风险的，当然个人使用的话是没问题的，但是如果有多人使用，root用户权限会非常大，并不安全。所以先学习了下如何创建用户，并且分配相关权限。</p>\n<h2 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h2><p>在windows中是使用ipconfig查看IP网络信息的，但是在linux系统中会提示没有这个指令，那相同能力的指令是什么呢，其实是ifconfig。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#ifconfig</span><br><span class=\"line\">docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class=\"line\">        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255</span><br><span class=\"line\">        ether 02:42:f9:91:0c:70  txqueuelen 0  (Ethernet)</span><br><span class=\"line\">        RX packets 3385  bytes 233447 (227.9 KiB)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 7300  bytes 448669 (438.1 KiB)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class=\"line\"></span><br><span class=\"line\">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class=\"line\">        inet 172.18.149.46  netmask 255.255.240.0  broadcast 172.18.159.255</span><br><span class=\"line\">        ether 00:16:3e:02:d1:f0  txqueuelen 1000  (Ethernet)</span><br><span class=\"line\">        RX packets 5062352  bytes 1452046450 (1.3 GiB)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 3885791  bytes 441227116 (420.7 MiB)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class=\"line\"></span><br><span class=\"line\">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536</span><br><span class=\"line\">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class=\"line\">        loop  txqueuelen 1  (Local Loopback)</span><br><span class=\"line\">        RX packets 0  bytes 0 (0.0 B)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 0  bytes 0 (0.0 B)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class=\"line\"></span><br><span class=\"line\">vethe8247e8: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class=\"line\">        ether 76:33:08:8d:a1:f0  txqueuelen 0  (Ethernet)</span><br><span class=\"line\">        RX packets 3204  bytes 265137 (258.9 KiB)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 7105  bytes 434120 (423.9 KiB)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class=\"line\"></span><br><span class=\"line\">vethfcf581a: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class=\"line\">        ether d6:5a:8c:29:23:7e  txqueuelen 0  (Ethernet)</span><br><span class=\"line\">        RX packets 133  bytes 11230 (10.9 KiB)</span><br><span class=\"line\">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class=\"line\">        TX packets 231  bytes 14338 (14.0 KiB)</span><br><span class=\"line\">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"iptables\"><a href=\"#iptables\" class=\"headerlink\" title=\"iptables\"></a>iptables</h3><p>防火墙配置规则</p>\n<p>iptables –list-rules</p>\n<h3 id=\"brctl\"><a href=\"#brctl\" class=\"headerlink\" title=\"brctl\"></a>brctl</h3><p>先引入工具包：yum install bridge-utils</p>\n<p>brctl show</p>\n<h3 id=\"查看端口占用情况\"><a href=\"#查看端口占用情况\" class=\"headerlink\" title=\"查看端口占用情况\"></a>查看端口占用情况</h3><p>netstat -tunlp<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#netstat -tunlp</span><br><span class=\"line\">Active Internet connections (only servers)</span><br><span class=\"line\">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</span><br><span class=\"line\">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      31413/sshd</span><br><span class=\"line\">tcp6       0      0 :::3306                 :::*                    LISTEN      28980/docker-proxy</span><br><span class=\"line\">udp        0      0 0.0.0.0:25940           0.0.0.0:*                           724/dhclient</span><br><span class=\"line\">udp        0      0 0.0.0.0:68              0.0.0.0:*                           724/dhclient</span><br><span class=\"line\">udp        0      0 172.20.0.1:123          0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 172.19.0.1:123          0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 172.17.0.1:123          0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 172.18.149.46:123       0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 127.0.0.1:123           0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp        0      0 0.0.0.0:123             0.0.0.0:*                           7939/ntpd</span><br><span class=\"line\">udp6       0      0 :::50357                :::*                                724/dhclient</span><br><span class=\"line\">udp6       0      0 :::123                  :::*                                7939/ntpd</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"硬盘使用情况\"><a href=\"#硬盘使用情况\" class=\"headerlink\" title=\"硬盘使用情况\"></a>硬盘使用情况</h2><blockquote>\n<p>df [OPTION]… [FILE]…</p>\n<ul>\n<li>-a, –all 包含所有的具有 0 Blocks 的文件系统</li>\n<li>–block-size={SIZE} 使用 {SIZE} 大小的 Blocks</li>\n<li>-h, –human-readable 使用人类可读的格式(预设值是不加这个选项的…)</li>\n<li>-H, –si 很像 -h, 但是用 1000 为单位而不是用 1024</li>\n<li>-i, –inodes 列出 inode 资讯，不列出已使用 block</li>\n<li>-k, –kilobytes 就像是 –block-size=1024</li>\n<li>-l, –local 限制列出的文件结构</li>\n<li>-m, –megabytes 就像 –block-size=1048576</li>\n<li>–no-sync 取得资讯前不 sync (预设值)</li>\n<li>-P, –portability 使用 POSIX 输出格式</li>\n<li>–sync 在取得资讯前 sync</li>\n<li>-t, –type=TYPE 限制列出文件系统的 TYPE</li>\n<li>-T, –print-type 显示文件系统的形式</li>\n<li>-x, –exclude-type=TYPE 限制列出文件系统不要显示 TYPE</li>\n<li>-v (忽略)</li>\n<li>–help 显示这个帮手并且离开</li>\n<li>–version 输出版本资讯并且离开<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root/elasticsearch]#df -hl</span><br><span class=\"line\">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class=\"line\">/dev/vda1        40G   16G   22G  43% /</span><br><span class=\"line\">devtmpfs        1.9G     0  1.9G   0% /dev</span><br><span class=\"line\">tmpfs           1.9G     0  1.9G   0% /dev/shm</span><br><span class=\"line\">tmpfs           1.9G  428K  1.9G   1% /run</span><br><span class=\"line\">tmpfs           1.9G     0  1.9G   0% /sys/fs/cgroup</span><br><span class=\"line\">overlay          40G   16G   22G  43% /var/lib/docker/overlay2/15c11eb5a1a871c9e41ce861b6fcd11063a2d5dec965b75985b1068cf05f9ce5/merged</span><br><span class=\"line\">shm              64M     0   64M   0% /var/lib/docker/containers/1254821edc4c200cd6e899a70347623bb38276bde0db1591f7c9c4dbc208a692/mounts/shm</span><br><span class=\"line\">tmpfs           380M     0  380M   0% /run/user/0</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</blockquote>"},{"title":"ElasticSearch基础RESTfulAPI","date":"2019-12-09T07:00:00.000Z","_content":"\n在学习Elasticsearch相关的api使用中，大多数其实可以通过kibana、cerebro来使用，很方便，但是当通过客户端应用程序连接的时候，其实还是要了解各个RESTfulAPI的细节，方便出现问题排查，所以记录了一下学习的基础API。\n\n<!-- more -->\n\n# 集群的监控\n集群应用的相关信息，其实可以通过部署cerebro来查看，但是也是要了解一下相关的RESTfulAPI的。\n- GET _cluster/health 查看集群的健康状况\n- GET _cat/nodes 查看节点信息\n- GET _cat/shards 查看分片信息\n\n# 文档的CRUD\n操作类型 | RESTfulAPI |  \n-- | -- |\nIndex | PUT my_index/_doc/id\nCreate | PUT my_index/_create/id\nRead | GET my_index/_doc/id\nUpdate | POST my_index/_update/id\nDelete | DELETE my_index/_doc/id\n\n- Type约定都用_doc\n- Create 如果ID已经存在，则会创建失败\n- Index 如果ID不存在，创建新的文档，否则，会删除现有的文档，然后创建新的文档，版本号增加\n- Update 文档必须已经存在，更新只会更新对应字段做增加修改\n\n## 创建文档\n有两种方式\n```\nPOST /my_index/_doc                       自动生成ID创建文档\n```\n\n```\nPUT /my_index/_create/${id}               指定ID创建文档\n```\n\n通过index操作，指定操作类型进行创建\n```\nPUT /my_index/_doc/${id}/?op_type=create  指定ID创建文档\n```\n\n## Index文档\n如果文档不存在，就会索引新文档，否则，现有的文档会被删除，新的文档被索引，版本信息+1。\n```\nPUT /my_index/_doc/${id}                  根据ID更新文档，如果不存在则创建文档\n{\n    // 要更新的内容\n}\n```\n\n## 获取文档\n找到文档会返回HTTP 200，找不到则会返回HTTP 404\n```\nGET /my_index/_doc/${id}                  获取文档\n```\n\n## 更新文档\n更新的信息必须包含在\"doc\"中\n```\nPOST /my_index/_update/${id}/             更新文档\n{\n    \"doc\":{\n        // 要更新的内容\n    }\n}\n```\n\n# Bulk API\n每次RESTfulAPI都会进行一次网络开销，如果多次调用会非常损耗性能。\n\nBulk API得核心思想就想在一次调用中，进行多种操作。\n\n支持对一个索引的多种操作，也支持对多个索引的多种操作。\n- Index\n- Create\n- Update\n- Delete\n\n即使单条操作失败，但并不会影响其他的操作。返回结果中包含了每一条的执行结果\n\n# 批量独取 mget\n批量独取，同Bulk API类似，都是通过减少网络连接减少对性能的开销。\n\n只需要提供一细列的index和对应文档ID，就可以一次返回多条文档信息。\n\n# 批量查询 msearch\n可以通过一次调用，对不同的索引，进行不同维度的查询。\n\n# 常见错误返回\n问题/状态码 | 原因\n-- | --\n无法连接 | 网络故障或者集群挂了\n连接无法关闭 | 网络故障或者节点出错\n429 | 集群过于繁忙\n4XX | 请求格式体有误\n500 | 集群内部错误","source":"_posts/elasticsearch_04_基础RESTfulAPI.md","raw":"---\ntitle: ElasticSearch基础RESTfulAPI\ndate: 2019-12-09 15:00:00\ntags: ElasticSearch\ncategories: Elastic Stack\n---\n\n在学习Elasticsearch相关的api使用中，大多数其实可以通过kibana、cerebro来使用，很方便，但是当通过客户端应用程序连接的时候，其实还是要了解各个RESTfulAPI的细节，方便出现问题排查，所以记录了一下学习的基础API。\n\n<!-- more -->\n\n# 集群的监控\n集群应用的相关信息，其实可以通过部署cerebro来查看，但是也是要了解一下相关的RESTfulAPI的。\n- GET _cluster/health 查看集群的健康状况\n- GET _cat/nodes 查看节点信息\n- GET _cat/shards 查看分片信息\n\n# 文档的CRUD\n操作类型 | RESTfulAPI |  \n-- | -- |\nIndex | PUT my_index/_doc/id\nCreate | PUT my_index/_create/id\nRead | GET my_index/_doc/id\nUpdate | POST my_index/_update/id\nDelete | DELETE my_index/_doc/id\n\n- Type约定都用_doc\n- Create 如果ID已经存在，则会创建失败\n- Index 如果ID不存在，创建新的文档，否则，会删除现有的文档，然后创建新的文档，版本号增加\n- Update 文档必须已经存在，更新只会更新对应字段做增加修改\n\n## 创建文档\n有两种方式\n```\nPOST /my_index/_doc                       自动生成ID创建文档\n```\n\n```\nPUT /my_index/_create/${id}               指定ID创建文档\n```\n\n通过index操作，指定操作类型进行创建\n```\nPUT /my_index/_doc/${id}/?op_type=create  指定ID创建文档\n```\n\n## Index文档\n如果文档不存在，就会索引新文档，否则，现有的文档会被删除，新的文档被索引，版本信息+1。\n```\nPUT /my_index/_doc/${id}                  根据ID更新文档，如果不存在则创建文档\n{\n    // 要更新的内容\n}\n```\n\n## 获取文档\n找到文档会返回HTTP 200，找不到则会返回HTTP 404\n```\nGET /my_index/_doc/${id}                  获取文档\n```\n\n## 更新文档\n更新的信息必须包含在\"doc\"中\n```\nPOST /my_index/_update/${id}/             更新文档\n{\n    \"doc\":{\n        // 要更新的内容\n    }\n}\n```\n\n# Bulk API\n每次RESTfulAPI都会进行一次网络开销，如果多次调用会非常损耗性能。\n\nBulk API得核心思想就想在一次调用中，进行多种操作。\n\n支持对一个索引的多种操作，也支持对多个索引的多种操作。\n- Index\n- Create\n- Update\n- Delete\n\n即使单条操作失败，但并不会影响其他的操作。返回结果中包含了每一条的执行结果\n\n# 批量独取 mget\n批量独取，同Bulk API类似，都是通过减少网络连接减少对性能的开销。\n\n只需要提供一细列的index和对应文档ID，就可以一次返回多条文档信息。\n\n# 批量查询 msearch\n可以通过一次调用，对不同的索引，进行不同维度的查询。\n\n# 常见错误返回\n问题/状态码 | 原因\n-- | --\n无法连接 | 网络故障或者集群挂了\n连接无法关闭 | 网络故障或者节点出错\n429 | 集群过于繁忙\n4XX | 请求格式体有误\n500 | 集群内部错误","slug":"elasticsearch_04_基础RESTfulAPI","published":1,"updated":"2019-12-09T01:14:18.262Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0h001fqotn49ynzxag","content":"<p>在学习Elasticsearch相关的api使用中，大多数其实可以通过kibana、cerebro来使用，很方便，但是当通过客户端应用程序连接的时候，其实还是要了解各个RESTfulAPI的细节，方便出现问题排查，所以记录了一下学习的基础API。</p>\n<a id=\"more\"></a>\n<h1 id=\"集群的监控\"><a href=\"#集群的监控\" class=\"headerlink\" title=\"集群的监控\"></a>集群的监控</h1><p>集群应用的相关信息，其实可以通过部署cerebro来查看，但是也是要了解一下相关的RESTfulAPI的。</p>\n<ul>\n<li>GET _cluster/health 查看集群的健康状况</li>\n<li>GET _cat/nodes 查看节点信息</li>\n<li>GET _cat/shards 查看分片信息</li>\n</ul>\n<h1 id=\"文档的CRUD\"><a href=\"#文档的CRUD\" class=\"headerlink\" title=\"文档的CRUD\"></a>文档的CRUD</h1><table>\n<thead>\n<tr>\n<th>操作类型</th>\n<th>RESTfulAPI</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Index</td>\n<td>PUT my_index/_doc/id</td>\n</tr>\n<tr>\n<td>Create</td>\n<td>PUT my_index/_create/id</td>\n</tr>\n<tr>\n<td>Read</td>\n<td>GET my_index/_doc/id</td>\n</tr>\n<tr>\n<td>Update</td>\n<td>POST my_index/_update/id</td>\n</tr>\n<tr>\n<td>Delete</td>\n<td>DELETE my_index/_doc/id</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>Type约定都用_doc</li>\n<li>Create 如果ID已经存在，则会创建失败</li>\n<li>Index 如果ID不存在，创建新的文档，否则，会删除现有的文档，然后创建新的文档，版本号增加</li>\n<li>Update 文档必须已经存在，更新只会更新对应字段做增加修改</li>\n</ul>\n<h2 id=\"创建文档\"><a href=\"#创建文档\" class=\"headerlink\" title=\"创建文档\"></a>创建文档</h2><p>有两种方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">POST /my_index/_doc                       自动生成ID创建文档</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /my_index/_create/$&#123;id&#125;               指定ID创建文档</span><br></pre></td></tr></table></figure>\n<p>通过index操作，指定操作类型进行创建<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /my_index/_doc/$&#123;id&#125;/?op_type=create  指定ID创建文档</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Index文档\"><a href=\"#Index文档\" class=\"headerlink\" title=\"Index文档\"></a>Index文档</h2><p>如果文档不存在，就会索引新文档，否则，现有的文档会被删除，新的文档被索引，版本信息+1。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /my_index/_doc/$&#123;id&#125;                  根据ID更新文档，如果不存在则创建文档</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    // 要更新的内容</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"获取文档\"><a href=\"#获取文档\" class=\"headerlink\" title=\"获取文档\"></a>获取文档</h2><p>找到文档会返回HTTP 200，找不到则会返回HTTP 404<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GET /my_index/_doc/$&#123;id&#125;                  获取文档</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"更新文档\"><a href=\"#更新文档\" class=\"headerlink\" title=\"更新文档\"></a>更新文档</h2><p>更新的信息必须包含在”doc”中<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">POST /my_index/_update/$&#123;id&#125;/             更新文档</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;doc&quot;:&#123;</span><br><span class=\"line\">        // 要更新的内容</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Bulk-API\"><a href=\"#Bulk-API\" class=\"headerlink\" title=\"Bulk API\"></a>Bulk API</h1><p>每次RESTfulAPI都会进行一次网络开销，如果多次调用会非常损耗性能。</p>\n<p>Bulk API得核心思想就想在一次调用中，进行多种操作。</p>\n<p>支持对一个索引的多种操作，也支持对多个索引的多种操作。</p>\n<ul>\n<li>Index</li>\n<li>Create</li>\n<li>Update</li>\n<li>Delete</li>\n</ul>\n<p>即使单条操作失败，但并不会影响其他的操作。返回结果中包含了每一条的执行结果</p>\n<h1 id=\"批量独取-mget\"><a href=\"#批量独取-mget\" class=\"headerlink\" title=\"批量独取 mget\"></a>批量独取 mget</h1><p>批量独取，同Bulk API类似，都是通过减少网络连接减少对性能的开销。</p>\n<p>只需要提供一细列的index和对应文档ID，就可以一次返回多条文档信息。</p>\n<h1 id=\"批量查询-msearch\"><a href=\"#批量查询-msearch\" class=\"headerlink\" title=\"批量查询 msearch\"></a>批量查询 msearch</h1><p>可以通过一次调用，对不同的索引，进行不同维度的查询。</p>\n<h1 id=\"常见错误返回\"><a href=\"#常见错误返回\" class=\"headerlink\" title=\"常见错误返回\"></a>常见错误返回</h1><table>\n<thead>\n<tr>\n<th>问题/状态码</th>\n<th>原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>无法连接</td>\n<td>网络故障或者集群挂了</td>\n</tr>\n<tr>\n<td>连接无法关闭</td>\n<td>网络故障或者节点出错</td>\n</tr>\n<tr>\n<td>429</td>\n<td>集群过于繁忙</td>\n</tr>\n<tr>\n<td>4XX</td>\n<td>请求格式体有误</td>\n</tr>\n<tr>\n<td>500</td>\n<td>集群内部错误</td>\n</tr>\n</tbody>\n</table>\n","site":{"data":{}},"excerpt":"<p>在学习Elasticsearch相关的api使用中，大多数其实可以通过kibana、cerebro来使用，很方便，但是当通过客户端应用程序连接的时候，其实还是要了解各个RESTfulAPI的细节，方便出现问题排查，所以记录了一下学习的基础API。</p>","more":"<h1 id=\"集群的监控\"><a href=\"#集群的监控\" class=\"headerlink\" title=\"集群的监控\"></a>集群的监控</h1><p>集群应用的相关信息，其实可以通过部署cerebro来查看，但是也是要了解一下相关的RESTfulAPI的。</p>\n<ul>\n<li>GET _cluster/health 查看集群的健康状况</li>\n<li>GET _cat/nodes 查看节点信息</li>\n<li>GET _cat/shards 查看分片信息</li>\n</ul>\n<h1 id=\"文档的CRUD\"><a href=\"#文档的CRUD\" class=\"headerlink\" title=\"文档的CRUD\"></a>文档的CRUD</h1><table>\n<thead>\n<tr>\n<th>操作类型</th>\n<th>RESTfulAPI</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Index</td>\n<td>PUT my_index/_doc/id</td>\n</tr>\n<tr>\n<td>Create</td>\n<td>PUT my_index/_create/id</td>\n</tr>\n<tr>\n<td>Read</td>\n<td>GET my_index/_doc/id</td>\n</tr>\n<tr>\n<td>Update</td>\n<td>POST my_index/_update/id</td>\n</tr>\n<tr>\n<td>Delete</td>\n<td>DELETE my_index/_doc/id</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>Type约定都用_doc</li>\n<li>Create 如果ID已经存在，则会创建失败</li>\n<li>Index 如果ID不存在，创建新的文档，否则，会删除现有的文档，然后创建新的文档，版本号增加</li>\n<li>Update 文档必须已经存在，更新只会更新对应字段做增加修改</li>\n</ul>\n<h2 id=\"创建文档\"><a href=\"#创建文档\" class=\"headerlink\" title=\"创建文档\"></a>创建文档</h2><p>有两种方式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">POST /my_index/_doc                       自动生成ID创建文档</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /my_index/_create/$&#123;id&#125;               指定ID创建文档</span><br></pre></td></tr></table></figure>\n<p>通过index操作，指定操作类型进行创建<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /my_index/_doc/$&#123;id&#125;/?op_type=create  指定ID创建文档</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Index文档\"><a href=\"#Index文档\" class=\"headerlink\" title=\"Index文档\"></a>Index文档</h2><p>如果文档不存在，就会索引新文档，否则，现有的文档会被删除，新的文档被索引，版本信息+1。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">PUT /my_index/_doc/$&#123;id&#125;                  根据ID更新文档，如果不存在则创建文档</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    // 要更新的内容</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"获取文档\"><a href=\"#获取文档\" class=\"headerlink\" title=\"获取文档\"></a>获取文档</h2><p>找到文档会返回HTTP 200，找不到则会返回HTTP 404<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GET /my_index/_doc/$&#123;id&#125;                  获取文档</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"更新文档\"><a href=\"#更新文档\" class=\"headerlink\" title=\"更新文档\"></a>更新文档</h2><p>更新的信息必须包含在”doc”中<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">POST /my_index/_update/$&#123;id&#125;/             更新文档</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;doc&quot;:&#123;</span><br><span class=\"line\">        // 要更新的内容</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Bulk-API\"><a href=\"#Bulk-API\" class=\"headerlink\" title=\"Bulk API\"></a>Bulk API</h1><p>每次RESTfulAPI都会进行一次网络开销，如果多次调用会非常损耗性能。</p>\n<p>Bulk API得核心思想就想在一次调用中，进行多种操作。</p>\n<p>支持对一个索引的多种操作，也支持对多个索引的多种操作。</p>\n<ul>\n<li>Index</li>\n<li>Create</li>\n<li>Update</li>\n<li>Delete</li>\n</ul>\n<p>即使单条操作失败，但并不会影响其他的操作。返回结果中包含了每一条的执行结果</p>\n<h1 id=\"批量独取-mget\"><a href=\"#批量独取-mget\" class=\"headerlink\" title=\"批量独取 mget\"></a>批量独取 mget</h1><p>批量独取，同Bulk API类似，都是通过减少网络连接减少对性能的开销。</p>\n<p>只需要提供一细列的index和对应文档ID，就可以一次返回多条文档信息。</p>\n<h1 id=\"批量查询-msearch\"><a href=\"#批量查询-msearch\" class=\"headerlink\" title=\"批量查询 msearch\"></a>批量查询 msearch</h1><p>可以通过一次调用，对不同的索引，进行不同维度的查询。</p>\n<h1 id=\"常见错误返回\"><a href=\"#常见错误返回\" class=\"headerlink\" title=\"常见错误返回\"></a>常见错误返回</h1><table>\n<thead>\n<tr>\n<th>问题/状态码</th>\n<th>原因</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>无法连接</td>\n<td>网络故障或者集群挂了</td>\n</tr>\n<tr>\n<td>连接无法关闭</td>\n<td>网络故障或者节点出错</td>\n</tr>\n<tr>\n<td>429</td>\n<td>集群过于繁忙</td>\n</tr>\n<tr>\n<td>4XX</td>\n<td>请求格式体有误</td>\n</tr>\n<tr>\n<td>500</td>\n<td>集群内部错误</td>\n</tr>\n</tbody>\n</table>"},{"title":"dockerfile 实践总结","date":"2019-09-24T02:00:00.000Z","_content":"\n> 最近工作比较忙，出差在外一直没有学习。学习了dockerfile的指令和编写，参考书中内容做了一些dockerfile的实践总结\n\n<!-- more -->\n首先要从实际的需求出发，定制适合应用、高校方便的镜像。\n\n要熟悉每个指令的含义和执行效果，多编写一些简单的demo进行测试，然后再编写正式的dockerfile。\n\ndocker hub官方仓库中提供了大量的优秀镜像和对应的dockerfie，就像是阅读源码一样，学习如何撰写高效的dockerfile。\n\n可以再编写dockerfile制作镜像过程中，从下面几个角度进行思考：\n\n## 精简镜像用途\n尽量让每个镜像的用途都比较集中、单一，避免构造大而复杂、多功能的镜像；\n\n## 选用合适的基础镜像\n过大的基础镜像会造成生成臃肿的镜像，一般推荐较为小巧的debian镜像；\n\n## 提供足够清晰的命令注释和维护者信息\nDockerfile也是一种代码，需要考虑方便后续扩展和他人使用；\n\n## 正确使用版本号\n使用明确的版本号信息，如1.0，2.0，而非latest，将避免内容不一致可能引发的惨案；\n\n## 减少镜像层数\n如果希望所生成镜像的层数尽量少，则要尽量合并指令，例如多个RUN指令可以合并为一条；\n\n## 及时删除临时文件和缓存文件\n特别是在执行apt-get指令后，/var/cache/apt下面会缓存一些安装包；\n\n## 提高生成速度\n如合理使用缓存，减少内容目录下的文件，或使用.dockerignore文件指定等；\n\n## 调整合理的指令顺序\n在开启缓存的情况下，内容不变的指令尽量放在前面，这样可以尽量复用；\n\n## 减少外部源的干扰 \n如果确实要从外部引入数据，需要指定持久的地址，并带有版本信息，让他人可以重复而不出错。","source":"_posts/docker_10_dockerfile.md","raw":"---\ntitle: dockerfile 实践总结\ndate: 2019-09-24 10:00:00\ntags: docker\ncategories: DevOps\n---\n\n> 最近工作比较忙，出差在外一直没有学习。学习了dockerfile的指令和编写，参考书中内容做了一些dockerfile的实践总结\n\n<!-- more -->\n首先要从实际的需求出发，定制适合应用、高校方便的镜像。\n\n要熟悉每个指令的含义和执行效果，多编写一些简单的demo进行测试，然后再编写正式的dockerfile。\n\ndocker hub官方仓库中提供了大量的优秀镜像和对应的dockerfie，就像是阅读源码一样，学习如何撰写高效的dockerfile。\n\n可以再编写dockerfile制作镜像过程中，从下面几个角度进行思考：\n\n## 精简镜像用途\n尽量让每个镜像的用途都比较集中、单一，避免构造大而复杂、多功能的镜像；\n\n## 选用合适的基础镜像\n过大的基础镜像会造成生成臃肿的镜像，一般推荐较为小巧的debian镜像；\n\n## 提供足够清晰的命令注释和维护者信息\nDockerfile也是一种代码，需要考虑方便后续扩展和他人使用；\n\n## 正确使用版本号\n使用明确的版本号信息，如1.0，2.0，而非latest，将避免内容不一致可能引发的惨案；\n\n## 减少镜像层数\n如果希望所生成镜像的层数尽量少，则要尽量合并指令，例如多个RUN指令可以合并为一条；\n\n## 及时删除临时文件和缓存文件\n特别是在执行apt-get指令后，/var/cache/apt下面会缓存一些安装包；\n\n## 提高生成速度\n如合理使用缓存，减少内容目录下的文件，或使用.dockerignore文件指定等；\n\n## 调整合理的指令顺序\n在开启缓存的情况下，内容不变的指令尽量放在前面，这样可以尽量复用；\n\n## 减少外部源的干扰 \n如果确实要从外部引入数据，需要指定持久的地址，并带有版本信息，让他人可以重复而不出错。","slug":"docker_10_dockerfile","published":1,"updated":"2019-12-11T13:26:28.521Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0j001hqotn2ctum201","content":"<blockquote>\n<p>最近工作比较忙，出差在外一直没有学习。学习了dockerfile的指令和编写，参考书中内容做了一些dockerfile的实践总结</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>首先要从实际的需求出发，定制适合应用、高校方便的镜像。</p>\n<p>要熟悉每个指令的含义和执行效果，多编写一些简单的demo进行测试，然后再编写正式的dockerfile。</p>\n<p>docker hub官方仓库中提供了大量的优秀镜像和对应的dockerfie，就像是阅读源码一样，学习如何撰写高效的dockerfile。</p>\n<p>可以再编写dockerfile制作镜像过程中，从下面几个角度进行思考：</p>\n<h2 id=\"精简镜像用途\"><a href=\"#精简镜像用途\" class=\"headerlink\" title=\"精简镜像用途\"></a>精简镜像用途</h2><p>尽量让每个镜像的用途都比较集中、单一，避免构造大而复杂、多功能的镜像；</p>\n<h2 id=\"选用合适的基础镜像\"><a href=\"#选用合适的基础镜像\" class=\"headerlink\" title=\"选用合适的基础镜像\"></a>选用合适的基础镜像</h2><p>过大的基础镜像会造成生成臃肿的镜像，一般推荐较为小巧的debian镜像；</p>\n<h2 id=\"提供足够清晰的命令注释和维护者信息\"><a href=\"#提供足够清晰的命令注释和维护者信息\" class=\"headerlink\" title=\"提供足够清晰的命令注释和维护者信息\"></a>提供足够清晰的命令注释和维护者信息</h2><p>Dockerfile也是一种代码，需要考虑方便后续扩展和他人使用；</p>\n<h2 id=\"正确使用版本号\"><a href=\"#正确使用版本号\" class=\"headerlink\" title=\"正确使用版本号\"></a>正确使用版本号</h2><p>使用明确的版本号信息，如1.0，2.0，而非latest，将避免内容不一致可能引发的惨案；</p>\n<h2 id=\"减少镜像层数\"><a href=\"#减少镜像层数\" class=\"headerlink\" title=\"减少镜像层数\"></a>减少镜像层数</h2><p>如果希望所生成镜像的层数尽量少，则要尽量合并指令，例如多个RUN指令可以合并为一条；</p>\n<h2 id=\"及时删除临时文件和缓存文件\"><a href=\"#及时删除临时文件和缓存文件\" class=\"headerlink\" title=\"及时删除临时文件和缓存文件\"></a>及时删除临时文件和缓存文件</h2><p>特别是在执行apt-get指令后，/var/cache/apt下面会缓存一些安装包；</p>\n<h2 id=\"提高生成速度\"><a href=\"#提高生成速度\" class=\"headerlink\" title=\"提高生成速度\"></a>提高生成速度</h2><p>如合理使用缓存，减少内容目录下的文件，或使用.dockerignore文件指定等；</p>\n<h2 id=\"调整合理的指令顺序\"><a href=\"#调整合理的指令顺序\" class=\"headerlink\" title=\"调整合理的指令顺序\"></a>调整合理的指令顺序</h2><p>在开启缓存的情况下，内容不变的指令尽量放在前面，这样可以尽量复用；</p>\n<h2 id=\"减少外部源的干扰\"><a href=\"#减少外部源的干扰\" class=\"headerlink\" title=\"减少外部源的干扰\"></a>减少外部源的干扰</h2><p>如果确实要从外部引入数据，需要指定持久的地址，并带有版本信息，让他人可以重复而不出错。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>最近工作比较忙，出差在外一直没有学习。学习了dockerfile的指令和编写，参考书中内容做了一些dockerfile的实践总结</p>\n</blockquote>","more":"<p>首先要从实际的需求出发，定制适合应用、高校方便的镜像。</p>\n<p>要熟悉每个指令的含义和执行效果，多编写一些简单的demo进行测试，然后再编写正式的dockerfile。</p>\n<p>docker hub官方仓库中提供了大量的优秀镜像和对应的dockerfie，就像是阅读源码一样，学习如何撰写高效的dockerfile。</p>\n<p>可以再编写dockerfile制作镜像过程中，从下面几个角度进行思考：</p>\n<h2 id=\"精简镜像用途\"><a href=\"#精简镜像用途\" class=\"headerlink\" title=\"精简镜像用途\"></a>精简镜像用途</h2><p>尽量让每个镜像的用途都比较集中、单一，避免构造大而复杂、多功能的镜像；</p>\n<h2 id=\"选用合适的基础镜像\"><a href=\"#选用合适的基础镜像\" class=\"headerlink\" title=\"选用合适的基础镜像\"></a>选用合适的基础镜像</h2><p>过大的基础镜像会造成生成臃肿的镜像，一般推荐较为小巧的debian镜像；</p>\n<h2 id=\"提供足够清晰的命令注释和维护者信息\"><a href=\"#提供足够清晰的命令注释和维护者信息\" class=\"headerlink\" title=\"提供足够清晰的命令注释和维护者信息\"></a>提供足够清晰的命令注释和维护者信息</h2><p>Dockerfile也是一种代码，需要考虑方便后续扩展和他人使用；</p>\n<h2 id=\"正确使用版本号\"><a href=\"#正确使用版本号\" class=\"headerlink\" title=\"正确使用版本号\"></a>正确使用版本号</h2><p>使用明确的版本号信息，如1.0，2.0，而非latest，将避免内容不一致可能引发的惨案；</p>\n<h2 id=\"减少镜像层数\"><a href=\"#减少镜像层数\" class=\"headerlink\" title=\"减少镜像层数\"></a>减少镜像层数</h2><p>如果希望所生成镜像的层数尽量少，则要尽量合并指令，例如多个RUN指令可以合并为一条；</p>\n<h2 id=\"及时删除临时文件和缓存文件\"><a href=\"#及时删除临时文件和缓存文件\" class=\"headerlink\" title=\"及时删除临时文件和缓存文件\"></a>及时删除临时文件和缓存文件</h2><p>特别是在执行apt-get指令后，/var/cache/apt下面会缓存一些安装包；</p>\n<h2 id=\"提高生成速度\"><a href=\"#提高生成速度\" class=\"headerlink\" title=\"提高生成速度\"></a>提高生成速度</h2><p>如合理使用缓存，减少内容目录下的文件，或使用.dockerignore文件指定等；</p>\n<h2 id=\"调整合理的指令顺序\"><a href=\"#调整合理的指令顺序\" class=\"headerlink\" title=\"调整合理的指令顺序\"></a>调整合理的指令顺序</h2><p>在开启缓存的情况下，内容不变的指令尽量放在前面，这样可以尽量复用；</p>\n<h2 id=\"减少外部源的干扰\"><a href=\"#减少外部源的干扰\" class=\"headerlink\" title=\"减少外部源的干扰\"></a>减少外部源的干扰</h2><p>如果确实要从外部引入数据，需要指定持久的地址，并带有版本信息，让他人可以重复而不出错。</p>"},{"title":"redis基础指令","date":"2019-03-11T02:00:00.000Z","_content":"\n学习一些基础指令\n\n<!-- more -->\n\n# string\n- get\n- set\n- exists 是否存在\n- del\n- mget\n\n失效时间设置\n- EXPIRE key seconds为给定 key 设置过期时间，以秒计。\n- EXPIREAT key timestamp EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。\n- PEXPIRE key milliseconds 设置 key 的过期时间以毫秒计。\n\n- PERSIST key 移除 key 的过期时间，key 将持久保持。\n- PTTL key 以毫秒为单位返回 key 的剩余的过期时间。\n- TTL key 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。\n\n- setex key s value 相当于set+expire\n- setnx key value 如果key不存在就执行set\n\n# 原子计数\n- set key num\n- incr key +1\n- decr key -1\n- incrby key num +num\n范围 signed long\n\n\n# 列表 list链表，插入删除O(1)，查询慢o(n)\n队列 进先出(FIFO-first in first out):\n> <- x,x,x <-\n- rpush key val1 val2 vals\n- llen key\n- lpop key\n\n栈 后进先出(LIFO-last in first out):\n> x,x,x <=>\n- rpush key val1 val2 vals\n- rpop\n\n# Hash\n- hset key field1 value1\n- hget key field1\n- hgetall key 查看全部属性、值\n- hmset key field1 val1 field2 val2 \n\n# set\n- sadd key value\n- smembers key\n- sismember key value 是否存在\n- scard key 获取长度\n- spop key\n\n\n# zset\n\n\n# keys\n- KEYS pattern\n- scan 游标 match 表达式 count 数量\n\n\n# redis服务信息\n- info 查看redis服务运行信息，server、client、memory、persistence 状态 主从复制信息 cpu 集群信息，键值对数据统计\n...\n","source":"_posts/redis_01_基础指令.md","raw":"---\ntitle: redis基础指令\ndate: 2019-03-11 10:00:00\ntags: redis\ncategories: 中间件\n---\n\n学习一些基础指令\n\n<!-- more -->\n\n# string\n- get\n- set\n- exists 是否存在\n- del\n- mget\n\n失效时间设置\n- EXPIRE key seconds为给定 key 设置过期时间，以秒计。\n- EXPIREAT key timestamp EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。\n- PEXPIRE key milliseconds 设置 key 的过期时间以毫秒计。\n\n- PERSIST key 移除 key 的过期时间，key 将持久保持。\n- PTTL key 以毫秒为单位返回 key 的剩余的过期时间。\n- TTL key 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。\n\n- setex key s value 相当于set+expire\n- setnx key value 如果key不存在就执行set\n\n# 原子计数\n- set key num\n- incr key +1\n- decr key -1\n- incrby key num +num\n范围 signed long\n\n\n# 列表 list链表，插入删除O(1)，查询慢o(n)\n队列 进先出(FIFO-first in first out):\n> <- x,x,x <-\n- rpush key val1 val2 vals\n- llen key\n- lpop key\n\n栈 后进先出(LIFO-last in first out):\n> x,x,x <=>\n- rpush key val1 val2 vals\n- rpop\n\n# Hash\n- hset key field1 value1\n- hget key field1\n- hgetall key 查看全部属性、值\n- hmset key field1 val1 field2 val2 \n\n# set\n- sadd key value\n- smembers key\n- sismember key value 是否存在\n- scard key 获取长度\n- spop key\n\n\n# zset\n\n\n# keys\n- KEYS pattern\n- scan 游标 match 表达式 count 数量\n\n\n# redis服务信息\n- info 查看redis服务运行信息，server、client、memory、persistence 状态 主从复制信息 cpu 集群信息，键值对数据统计\n...\n","slug":"redis_01_基础指令","published":1,"updated":"2020-05-14T09:17:37.598Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0m001lqotn2s9rf7sf","content":"<p>学习一些基础指令</p>\n<a id=\"more\"></a>\n<h1 id=\"string\"><a href=\"#string\" class=\"headerlink\" title=\"string\"></a>string</h1><ul>\n<li>get</li>\n<li>set</li>\n<li>exists 是否存在</li>\n<li>del</li>\n<li>mget</li>\n</ul>\n<p>失效时间设置</p>\n<ul>\n<li>EXPIRE key seconds为给定 key 设置过期时间，以秒计。</li>\n<li>EXPIREAT key timestamp EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。</li>\n<li><p>PEXPIRE key milliseconds 设置 key 的过期时间以毫秒计。</p>\n</li>\n<li><p>PERSIST key 移除 key 的过期时间，key 将持久保持。</p>\n</li>\n<li>PTTL key 以毫秒为单位返回 key 的剩余的过期时间。</li>\n<li><p>TTL key 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。</p>\n</li>\n<li><p>setex key s value 相当于set+expire</p>\n</li>\n<li>setnx key value 如果key不存在就执行set</li>\n</ul>\n<h1 id=\"原子计数\"><a href=\"#原子计数\" class=\"headerlink\" title=\"原子计数\"></a>原子计数</h1><ul>\n<li>set key num</li>\n<li>incr key +1</li>\n<li>decr key -1</li>\n<li>incrby key num +num<br>范围 signed long</li>\n</ul>\n<h1 id=\"列表-list链表，插入删除O-1-，查询慢o-n\"><a href=\"#列表-list链表，插入删除O-1-，查询慢o-n\" class=\"headerlink\" title=\"列表 list链表，插入删除O(1)，查询慢o(n)\"></a>列表 list链表，插入删除O(1)，查询慢o(n)</h1><p>队列 进先出(FIFO-first in first out):</p>\n<blockquote>\n<p>&lt;- x,x,x &lt;-</p>\n<ul>\n<li>rpush key val1 val2 vals</li>\n<li>llen key</li>\n<li>lpop key</li>\n</ul>\n</blockquote>\n<p>栈 后进先出(LIFO-last in first out):</p>\n<blockquote>\n<p>x,x,x &lt;=&gt;</p>\n<ul>\n<li>rpush key val1 val2 vals</li>\n<li>rpop</li>\n</ul>\n</blockquote>\n<h1 id=\"Hash\"><a href=\"#Hash\" class=\"headerlink\" title=\"Hash\"></a>Hash</h1><ul>\n<li>hset key field1 value1</li>\n<li>hget key field1</li>\n<li>hgetall key 查看全部属性、值</li>\n<li>hmset key field1 val1 field2 val2 </li>\n</ul>\n<h1 id=\"set\"><a href=\"#set\" class=\"headerlink\" title=\"set\"></a>set</h1><ul>\n<li>sadd key value</li>\n<li>smembers key</li>\n<li>sismember key value 是否存在</li>\n<li>scard key 获取长度</li>\n<li>spop key</li>\n</ul>\n<h1 id=\"zset\"><a href=\"#zset\" class=\"headerlink\" title=\"zset\"></a>zset</h1><h1 id=\"keys\"><a href=\"#keys\" class=\"headerlink\" title=\"keys\"></a>keys</h1><ul>\n<li>KEYS pattern</li>\n<li>scan 游标 match 表达式 count 数量</li>\n</ul>\n<h1 id=\"redis服务信息\"><a href=\"#redis服务信息\" class=\"headerlink\" title=\"redis服务信息\"></a>redis服务信息</h1><ul>\n<li>info 查看redis服务运行信息，server、client、memory、persistence 状态 主从复制信息 cpu 集群信息，键值对数据统计<br>…</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>学习一些基础指令</p>","more":"<h1 id=\"string\"><a href=\"#string\" class=\"headerlink\" title=\"string\"></a>string</h1><ul>\n<li>get</li>\n<li>set</li>\n<li>exists 是否存在</li>\n<li>del</li>\n<li>mget</li>\n</ul>\n<p>失效时间设置</p>\n<ul>\n<li>EXPIRE key seconds为给定 key 设置过期时间，以秒计。</li>\n<li>EXPIREAT key timestamp EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。</li>\n<li><p>PEXPIRE key milliseconds 设置 key 的过期时间以毫秒计。</p>\n</li>\n<li><p>PERSIST key 移除 key 的过期时间，key 将持久保持。</p>\n</li>\n<li>PTTL key 以毫秒为单位返回 key 的剩余的过期时间。</li>\n<li><p>TTL key 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。</p>\n</li>\n<li><p>setex key s value 相当于set+expire</p>\n</li>\n<li>setnx key value 如果key不存在就执行set</li>\n</ul>\n<h1 id=\"原子计数\"><a href=\"#原子计数\" class=\"headerlink\" title=\"原子计数\"></a>原子计数</h1><ul>\n<li>set key num</li>\n<li>incr key +1</li>\n<li>decr key -1</li>\n<li>incrby key num +num<br>范围 signed long</li>\n</ul>\n<h1 id=\"列表-list链表，插入删除O-1-，查询慢o-n\"><a href=\"#列表-list链表，插入删除O-1-，查询慢o-n\" class=\"headerlink\" title=\"列表 list链表，插入删除O(1)，查询慢o(n)\"></a>列表 list链表，插入删除O(1)，查询慢o(n)</h1><p>队列 进先出(FIFO-first in first out):</p>\n<blockquote>\n<p>&lt;- x,x,x &lt;-</p>\n<ul>\n<li>rpush key val1 val2 vals</li>\n<li>llen key</li>\n<li>lpop key</li>\n</ul>\n</blockquote>\n<p>栈 后进先出(LIFO-last in first out):</p>\n<blockquote>\n<p>x,x,x &lt;=&gt;</p>\n<ul>\n<li>rpush key val1 val2 vals</li>\n<li>rpop</li>\n</ul>\n</blockquote>\n<h1 id=\"Hash\"><a href=\"#Hash\" class=\"headerlink\" title=\"Hash\"></a>Hash</h1><ul>\n<li>hset key field1 value1</li>\n<li>hget key field1</li>\n<li>hgetall key 查看全部属性、值</li>\n<li>hmset key field1 val1 field2 val2 </li>\n</ul>\n<h1 id=\"set\"><a href=\"#set\" class=\"headerlink\" title=\"set\"></a>set</h1><ul>\n<li>sadd key value</li>\n<li>smembers key</li>\n<li>sismember key value 是否存在</li>\n<li>scard key 获取长度</li>\n<li>spop key</li>\n</ul>\n<h1 id=\"zset\"><a href=\"#zset\" class=\"headerlink\" title=\"zset\"></a>zset</h1><h1 id=\"keys\"><a href=\"#keys\" class=\"headerlink\" title=\"keys\"></a>keys</h1><ul>\n<li>KEYS pattern</li>\n<li>scan 游标 match 表达式 count 数量</li>\n</ul>\n<h1 id=\"redis服务信息\"><a href=\"#redis服务信息\" class=\"headerlink\" title=\"redis服务信息\"></a>redis服务信息</h1><ul>\n<li>info 查看redis服务运行信息，server、client、memory、persistence 状态 主从复制信息 cpu 集群信息，键值对数据统计<br>…</li>\n</ul>"},{"title":"redis持久化、淘汰策略、高可用方案的基础","date":"2020-03-12T02:00:00.000Z","_content":"\n学习一些redis的进阶知识基础\n<!-- more -->\n\n3.x\n4.x ruby \n5.0 C语言 集群配置等更简单\n\n\n# 持久化\n## RDB快照 snapshop\ndump.rdb二进制文件保存\n\nredis.conf中，save seconds changes进行配置，设置为save \"\"则为关闭\n\n## AOF append-only file\nredis.conf中\n- appendonly no 修改为yes开启\n- appendfilename 默认appendonly.aof，保存的都是命令 resp协议 \n- appendfsync 持久化方式和频率\n    - always 每次新命令都追加到AOF文件时候执行一次fsync，效率低，数据安全\n    - everysec 每秒fsync一次\n    - no 从不fsync\n\nRDB可能会存在数据丢失\nAOF大数据量恢复速度相比RDB要慢\n\nAOF rewirte重写\n- bgrewriteaof 手动触发重写指令\n\n- auto-aof-rewrite-percentage 100 AOF自动重写百分比\n- auto-aof-rewrite-min-size 64mb AOF自动重写最小容量\n\n\n### 4.0后支持混合持久化\naof-use-rdb-preamble yes\nappendonly.aof文件中记录的RDB格式 + AOF格式\n\n如果RDB和AOF都开启，默认会使用AOF进行数据恢复\n\n\n# 缓存淘汰策略\n当redis内存超过物理内存限制的时候，内存数据会开始与磁盘产生频繁的交换(swap)，由于涉及到磁盘IO操作，redis的性能会急剧下降。\n\n当实际内存超出maxmemory时，redis提供了几种可选策略(maxmemory-policy)来让来决定该如何调整出新的空间继续提供读写服务\n- LRU（Least Recently Used，最近最少使用）\n- LFU（Least Frequently Used ，最不频繁使用）\n\n- volatile 设置了失效时间\n- allkeys 全部key\n```\n# volatile-lru -> Evict using approximated LRU among the keys with an expire set.\n# allkeys-lru -> Evict any key using approximated LRU.\n# volatile-lfu -> Evict using approximated LFU among the keys with an expire set.\n# allkeys-lfu -> Evict any key using approximated LFU.\n# volatile-random -> Remove a random key among the ones with an expire set.\n# allkeys-random -> Remove a random key, any key.\n# volatile-ttl -> Remove the key with the nearest expire time (minor TTL)\n# noeviction -> Don't evict anything, just return an error on write operations.\n```\n\n# 高可用\n## Redis Sentinel(哨兵模式)\n由若干sentinel节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。sentinel的节点数量要满足2n+1(n>=1)个的奇数个。\n\n两个集群在同时工作，一个是sentinel集群，一个是数据节点的集群(master-slave)\n\n客户端会先连接一个sentinel实例，使用SENTINEL get-master-addr-by-name master-name 获取Redis地址信息。连接返回的Redis地址信息，通过ROLE命令查询是否是Master。如果是，连接进入正常的服务环节。否则应该断开重新查询。\n\n配置文件sentinel.conf\n- min-slaves-to-write 1\n- min-slaves-max-lag 10\n\n## Redis Cluster(集群模式)\nredis官方提供的新的集群配置。由多个主从节点群组成的分布式服务群，具有复制、高可用、分片的特性。不需要sentinel哨兵也能完成节点的移除和故障转移的功能。\n\n至少要有三个Master节点\n\n修改配置文件\n- cluster-enabled yes 启动集群模式\n- cluster-config-file 集群节点配置文件\n- cluster-node-timeout ms 集群节点的超时时间\n- 去除客户端访问 # bind 127.0.0.1\n- protected-mode no 关闭保护模式\n需要密码则配置\n- requirepass xxx 设置密码\n- masterauth xxx 集群通信设置master密码\n\n4.0用/src/redis-trib.rb 一个ruby脚本，5.0使用redis-cli --cluster就可以配置集群了\n\n\n```\n[root@iZwz9bvlfc3n574x9ygoj9Z /root/redis-5.0.3]$./src/redis-cli --cluster help\nCluster Manager Commands:\n  create         host1:port1 ... hostN:portN\n                 --cluster-replicas <arg>\n  check          host:port\n                 --cluster-search-multiple-owners\n  info           host:port\n  fix            host:port\n                 --cluster-search-multiple-owners\n  reshard        host:port\n                 --cluster-from <arg>\n                 --cluster-to <arg>\n                 --cluster-slots <arg>\n                 --cluster-yes\n                 --cluster-timeout <arg>\n                 --cluster-pipeline <arg>\n                 --cluster-replace\n  rebalance      host:port\n                 --cluster-weight <node1=w1...nodeN=wN>\n                 --cluster-use-empty-masters\n                 --cluster-timeout <arg>\n                 --cluster-simulate\n                 --cluster-pipeline <arg>\n                 --cluster-threshold <arg>\n                 --cluster-replace\n  add-node       new_host:new_port existing_host:existing_port\n                 --cluster-slave\n                 --cluster-master-id <arg>\n  del-node       host:port node_id\n  call           host:port command arg arg .. arg\n  set-timeout    host:port milliseconds\n  import         host:port\n                 --cluster-from <arg>\n                 --cluster-copy\n                 --cluster-replace\n  help\n\nFor check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster.\n\n```\n\n常用详解\n- redis-cli -a 输入启动节点的密码\n- create \n    - ip:prot ipN:protN\n    - --cluster-replicas 复制因子，每个主从节点的比例\n\n访问集群模式\n- /src/redis-cli -a xxx -c -h host -p port\n- cluster info 查询集群信息\n- cluster nodes 查看集群各个节点信息\n\n\n> HASH_CLOT = CRC16(key)mod 16384\n \n> 共16384 sloat\n\n\n### 添加节点（水平扩展）\n- add-node 添加节点\n- reshard host:port 重新分片\n\n### 删除节点\n- reshard 将分配的sloat分配到其他可用主节点中\n- del-node\n- rebalance 集群内部做迁移，可以设置节点的权重（weight），迁移过程中sloat都会阻塞\n\n## 集群选举原理\n当Slave发现自己的Master变成FAIL状态时，便尝试进行Fallover，以聘成为新的Master。由于挂掉的Master可能会有多个Slave，从而存在多个Slave竞争的过程，其过程如下：\n1. slave发现自己的Master变为FAIL\n2. 将自己记录的集群CurrentEpoch加1，并广播FAILOVER_AUTH_REQUEST信息\n3. 其他节点收到该信息，只有Master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ACK\n4. 尝试FAILOVER的Slave收集FAILOVER_AUTH_ACK\n5. 超过半数后变成新的Master\n6. 广播Pong通知其他集群节点\n\n从节点并不是在主节点一进入FAIL状态就马上尝试发起选举的，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，Slave如果立即尝试选举或许尚未意识到FAIL状态，可能会拒绝投票\n\n延迟计算公式：\n```\nDELAY = 500ms + random(0 -500ms) + SLAVE_RANK + 1000ms\n```\n- SLAVE_RANK表示此Slave已经从Master复制数据的总量的Rank。Rank越小代表已复制的数据越新，持有最新数据的Slave将会首先发起选举。","source":"_posts/redis_02_进阶基础.md","raw":"---\ntitle: redis持久化、淘汰策略、高可用方案的基础\ndate: 2020-03-12 10:00:00\ntags: redis\ncategories: 中间件\n---\n\n学习一些redis的进阶知识基础\n<!-- more -->\n\n3.x\n4.x ruby \n5.0 C语言 集群配置等更简单\n\n\n# 持久化\n## RDB快照 snapshop\ndump.rdb二进制文件保存\n\nredis.conf中，save seconds changes进行配置，设置为save \"\"则为关闭\n\n## AOF append-only file\nredis.conf中\n- appendonly no 修改为yes开启\n- appendfilename 默认appendonly.aof，保存的都是命令 resp协议 \n- appendfsync 持久化方式和频率\n    - always 每次新命令都追加到AOF文件时候执行一次fsync，效率低，数据安全\n    - everysec 每秒fsync一次\n    - no 从不fsync\n\nRDB可能会存在数据丢失\nAOF大数据量恢复速度相比RDB要慢\n\nAOF rewirte重写\n- bgrewriteaof 手动触发重写指令\n\n- auto-aof-rewrite-percentage 100 AOF自动重写百分比\n- auto-aof-rewrite-min-size 64mb AOF自动重写最小容量\n\n\n### 4.0后支持混合持久化\naof-use-rdb-preamble yes\nappendonly.aof文件中记录的RDB格式 + AOF格式\n\n如果RDB和AOF都开启，默认会使用AOF进行数据恢复\n\n\n# 缓存淘汰策略\n当redis内存超过物理内存限制的时候，内存数据会开始与磁盘产生频繁的交换(swap)，由于涉及到磁盘IO操作，redis的性能会急剧下降。\n\n当实际内存超出maxmemory时，redis提供了几种可选策略(maxmemory-policy)来让来决定该如何调整出新的空间继续提供读写服务\n- LRU（Least Recently Used，最近最少使用）\n- LFU（Least Frequently Used ，最不频繁使用）\n\n- volatile 设置了失效时间\n- allkeys 全部key\n```\n# volatile-lru -> Evict using approximated LRU among the keys with an expire set.\n# allkeys-lru -> Evict any key using approximated LRU.\n# volatile-lfu -> Evict using approximated LFU among the keys with an expire set.\n# allkeys-lfu -> Evict any key using approximated LFU.\n# volatile-random -> Remove a random key among the ones with an expire set.\n# allkeys-random -> Remove a random key, any key.\n# volatile-ttl -> Remove the key with the nearest expire time (minor TTL)\n# noeviction -> Don't evict anything, just return an error on write operations.\n```\n\n# 高可用\n## Redis Sentinel(哨兵模式)\n由若干sentinel节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。sentinel的节点数量要满足2n+1(n>=1)个的奇数个。\n\n两个集群在同时工作，一个是sentinel集群，一个是数据节点的集群(master-slave)\n\n客户端会先连接一个sentinel实例，使用SENTINEL get-master-addr-by-name master-name 获取Redis地址信息。连接返回的Redis地址信息，通过ROLE命令查询是否是Master。如果是，连接进入正常的服务环节。否则应该断开重新查询。\n\n配置文件sentinel.conf\n- min-slaves-to-write 1\n- min-slaves-max-lag 10\n\n## Redis Cluster(集群模式)\nredis官方提供的新的集群配置。由多个主从节点群组成的分布式服务群，具有复制、高可用、分片的特性。不需要sentinel哨兵也能完成节点的移除和故障转移的功能。\n\n至少要有三个Master节点\n\n修改配置文件\n- cluster-enabled yes 启动集群模式\n- cluster-config-file 集群节点配置文件\n- cluster-node-timeout ms 集群节点的超时时间\n- 去除客户端访问 # bind 127.0.0.1\n- protected-mode no 关闭保护模式\n需要密码则配置\n- requirepass xxx 设置密码\n- masterauth xxx 集群通信设置master密码\n\n4.0用/src/redis-trib.rb 一个ruby脚本，5.0使用redis-cli --cluster就可以配置集群了\n\n\n```\n[root@iZwz9bvlfc3n574x9ygoj9Z /root/redis-5.0.3]$./src/redis-cli --cluster help\nCluster Manager Commands:\n  create         host1:port1 ... hostN:portN\n                 --cluster-replicas <arg>\n  check          host:port\n                 --cluster-search-multiple-owners\n  info           host:port\n  fix            host:port\n                 --cluster-search-multiple-owners\n  reshard        host:port\n                 --cluster-from <arg>\n                 --cluster-to <arg>\n                 --cluster-slots <arg>\n                 --cluster-yes\n                 --cluster-timeout <arg>\n                 --cluster-pipeline <arg>\n                 --cluster-replace\n  rebalance      host:port\n                 --cluster-weight <node1=w1...nodeN=wN>\n                 --cluster-use-empty-masters\n                 --cluster-timeout <arg>\n                 --cluster-simulate\n                 --cluster-pipeline <arg>\n                 --cluster-threshold <arg>\n                 --cluster-replace\n  add-node       new_host:new_port existing_host:existing_port\n                 --cluster-slave\n                 --cluster-master-id <arg>\n  del-node       host:port node_id\n  call           host:port command arg arg .. arg\n  set-timeout    host:port milliseconds\n  import         host:port\n                 --cluster-from <arg>\n                 --cluster-copy\n                 --cluster-replace\n  help\n\nFor check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster.\n\n```\n\n常用详解\n- redis-cli -a 输入启动节点的密码\n- create \n    - ip:prot ipN:protN\n    - --cluster-replicas 复制因子，每个主从节点的比例\n\n访问集群模式\n- /src/redis-cli -a xxx -c -h host -p port\n- cluster info 查询集群信息\n- cluster nodes 查看集群各个节点信息\n\n\n> HASH_CLOT = CRC16(key)mod 16384\n \n> 共16384 sloat\n\n\n### 添加节点（水平扩展）\n- add-node 添加节点\n- reshard host:port 重新分片\n\n### 删除节点\n- reshard 将分配的sloat分配到其他可用主节点中\n- del-node\n- rebalance 集群内部做迁移，可以设置节点的权重（weight），迁移过程中sloat都会阻塞\n\n## 集群选举原理\n当Slave发现自己的Master变成FAIL状态时，便尝试进行Fallover，以聘成为新的Master。由于挂掉的Master可能会有多个Slave，从而存在多个Slave竞争的过程，其过程如下：\n1. slave发现自己的Master变为FAIL\n2. 将自己记录的集群CurrentEpoch加1，并广播FAILOVER_AUTH_REQUEST信息\n3. 其他节点收到该信息，只有Master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ACK\n4. 尝试FAILOVER的Slave收集FAILOVER_AUTH_ACK\n5. 超过半数后变成新的Master\n6. 广播Pong通知其他集群节点\n\n从节点并不是在主节点一进入FAIL状态就马上尝试发起选举的，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，Slave如果立即尝试选举或许尚未意识到FAIL状态，可能会拒绝投票\n\n延迟计算公式：\n```\nDELAY = 500ms + random(0 -500ms) + SLAVE_RANK + 1000ms\n```\n- SLAVE_RANK表示此Slave已经从Master复制数据的总量的Rank。Rank越小代表已复制的数据越新，持有最新数据的Slave将会首先发起选举。","slug":"redis_02_进阶基础","published":1,"updated":"2020-05-12T22:32:06.140Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0o001nqotnefhc4osw","content":"<p>学习一些redis的进阶知识基础<br><a id=\"more\"></a></p>\n<p>3.x<br>4.x ruby<br>5.0 C语言 集群配置等更简单</p>\n<h1 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h1><h2 id=\"RDB快照-snapshop\"><a href=\"#RDB快照-snapshop\" class=\"headerlink\" title=\"RDB快照 snapshop\"></a>RDB快照 snapshop</h2><p>dump.rdb二进制文件保存</p>\n<p>redis.conf中，save seconds changes进行配置，设置为save “”则为关闭</p>\n<h2 id=\"AOF-append-only-file\"><a href=\"#AOF-append-only-file\" class=\"headerlink\" title=\"AOF append-only file\"></a>AOF append-only file</h2><p>redis.conf中</p>\n<ul>\n<li>appendonly no 修改为yes开启</li>\n<li>appendfilename 默认appendonly.aof，保存的都是命令 resp协议 </li>\n<li>appendfsync 持久化方式和频率<ul>\n<li>always 每次新命令都追加到AOF文件时候执行一次fsync，效率低，数据安全</li>\n<li>everysec 每秒fsync一次</li>\n<li>no 从不fsync</li>\n</ul>\n</li>\n</ul>\n<p>RDB可能会存在数据丢失<br>AOF大数据量恢复速度相比RDB要慢</p>\n<p>AOF rewirte重写</p>\n<ul>\n<li><p>bgrewriteaof 手动触发重写指令</p>\n</li>\n<li><p>auto-aof-rewrite-percentage 100 AOF自动重写百分比</p>\n</li>\n<li>auto-aof-rewrite-min-size 64mb AOF自动重写最小容量</li>\n</ul>\n<h3 id=\"4-0后支持混合持久化\"><a href=\"#4-0后支持混合持久化\" class=\"headerlink\" title=\"4.0后支持混合持久化\"></a>4.0后支持混合持久化</h3><p>aof-use-rdb-preamble yes<br>appendonly.aof文件中记录的RDB格式 + AOF格式</p>\n<p>如果RDB和AOF都开启，默认会使用AOF进行数据恢复</p>\n<h1 id=\"缓存淘汰策略\"><a href=\"#缓存淘汰策略\" class=\"headerlink\" title=\"缓存淘汰策略\"></a>缓存淘汰策略</h1><p>当redis内存超过物理内存限制的时候，内存数据会开始与磁盘产生频繁的交换(swap)，由于涉及到磁盘IO操作，redis的性能会急剧下降。</p>\n<p>当实际内存超出maxmemory时，redis提供了几种可选策略(maxmemory-policy)来让来决定该如何调整出新的空间继续提供读写服务</p>\n<ul>\n<li>LRU（Least Recently Used，最近最少使用）</li>\n<li><p>LFU（Least Frequently Used ，最不频繁使用）</p>\n</li>\n<li><p>volatile 设置了失效时间</p>\n</li>\n<li>allkeys 全部key<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.</span><br><span class=\"line\"># allkeys-lru -&gt; Evict any key using approximated LRU.</span><br><span class=\"line\"># volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.</span><br><span class=\"line\"># allkeys-lfu -&gt; Evict any key using approximated LFU.</span><br><span class=\"line\"># volatile-random -&gt; Remove a random key among the ones with an expire set.</span><br><span class=\"line\"># allkeys-random -&gt; Remove a random key, any key.</span><br><span class=\"line\"># volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)</span><br><span class=\"line\"># noeviction -&gt; Don&apos;t evict anything, just return an error on write operations.</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h1 id=\"高可用\"><a href=\"#高可用\" class=\"headerlink\" title=\"高可用\"></a>高可用</h1><h2 id=\"Redis-Sentinel-哨兵模式\"><a href=\"#Redis-Sentinel-哨兵模式\" class=\"headerlink\" title=\"Redis Sentinel(哨兵模式)\"></a>Redis Sentinel(哨兵模式)</h2><p>由若干sentinel节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。sentinel的节点数量要满足2n+1(n&gt;=1)个的奇数个。</p>\n<p>两个集群在同时工作，一个是sentinel集群，一个是数据节点的集群(master-slave)</p>\n<p>客户端会先连接一个sentinel实例，使用SENTINEL get-master-addr-by-name master-name 获取Redis地址信息。连接返回的Redis地址信息，通过ROLE命令查询是否是Master。如果是，连接进入正常的服务环节。否则应该断开重新查询。</p>\n<p>配置文件sentinel.conf</p>\n<ul>\n<li>min-slaves-to-write 1</li>\n<li>min-slaves-max-lag 10</li>\n</ul>\n<h2 id=\"Redis-Cluster-集群模式\"><a href=\"#Redis-Cluster-集群模式\" class=\"headerlink\" title=\"Redis Cluster(集群模式)\"></a>Redis Cluster(集群模式)</h2><p>redis官方提供的新的集群配置。由多个主从节点群组成的分布式服务群，具有复制、高可用、分片的特性。不需要sentinel哨兵也能完成节点的移除和故障转移的功能。</p>\n<p>至少要有三个Master节点</p>\n<p>修改配置文件</p>\n<ul>\n<li>cluster-enabled yes 启动集群模式</li>\n<li>cluster-config-file 集群节点配置文件</li>\n<li>cluster-node-timeout ms 集群节点的超时时间</li>\n<li>去除客户端访问 # bind 127.0.0.1</li>\n<li>protected-mode no 关闭保护模式<br>需要密码则配置</li>\n<li>requirepass xxx 设置密码</li>\n<li>masterauth xxx 集群通信设置master密码</li>\n</ul>\n<p>4.0用/src/redis-trib.rb 一个ruby脚本，5.0使用redis-cli –cluster就可以配置集群了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz9bvlfc3n574x9ygoj9Z /root/redis-5.0.3]$./src/redis-cli --cluster help</span><br><span class=\"line\">Cluster Manager Commands:</span><br><span class=\"line\">  create         host1:port1 ... hostN:portN</span><br><span class=\"line\">                 --cluster-replicas &lt;arg&gt;</span><br><span class=\"line\">  check          host:port</span><br><span class=\"line\">                 --cluster-search-multiple-owners</span><br><span class=\"line\">  info           host:port</span><br><span class=\"line\">  fix            host:port</span><br><span class=\"line\">                 --cluster-search-multiple-owners</span><br><span class=\"line\">  reshard        host:port</span><br><span class=\"line\">                 --cluster-from &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-to &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-slots &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-yes</span><br><span class=\"line\">                 --cluster-timeout &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-pipeline &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-replace</span><br><span class=\"line\">  rebalance      host:port</span><br><span class=\"line\">                 --cluster-weight &lt;node1=w1...nodeN=wN&gt;</span><br><span class=\"line\">                 --cluster-use-empty-masters</span><br><span class=\"line\">                 --cluster-timeout &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-simulate</span><br><span class=\"line\">                 --cluster-pipeline &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-threshold &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-replace</span><br><span class=\"line\">  add-node       new_host:new_port existing_host:existing_port</span><br><span class=\"line\">                 --cluster-slave</span><br><span class=\"line\">                 --cluster-master-id &lt;arg&gt;</span><br><span class=\"line\">  del-node       host:port node_id</span><br><span class=\"line\">  call           host:port command arg arg .. arg</span><br><span class=\"line\">  set-timeout    host:port milliseconds</span><br><span class=\"line\">  import         host:port</span><br><span class=\"line\">                 --cluster-from &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-copy</span><br><span class=\"line\">                 --cluster-replace</span><br><span class=\"line\">  help</span><br><span class=\"line\"></span><br><span class=\"line\">For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster.</span><br></pre></td></tr></table></figure>\n<p>常用详解</p>\n<ul>\n<li>redis-cli -a 输入启动节点的密码</li>\n<li>create <ul>\n<li>ip:prot ipN:protN</li>\n<li>–cluster-replicas 复制因子，每个主从节点的比例</li>\n</ul>\n</li>\n</ul>\n<p>访问集群模式</p>\n<ul>\n<li>/src/redis-cli -a xxx -c -h host -p port</li>\n<li>cluster info 查询集群信息</li>\n<li>cluster nodes 查看集群各个节点信息</li>\n</ul>\n<blockquote>\n<p>HASH_CLOT = CRC16(key)mod 16384</p>\n</blockquote>\n<blockquote>\n<p>共16384 sloat</p>\n</blockquote>\n<h3 id=\"添加节点（水平扩展）\"><a href=\"#添加节点（水平扩展）\" class=\"headerlink\" title=\"添加节点（水平扩展）\"></a>添加节点（水平扩展）</h3><ul>\n<li>add-node 添加节点</li>\n<li>reshard host:port 重新分片</li>\n</ul>\n<h3 id=\"删除节点\"><a href=\"#删除节点\" class=\"headerlink\" title=\"删除节点\"></a>删除节点</h3><ul>\n<li>reshard 将分配的sloat分配到其他可用主节点中</li>\n<li>del-node</li>\n<li>rebalance 集群内部做迁移，可以设置节点的权重（weight），迁移过程中sloat都会阻塞</li>\n</ul>\n<h2 id=\"集群选举原理\"><a href=\"#集群选举原理\" class=\"headerlink\" title=\"集群选举原理\"></a>集群选举原理</h2><p>当Slave发现自己的Master变成FAIL状态时，便尝试进行Fallover，以聘成为新的Master。由于挂掉的Master可能会有多个Slave，从而存在多个Slave竞争的过程，其过程如下：</p>\n<ol>\n<li>slave发现自己的Master变为FAIL</li>\n<li>将自己记录的集群CurrentEpoch加1，并广播FAILOVER_AUTH_REQUEST信息</li>\n<li>其他节点收到该信息，只有Master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ACK</li>\n<li>尝试FAILOVER的Slave收集FAILOVER_AUTH_ACK</li>\n<li>超过半数后变成新的Master</li>\n<li>广播Pong通知其他集群节点</li>\n</ol>\n<p>从节点并不是在主节点一进入FAIL状态就马上尝试发起选举的，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，Slave如果立即尝试选举或许尚未意识到FAIL状态，可能会拒绝投票</p>\n<p>延迟计算公式：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DELAY = 500ms + random(0 -500ms) + SLAVE_RANK + 1000ms</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>SLAVE_RANK表示此Slave已经从Master复制数据的总量的Rank。Rank越小代表已复制的数据越新，持有最新数据的Slave将会首先发起选举。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>学习一些redis的进阶知识基础<br>","more":"</p>\n<p>3.x<br>4.x ruby<br>5.0 C语言 集群配置等更简单</p>\n<h1 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h1><h2 id=\"RDB快照-snapshop\"><a href=\"#RDB快照-snapshop\" class=\"headerlink\" title=\"RDB快照 snapshop\"></a>RDB快照 snapshop</h2><p>dump.rdb二进制文件保存</p>\n<p>redis.conf中，save seconds changes进行配置，设置为save “”则为关闭</p>\n<h2 id=\"AOF-append-only-file\"><a href=\"#AOF-append-only-file\" class=\"headerlink\" title=\"AOF append-only file\"></a>AOF append-only file</h2><p>redis.conf中</p>\n<ul>\n<li>appendonly no 修改为yes开启</li>\n<li>appendfilename 默认appendonly.aof，保存的都是命令 resp协议 </li>\n<li>appendfsync 持久化方式和频率<ul>\n<li>always 每次新命令都追加到AOF文件时候执行一次fsync，效率低，数据安全</li>\n<li>everysec 每秒fsync一次</li>\n<li>no 从不fsync</li>\n</ul>\n</li>\n</ul>\n<p>RDB可能会存在数据丢失<br>AOF大数据量恢复速度相比RDB要慢</p>\n<p>AOF rewirte重写</p>\n<ul>\n<li><p>bgrewriteaof 手动触发重写指令</p>\n</li>\n<li><p>auto-aof-rewrite-percentage 100 AOF自动重写百分比</p>\n</li>\n<li>auto-aof-rewrite-min-size 64mb AOF自动重写最小容量</li>\n</ul>\n<h3 id=\"4-0后支持混合持久化\"><a href=\"#4-0后支持混合持久化\" class=\"headerlink\" title=\"4.0后支持混合持久化\"></a>4.0后支持混合持久化</h3><p>aof-use-rdb-preamble yes<br>appendonly.aof文件中记录的RDB格式 + AOF格式</p>\n<p>如果RDB和AOF都开启，默认会使用AOF进行数据恢复</p>\n<h1 id=\"缓存淘汰策略\"><a href=\"#缓存淘汰策略\" class=\"headerlink\" title=\"缓存淘汰策略\"></a>缓存淘汰策略</h1><p>当redis内存超过物理内存限制的时候，内存数据会开始与磁盘产生频繁的交换(swap)，由于涉及到磁盘IO操作，redis的性能会急剧下降。</p>\n<p>当实际内存超出maxmemory时，redis提供了几种可选策略(maxmemory-policy)来让来决定该如何调整出新的空间继续提供读写服务</p>\n<ul>\n<li>LRU（Least Recently Used，最近最少使用）</li>\n<li><p>LFU（Least Frequently Used ，最不频繁使用）</p>\n</li>\n<li><p>volatile 设置了失效时间</p>\n</li>\n<li>allkeys 全部key<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.</span><br><span class=\"line\"># allkeys-lru -&gt; Evict any key using approximated LRU.</span><br><span class=\"line\"># volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.</span><br><span class=\"line\"># allkeys-lfu -&gt; Evict any key using approximated LFU.</span><br><span class=\"line\"># volatile-random -&gt; Remove a random key among the ones with an expire set.</span><br><span class=\"line\"># allkeys-random -&gt; Remove a random key, any key.</span><br><span class=\"line\"># volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)</span><br><span class=\"line\"># noeviction -&gt; Don&apos;t evict anything, just return an error on write operations.</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h1 id=\"高可用\"><a href=\"#高可用\" class=\"headerlink\" title=\"高可用\"></a>高可用</h1><h2 id=\"Redis-Sentinel-哨兵模式\"><a href=\"#Redis-Sentinel-哨兵模式\" class=\"headerlink\" title=\"Redis Sentinel(哨兵模式)\"></a>Redis Sentinel(哨兵模式)</h2><p>由若干sentinel节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。sentinel的节点数量要满足2n+1(n&gt;=1)个的奇数个。</p>\n<p>两个集群在同时工作，一个是sentinel集群，一个是数据节点的集群(master-slave)</p>\n<p>客户端会先连接一个sentinel实例，使用SENTINEL get-master-addr-by-name master-name 获取Redis地址信息。连接返回的Redis地址信息，通过ROLE命令查询是否是Master。如果是，连接进入正常的服务环节。否则应该断开重新查询。</p>\n<p>配置文件sentinel.conf</p>\n<ul>\n<li>min-slaves-to-write 1</li>\n<li>min-slaves-max-lag 10</li>\n</ul>\n<h2 id=\"Redis-Cluster-集群模式\"><a href=\"#Redis-Cluster-集群模式\" class=\"headerlink\" title=\"Redis Cluster(集群模式)\"></a>Redis Cluster(集群模式)</h2><p>redis官方提供的新的集群配置。由多个主从节点群组成的分布式服务群，具有复制、高可用、分片的特性。不需要sentinel哨兵也能完成节点的移除和故障转移的功能。</p>\n<p>至少要有三个Master节点</p>\n<p>修改配置文件</p>\n<ul>\n<li>cluster-enabled yes 启动集群模式</li>\n<li>cluster-config-file 集群节点配置文件</li>\n<li>cluster-node-timeout ms 集群节点的超时时间</li>\n<li>去除客户端访问 # bind 127.0.0.1</li>\n<li>protected-mode no 关闭保护模式<br>需要密码则配置</li>\n<li>requirepass xxx 设置密码</li>\n<li>masterauth xxx 集群通信设置master密码</li>\n</ul>\n<p>4.0用/src/redis-trib.rb 一个ruby脚本，5.0使用redis-cli –cluster就可以配置集群了</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz9bvlfc3n574x9ygoj9Z /root/redis-5.0.3]$./src/redis-cli --cluster help</span><br><span class=\"line\">Cluster Manager Commands:</span><br><span class=\"line\">  create         host1:port1 ... hostN:portN</span><br><span class=\"line\">                 --cluster-replicas &lt;arg&gt;</span><br><span class=\"line\">  check          host:port</span><br><span class=\"line\">                 --cluster-search-multiple-owners</span><br><span class=\"line\">  info           host:port</span><br><span class=\"line\">  fix            host:port</span><br><span class=\"line\">                 --cluster-search-multiple-owners</span><br><span class=\"line\">  reshard        host:port</span><br><span class=\"line\">                 --cluster-from &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-to &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-slots &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-yes</span><br><span class=\"line\">                 --cluster-timeout &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-pipeline &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-replace</span><br><span class=\"line\">  rebalance      host:port</span><br><span class=\"line\">                 --cluster-weight &lt;node1=w1...nodeN=wN&gt;</span><br><span class=\"line\">                 --cluster-use-empty-masters</span><br><span class=\"line\">                 --cluster-timeout &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-simulate</span><br><span class=\"line\">                 --cluster-pipeline &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-threshold &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-replace</span><br><span class=\"line\">  add-node       new_host:new_port existing_host:existing_port</span><br><span class=\"line\">                 --cluster-slave</span><br><span class=\"line\">                 --cluster-master-id &lt;arg&gt;</span><br><span class=\"line\">  del-node       host:port node_id</span><br><span class=\"line\">  call           host:port command arg arg .. arg</span><br><span class=\"line\">  set-timeout    host:port milliseconds</span><br><span class=\"line\">  import         host:port</span><br><span class=\"line\">                 --cluster-from &lt;arg&gt;</span><br><span class=\"line\">                 --cluster-copy</span><br><span class=\"line\">                 --cluster-replace</span><br><span class=\"line\">  help</span><br><span class=\"line\"></span><br><span class=\"line\">For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster.</span><br></pre></td></tr></table></figure>\n<p>常用详解</p>\n<ul>\n<li>redis-cli -a 输入启动节点的密码</li>\n<li>create <ul>\n<li>ip:prot ipN:protN</li>\n<li>–cluster-replicas 复制因子，每个主从节点的比例</li>\n</ul>\n</li>\n</ul>\n<p>访问集群模式</p>\n<ul>\n<li>/src/redis-cli -a xxx -c -h host -p port</li>\n<li>cluster info 查询集群信息</li>\n<li>cluster nodes 查看集群各个节点信息</li>\n</ul>\n<blockquote>\n<p>HASH_CLOT = CRC16(key)mod 16384</p>\n</blockquote>\n<blockquote>\n<p>共16384 sloat</p>\n</blockquote>\n<h3 id=\"添加节点（水平扩展）\"><a href=\"#添加节点（水平扩展）\" class=\"headerlink\" title=\"添加节点（水平扩展）\"></a>添加节点（水平扩展）</h3><ul>\n<li>add-node 添加节点</li>\n<li>reshard host:port 重新分片</li>\n</ul>\n<h3 id=\"删除节点\"><a href=\"#删除节点\" class=\"headerlink\" title=\"删除节点\"></a>删除节点</h3><ul>\n<li>reshard 将分配的sloat分配到其他可用主节点中</li>\n<li>del-node</li>\n<li>rebalance 集群内部做迁移，可以设置节点的权重（weight），迁移过程中sloat都会阻塞</li>\n</ul>\n<h2 id=\"集群选举原理\"><a href=\"#集群选举原理\" class=\"headerlink\" title=\"集群选举原理\"></a>集群选举原理</h2><p>当Slave发现自己的Master变成FAIL状态时，便尝试进行Fallover，以聘成为新的Master。由于挂掉的Master可能会有多个Slave，从而存在多个Slave竞争的过程，其过程如下：</p>\n<ol>\n<li>slave发现自己的Master变为FAIL</li>\n<li>将自己记录的集群CurrentEpoch加1，并广播FAILOVER_AUTH_REQUEST信息</li>\n<li>其他节点收到该信息，只有Master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ACK</li>\n<li>尝试FAILOVER的Slave收集FAILOVER_AUTH_ACK</li>\n<li>超过半数后变成新的Master</li>\n<li>广播Pong通知其他集群节点</li>\n</ol>\n<p>从节点并不是在主节点一进入FAIL状态就马上尝试发起选举的，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，Slave如果立即尝试选举或许尚未意识到FAIL状态，可能会拒绝投票</p>\n<p>延迟计算公式：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DELAY = 500ms + random(0 -500ms) + SLAVE_RANK + 1000ms</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>SLAVE_RANK表示此Slave已经从Master复制数据的总量的Rank。Rank越小代表已复制的数据越新，持有最新数据的Slave将会首先发起选举。</li>\n</ul>"},{"title":"Java Thread","date":"2018-11-28T06:12:17.000Z","_content":"\n> 本篇是在对线程基础进行学习时的概念知识的随笔\n\n<!-- more -->\n\n## 线程\n每一个java进程，都伴随着N个线程进行执行，入口main函数为主线程。\n\n## 线程的状态\n线程启动使用的start()方法，但是启动的时候，线程将进入一种就绪状态，现在并没有立刻执行。\n\n进入到就绪状态之后就需要等待进行资源调度，当某一个线程的调度成功之后，则回进入到运行状态（run方法）\n\n但是所有的线程不可能一致执行下去，中间需要产生一些暂停的状态，例如：某个线程执行一段时间之后就需要让出资源，这个线程将会进入阻塞状态\n\nrun()方法执行结束后，实际该线程的主要任务也就结束了，此时将会直接进入到停止状态\n\n1. start() 就绪\n2. run() 运行状态\n3. 阻塞状态\n4. 停止状态\n\n注：线程的停止等相关方法在jdk1.2就已经废弃，如果想停止线程应当自定义编写线程推出的条件对线程进行退出，而不是外部的暴力退出线程。\n\n## 线程休眠\n希望一个线程可以暂缓执行，进行休眠的时候可能会产生中断异常\n\n休眠的特点是可以自动实现线程的唤醒，以继续进行后续的处理，但休眠也是有先后顺序的\n\n## 线程中断\n所有正在执行的线程都是可以被中断的，中断线程必须进行异常的处理\n* 判断线程是否被中断：public static boolean interrupted()\n* 中断线程执行：public void interrupt()\n\ninterrupt()不能中断在运行中的线程，它只能改变中断状态\n\n## 线程的强制执行\n当满足于某些条件之后，某一个线程对象可以一直独占资源，一直到该线程的程序执行结束\n\n通过需要进行join的线程对象调用\n* public final void join() throws InterruptedException \n  \n## 线程的礼让\n将资源让出给其他线程先执行\n* public static native void yield();\n\n## 线程优先级\n* 线程优先级越高，越有可能先执行（先抢占到资源），在Thread类中针对于优先级有两个方法：\n* 设置优先级：public final void setPriority(int newPriority)\n* 获取优先级：public final void getPriority()\n* 优先级常量，分别为低、中、高优先级\n```java\n    /**\n     * The minimum priority that a thread can have.\n     */\n    public final static int MIN_PRIORITY = 1;\n\n   /**\n     * The default priority that is assigned to a thread.\n     */\n    public final static int NORM_PRIORITY = 5;\n\n    /**\n     * The maximum priority that a thread can have.\n     */\n    public final static int MAX_PRIORITY = 10;\n```\n主线程、子线程默认的优先级为NORM_PRIORITY，中优先级\n\n设置高优先级后，该线程有可能，但并不是必定会优先执行\n\n\n## 线程同步问题\n\n* 关键字：synchronized，同步代码块、同步方法中只允许一个线程执行，大都使用同步方法。\n```java\nsynchronized(同步对象){\n    同步代码操作;\n}\n```\n一般要进行同步对象处理的时候可以采用当前对象this进行同步。\n\n同步会造成程序性能的整体降低\n\n\n## 线程死锁\n\n死锁造成的主要原因是因为彼此都在互相等待，等待对方先让出资源。\n\n若干个线程访问同一资源时一定要进行同步处理，而过多的同步处理可能会造成死锁。\n\n如何避免死锁：\n\n    避免在对象的同步方法种调用其他对象的同步方法\n\n    死锁的根本原因1）是多个线程涉及到多个锁，这些锁存在着交叉，所以可能会导致了一个锁依赖的闭环；2）默认的锁申请操作是阻塞的。所以要避免死锁，就要在一遇到多个对象锁交叉的情况，就要仔细审查这几个对象的类中的所有方法，是否存在着导致锁依赖的环路的可能性。要采取各种方法来杜绝这种可能性。\n\n\n一旦我们在一个同步方法中，或者说在一个锁的保护的范围中，调用了其它对象的方法时，就要十而分的小心：\n\n1）如果其它对象的这个方法会消耗比较长的时间，那么就会导致锁被我们持有了很长的时间；\n\n2）如果其它对象的这个方法是一个同步方法，那么就要注意避免发生死锁的可能性了；\n\n## 守护线程\n守护线程的生命周期紧随用户线程，JVM最大的守护线程是GC线程，程序执行中GC线程将一直存在，如果程序执行完毕，GC线程也会消失\n\n* 设置为当前线程的守护线程 public final void setDaemon(boolean on)\n\n* 是否是守护线程 public final boolean isDaemon()\n\n## volatile关键字\n用于修饰关键字，表示该属性为直接属性操作，不进行副本拷贝处理。\n一些文档和书中错误的讲其描写为同步属性。\n\n在正常进行变量处理的时候一般会经历以下几个步骤：\n1. 获取变量原有的数据内容副本\n2. 利用副本为变量进行数学计算\n3. 将计算后的变量保存到原始空间之中\n\n如果加上了volatile关键字，表示不使用副本，直接操作原始变量，相当于节约了拷贝副本\n\n![volatile-photo](/image/volatile.png)\n\nvolatile与synchronized的区别：\n\n    volatile只能描述属性，而synchronized可以用于代码块与方法。\n    volatile无法描述属性进行同步处理，只是一种直接内存的处理，避免了副本处理。\n\n对于volatile的详细解释，可以参考\n\nhttps://www.ibm.com/developerworks/cn/java/j-jtp06197.html\n\nhttps://www.cnblogs.com/dolphin0520/p/3920373.html","source":"_posts/thread.md","raw":"---\ntitle: Java Thread\ndate: 2018-11-28 14:12:17\ntags: Java\ncategories: Java\n---\n\n> 本篇是在对线程基础进行学习时的概念知识的随笔\n\n<!-- more -->\n\n## 线程\n每一个java进程，都伴随着N个线程进行执行，入口main函数为主线程。\n\n## 线程的状态\n线程启动使用的start()方法，但是启动的时候，线程将进入一种就绪状态，现在并没有立刻执行。\n\n进入到就绪状态之后就需要等待进行资源调度，当某一个线程的调度成功之后，则回进入到运行状态（run方法）\n\n但是所有的线程不可能一致执行下去，中间需要产生一些暂停的状态，例如：某个线程执行一段时间之后就需要让出资源，这个线程将会进入阻塞状态\n\nrun()方法执行结束后，实际该线程的主要任务也就结束了，此时将会直接进入到停止状态\n\n1. start() 就绪\n2. run() 运行状态\n3. 阻塞状态\n4. 停止状态\n\n注：线程的停止等相关方法在jdk1.2就已经废弃，如果想停止线程应当自定义编写线程推出的条件对线程进行退出，而不是外部的暴力退出线程。\n\n## 线程休眠\n希望一个线程可以暂缓执行，进行休眠的时候可能会产生中断异常\n\n休眠的特点是可以自动实现线程的唤醒，以继续进行后续的处理，但休眠也是有先后顺序的\n\n## 线程中断\n所有正在执行的线程都是可以被中断的，中断线程必须进行异常的处理\n* 判断线程是否被中断：public static boolean interrupted()\n* 中断线程执行：public void interrupt()\n\ninterrupt()不能中断在运行中的线程，它只能改变中断状态\n\n## 线程的强制执行\n当满足于某些条件之后，某一个线程对象可以一直独占资源，一直到该线程的程序执行结束\n\n通过需要进行join的线程对象调用\n* public final void join() throws InterruptedException \n  \n## 线程的礼让\n将资源让出给其他线程先执行\n* public static native void yield();\n\n## 线程优先级\n* 线程优先级越高，越有可能先执行（先抢占到资源），在Thread类中针对于优先级有两个方法：\n* 设置优先级：public final void setPriority(int newPriority)\n* 获取优先级：public final void getPriority()\n* 优先级常量，分别为低、中、高优先级\n```java\n    /**\n     * The minimum priority that a thread can have.\n     */\n    public final static int MIN_PRIORITY = 1;\n\n   /**\n     * The default priority that is assigned to a thread.\n     */\n    public final static int NORM_PRIORITY = 5;\n\n    /**\n     * The maximum priority that a thread can have.\n     */\n    public final static int MAX_PRIORITY = 10;\n```\n主线程、子线程默认的优先级为NORM_PRIORITY，中优先级\n\n设置高优先级后，该线程有可能，但并不是必定会优先执行\n\n\n## 线程同步问题\n\n* 关键字：synchronized，同步代码块、同步方法中只允许一个线程执行，大都使用同步方法。\n```java\nsynchronized(同步对象){\n    同步代码操作;\n}\n```\n一般要进行同步对象处理的时候可以采用当前对象this进行同步。\n\n同步会造成程序性能的整体降低\n\n\n## 线程死锁\n\n死锁造成的主要原因是因为彼此都在互相等待，等待对方先让出资源。\n\n若干个线程访问同一资源时一定要进行同步处理，而过多的同步处理可能会造成死锁。\n\n如何避免死锁：\n\n    避免在对象的同步方法种调用其他对象的同步方法\n\n    死锁的根本原因1）是多个线程涉及到多个锁，这些锁存在着交叉，所以可能会导致了一个锁依赖的闭环；2）默认的锁申请操作是阻塞的。所以要避免死锁，就要在一遇到多个对象锁交叉的情况，就要仔细审查这几个对象的类中的所有方法，是否存在着导致锁依赖的环路的可能性。要采取各种方法来杜绝这种可能性。\n\n\n一旦我们在一个同步方法中，或者说在一个锁的保护的范围中，调用了其它对象的方法时，就要十而分的小心：\n\n1）如果其它对象的这个方法会消耗比较长的时间，那么就会导致锁被我们持有了很长的时间；\n\n2）如果其它对象的这个方法是一个同步方法，那么就要注意避免发生死锁的可能性了；\n\n## 守护线程\n守护线程的生命周期紧随用户线程，JVM最大的守护线程是GC线程，程序执行中GC线程将一直存在，如果程序执行完毕，GC线程也会消失\n\n* 设置为当前线程的守护线程 public final void setDaemon(boolean on)\n\n* 是否是守护线程 public final boolean isDaemon()\n\n## volatile关键字\n用于修饰关键字，表示该属性为直接属性操作，不进行副本拷贝处理。\n一些文档和书中错误的讲其描写为同步属性。\n\n在正常进行变量处理的时候一般会经历以下几个步骤：\n1. 获取变量原有的数据内容副本\n2. 利用副本为变量进行数学计算\n3. 将计算后的变量保存到原始空间之中\n\n如果加上了volatile关键字，表示不使用副本，直接操作原始变量，相当于节约了拷贝副本\n\n![volatile-photo](/image/volatile.png)\n\nvolatile与synchronized的区别：\n\n    volatile只能描述属性，而synchronized可以用于代码块与方法。\n    volatile无法描述属性进行同步处理，只是一种直接内存的处理，避免了副本处理。\n\n对于volatile的详细解释，可以参考\n\nhttps://www.ibm.com/developerworks/cn/java/j-jtp06197.html\n\nhttps://www.cnblogs.com/dolphin0520/p/3920373.html","slug":"thread","published":1,"updated":"2019-08-26T07:53:11.261Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0r001sqotng43w0bcf","content":"<blockquote>\n<p>本篇是在对线程基础进行学习时的概念知识的随笔</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h2><p>每一个java进程，都伴随着N个线程进行执行，入口main函数为主线程。</p>\n<h2 id=\"线程的状态\"><a href=\"#线程的状态\" class=\"headerlink\" title=\"线程的状态\"></a>线程的状态</h2><p>线程启动使用的start()方法，但是启动的时候，线程将进入一种就绪状态，现在并没有立刻执行。</p>\n<p>进入到就绪状态之后就需要等待进行资源调度，当某一个线程的调度成功之后，则回进入到运行状态（run方法）</p>\n<p>但是所有的线程不可能一致执行下去，中间需要产生一些暂停的状态，例如：某个线程执行一段时间之后就需要让出资源，这个线程将会进入阻塞状态</p>\n<p>run()方法执行结束后，实际该线程的主要任务也就结束了，此时将会直接进入到停止状态</p>\n<ol>\n<li>start() 就绪</li>\n<li>run() 运行状态</li>\n<li>阻塞状态</li>\n<li>停止状态</li>\n</ol>\n<p>注：线程的停止等相关方法在jdk1.2就已经废弃，如果想停止线程应当自定义编写线程推出的条件对线程进行退出，而不是外部的暴力退出线程。</p>\n<h2 id=\"线程休眠\"><a href=\"#线程休眠\" class=\"headerlink\" title=\"线程休眠\"></a>线程休眠</h2><p>希望一个线程可以暂缓执行，进行休眠的时候可能会产生中断异常</p>\n<p>休眠的特点是可以自动实现线程的唤醒，以继续进行后续的处理，但休眠也是有先后顺序的</p>\n<h2 id=\"线程中断\"><a href=\"#线程中断\" class=\"headerlink\" title=\"线程中断\"></a>线程中断</h2><p>所有正在执行的线程都是可以被中断的，中断线程必须进行异常的处理</p>\n<ul>\n<li>判断线程是否被中断：public static boolean interrupted()</li>\n<li>中断线程执行：public void interrupt()</li>\n</ul>\n<p>interrupt()不能中断在运行中的线程，它只能改变中断状态</p>\n<h2 id=\"线程的强制执行\"><a href=\"#线程的强制执行\" class=\"headerlink\" title=\"线程的强制执行\"></a>线程的强制执行</h2><p>当满足于某些条件之后，某一个线程对象可以一直独占资源，一直到该线程的程序执行结束</p>\n<p>通过需要进行join的线程对象调用</p>\n<ul>\n<li>public final void join() throws InterruptedException </li>\n</ul>\n<h2 id=\"线程的礼让\"><a href=\"#线程的礼让\" class=\"headerlink\" title=\"线程的礼让\"></a>线程的礼让</h2><p>将资源让出给其他线程先执行</p>\n<ul>\n<li>public static native void yield();</li>\n</ul>\n<h2 id=\"线程优先级\"><a href=\"#线程优先级\" class=\"headerlink\" title=\"线程优先级\"></a>线程优先级</h2><ul>\n<li>线程优先级越高，越有可能先执行（先抢占到资源），在Thread类中针对于优先级有两个方法：</li>\n<li>设置优先级：public final void setPriority(int newPriority)</li>\n<li>获取优先级：public final void getPriority()</li>\n<li>优先级常量，分别为低、中、高优先级<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * The minimum priority that a thread can have.</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> MIN_PRIORITY = <span class=\"number\">1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * The default priority that is assigned to a thread.</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> NORM_PRIORITY = <span class=\"number\">5</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * The maximum priority that a thread can have.</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> MAX_PRIORITY = <span class=\"number\">10</span>;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>主线程、子线程默认的优先级为NORM_PRIORITY，中优先级</p>\n<p>设置高优先级后，该线程有可能，但并不是必定会优先执行</p>\n<h2 id=\"线程同步问题\"><a href=\"#线程同步问题\" class=\"headerlink\" title=\"线程同步问题\"></a>线程同步问题</h2><ul>\n<li>关键字：synchronized，同步代码块、同步方法中只允许一个线程执行，大都使用同步方法。<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">synchronized</span>(同步对象)&#123;</span><br><span class=\"line\">    同步代码操作;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>一般要进行同步对象处理的时候可以采用当前对象this进行同步。</p>\n<p>同步会造成程序性能的整体降低</p>\n<h2 id=\"线程死锁\"><a href=\"#线程死锁\" class=\"headerlink\" title=\"线程死锁\"></a>线程死锁</h2><p>死锁造成的主要原因是因为彼此都在互相等待，等待对方先让出资源。</p>\n<p>若干个线程访问同一资源时一定要进行同步处理，而过多的同步处理可能会造成死锁。</p>\n<p>如何避免死锁：</p>\n<pre><code>避免在对象的同步方法种调用其他对象的同步方法\n\n死锁的根本原因1）是多个线程涉及到多个锁，这些锁存在着交叉，所以可能会导致了一个锁依赖的闭环；2）默认的锁申请操作是阻塞的。所以要避免死锁，就要在一遇到多个对象锁交叉的情况，就要仔细审查这几个对象的类中的所有方法，是否存在着导致锁依赖的环路的可能性。要采取各种方法来杜绝这种可能性。\n</code></pre><p>一旦我们在一个同步方法中，或者说在一个锁的保护的范围中，调用了其它对象的方法时，就要十而分的小心：</p>\n<p>1）如果其它对象的这个方法会消耗比较长的时间，那么就会导致锁被我们持有了很长的时间；</p>\n<p>2）如果其它对象的这个方法是一个同步方法，那么就要注意避免发生死锁的可能性了；</p>\n<h2 id=\"守护线程\"><a href=\"#守护线程\" class=\"headerlink\" title=\"守护线程\"></a>守护线程</h2><p>守护线程的生命周期紧随用户线程，JVM最大的守护线程是GC线程，程序执行中GC线程将一直存在，如果程序执行完毕，GC线程也会消失</p>\n<ul>\n<li><p>设置为当前线程的守护线程 public final void setDaemon(boolean on)</p>\n</li>\n<li><p>是否是守护线程 public final boolean isDaemon()</p>\n</li>\n</ul>\n<h2 id=\"volatile关键字\"><a href=\"#volatile关键字\" class=\"headerlink\" title=\"volatile关键字\"></a>volatile关键字</h2><p>用于修饰关键字，表示该属性为直接属性操作，不进行副本拷贝处理。<br>一些文档和书中错误的讲其描写为同步属性。</p>\n<p>在正常进行变量处理的时候一般会经历以下几个步骤：</p>\n<ol>\n<li>获取变量原有的数据内容副本</li>\n<li>利用副本为变量进行数学计算</li>\n<li>将计算后的变量保存到原始空间之中</li>\n</ol>\n<p>如果加上了volatile关键字，表示不使用副本，直接操作原始变量，相当于节约了拷贝副本</p>\n<p><img src=\"/image/volatile.png\" alt=\"volatile-photo\"></p>\n<p>volatile与synchronized的区别：</p>\n<pre><code>volatile只能描述属性，而synchronized可以用于代码块与方法。\nvolatile无法描述属性进行同步处理，只是一种直接内存的处理，避免了副本处理。\n</code></pre><p>对于volatile的详细解释，可以参考</p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/java/j-jtp06197.html\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-jtp06197.html</a></p>\n<p><a href=\"https://www.cnblogs.com/dolphin0520/p/3920373.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/dolphin0520/p/3920373.html</a></p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本篇是在对线程基础进行学习时的概念知识的随笔</p>\n</blockquote>","more":"<h2 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h2><p>每一个java进程，都伴随着N个线程进行执行，入口main函数为主线程。</p>\n<h2 id=\"线程的状态\"><a href=\"#线程的状态\" class=\"headerlink\" title=\"线程的状态\"></a>线程的状态</h2><p>线程启动使用的start()方法，但是启动的时候，线程将进入一种就绪状态，现在并没有立刻执行。</p>\n<p>进入到就绪状态之后就需要等待进行资源调度，当某一个线程的调度成功之后，则回进入到运行状态（run方法）</p>\n<p>但是所有的线程不可能一致执行下去，中间需要产生一些暂停的状态，例如：某个线程执行一段时间之后就需要让出资源，这个线程将会进入阻塞状态</p>\n<p>run()方法执行结束后，实际该线程的主要任务也就结束了，此时将会直接进入到停止状态</p>\n<ol>\n<li>start() 就绪</li>\n<li>run() 运行状态</li>\n<li>阻塞状态</li>\n<li>停止状态</li>\n</ol>\n<p>注：线程的停止等相关方法在jdk1.2就已经废弃，如果想停止线程应当自定义编写线程推出的条件对线程进行退出，而不是外部的暴力退出线程。</p>\n<h2 id=\"线程休眠\"><a href=\"#线程休眠\" class=\"headerlink\" title=\"线程休眠\"></a>线程休眠</h2><p>希望一个线程可以暂缓执行，进行休眠的时候可能会产生中断异常</p>\n<p>休眠的特点是可以自动实现线程的唤醒，以继续进行后续的处理，但休眠也是有先后顺序的</p>\n<h2 id=\"线程中断\"><a href=\"#线程中断\" class=\"headerlink\" title=\"线程中断\"></a>线程中断</h2><p>所有正在执行的线程都是可以被中断的，中断线程必须进行异常的处理</p>\n<ul>\n<li>判断线程是否被中断：public static boolean interrupted()</li>\n<li>中断线程执行：public void interrupt()</li>\n</ul>\n<p>interrupt()不能中断在运行中的线程，它只能改变中断状态</p>\n<h2 id=\"线程的强制执行\"><a href=\"#线程的强制执行\" class=\"headerlink\" title=\"线程的强制执行\"></a>线程的强制执行</h2><p>当满足于某些条件之后，某一个线程对象可以一直独占资源，一直到该线程的程序执行结束</p>\n<p>通过需要进行join的线程对象调用</p>\n<ul>\n<li>public final void join() throws InterruptedException </li>\n</ul>\n<h2 id=\"线程的礼让\"><a href=\"#线程的礼让\" class=\"headerlink\" title=\"线程的礼让\"></a>线程的礼让</h2><p>将资源让出给其他线程先执行</p>\n<ul>\n<li>public static native void yield();</li>\n</ul>\n<h2 id=\"线程优先级\"><a href=\"#线程优先级\" class=\"headerlink\" title=\"线程优先级\"></a>线程优先级</h2><ul>\n<li>线程优先级越高，越有可能先执行（先抢占到资源），在Thread类中针对于优先级有两个方法：</li>\n<li>设置优先级：public final void setPriority(int newPriority)</li>\n<li>获取优先级：public final void getPriority()</li>\n<li>优先级常量，分别为低、中、高优先级<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * The minimum priority that a thread can have.</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> MIN_PRIORITY = <span class=\"number\">1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * The default priority that is assigned to a thread.</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> NORM_PRIORITY = <span class=\"number\">5</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * The maximum priority that a thread can have.</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"> <span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> MAX_PRIORITY = <span class=\"number\">10</span>;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>主线程、子线程默认的优先级为NORM_PRIORITY，中优先级</p>\n<p>设置高优先级后，该线程有可能，但并不是必定会优先执行</p>\n<h2 id=\"线程同步问题\"><a href=\"#线程同步问题\" class=\"headerlink\" title=\"线程同步问题\"></a>线程同步问题</h2><ul>\n<li>关键字：synchronized，同步代码块、同步方法中只允许一个线程执行，大都使用同步方法。<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">synchronized</span>(同步对象)&#123;</span><br><span class=\"line\">    同步代码操作;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>一般要进行同步对象处理的时候可以采用当前对象this进行同步。</p>\n<p>同步会造成程序性能的整体降低</p>\n<h2 id=\"线程死锁\"><a href=\"#线程死锁\" class=\"headerlink\" title=\"线程死锁\"></a>线程死锁</h2><p>死锁造成的主要原因是因为彼此都在互相等待，等待对方先让出资源。</p>\n<p>若干个线程访问同一资源时一定要进行同步处理，而过多的同步处理可能会造成死锁。</p>\n<p>如何避免死锁：</p>\n<pre><code>避免在对象的同步方法种调用其他对象的同步方法\n\n死锁的根本原因1）是多个线程涉及到多个锁，这些锁存在着交叉，所以可能会导致了一个锁依赖的闭环；2）默认的锁申请操作是阻塞的。所以要避免死锁，就要在一遇到多个对象锁交叉的情况，就要仔细审查这几个对象的类中的所有方法，是否存在着导致锁依赖的环路的可能性。要采取各种方法来杜绝这种可能性。\n</code></pre><p>一旦我们在一个同步方法中，或者说在一个锁的保护的范围中，调用了其它对象的方法时，就要十而分的小心：</p>\n<p>1）如果其它对象的这个方法会消耗比较长的时间，那么就会导致锁被我们持有了很长的时间；</p>\n<p>2）如果其它对象的这个方法是一个同步方法，那么就要注意避免发生死锁的可能性了；</p>\n<h2 id=\"守护线程\"><a href=\"#守护线程\" class=\"headerlink\" title=\"守护线程\"></a>守护线程</h2><p>守护线程的生命周期紧随用户线程，JVM最大的守护线程是GC线程，程序执行中GC线程将一直存在，如果程序执行完毕，GC线程也会消失</p>\n<ul>\n<li><p>设置为当前线程的守护线程 public final void setDaemon(boolean on)</p>\n</li>\n<li><p>是否是守护线程 public final boolean isDaemon()</p>\n</li>\n</ul>\n<h2 id=\"volatile关键字\"><a href=\"#volatile关键字\" class=\"headerlink\" title=\"volatile关键字\"></a>volatile关键字</h2><p>用于修饰关键字，表示该属性为直接属性操作，不进行副本拷贝处理。<br>一些文档和书中错误的讲其描写为同步属性。</p>\n<p>在正常进行变量处理的时候一般会经历以下几个步骤：</p>\n<ol>\n<li>获取变量原有的数据内容副本</li>\n<li>利用副本为变量进行数学计算</li>\n<li>将计算后的变量保存到原始空间之中</li>\n</ol>\n<p>如果加上了volatile关键字，表示不使用副本，直接操作原始变量，相当于节约了拷贝副本</p>\n<p><img src=\"/image/volatile.png\" alt=\"volatile-photo\"></p>\n<p>volatile与synchronized的区别：</p>\n<pre><code>volatile只能描述属性，而synchronized可以用于代码块与方法。\nvolatile无法描述属性进行同步处理，只是一种直接内存的处理，避免了副本处理。\n</code></pre><p>对于volatile的详细解释，可以参考</p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/java/j-jtp06197.html\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-jtp06197.html</a></p>\n<p><a href=\"https://www.cnblogs.com/dolphin0520/p/3920373.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/dolphin0520/p/3920373.html</a></p>"},{"title":"mybatis源码学习","date":"2019-03-20T02:00:00.000Z","_content":"\n朋友介绍说mybatis源码比较适合入门的源码学习，一直以来mybatis也只是停留在最基础的使用阶段，那接下来就打算学习下mybatis的源码，记录下笔记。\n<!-- more -->\n\n# 核心组成\n- Configuration\n- SqlSessionFactory\n- Session\n- Executor\n- MappedStatement\n- StatementHandler\n- ResultSetHandler\n\n# 包目录结构\n- annotations 注解相关，如slect insert\n- binding mapper相关\n- builder dom操作、xml相关\n- cache 缓存\n- cursor 返回结果resultset\n- datasourcer 数据源管理\n- exceptions 自定义异常\n- executor 执行器\n- io classloader\n- jdbc jdbc\n- lang jdk7、jdk8\n- logging 日志相关 \n- mapping mapper相关的封装\n- parsing xml解析\n- plugin 拦截器\n- reflection 反射相关\n- scripting \n- session\n- transaction 事务相关\n- type\n\n# 大概的执行流程\n```\nSqlSesionFactoryBuilder -> parse()\n    Configuration -> build()\n        SqlSessionFactory —> openSession() \n            SqlSession -> query()\n                Executor -> newStatementHandler()\n                    StatementHandler -> handlerResultSets()\n                        ResultSetHandler\n```\n# SqlSessionFactoryBuilder\n根据配置或者类，使用build()方法生成SqlSessionFacotry\n\n主要使用的为\n- InpuStream字节流 XMLConfigBuilder，解析XML配置创建DefaultSqlSessionFactory\n- Reader字符流 同上\n- Configuration 通过类的方式直接创建\n\n## 设计模式\nSqlSessionFactoryBuilder创建SqlSessionFactory采用了建造者的设计模式，相信大家一定非常熟悉，这里SqlSessionFactoryBuilder扮演具体的建造者，Configuration类则负责建造的细节工作，SqlSession则是构造出来的产品\n\n# SqlSessionFactory\n作用：通过openSession()生产SqlSession\n\n# SqlSession\n## 作用\n1. 获取映射器，让映射器通过命名空间和方法名称找到对应的SQL，发送给数据库执行后返回结果\n2. 通过update、insert、select、delete等方法，带上SQL的id来操作在XML中配置好的SQL，从而完成工作，与此同时它也支持事务，通过commit、rollback方法提交或者回滚事务。\n\n## 四个主要对象            \n### Executor\n调度StatementHandler、ParameterHandler、ResultHandler等来执行对应的SQL。\n\nExecutorType\n- SIMPLE 简易执行器，默认执行器\n- REUSE 执行器重用预处理语句\n- BATCH 执行器重用语句和批量更新，针对批量专用的执行器\n\n### StatementHandler\n使用数据库的Statement（PrepareStatement）执行操作\n\nStatementHandler实现抽象类BaseStatementHandler的子类有以下三种，分别对应了不同类型的Executor\n- SimpleStatementHandler：对应SIMPLE执行器\n- PrepareStatementHandler：对应REUSE执行器\n- CallableStatementHandler：对应BATCH执行器\n\n### ParameterHandler\n用于SQL对参数的处理\n\n### ResultSetHandler\n进行最后数据集（ResultSet）的封装返回处理\n\n\n# Sql Mapper\n作用：\n1. 定义参数\n2. 描述缓存\n3. 描述SQL语句\n4. 定义查询结果和POJO的映射关系\n\nmapper接口类的全路径\nmapper接口包的全路径\nmapper接口全路径配置文件\nxml配置文件引入映射器\n\n# cache\n``` java\nCacheKey cacheKey = new CacheKey();\n// 设置 id、offset、limit、sql 到 CacheKey 对象中\ncacheKey.update(ms.getId());\ncacheKey.update(rowBounds.getOffset());\ncacheKey.update(rowBounds.getLimit());\ncacheKey.update(boundSql.getSql());\n```\nmybatis缓存是一次数据库会话中的，commit等操作之后就不会存在了。\n\n\n# InterceptorChain\n在公司前段时间做数据权限就是基于InterceptorChain做的，是mybatis很重要的组成部分","source":"_posts/mybatis_01.md","raw":"---\ntitle: mybatis源码学习\ndate: 2019-03-20 10:00:00\ntags: mybatis\ncategories: Java\n---\n\n朋友介绍说mybatis源码比较适合入门的源码学习，一直以来mybatis也只是停留在最基础的使用阶段，那接下来就打算学习下mybatis的源码，记录下笔记。\n<!-- more -->\n\n# 核心组成\n- Configuration\n- SqlSessionFactory\n- Session\n- Executor\n- MappedStatement\n- StatementHandler\n- ResultSetHandler\n\n# 包目录结构\n- annotations 注解相关，如slect insert\n- binding mapper相关\n- builder dom操作、xml相关\n- cache 缓存\n- cursor 返回结果resultset\n- datasourcer 数据源管理\n- exceptions 自定义异常\n- executor 执行器\n- io classloader\n- jdbc jdbc\n- lang jdk7、jdk8\n- logging 日志相关 \n- mapping mapper相关的封装\n- parsing xml解析\n- plugin 拦截器\n- reflection 反射相关\n- scripting \n- session\n- transaction 事务相关\n- type\n\n# 大概的执行流程\n```\nSqlSesionFactoryBuilder -> parse()\n    Configuration -> build()\n        SqlSessionFactory —> openSession() \n            SqlSession -> query()\n                Executor -> newStatementHandler()\n                    StatementHandler -> handlerResultSets()\n                        ResultSetHandler\n```\n# SqlSessionFactoryBuilder\n根据配置或者类，使用build()方法生成SqlSessionFacotry\n\n主要使用的为\n- InpuStream字节流 XMLConfigBuilder，解析XML配置创建DefaultSqlSessionFactory\n- Reader字符流 同上\n- Configuration 通过类的方式直接创建\n\n## 设计模式\nSqlSessionFactoryBuilder创建SqlSessionFactory采用了建造者的设计模式，相信大家一定非常熟悉，这里SqlSessionFactoryBuilder扮演具体的建造者，Configuration类则负责建造的细节工作，SqlSession则是构造出来的产品\n\n# SqlSessionFactory\n作用：通过openSession()生产SqlSession\n\n# SqlSession\n## 作用\n1. 获取映射器，让映射器通过命名空间和方法名称找到对应的SQL，发送给数据库执行后返回结果\n2. 通过update、insert、select、delete等方法，带上SQL的id来操作在XML中配置好的SQL，从而完成工作，与此同时它也支持事务，通过commit、rollback方法提交或者回滚事务。\n\n## 四个主要对象            \n### Executor\n调度StatementHandler、ParameterHandler、ResultHandler等来执行对应的SQL。\n\nExecutorType\n- SIMPLE 简易执行器，默认执行器\n- REUSE 执行器重用预处理语句\n- BATCH 执行器重用语句和批量更新，针对批量专用的执行器\n\n### StatementHandler\n使用数据库的Statement（PrepareStatement）执行操作\n\nStatementHandler实现抽象类BaseStatementHandler的子类有以下三种，分别对应了不同类型的Executor\n- SimpleStatementHandler：对应SIMPLE执行器\n- PrepareStatementHandler：对应REUSE执行器\n- CallableStatementHandler：对应BATCH执行器\n\n### ParameterHandler\n用于SQL对参数的处理\n\n### ResultSetHandler\n进行最后数据集（ResultSet）的封装返回处理\n\n\n# Sql Mapper\n作用：\n1. 定义参数\n2. 描述缓存\n3. 描述SQL语句\n4. 定义查询结果和POJO的映射关系\n\nmapper接口类的全路径\nmapper接口包的全路径\nmapper接口全路径配置文件\nxml配置文件引入映射器\n\n# cache\n``` java\nCacheKey cacheKey = new CacheKey();\n// 设置 id、offset、limit、sql 到 CacheKey 对象中\ncacheKey.update(ms.getId());\ncacheKey.update(rowBounds.getOffset());\ncacheKey.update(rowBounds.getLimit());\ncacheKey.update(boundSql.getSql());\n```\nmybatis缓存是一次数据库会话中的，commit等操作之后就不会存在了。\n\n\n# InterceptorChain\n在公司前段时间做数据权限就是基于InterceptorChain做的，是mybatis很重要的组成部分","slug":"mybatis_01","published":1,"updated":"2020-05-16T15:12:28.068Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0s001vqotn92gdmcjl","content":"<p>朋友介绍说mybatis源码比较适合入门的源码学习，一直以来mybatis也只是停留在最基础的使用阶段，那接下来就打算学习下mybatis的源码，记录下笔记。<br><a id=\"more\"></a></p>\n<h1 id=\"核心组成\"><a href=\"#核心组成\" class=\"headerlink\" title=\"核心组成\"></a>核心组成</h1><ul>\n<li>Configuration</li>\n<li>SqlSessionFactory</li>\n<li>Session</li>\n<li>Executor</li>\n<li>MappedStatement</li>\n<li>StatementHandler</li>\n<li>ResultSetHandler</li>\n</ul>\n<h1 id=\"包目录结构\"><a href=\"#包目录结构\" class=\"headerlink\" title=\"包目录结构\"></a>包目录结构</h1><ul>\n<li>annotations 注解相关，如slect insert</li>\n<li>binding mapper相关</li>\n<li>builder dom操作、xml相关</li>\n<li>cache 缓存</li>\n<li>cursor 返回结果resultset</li>\n<li>datasourcer 数据源管理</li>\n<li>exceptions 自定义异常</li>\n<li>executor 执行器</li>\n<li>io classloader</li>\n<li>jdbc jdbc</li>\n<li>lang jdk7、jdk8</li>\n<li>logging 日志相关 </li>\n<li>mapping mapper相关的封装</li>\n<li>parsing xml解析</li>\n<li>plugin 拦截器</li>\n<li>reflection 反射相关</li>\n<li>scripting </li>\n<li>session</li>\n<li>transaction 事务相关</li>\n<li>type</li>\n</ul>\n<h1 id=\"大概的执行流程\"><a href=\"#大概的执行流程\" class=\"headerlink\" title=\"大概的执行流程\"></a>大概的执行流程</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SqlSesionFactoryBuilder -&gt; parse()</span><br><span class=\"line\">    Configuration -&gt; build()</span><br><span class=\"line\">        SqlSessionFactory —&gt; openSession() </span><br><span class=\"line\">            SqlSession -&gt; query()</span><br><span class=\"line\">                Executor -&gt; newStatementHandler()</span><br><span class=\"line\">                    StatementHandler -&gt; handlerResultSets()</span><br><span class=\"line\">                        ResultSetHandler</span><br></pre></td></tr></table></figure>\n<h1 id=\"SqlSessionFactoryBuilder\"><a href=\"#SqlSessionFactoryBuilder\" class=\"headerlink\" title=\"SqlSessionFactoryBuilder\"></a>SqlSessionFactoryBuilder</h1><p>根据配置或者类，使用build()方法生成SqlSessionFacotry</p>\n<p>主要使用的为</p>\n<ul>\n<li>InpuStream字节流 XMLConfigBuilder，解析XML配置创建DefaultSqlSessionFactory</li>\n<li>Reader字符流 同上</li>\n<li>Configuration 通过类的方式直接创建</li>\n</ul>\n<h2 id=\"设计模式\"><a href=\"#设计模式\" class=\"headerlink\" title=\"设计模式\"></a>设计模式</h2><p>SqlSessionFactoryBuilder创建SqlSessionFactory采用了建造者的设计模式，相信大家一定非常熟悉，这里SqlSessionFactoryBuilder扮演具体的建造者，Configuration类则负责建造的细节工作，SqlSession则是构造出来的产品</p>\n<h1 id=\"SqlSessionFactory\"><a href=\"#SqlSessionFactory\" class=\"headerlink\" title=\"SqlSessionFactory\"></a>SqlSessionFactory</h1><p>作用：通过openSession()生产SqlSession</p>\n<h1 id=\"SqlSession\"><a href=\"#SqlSession\" class=\"headerlink\" title=\"SqlSession\"></a>SqlSession</h1><h2 id=\"作用\"><a href=\"#作用\" class=\"headerlink\" title=\"作用\"></a>作用</h2><ol>\n<li>获取映射器，让映射器通过命名空间和方法名称找到对应的SQL，发送给数据库执行后返回结果</li>\n<li>通过update、insert、select、delete等方法，带上SQL的id来操作在XML中配置好的SQL，从而完成工作，与此同时它也支持事务，通过commit、rollback方法提交或者回滚事务。</li>\n</ol>\n<h2 id=\"四个主要对象\"><a href=\"#四个主要对象\" class=\"headerlink\" title=\"四个主要对象\"></a>四个主要对象</h2><h3 id=\"Executor\"><a href=\"#Executor\" class=\"headerlink\" title=\"Executor\"></a>Executor</h3><p>调度StatementHandler、ParameterHandler、ResultHandler等来执行对应的SQL。</p>\n<p>ExecutorType</p>\n<ul>\n<li>SIMPLE 简易执行器，默认执行器</li>\n<li>REUSE 执行器重用预处理语句</li>\n<li>BATCH 执行器重用语句和批量更新，针对批量专用的执行器</li>\n</ul>\n<h3 id=\"StatementHandler\"><a href=\"#StatementHandler\" class=\"headerlink\" title=\"StatementHandler\"></a>StatementHandler</h3><p>使用数据库的Statement（PrepareStatement）执行操作</p>\n<p>StatementHandler实现抽象类BaseStatementHandler的子类有以下三种，分别对应了不同类型的Executor</p>\n<ul>\n<li>SimpleStatementHandler：对应SIMPLE执行器</li>\n<li>PrepareStatementHandler：对应REUSE执行器</li>\n<li>CallableStatementHandler：对应BATCH执行器</li>\n</ul>\n<h3 id=\"ParameterHandler\"><a href=\"#ParameterHandler\" class=\"headerlink\" title=\"ParameterHandler\"></a>ParameterHandler</h3><p>用于SQL对参数的处理</p>\n<h3 id=\"ResultSetHandler\"><a href=\"#ResultSetHandler\" class=\"headerlink\" title=\"ResultSetHandler\"></a>ResultSetHandler</h3><p>进行最后数据集（ResultSet）的封装返回处理</p>\n<h1 id=\"Sql-Mapper\"><a href=\"#Sql-Mapper\" class=\"headerlink\" title=\"Sql Mapper\"></a>Sql Mapper</h1><p>作用：</p>\n<ol>\n<li>定义参数</li>\n<li>描述缓存</li>\n<li>描述SQL语句</li>\n<li>定义查询结果和POJO的映射关系</li>\n</ol>\n<p>mapper接口类的全路径<br>mapper接口包的全路径<br>mapper接口全路径配置文件<br>xml配置文件引入映射器</p>\n<h1 id=\"cache\"><a href=\"#cache\" class=\"headerlink\" title=\"cache\"></a>cache</h1><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CacheKey cacheKey = <span class=\"keyword\">new</span> CacheKey();</span><br><span class=\"line\"><span class=\"comment\">// 设置 id、offset、limit、sql 到 CacheKey 对象中</span></span><br><span class=\"line\">cacheKey.update(ms.getId());</span><br><span class=\"line\">cacheKey.update(rowBounds.getOffset());</span><br><span class=\"line\">cacheKey.update(rowBounds.getLimit());</span><br><span class=\"line\">cacheKey.update(boundSql.getSql());</span><br></pre></td></tr></table></figure>\n<p>mybatis缓存是一次数据库会话中的，commit等操作之后就不会存在了。</p>\n<h1 id=\"InterceptorChain\"><a href=\"#InterceptorChain\" class=\"headerlink\" title=\"InterceptorChain\"></a>InterceptorChain</h1><p>在公司前段时间做数据权限就是基于InterceptorChain做的，是mybatis很重要的组成部分</p>\n","site":{"data":{}},"excerpt":"<p>朋友介绍说mybatis源码比较适合入门的源码学习，一直以来mybatis也只是停留在最基础的使用阶段，那接下来就打算学习下mybatis的源码，记录下笔记。<br>","more":"</p>\n<h1 id=\"核心组成\"><a href=\"#核心组成\" class=\"headerlink\" title=\"核心组成\"></a>核心组成</h1><ul>\n<li>Configuration</li>\n<li>SqlSessionFactory</li>\n<li>Session</li>\n<li>Executor</li>\n<li>MappedStatement</li>\n<li>StatementHandler</li>\n<li>ResultSetHandler</li>\n</ul>\n<h1 id=\"包目录结构\"><a href=\"#包目录结构\" class=\"headerlink\" title=\"包目录结构\"></a>包目录结构</h1><ul>\n<li>annotations 注解相关，如slect insert</li>\n<li>binding mapper相关</li>\n<li>builder dom操作、xml相关</li>\n<li>cache 缓存</li>\n<li>cursor 返回结果resultset</li>\n<li>datasourcer 数据源管理</li>\n<li>exceptions 自定义异常</li>\n<li>executor 执行器</li>\n<li>io classloader</li>\n<li>jdbc jdbc</li>\n<li>lang jdk7、jdk8</li>\n<li>logging 日志相关 </li>\n<li>mapping mapper相关的封装</li>\n<li>parsing xml解析</li>\n<li>plugin 拦截器</li>\n<li>reflection 反射相关</li>\n<li>scripting </li>\n<li>session</li>\n<li>transaction 事务相关</li>\n<li>type</li>\n</ul>\n<h1 id=\"大概的执行流程\"><a href=\"#大概的执行流程\" class=\"headerlink\" title=\"大概的执行流程\"></a>大概的执行流程</h1><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SqlSesionFactoryBuilder -&gt; parse()</span><br><span class=\"line\">    Configuration -&gt; build()</span><br><span class=\"line\">        SqlSessionFactory —&gt; openSession() </span><br><span class=\"line\">            SqlSession -&gt; query()</span><br><span class=\"line\">                Executor -&gt; newStatementHandler()</span><br><span class=\"line\">                    StatementHandler -&gt; handlerResultSets()</span><br><span class=\"line\">                        ResultSetHandler</span><br></pre></td></tr></table></figure>\n<h1 id=\"SqlSessionFactoryBuilder\"><a href=\"#SqlSessionFactoryBuilder\" class=\"headerlink\" title=\"SqlSessionFactoryBuilder\"></a>SqlSessionFactoryBuilder</h1><p>根据配置或者类，使用build()方法生成SqlSessionFacotry</p>\n<p>主要使用的为</p>\n<ul>\n<li>InpuStream字节流 XMLConfigBuilder，解析XML配置创建DefaultSqlSessionFactory</li>\n<li>Reader字符流 同上</li>\n<li>Configuration 通过类的方式直接创建</li>\n</ul>\n<h2 id=\"设计模式\"><a href=\"#设计模式\" class=\"headerlink\" title=\"设计模式\"></a>设计模式</h2><p>SqlSessionFactoryBuilder创建SqlSessionFactory采用了建造者的设计模式，相信大家一定非常熟悉，这里SqlSessionFactoryBuilder扮演具体的建造者，Configuration类则负责建造的细节工作，SqlSession则是构造出来的产品</p>\n<h1 id=\"SqlSessionFactory\"><a href=\"#SqlSessionFactory\" class=\"headerlink\" title=\"SqlSessionFactory\"></a>SqlSessionFactory</h1><p>作用：通过openSession()生产SqlSession</p>\n<h1 id=\"SqlSession\"><a href=\"#SqlSession\" class=\"headerlink\" title=\"SqlSession\"></a>SqlSession</h1><h2 id=\"作用\"><a href=\"#作用\" class=\"headerlink\" title=\"作用\"></a>作用</h2><ol>\n<li>获取映射器，让映射器通过命名空间和方法名称找到对应的SQL，发送给数据库执行后返回结果</li>\n<li>通过update、insert、select、delete等方法，带上SQL的id来操作在XML中配置好的SQL，从而完成工作，与此同时它也支持事务，通过commit、rollback方法提交或者回滚事务。</li>\n</ol>\n<h2 id=\"四个主要对象\"><a href=\"#四个主要对象\" class=\"headerlink\" title=\"四个主要对象\"></a>四个主要对象</h2><h3 id=\"Executor\"><a href=\"#Executor\" class=\"headerlink\" title=\"Executor\"></a>Executor</h3><p>调度StatementHandler、ParameterHandler、ResultHandler等来执行对应的SQL。</p>\n<p>ExecutorType</p>\n<ul>\n<li>SIMPLE 简易执行器，默认执行器</li>\n<li>REUSE 执行器重用预处理语句</li>\n<li>BATCH 执行器重用语句和批量更新，针对批量专用的执行器</li>\n</ul>\n<h3 id=\"StatementHandler\"><a href=\"#StatementHandler\" class=\"headerlink\" title=\"StatementHandler\"></a>StatementHandler</h3><p>使用数据库的Statement（PrepareStatement）执行操作</p>\n<p>StatementHandler实现抽象类BaseStatementHandler的子类有以下三种，分别对应了不同类型的Executor</p>\n<ul>\n<li>SimpleStatementHandler：对应SIMPLE执行器</li>\n<li>PrepareStatementHandler：对应REUSE执行器</li>\n<li>CallableStatementHandler：对应BATCH执行器</li>\n</ul>\n<h3 id=\"ParameterHandler\"><a href=\"#ParameterHandler\" class=\"headerlink\" title=\"ParameterHandler\"></a>ParameterHandler</h3><p>用于SQL对参数的处理</p>\n<h3 id=\"ResultSetHandler\"><a href=\"#ResultSetHandler\" class=\"headerlink\" title=\"ResultSetHandler\"></a>ResultSetHandler</h3><p>进行最后数据集（ResultSet）的封装返回处理</p>\n<h1 id=\"Sql-Mapper\"><a href=\"#Sql-Mapper\" class=\"headerlink\" title=\"Sql Mapper\"></a>Sql Mapper</h1><p>作用：</p>\n<ol>\n<li>定义参数</li>\n<li>描述缓存</li>\n<li>描述SQL语句</li>\n<li>定义查询结果和POJO的映射关系</li>\n</ol>\n<p>mapper接口类的全路径<br>mapper接口包的全路径<br>mapper接口全路径配置文件<br>xml配置文件引入映射器</p>\n<h1 id=\"cache\"><a href=\"#cache\" class=\"headerlink\" title=\"cache\"></a>cache</h1><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CacheKey cacheKey = <span class=\"keyword\">new</span> CacheKey();</span><br><span class=\"line\"><span class=\"comment\">// 设置 id、offset、limit、sql 到 CacheKey 对象中</span></span><br><span class=\"line\">cacheKey.update(ms.getId());</span><br><span class=\"line\">cacheKey.update(rowBounds.getOffset());</span><br><span class=\"line\">cacheKey.update(rowBounds.getLimit());</span><br><span class=\"line\">cacheKey.update(boundSql.getSql());</span><br></pre></td></tr></table></figure>\n<p>mybatis缓存是一次数据库会话中的，commit等操作之后就不会存在了。</p>\n<h1 id=\"InterceptorChain\"><a href=\"#InterceptorChain\" class=\"headerlink\" title=\"InterceptorChain\"></a>InterceptorChain</h1><p>在公司前段时间做数据权限就是基于InterceptorChain做的，是mybatis很重要的组成部分</p>"},{"title":"事务相关基本概念","date":"2019-03-06T03:00:00.000Z","_content":"\n> 在学习spring框架中事务相关的源码，还有学习一些分布式事务相关知识之前，先温习下事务相关的基础知识，后续还会进行更新和补充。\n\n<!-- more -->\n\n# 事务特性\n事务特性分为四个：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持续性（Durability）简称ACID\n## 原子性（Atomicity）\n事务是数据库逻辑工作单元，事务中包含的操作要么全部执行成功，要么全部失败。\n## 一致性（Consistency）\n事务执行的结果必须是使数据库数据从一个一致性状态变到另外一种一致性状态。当事务执行成功后就说明数据库处于一致性状态。如果在执行过程中发生错误，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于不一致状态。\n## 隔离性（Isolation）\n一个事务的执行过程中不能影响到其他事务的执行，即一个事务内部的操作及其使用的数据对其他事务是隔离的，并发执行各个事务之间无不干扰。\n## 持续性（Durability）\n即一个事务执一旦提交，它对数据库数据的改变是永久性的。之后的其它操作不应该对其执行结果有任何影响。\n\n# 事务隔离级别\n事务的隔离级别也分为四种，由低到高依次分别为：read uncommited（读未提交）、read commited（读提交）、read repeatable（读重复）、serializable（序列化），这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。\n## 读未提交（read uncommited）\n最低的事务隔离级别，它允许另外一个事务可以看到这个事务未提交的数据。\n## 读提交（read commited）\n保证一个事务提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。\n## 读重复（read repeatable）\n这种事务隔离级别可以防止脏读，不可重复读。但是可能会出现幻象读。它除了保证一个事务不能被另外一个事务读取未提交的数据之外还避免了以下情况产生（不可重复读）。\n## 序列化（serializable）\n这是花费最高代价但最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读之外，还避免了幻象读。\n\n# 脏读、不可重复读、幻读\n## 脏读\n指当一个事务正字访问数据，并且对数据进行了修改，而这种数据还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据还没有提交那么另外一个事务读取到的这个数据我们称之为脏数据。依据脏数据所做的操作可能是不正确的。\n## 不可重复读\n指在一个事务内，多次读同一数据。在这个事务还没有执行结束，另外一个事务也访问该同一数据，那么在第一个事务中的两次读取数据之间，由于第二个事务的修改第一个事务两次读到的数据可能是不一样的，这样就发生了在一个事物内两次连续读到的数据是不一样的，这种情况被称为是不可重复读。\n## 幻读\n一个事务先后读取一个范围的记录，但两次读取的纪录数不同，我们称之为幻象读（两次执行同一条select语句会出现不同的结果，第二次读会增加一数据行，并没有说这两次执行是在同一个事务中）\n\n# 隔离级别与数据读取问题的关系\n√：可能出现;×：不可能出现 | 脏读 | 不可重复读 | 幻读\n---|---|---|---\n读未提交（read uncommited） | √ | √ | √\n读提交（read commited）     | × | √ | √ \n读重复（read repeatable）   | × | × | √ \n序列化（serializable）      | × | × | × \n\n\n# spring支持的7种事务传播特性\n## propagation_required\n如果当前没有事务就创建一个，如果有就加入到这个事务中。Spring默认的事务传播特性。\n## propagation_supports\n支持当前事务，如果没有当前事务，就以非事务方式执行。\n## propagation_mandatory\n使用当前事务，如果没有当前事务则抛出异常。\n## propagation_required_new\n新建事务，如果当前存在事务，把当前事务挂起。\n## propagation_not_supported\n以非事务方式执行操作，如果当前存在事务，把当前事务挂起。\n## propagation_never\n以非事务方式执行操作，如果当前存在事务则抛出异常。\n## propagation_nested\n如果当前存在事务，则在嵌套事务内执行。如果当前无事务，则执行与propagation_required相同的操作。\n\n","source":"_posts/事务相关基本概念.md","raw":"---\ntitle: 事务相关基本概念\ndate: 2019-03-06 11:00:00\ntags: 事务\ncategories: 其他\n---\n\n> 在学习spring框架中事务相关的源码，还有学习一些分布式事务相关知识之前，先温习下事务相关的基础知识，后续还会进行更新和补充。\n\n<!-- more -->\n\n# 事务特性\n事务特性分为四个：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持续性（Durability）简称ACID\n## 原子性（Atomicity）\n事务是数据库逻辑工作单元，事务中包含的操作要么全部执行成功，要么全部失败。\n## 一致性（Consistency）\n事务执行的结果必须是使数据库数据从一个一致性状态变到另外一种一致性状态。当事务执行成功后就说明数据库处于一致性状态。如果在执行过程中发生错误，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于不一致状态。\n## 隔离性（Isolation）\n一个事务的执行过程中不能影响到其他事务的执行，即一个事务内部的操作及其使用的数据对其他事务是隔离的，并发执行各个事务之间无不干扰。\n## 持续性（Durability）\n即一个事务执一旦提交，它对数据库数据的改变是永久性的。之后的其它操作不应该对其执行结果有任何影响。\n\n# 事务隔离级别\n事务的隔离级别也分为四种，由低到高依次分别为：read uncommited（读未提交）、read commited（读提交）、read repeatable（读重复）、serializable（序列化），这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。\n## 读未提交（read uncommited）\n最低的事务隔离级别，它允许另外一个事务可以看到这个事务未提交的数据。\n## 读提交（read commited）\n保证一个事务提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。\n## 读重复（read repeatable）\n这种事务隔离级别可以防止脏读，不可重复读。但是可能会出现幻象读。它除了保证一个事务不能被另外一个事务读取未提交的数据之外还避免了以下情况产生（不可重复读）。\n## 序列化（serializable）\n这是花费最高代价但最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读之外，还避免了幻象读。\n\n# 脏读、不可重复读、幻读\n## 脏读\n指当一个事务正字访问数据，并且对数据进行了修改，而这种数据还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据还没有提交那么另外一个事务读取到的这个数据我们称之为脏数据。依据脏数据所做的操作可能是不正确的。\n## 不可重复读\n指在一个事务内，多次读同一数据。在这个事务还没有执行结束，另外一个事务也访问该同一数据，那么在第一个事务中的两次读取数据之间，由于第二个事务的修改第一个事务两次读到的数据可能是不一样的，这样就发生了在一个事物内两次连续读到的数据是不一样的，这种情况被称为是不可重复读。\n## 幻读\n一个事务先后读取一个范围的记录，但两次读取的纪录数不同，我们称之为幻象读（两次执行同一条select语句会出现不同的结果，第二次读会增加一数据行，并没有说这两次执行是在同一个事务中）\n\n# 隔离级别与数据读取问题的关系\n√：可能出现;×：不可能出现 | 脏读 | 不可重复读 | 幻读\n---|---|---|---\n读未提交（read uncommited） | √ | √ | √\n读提交（read commited）     | × | √ | √ \n读重复（read repeatable）   | × | × | √ \n序列化（serializable）      | × | × | × \n\n\n# spring支持的7种事务传播特性\n## propagation_required\n如果当前没有事务就创建一个，如果有就加入到这个事务中。Spring默认的事务传播特性。\n## propagation_supports\n支持当前事务，如果没有当前事务，就以非事务方式执行。\n## propagation_mandatory\n使用当前事务，如果没有当前事务则抛出异常。\n## propagation_required_new\n新建事务，如果当前存在事务，把当前事务挂起。\n## propagation_not_supported\n以非事务方式执行操作，如果当前存在事务，把当前事务挂起。\n## propagation_never\n以非事务方式执行操作，如果当前存在事务则抛出异常。\n## propagation_nested\n如果当前存在事务，则在嵌套事务内执行。如果当前无事务，则执行与propagation_required相同的操作。\n\n","slug":"事务相关基本概念","published":1,"updated":"2019-08-26T07:57:13.711Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0v0020qotn4z9k3ynx","content":"<blockquote>\n<p>在学习spring框架中事务相关的源码，还有学习一些分布式事务相关知识之前，先温习下事务相关的基础知识，后续还会进行更新和补充。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"事务特性\"><a href=\"#事务特性\" class=\"headerlink\" title=\"事务特性\"></a>事务特性</h1><p>事务特性分为四个：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持续性（Durability）简称ACID</p>\n<h2 id=\"原子性（Atomicity）\"><a href=\"#原子性（Atomicity）\" class=\"headerlink\" title=\"原子性（Atomicity）\"></a>原子性（Atomicity）</h2><p>事务是数据库逻辑工作单元，事务中包含的操作要么全部执行成功，要么全部失败。</p>\n<h2 id=\"一致性（Consistency）\"><a href=\"#一致性（Consistency）\" class=\"headerlink\" title=\"一致性（Consistency）\"></a>一致性（Consistency）</h2><p>事务执行的结果必须是使数据库数据从一个一致性状态变到另外一种一致性状态。当事务执行成功后就说明数据库处于一致性状态。如果在执行过程中发生错误，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于不一致状态。</p>\n<h2 id=\"隔离性（Isolation）\"><a href=\"#隔离性（Isolation）\" class=\"headerlink\" title=\"隔离性（Isolation）\"></a>隔离性（Isolation）</h2><p>一个事务的执行过程中不能影响到其他事务的执行，即一个事务内部的操作及其使用的数据对其他事务是隔离的，并发执行各个事务之间无不干扰。</p>\n<h2 id=\"持续性（Durability）\"><a href=\"#持续性（Durability）\" class=\"headerlink\" title=\"持续性（Durability）\"></a>持续性（Durability）</h2><p>即一个事务执一旦提交，它对数据库数据的改变是永久性的。之后的其它操作不应该对其执行结果有任何影响。</p>\n<h1 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h1><p>事务的隔离级别也分为四种，由低到高依次分别为：read uncommited（读未提交）、read commited（读提交）、read repeatable（读重复）、serializable（序列化），这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。</p>\n<h2 id=\"读未提交（read-uncommited）\"><a href=\"#读未提交（read-uncommited）\" class=\"headerlink\" title=\"读未提交（read uncommited）\"></a>读未提交（read uncommited）</h2><p>最低的事务隔离级别，它允许另外一个事务可以看到这个事务未提交的数据。</p>\n<h2 id=\"读提交（read-commited）\"><a href=\"#读提交（read-commited）\" class=\"headerlink\" title=\"读提交（read commited）\"></a>读提交（read commited）</h2><p>保证一个事务提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。</p>\n<h2 id=\"读重复（read-repeatable）\"><a href=\"#读重复（read-repeatable）\" class=\"headerlink\" title=\"读重复（read repeatable）\"></a>读重复（read repeatable）</h2><p>这种事务隔离级别可以防止脏读，不可重复读。但是可能会出现幻象读。它除了保证一个事务不能被另外一个事务读取未提交的数据之外还避免了以下情况产生（不可重复读）。</p>\n<h2 id=\"序列化（serializable）\"><a href=\"#序列化（serializable）\" class=\"headerlink\" title=\"序列化（serializable）\"></a>序列化（serializable）</h2><p>这是花费最高代价但最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读之外，还避免了幻象读。</p>\n<h1 id=\"脏读、不可重复读、幻读\"><a href=\"#脏读、不可重复读、幻读\" class=\"headerlink\" title=\"脏读、不可重复读、幻读\"></a>脏读、不可重复读、幻读</h1><h2 id=\"脏读\"><a href=\"#脏读\" class=\"headerlink\" title=\"脏读\"></a>脏读</h2><p>指当一个事务正字访问数据，并且对数据进行了修改，而这种数据还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据还没有提交那么另外一个事务读取到的这个数据我们称之为脏数据。依据脏数据所做的操作可能是不正确的。</p>\n<h2 id=\"不可重复读\"><a href=\"#不可重复读\" class=\"headerlink\" title=\"不可重复读\"></a>不可重复读</h2><p>指在一个事务内，多次读同一数据。在这个事务还没有执行结束，另外一个事务也访问该同一数据，那么在第一个事务中的两次读取数据之间，由于第二个事务的修改第一个事务两次读到的数据可能是不一样的，这样就发生了在一个事物内两次连续读到的数据是不一样的，这种情况被称为是不可重复读。</p>\n<h2 id=\"幻读\"><a href=\"#幻读\" class=\"headerlink\" title=\"幻读\"></a>幻读</h2><p>一个事务先后读取一个范围的记录，但两次读取的纪录数不同，我们称之为幻象读（两次执行同一条select语句会出现不同的结果，第二次读会增加一数据行，并没有说这两次执行是在同一个事务中）</p>\n<h1 id=\"隔离级别与数据读取问题的关系\"><a href=\"#隔离级别与数据读取问题的关系\" class=\"headerlink\" title=\"隔离级别与数据读取问题的关系\"></a>隔离级别与数据读取问题的关系</h1><table>\n<thead>\n<tr>\n<th>√：可能出现;×：不可能出现</th>\n<th>脏读</th>\n<th>不可重复读</th>\n<th>幻读</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>读未提交（read uncommited）</td>\n<td>√</td>\n<td>√</td>\n<td>√</td>\n</tr>\n<tr>\n<td>读提交（read commited）</td>\n<td>×</td>\n<td>√</td>\n<td>√ </td>\n</tr>\n<tr>\n<td>读重复（read repeatable）</td>\n<td>×</td>\n<td>×</td>\n<td>√ </td>\n</tr>\n<tr>\n<td>序列化（serializable）</td>\n<td>×</td>\n<td>×</td>\n<td>× </td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"spring支持的7种事务传播特性\"><a href=\"#spring支持的7种事务传播特性\" class=\"headerlink\" title=\"spring支持的7种事务传播特性\"></a>spring支持的7种事务传播特性</h1><h2 id=\"propagation-required\"><a href=\"#propagation-required\" class=\"headerlink\" title=\"propagation_required\"></a>propagation_required</h2><p>如果当前没有事务就创建一个，如果有就加入到这个事务中。Spring默认的事务传播特性。</p>\n<h2 id=\"propagation-supports\"><a href=\"#propagation-supports\" class=\"headerlink\" title=\"propagation_supports\"></a>propagation_supports</h2><p>支持当前事务，如果没有当前事务，就以非事务方式执行。</p>\n<h2 id=\"propagation-mandatory\"><a href=\"#propagation-mandatory\" class=\"headerlink\" title=\"propagation_mandatory\"></a>propagation_mandatory</h2><p>使用当前事务，如果没有当前事务则抛出异常。</p>\n<h2 id=\"propagation-required-new\"><a href=\"#propagation-required-new\" class=\"headerlink\" title=\"propagation_required_new\"></a>propagation_required_new</h2><p>新建事务，如果当前存在事务，把当前事务挂起。</p>\n<h2 id=\"propagation-not-supported\"><a href=\"#propagation-not-supported\" class=\"headerlink\" title=\"propagation_not_supported\"></a>propagation_not_supported</h2><p>以非事务方式执行操作，如果当前存在事务，把当前事务挂起。</p>\n<h2 id=\"propagation-never\"><a href=\"#propagation-never\" class=\"headerlink\" title=\"propagation_never\"></a>propagation_never</h2><p>以非事务方式执行操作，如果当前存在事务则抛出异常。</p>\n<h2 id=\"propagation-nested\"><a href=\"#propagation-nested\" class=\"headerlink\" title=\"propagation_nested\"></a>propagation_nested</h2><p>如果当前存在事务，则在嵌套事务内执行。如果当前无事务，则执行与propagation_required相同的操作。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>在学习spring框架中事务相关的源码，还有学习一些分布式事务相关知识之前，先温习下事务相关的基础知识，后续还会进行更新和补充。</p>\n</blockquote>","more":"<h1 id=\"事务特性\"><a href=\"#事务特性\" class=\"headerlink\" title=\"事务特性\"></a>事务特性</h1><p>事务特性分为四个：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持续性（Durability）简称ACID</p>\n<h2 id=\"原子性（Atomicity）\"><a href=\"#原子性（Atomicity）\" class=\"headerlink\" title=\"原子性（Atomicity）\"></a>原子性（Atomicity）</h2><p>事务是数据库逻辑工作单元，事务中包含的操作要么全部执行成功，要么全部失败。</p>\n<h2 id=\"一致性（Consistency）\"><a href=\"#一致性（Consistency）\" class=\"headerlink\" title=\"一致性（Consistency）\"></a>一致性（Consistency）</h2><p>事务执行的结果必须是使数据库数据从一个一致性状态变到另外一种一致性状态。当事务执行成功后就说明数据库处于一致性状态。如果在执行过程中发生错误，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于不一致状态。</p>\n<h2 id=\"隔离性（Isolation）\"><a href=\"#隔离性（Isolation）\" class=\"headerlink\" title=\"隔离性（Isolation）\"></a>隔离性（Isolation）</h2><p>一个事务的执行过程中不能影响到其他事务的执行，即一个事务内部的操作及其使用的数据对其他事务是隔离的，并发执行各个事务之间无不干扰。</p>\n<h2 id=\"持续性（Durability）\"><a href=\"#持续性（Durability）\" class=\"headerlink\" title=\"持续性（Durability）\"></a>持续性（Durability）</h2><p>即一个事务执一旦提交，它对数据库数据的改变是永久性的。之后的其它操作不应该对其执行结果有任何影响。</p>\n<h1 id=\"事务隔离级别\"><a href=\"#事务隔离级别\" class=\"headerlink\" title=\"事务隔离级别\"></a>事务隔离级别</h1><p>事务的隔离级别也分为四种，由低到高依次分别为：read uncommited（读未提交）、read commited（读提交）、read repeatable（读重复）、serializable（序列化），这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。</p>\n<h2 id=\"读未提交（read-uncommited）\"><a href=\"#读未提交（read-uncommited）\" class=\"headerlink\" title=\"读未提交（read uncommited）\"></a>读未提交（read uncommited）</h2><p>最低的事务隔离级别，它允许另外一个事务可以看到这个事务未提交的数据。</p>\n<h2 id=\"读提交（read-commited）\"><a href=\"#读提交（read-commited）\" class=\"headerlink\" title=\"读提交（read commited）\"></a>读提交（read commited）</h2><p>保证一个事务提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。</p>\n<h2 id=\"读重复（read-repeatable）\"><a href=\"#读重复（read-repeatable）\" class=\"headerlink\" title=\"读重复（read repeatable）\"></a>读重复（read repeatable）</h2><p>这种事务隔离级别可以防止脏读，不可重复读。但是可能会出现幻象读。它除了保证一个事务不能被另外一个事务读取未提交的数据之外还避免了以下情况产生（不可重复读）。</p>\n<h2 id=\"序列化（serializable）\"><a href=\"#序列化（serializable）\" class=\"headerlink\" title=\"序列化（serializable）\"></a>序列化（serializable）</h2><p>这是花费最高代价但最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读之外，还避免了幻象读。</p>\n<h1 id=\"脏读、不可重复读、幻读\"><a href=\"#脏读、不可重复读、幻读\" class=\"headerlink\" title=\"脏读、不可重复读、幻读\"></a>脏读、不可重复读、幻读</h1><h2 id=\"脏读\"><a href=\"#脏读\" class=\"headerlink\" title=\"脏读\"></a>脏读</h2><p>指当一个事务正字访问数据，并且对数据进行了修改，而这种数据还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据还没有提交那么另外一个事务读取到的这个数据我们称之为脏数据。依据脏数据所做的操作可能是不正确的。</p>\n<h2 id=\"不可重复读\"><a href=\"#不可重复读\" class=\"headerlink\" title=\"不可重复读\"></a>不可重复读</h2><p>指在一个事务内，多次读同一数据。在这个事务还没有执行结束，另外一个事务也访问该同一数据，那么在第一个事务中的两次读取数据之间，由于第二个事务的修改第一个事务两次读到的数据可能是不一样的，这样就发生了在一个事物内两次连续读到的数据是不一样的，这种情况被称为是不可重复读。</p>\n<h2 id=\"幻读\"><a href=\"#幻读\" class=\"headerlink\" title=\"幻读\"></a>幻读</h2><p>一个事务先后读取一个范围的记录，但两次读取的纪录数不同，我们称之为幻象读（两次执行同一条select语句会出现不同的结果，第二次读会增加一数据行，并没有说这两次执行是在同一个事务中）</p>\n<h1 id=\"隔离级别与数据读取问题的关系\"><a href=\"#隔离级别与数据读取问题的关系\" class=\"headerlink\" title=\"隔离级别与数据读取问题的关系\"></a>隔离级别与数据读取问题的关系</h1><table>\n<thead>\n<tr>\n<th>√：可能出现;×：不可能出现</th>\n<th>脏读</th>\n<th>不可重复读</th>\n<th>幻读</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>读未提交（read uncommited）</td>\n<td>√</td>\n<td>√</td>\n<td>√</td>\n</tr>\n<tr>\n<td>读提交（read commited）</td>\n<td>×</td>\n<td>√</td>\n<td>√ </td>\n</tr>\n<tr>\n<td>读重复（read repeatable）</td>\n<td>×</td>\n<td>×</td>\n<td>√ </td>\n</tr>\n<tr>\n<td>序列化（serializable）</td>\n<td>×</td>\n<td>×</td>\n<td>× </td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"spring支持的7种事务传播特性\"><a href=\"#spring支持的7种事务传播特性\" class=\"headerlink\" title=\"spring支持的7种事务传播特性\"></a>spring支持的7种事务传播特性</h1><h2 id=\"propagation-required\"><a href=\"#propagation-required\" class=\"headerlink\" title=\"propagation_required\"></a>propagation_required</h2><p>如果当前没有事务就创建一个，如果有就加入到这个事务中。Spring默认的事务传播特性。</p>\n<h2 id=\"propagation-supports\"><a href=\"#propagation-supports\" class=\"headerlink\" title=\"propagation_supports\"></a>propagation_supports</h2><p>支持当前事务，如果没有当前事务，就以非事务方式执行。</p>\n<h2 id=\"propagation-mandatory\"><a href=\"#propagation-mandatory\" class=\"headerlink\" title=\"propagation_mandatory\"></a>propagation_mandatory</h2><p>使用当前事务，如果没有当前事务则抛出异常。</p>\n<h2 id=\"propagation-required-new\"><a href=\"#propagation-required-new\" class=\"headerlink\" title=\"propagation_required_new\"></a>propagation_required_new</h2><p>新建事务，如果当前存在事务，把当前事务挂起。</p>\n<h2 id=\"propagation-not-supported\"><a href=\"#propagation-not-supported\" class=\"headerlink\" title=\"propagation_not_supported\"></a>propagation_not_supported</h2><p>以非事务方式执行操作，如果当前存在事务，把当前事务挂起。</p>\n<h2 id=\"propagation-never\"><a href=\"#propagation-never\" class=\"headerlink\" title=\"propagation_never\"></a>propagation_never</h2><p>以非事务方式执行操作，如果当前存在事务则抛出异常。</p>\n<h2 id=\"propagation-nested\"><a href=\"#propagation-nested\" class=\"headerlink\" title=\"propagation_nested\"></a>propagation_nested</h2><p>如果当前存在事务，则在嵌套事务内执行。如果当前无事务，则执行与propagation_required相同的操作。</p>"},{"title":"分布式ID","date":"2020-01-09T03:00:00.000Z","_content":"\n记录下关于分布式ID相关知识点\n\n<!-- more -->\n# 分布式ID基本要求\n1. 全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。\n2. 趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。\n3. 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。\n4. 信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。\n5. 分布式id里面最好包含时间戳，这样就能够在开发中快速了解这个分布式id的生成时间。\n\n上述的基本要求中，3和4点其实是互斥的，要根据实际业务要求来进行判断。\n\n# 生成方案\n其实主要有两种方式生成，一种是根据某种算法组合生成，另外一种是依赖数据库、缓存中间件、ZK等协助生成。下面分别介绍下几种常见的生成方式。\n\n## snowflake\nsnowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生4096个ID），最后还有一个符号位，由于ID大都为正数，所以是0。\n\n![snowflake-photo](/image/snowflake.png)\n\n### 时间回拨问题\n由于snowflake是包含时间戳组成的，如果出现了部署服务器时间回退的问题，则可能会产生重复的id。一般情况下生产环境的机器是不会随意调整时间的，但是也可能会出现特殊情况，需要对此做一些应对。\n\n每个时间段下，并不一定会在该时间段内生成达到上限，所以一定会在该短时间内有大量的id被浪费。这些被浪费的资源就可以利用起来。\n\n比如在内存中保存每个时间戳的生成id，在发生时间回拨的时候，取上一次时间最后记录的id对序列部分进行+1使用。\n\n也可以利用扩展位，因为snowflake算法的极限是每毫秒的每一个节点生成4059个id值，也就是说每毫秒的极限是生成023*4059=4 152 357个id值，这对于中小公司来说根本就是浪费，所以我们可以把这里的位数给减少一些，就比如把12位的序列号变成10位，留两位给时间回拨，这样就很容易的解决了时间回拨问题，如果发生时间回拨，那么就直接给当前id加1。\n\n## UUID\n通用唯一标识符（UUID）是一个128位的用于在计算机系统中以识别信息的数目。通常在Microsoft创建的软件中也使用术语全球唯一标识符（GUID）。\n\n在其规范的文本表示形式中，UUID 的16 个八位字节表示为32个十六进制（基数16）数字，以5个组显示，由连字符分隔，格式为8-4-4-4-12，共36个字符（32个字母数字字符和4个连字符）。例如：\n```\n123e4567-e89b-12d3-a456-426655440000\nxxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx\n```\n4位M和1到3位N字段编码UUID本身的格式。数字的4位M是UUID版本，数字的1至3个最高有效位对NUUID变体进行编码。（请参见下文。）在示例中，M为1，N为a（10xx 2），这意味着这是版本1，版本1的UUID。即基于时间的DCE/RFC 4122 UUID。\n\n规范的8-4-4-4-12格式字符串基于UUID的16个字节的记录布局：\n### UUID记录布局\n名称 | 长度（字节） | 长度（十六进制数字） | 内容\n-- | -- | -- | --\ntime_low | 4 | 8 | 给出时间的低32位的整数\ntime_mid | 2 | 4 | 给出时间的中间16位的整数\ntime_hi_and_version | 2 | 4 | 最高有效位为4位“版本”，然后是时间的高12位\nclock_seq_hi_and_res clock_seq_low | 2 | 4 | 最高有效位为1至3位“变量”，随后为13至15位时钟序列\n节点 | 6 | 12 | 48位节点ID\n\n### JDK提供的工具类\n可以直接使用java.util.UUID来生成UUID\n``` java\npublic static void main(String[] args) {\n    System.out.println(UUID.randomUUID().toString().replace(\"-\", \"\").toLowerCase());\n}\n```\n### UUID是否适合做分布式ID\n如果需求是只保证唯一性，那么UUID也是可以使用的，但是按照上面的分布式id的要求， UUID其实是不能做成分布式id的，原因如下：\n1. 首先分布式id一般都会作为主键，但是安装mysql官方推荐主键要尽量越短越好，UUID每一个都很长，所以不是很推荐\n2. 既然分布式id是主键，然后主键是包含索引的，然后mysql的索引是通过b+树来实现的，每一次新的UUID数据的插入，为了查询的优化，都会对索引底层的b+树进行修改，因为UUID数据是无序的，所以每一次UUID数据的插入都会对主键地城的b+树进行很大的修改，这一点很不好\n3. 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。\n\n## Redis集群生成\n\n## 数据库递增\n\n# 参考资料\n* https://www.jianshu.com/p/b1124283fc43\n* https://www.itqiankun.com/article/1565060480\n","source":"_posts/分布式ID.md","raw":"---\ntitle: 分布式ID\ndate: 2020-01-09 11:00:00\ntags: 分布式ID\ncategories: 分布式\n---\n\n记录下关于分布式ID相关知识点\n\n<!-- more -->\n# 分布式ID基本要求\n1. 全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。\n2. 趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。\n3. 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。\n4. 信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。\n5. 分布式id里面最好包含时间戳，这样就能够在开发中快速了解这个分布式id的生成时间。\n\n上述的基本要求中，3和4点其实是互斥的，要根据实际业务要求来进行判断。\n\n# 生成方案\n其实主要有两种方式生成，一种是根据某种算法组合生成，另外一种是依赖数据库、缓存中间件、ZK等协助生成。下面分别介绍下几种常见的生成方式。\n\n## snowflake\nsnowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生4096个ID），最后还有一个符号位，由于ID大都为正数，所以是0。\n\n![snowflake-photo](/image/snowflake.png)\n\n### 时间回拨问题\n由于snowflake是包含时间戳组成的，如果出现了部署服务器时间回退的问题，则可能会产生重复的id。一般情况下生产环境的机器是不会随意调整时间的，但是也可能会出现特殊情况，需要对此做一些应对。\n\n每个时间段下，并不一定会在该时间段内生成达到上限，所以一定会在该短时间内有大量的id被浪费。这些被浪费的资源就可以利用起来。\n\n比如在内存中保存每个时间戳的生成id，在发生时间回拨的时候，取上一次时间最后记录的id对序列部分进行+1使用。\n\n也可以利用扩展位，因为snowflake算法的极限是每毫秒的每一个节点生成4059个id值，也就是说每毫秒的极限是生成023*4059=4 152 357个id值，这对于中小公司来说根本就是浪费，所以我们可以把这里的位数给减少一些，就比如把12位的序列号变成10位，留两位给时间回拨，这样就很容易的解决了时间回拨问题，如果发生时间回拨，那么就直接给当前id加1。\n\n## UUID\n通用唯一标识符（UUID）是一个128位的用于在计算机系统中以识别信息的数目。通常在Microsoft创建的软件中也使用术语全球唯一标识符（GUID）。\n\n在其规范的文本表示形式中，UUID 的16 个八位字节表示为32个十六进制（基数16）数字，以5个组显示，由连字符分隔，格式为8-4-4-4-12，共36个字符（32个字母数字字符和4个连字符）。例如：\n```\n123e4567-e89b-12d3-a456-426655440000\nxxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx\n```\n4位M和1到3位N字段编码UUID本身的格式。数字的4位M是UUID版本，数字的1至3个最高有效位对NUUID变体进行编码。（请参见下文。）在示例中，M为1，N为a（10xx 2），这意味着这是版本1，版本1的UUID。即基于时间的DCE/RFC 4122 UUID。\n\n规范的8-4-4-4-12格式字符串基于UUID的16个字节的记录布局：\n### UUID记录布局\n名称 | 长度（字节） | 长度（十六进制数字） | 内容\n-- | -- | -- | --\ntime_low | 4 | 8 | 给出时间的低32位的整数\ntime_mid | 2 | 4 | 给出时间的中间16位的整数\ntime_hi_and_version | 2 | 4 | 最高有效位为4位“版本”，然后是时间的高12位\nclock_seq_hi_and_res clock_seq_low | 2 | 4 | 最高有效位为1至3位“变量”，随后为13至15位时钟序列\n节点 | 6 | 12 | 48位节点ID\n\n### JDK提供的工具类\n可以直接使用java.util.UUID来生成UUID\n``` java\npublic static void main(String[] args) {\n    System.out.println(UUID.randomUUID().toString().replace(\"-\", \"\").toLowerCase());\n}\n```\n### UUID是否适合做分布式ID\n如果需求是只保证唯一性，那么UUID也是可以使用的，但是按照上面的分布式id的要求， UUID其实是不能做成分布式id的，原因如下：\n1. 首先分布式id一般都会作为主键，但是安装mysql官方推荐主键要尽量越短越好，UUID每一个都很长，所以不是很推荐\n2. 既然分布式id是主键，然后主键是包含索引的，然后mysql的索引是通过b+树来实现的，每一次新的UUID数据的插入，为了查询的优化，都会对索引底层的b+树进行修改，因为UUID数据是无序的，所以每一次UUID数据的插入都会对主键地城的b+树进行很大的修改，这一点很不好\n3. 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。\n\n## Redis集群生成\n\n## 数据库递增\n\n# 参考资料\n* https://www.jianshu.com/p/b1124283fc43\n* https://www.itqiankun.com/article/1565060480\n","slug":"分布式ID","published":1,"updated":"2020-01-10T03:02:18.640Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0x0022qotn3b7hwml9","content":"<p>记录下关于分布式ID相关知识点</p>\n<a id=\"more\"></a>\n<h1 id=\"分布式ID基本要求\"><a href=\"#分布式ID基本要求\" class=\"headerlink\" title=\"分布式ID基本要求\"></a>分布式ID基本要求</h1><ol>\n<li>全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。</li>\n<li>趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。</li>\n<li>单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。</li>\n<li>信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。</li>\n<li>分布式id里面最好包含时间戳，这样就能够在开发中快速了解这个分布式id的生成时间。</li>\n</ol>\n<p>上述的基本要求中，3和4点其实是互斥的，要根据实际业务要求来进行判断。</p>\n<h1 id=\"生成方案\"><a href=\"#生成方案\" class=\"headerlink\" title=\"生成方案\"></a>生成方案</h1><p>其实主要有两种方式生成，一种是根据某种算法组合生成，另外一种是依赖数据库、缓存中间件、ZK等协助生成。下面分别介绍下几种常见的生成方式。</p>\n<h2 id=\"snowflake\"><a href=\"#snowflake\" class=\"headerlink\" title=\"snowflake\"></a>snowflake</h2><p>snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生4096个ID），最后还有一个符号位，由于ID大都为正数，所以是0。</p>\n<p><img src=\"/image/snowflake.png\" alt=\"snowflake-photo\"></p>\n<h3 id=\"时间回拨问题\"><a href=\"#时间回拨问题\" class=\"headerlink\" title=\"时间回拨问题\"></a>时间回拨问题</h3><p>由于snowflake是包含时间戳组成的，如果出现了部署服务器时间回退的问题，则可能会产生重复的id。一般情况下生产环境的机器是不会随意调整时间的，但是也可能会出现特殊情况，需要对此做一些应对。</p>\n<p>每个时间段下，并不一定会在该时间段内生成达到上限，所以一定会在该短时间内有大量的id被浪费。这些被浪费的资源就可以利用起来。</p>\n<p>比如在内存中保存每个时间戳的生成id，在发生时间回拨的时候，取上一次时间最后记录的id对序列部分进行+1使用。</p>\n<p>也可以利用扩展位，因为snowflake算法的极限是每毫秒的每一个节点生成4059个id值，也就是说每毫秒的极限是生成023*4059=4 152 357个id值，这对于中小公司来说根本就是浪费，所以我们可以把这里的位数给减少一些，就比如把12位的序列号变成10位，留两位给时间回拨，这样就很容易的解决了时间回拨问题，如果发生时间回拨，那么就直接给当前id加1。</p>\n<h2 id=\"UUID\"><a href=\"#UUID\" class=\"headerlink\" title=\"UUID\"></a>UUID</h2><p>通用唯一标识符（UUID）是一个128位的用于在计算机系统中以识别信息的数目。通常在Microsoft创建的软件中也使用术语全球唯一标识符（GUID）。</p>\n<p>在其规范的文本表示形式中，UUID 的16 个八位字节表示为32个十六进制（基数16）数字，以5个组显示，由连字符分隔，格式为8-4-4-4-12，共36个字符（32个字母数字字符和4个连字符）。例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">123e4567-e89b-12d3-a456-426655440000</span><br><span class=\"line\">xxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx</span><br></pre></td></tr></table></figure></p>\n<p>4位M和1到3位N字段编码UUID本身的格式。数字的4位M是UUID版本，数字的1至3个最高有效位对NUUID变体进行编码。（请参见下文。）在示例中，M为1，N为a（10xx 2），这意味着这是版本1，版本1的UUID。即基于时间的DCE/RFC 4122 UUID。</p>\n<p>规范的8-4-4-4-12格式字符串基于UUID的16个字节的记录布局：</p>\n<h3 id=\"UUID记录布局\"><a href=\"#UUID记录布局\" class=\"headerlink\" title=\"UUID记录布局\"></a>UUID记录布局</h3><table>\n<thead>\n<tr>\n<th>名称</th>\n<th>长度（字节）</th>\n<th>长度（十六进制数字）</th>\n<th>内容</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>time_low</td>\n<td>4</td>\n<td>8</td>\n<td>给出时间的低32位的整数</td>\n</tr>\n<tr>\n<td>time_mid</td>\n<td>2</td>\n<td>4</td>\n<td>给出时间的中间16位的整数</td>\n</tr>\n<tr>\n<td>time_hi_and_version</td>\n<td>2</td>\n<td>4</td>\n<td>最高有效位为4位“版本”，然后是时间的高12位</td>\n</tr>\n<tr>\n<td>clock_seq_hi_and_res clock_seq_low</td>\n<td>2</td>\n<td>4</td>\n<td>最高有效位为1至3位“变量”，随后为13至15位时钟序列</td>\n</tr>\n<tr>\n<td>节点</td>\n<td>6</td>\n<td>12</td>\n<td>48位节点ID</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"JDK提供的工具类\"><a href=\"#JDK提供的工具类\" class=\"headerlink\" title=\"JDK提供的工具类\"></a>JDK提供的工具类</h3><p>可以直接使用java.util.UUID来生成UUID<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    System.out.println(UUID.randomUUID().toString().replace(<span class=\"string\">\"-\"</span>, <span class=\"string\">\"\"</span>).toLowerCase());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"UUID是否适合做分布式ID\"><a href=\"#UUID是否适合做分布式ID\" class=\"headerlink\" title=\"UUID是否适合做分布式ID\"></a>UUID是否适合做分布式ID</h3><p>如果需求是只保证唯一性，那么UUID也是可以使用的，但是按照上面的分布式id的要求， UUID其实是不能做成分布式id的，原因如下：</p>\n<ol>\n<li>首先分布式id一般都会作为主键，但是安装mysql官方推荐主键要尽量越短越好，UUID每一个都很长，所以不是很推荐</li>\n<li>既然分布式id是主键，然后主键是包含索引的，然后mysql的索引是通过b+树来实现的，每一次新的UUID数据的插入，为了查询的优化，都会对索引底层的b+树进行修改，因为UUID数据是无序的，所以每一次UUID数据的插入都会对主键地城的b+树进行很大的修改，这一点很不好</li>\n<li>信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。</li>\n</ol>\n<h2 id=\"Redis集群生成\"><a href=\"#Redis集群生成\" class=\"headerlink\" title=\"Redis集群生成\"></a>Redis集群生成</h2><h2 id=\"数据库递增\"><a href=\"#数据库递增\" class=\"headerlink\" title=\"数据库递增\"></a>数据库递增</h2><h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://www.jianshu.com/p/b1124283fc43\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/b1124283fc43</a></li>\n<li><a href=\"https://www.itqiankun.com/article/1565060480\" target=\"_blank\" rel=\"noopener\">https://www.itqiankun.com/article/1565060480</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>记录下关于分布式ID相关知识点</p>","more":"<h1 id=\"分布式ID基本要求\"><a href=\"#分布式ID基本要求\" class=\"headerlink\" title=\"分布式ID基本要求\"></a>分布式ID基本要求</h1><ol>\n<li>全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。</li>\n<li>趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。</li>\n<li>单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。</li>\n<li>信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。</li>\n<li>分布式id里面最好包含时间戳，这样就能够在开发中快速了解这个分布式id的生成时间。</li>\n</ol>\n<p>上述的基本要求中，3和4点其实是互斥的，要根据实际业务要求来进行判断。</p>\n<h1 id=\"生成方案\"><a href=\"#生成方案\" class=\"headerlink\" title=\"生成方案\"></a>生成方案</h1><p>其实主要有两种方式生成，一种是根据某种算法组合生成，另外一种是依赖数据库、缓存中间件、ZK等协助生成。下面分别介绍下几种常见的生成方式。</p>\n<h2 id=\"snowflake\"><a href=\"#snowflake\" class=\"headerlink\" title=\"snowflake\"></a>snowflake</h2><p>snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生4096个ID），最后还有一个符号位，由于ID大都为正数，所以是0。</p>\n<p><img src=\"/image/snowflake.png\" alt=\"snowflake-photo\"></p>\n<h3 id=\"时间回拨问题\"><a href=\"#时间回拨问题\" class=\"headerlink\" title=\"时间回拨问题\"></a>时间回拨问题</h3><p>由于snowflake是包含时间戳组成的，如果出现了部署服务器时间回退的问题，则可能会产生重复的id。一般情况下生产环境的机器是不会随意调整时间的，但是也可能会出现特殊情况，需要对此做一些应对。</p>\n<p>每个时间段下，并不一定会在该时间段内生成达到上限，所以一定会在该短时间内有大量的id被浪费。这些被浪费的资源就可以利用起来。</p>\n<p>比如在内存中保存每个时间戳的生成id，在发生时间回拨的时候，取上一次时间最后记录的id对序列部分进行+1使用。</p>\n<p>也可以利用扩展位，因为snowflake算法的极限是每毫秒的每一个节点生成4059个id值，也就是说每毫秒的极限是生成023*4059=4 152 357个id值，这对于中小公司来说根本就是浪费，所以我们可以把这里的位数给减少一些，就比如把12位的序列号变成10位，留两位给时间回拨，这样就很容易的解决了时间回拨问题，如果发生时间回拨，那么就直接给当前id加1。</p>\n<h2 id=\"UUID\"><a href=\"#UUID\" class=\"headerlink\" title=\"UUID\"></a>UUID</h2><p>通用唯一标识符（UUID）是一个128位的用于在计算机系统中以识别信息的数目。通常在Microsoft创建的软件中也使用术语全球唯一标识符（GUID）。</p>\n<p>在其规范的文本表示形式中，UUID 的16 个八位字节表示为32个十六进制（基数16）数字，以5个组显示，由连字符分隔，格式为8-4-4-4-12，共36个字符（32个字母数字字符和4个连字符）。例如：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">123e4567-e89b-12d3-a456-426655440000</span><br><span class=\"line\">xxxxxxxx-xxxx-Mxxx-Nxxx-xxxxxxxxxxxx</span><br></pre></td></tr></table></figure></p>\n<p>4位M和1到3位N字段编码UUID本身的格式。数字的4位M是UUID版本，数字的1至3个最高有效位对NUUID变体进行编码。（请参见下文。）在示例中，M为1，N为a（10xx 2），这意味着这是版本1，版本1的UUID。即基于时间的DCE/RFC 4122 UUID。</p>\n<p>规范的8-4-4-4-12格式字符串基于UUID的16个字节的记录布局：</p>\n<h3 id=\"UUID记录布局\"><a href=\"#UUID记录布局\" class=\"headerlink\" title=\"UUID记录布局\"></a>UUID记录布局</h3><table>\n<thead>\n<tr>\n<th>名称</th>\n<th>长度（字节）</th>\n<th>长度（十六进制数字）</th>\n<th>内容</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>time_low</td>\n<td>4</td>\n<td>8</td>\n<td>给出时间的低32位的整数</td>\n</tr>\n<tr>\n<td>time_mid</td>\n<td>2</td>\n<td>4</td>\n<td>给出时间的中间16位的整数</td>\n</tr>\n<tr>\n<td>time_hi_and_version</td>\n<td>2</td>\n<td>4</td>\n<td>最高有效位为4位“版本”，然后是时间的高12位</td>\n</tr>\n<tr>\n<td>clock_seq_hi_and_res clock_seq_low</td>\n<td>2</td>\n<td>4</td>\n<td>最高有效位为1至3位“变量”，随后为13至15位时钟序列</td>\n</tr>\n<tr>\n<td>节点</td>\n<td>6</td>\n<td>12</td>\n<td>48位节点ID</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"JDK提供的工具类\"><a href=\"#JDK提供的工具类\" class=\"headerlink\" title=\"JDK提供的工具类\"></a>JDK提供的工具类</h3><p>可以直接使用java.util.UUID来生成UUID<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    System.out.println(UUID.randomUUID().toString().replace(<span class=\"string\">\"-\"</span>, <span class=\"string\">\"\"</span>).toLowerCase());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"UUID是否适合做分布式ID\"><a href=\"#UUID是否适合做分布式ID\" class=\"headerlink\" title=\"UUID是否适合做分布式ID\"></a>UUID是否适合做分布式ID</h3><p>如果需求是只保证唯一性，那么UUID也是可以使用的，但是按照上面的分布式id的要求， UUID其实是不能做成分布式id的，原因如下：</p>\n<ol>\n<li>首先分布式id一般都会作为主键，但是安装mysql官方推荐主键要尽量越短越好，UUID每一个都很长，所以不是很推荐</li>\n<li>既然分布式id是主键，然后主键是包含索引的，然后mysql的索引是通过b+树来实现的，每一次新的UUID数据的插入，为了查询的优化，都会对索引底层的b+树进行修改，因为UUID数据是无序的，所以每一次UUID数据的插入都会对主键地城的b+树进行很大的修改，这一点很不好</li>\n<li>信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。</li>\n</ol>\n<h2 id=\"Redis集群生成\"><a href=\"#Redis集群生成\" class=\"headerlink\" title=\"Redis集群生成\"></a>Redis集群生成</h2><h2 id=\"数据库递增\"><a href=\"#数据库递增\" class=\"headerlink\" title=\"数据库递增\"></a>数据库递增</h2><h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://www.jianshu.com/p/b1124283fc43\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/b1124283fc43</a></li>\n<li><a href=\"https://www.itqiankun.com/article/1565060480\" target=\"_blank\" rel=\"noopener\">https://www.itqiankun.com/article/1565060480</a></li>\n</ul>"},{"title":"数据库设计三范式&五大约束","date":"2019-04-26T02:00:00.000Z","_content":"\n> 虽说已经使用数据库有两三年了，也能写出稍微复杂点的SQL、存储过程，略懂一些库表、SQL优化等，但是对于数据库设计相关一直都是含糊不清的。直到前些日子被人问道数据库三范式是什么？一些关于数据库设计的标准其实很早就有了，看似很简单，但是很多业务开发并没有考虑到这些，所以记录下。\n\n<!-- more -->\n## 数据库设计三范式\n### 第一范式（1NF）：\n> 数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性；\n\n### 第二范式（2NF）：\n> 满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；\n\n### 第三范式（3NF）：\n> 必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；\n\n第一范式和第二范式在于有没有分出两张表，第二范式是说一张表中包含了所种不同的实体属性，那么要必须分成多张表， 第三范式是要求已经分成了多张表，那么一张表中只能有另一张表中的id（主键），而不能有其他的任何信息（其他的信息一律用主键在另一表查询）。\n\n## 数据库五大约束\n1. primary KEY:设置主键约束；\n2. UNIQUE：设置唯一性约束，不能有重复值；\n3. DEFAULT 默认值约束，height DOUBLE(3,2)DEFAULT 1.2 height不输入是默认为1,2\n4. NOT NULL：设置非空约束，该字段不能为空；\n5. FOREIGN key :设置外键约束。","source":"_posts/数据库三范式.md","raw":"---\ntitle: 数据库设计三范式&五大约束\ndate: 2019-04-26 10:00:00\ntags: 数据库\ncategories: 数据库\n---\n\n> 虽说已经使用数据库有两三年了，也能写出稍微复杂点的SQL、存储过程，略懂一些库表、SQL优化等，但是对于数据库设计相关一直都是含糊不清的。直到前些日子被人问道数据库三范式是什么？一些关于数据库设计的标准其实很早就有了，看似很简单，但是很多业务开发并没有考虑到这些，所以记录下。\n\n<!-- more -->\n## 数据库设计三范式\n### 第一范式（1NF）：\n> 数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性；\n\n### 第二范式（2NF）：\n> 满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；\n\n### 第三范式（3NF）：\n> 必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；\n\n第一范式和第二范式在于有没有分出两张表，第二范式是说一张表中包含了所种不同的实体属性，那么要必须分成多张表， 第三范式是要求已经分成了多张表，那么一张表中只能有另一张表中的id（主键），而不能有其他的任何信息（其他的信息一律用主键在另一表查询）。\n\n## 数据库五大约束\n1. primary KEY:设置主键约束；\n2. UNIQUE：设置唯一性约束，不能有重复值；\n3. DEFAULT 默认值约束，height DOUBLE(3,2)DEFAULT 1.2 height不输入是默认为1,2\n4. NOT NULL：设置非空约束，该字段不能为空；\n5. FOREIGN key :设置外键约束。","slug":"数据库三范式","published":1,"updated":"2019-08-26T07:54:20.251Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl0z0026qotnu1jmhf1q","content":"<blockquote>\n<p>虽说已经使用数据库有两三年了，也能写出稍微复杂点的SQL、存储过程，略懂一些库表、SQL优化等，但是对于数据库设计相关一直都是含糊不清的。直到前些日子被人问道数据库三范式是什么？一些关于数据库设计的标准其实很早就有了，看似很简单，但是很多业务开发并没有考虑到这些，所以记录下。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"数据库设计三范式\"><a href=\"#数据库设计三范式\" class=\"headerlink\" title=\"数据库设计三范式\"></a>数据库设计三范式</h2><h3 id=\"第一范式（1NF）：\"><a href=\"#第一范式（1NF）：\" class=\"headerlink\" title=\"第一范式（1NF）：\"></a>第一范式（1NF）：</h3><blockquote>\n<p>数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性；</p>\n</blockquote>\n<h3 id=\"第二范式（2NF）：\"><a href=\"#第二范式（2NF）：\" class=\"headerlink\" title=\"第二范式（2NF）：\"></a>第二范式（2NF）：</h3><blockquote>\n<p>满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；</p>\n</blockquote>\n<h3 id=\"第三范式（3NF）：\"><a href=\"#第三范式（3NF）：\" class=\"headerlink\" title=\"第三范式（3NF）：\"></a>第三范式（3NF）：</h3><blockquote>\n<p>必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；</p>\n</blockquote>\n<p>第一范式和第二范式在于有没有分出两张表，第二范式是说一张表中包含了所种不同的实体属性，那么要必须分成多张表， 第三范式是要求已经分成了多张表，那么一张表中只能有另一张表中的id（主键），而不能有其他的任何信息（其他的信息一律用主键在另一表查询）。</p>\n<h2 id=\"数据库五大约束\"><a href=\"#数据库五大约束\" class=\"headerlink\" title=\"数据库五大约束\"></a>数据库五大约束</h2><ol>\n<li>primary KEY:设置主键约束；</li>\n<li>UNIQUE：设置唯一性约束，不能有重复值；</li>\n<li>DEFAULT 默认值约束，height DOUBLE(3,2)DEFAULT 1.2 height不输入是默认为1,2</li>\n<li>NOT NULL：设置非空约束，该字段不能为空；</li>\n<li>FOREIGN key :设置外键约束。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>虽说已经使用数据库有两三年了，也能写出稍微复杂点的SQL、存储过程，略懂一些库表、SQL优化等，但是对于数据库设计相关一直都是含糊不清的。直到前些日子被人问道数据库三范式是什么？一些关于数据库设计的标准其实很早就有了，看似很简单，但是很多业务开发并没有考虑到这些，所以记录下。</p>\n</blockquote>","more":"<h2 id=\"数据库设计三范式\"><a href=\"#数据库设计三范式\" class=\"headerlink\" title=\"数据库设计三范式\"></a>数据库设计三范式</h2><h3 id=\"第一范式（1NF）：\"><a href=\"#第一范式（1NF）：\" class=\"headerlink\" title=\"第一范式（1NF）：\"></a>第一范式（1NF）：</h3><blockquote>\n<p>数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性；</p>\n</blockquote>\n<h3 id=\"第二范式（2NF）：\"><a href=\"#第二范式（2NF）：\" class=\"headerlink\" title=\"第二范式（2NF）：\"></a>第二范式（2NF）：</h3><blockquote>\n<p>满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情；</p>\n</blockquote>\n<h3 id=\"第三范式（3NF）：\"><a href=\"#第三范式（3NF）：\" class=\"headerlink\" title=\"第三范式（3NF）：\"></a>第三范式（3NF）：</h3><blockquote>\n<p>必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）；</p>\n</blockquote>\n<p>第一范式和第二范式在于有没有分出两张表，第二范式是说一张表中包含了所种不同的实体属性，那么要必须分成多张表， 第三范式是要求已经分成了多张表，那么一张表中只能有另一张表中的id（主键），而不能有其他的任何信息（其他的信息一律用主键在另一表查询）。</p>\n<h2 id=\"数据库五大约束\"><a href=\"#数据库五大约束\" class=\"headerlink\" title=\"数据库五大约束\"></a>数据库五大约束</h2><ol>\n<li>primary KEY:设置主键约束；</li>\n<li>UNIQUE：设置唯一性约束，不能有重复值；</li>\n<li>DEFAULT 默认值约束，height DOUBLE(3,2)DEFAULT 1.2 height不输入是默认为1,2</li>\n<li>NOT NULL：设置非空约束，该字段不能为空；</li>\n<li>FOREIGN key :设置外键约束。</li>\n</ol>"},{"title":"前端性能优化","date":"2019-08-22T01:00:00.000Z","_content":"\n来自有凡分享的前端性能优化\n\n<!-- more -->\n\n![前端性能优化](/image/performance_optimization_01.jpeg \"前端性能优化\")\n\n性能优化可以准确地分为：网络方面、DOM操作及渲染方面、数据方面。\n\n## 网络方面\n\nweb应用，总是会有一部分的时间浪费在网络连接和资源下载方面。往往建立一次网络连接是需要时间成本的。而且浏览器同一时间所发送的网络请求数是有限的。\n\n1. **减少http请求**：\n  * 合并js文件；\n  * 合并css文件；\n  * 雪碧图的使用(css sprite)；\n  * 使用base64表示简单的图片；\n\n2. **减小资源体积**：\n  * gzip压缩，将 html 中重复的部分进行一个打包，多次复用的过程；\n  * js混淆，简单的压缩(将空白字符删除)、丑化(丑化的方法，就是将一些变量缩小)、或者可以使用php对js进行混淆加密；\n  * css压缩；\n  * 图片压缩，使用png等图片格式，减少矢量图、高清图等的使用；\n  \n3. **缓存**：\n  * DNS缓存；\n  * CDN部署与缓存；\n  * http缓存；\n\n4. **移动端优化**：\n  * 使用长cache，即设置较长的缓存时间，减少重定向；\n  * 首屏优化，保证首屏加载数据小于14kb；\n  * 不滥用web字体；\n\n## 渲染和DOM操作方面\n\n在网页初步加载时，获取到HTML文件之后，最初的工作是构建DOM和构建CSSOM两个树，之后将他们合并形成渲染树，最后对其进行打印。我们可以通过图片来看一下，简单的过程：\n\n![优化渲染](/image/performance_optimization_02.jpg \"优化渲染\")\n\n1. **优化网页渲染**：\n  * css的文件放在头部；\n    > 保证解析DOM的同时，解析css文件。因为，CSS（外链或内联）会阻塞整个DOM的渲染，然而DOM解析会正常进行，所以将css文件放在头部进行解析，可以加快网页的构建速度\n\n  * js文件放在尾部或者异步；\n    > js（外链或内联）会阻塞后续DOM的解析，后续DOM的渲染也将被阻塞，而且一旦js中遇到DOM元素的操作，很可能会影响\n\n  * 尽量避免內联样式；\n    > 可以有效的减少html的体积，一般考虑内联样式的时候，往往是样式本身体积比较小，往往加载网络资源的时间会大于它的时候\n\n2. **DOM操作优化**：\n  * 避免在document上直接进行频繁的DOM操作，使用classname代替大量的内联样式修改，对于复杂的UI元素，设置position为absolute或fixed；\n    > 希望 **减少回流和重绘**，进行一次DOM操作的代价是非常之大的\n\n  * 尽量使用css动画；\n    > css动画本身比较简单，而且相较于js的复杂动画，浏览器本身对其进行了优化\n\n  * 使用requestAnimationFrame代替setInterval操作；\n    > setInterval定时器会有一定的延时，对于变动性高的动画来说，会出现卡顿现象。而requestAnimationFrame正好解决的整个问题\n\n  * 适当使用canvas；\n  * 尽量减少css表达式的使用；\n    > 例子：left: expression(document.body.offsetWidth - 180\"px\")，css表达式频繁触发的特性，会拖累网页的性能，出现卡顿\n\n  * 使用事件代理；\n    > 往往对于具备冒泡性质的事件来说，使用事件代理不失为一种好的方法。举个例子：一段列表都需要设定点击事件，这时如果你给列表中的每一项设定监听，往往会导致整体的性能下降，但是如果你给整个列表设置一个事件，然后通过点击定位目标来触发相应的操作，往往性能就会得到改善\n\n3. **操作细节注意**：\n  * 避免图片或者iframe使用空src；\n  * 在css属性为0时，去掉单位；\n  * 禁止图像缩放；\n  * 正确的css前缀的使用；\n  * 移除空的css规则；\n  * 对于css中可继承的属性，如font-size，尽量使用继承，少一点设置；\n  * 缩短css选择器，多使用伪元素等帮助定位；\n\n4. **移动端优化**：\n  * 长列表滚动优化；\n    > IOS尽量使用局部滚动，android尽量使用全局滚动。同时，需要给body添加上-webkit-overflow-scrolling: touch来优化移动段的滚动\n\n  * 函数防抖和函数节流；\n    > **函数防抖**，当调用动作过n毫秒后，才会执行该动作，若在这n毫秒内又调用此动作则将重新计算执行时间；  \n    > **函数节流**，预先设定一个执行周期，当调用动作的时刻大于等于执行周期则执行该动作，然后进入下一个新周期\n\n  * 使用touchstart、touchend代替click；\n    > click在移动端会有300ms延时，这应该是一个常识呗\n\n  * HTML的viewport设置；\n    > 可以防止页面的缩放，来优化性能\n\n  * 开启GPU渲染加速；\n\n## 数据方面\n数据，也可以说是前端优化方面比较重要的一块内容。页面与用户的交互响应，往往伴随着数据交互，处理，以及ajax的异步请求等内容。\n\n1. **图片加载处理**：\n  * 图片预加载;\n    > 预加载的寓意就是提前加载内容。而图片的预加载往往会被用在图片资源比较大，即时加载时会导致很长的等待过程时，才会被使用的。常见场景：图片漫画展示时。往往会预加载一张到两张的图片。\n\n  * 图片懒加载;\n    > 常见的图片懒加载的方式就是：在最初给图片的src设置一个比较简单的图片，然后将图片的真实地址设置给自定义的属性，做一个占位，然后给图片设置监听事件，一旦图片到达视口范围，从图片的自定义属性中获取出真是地址，然后赋值给src，让其进行加载。\n\n  * 首屏加载时进度条的显示;\n\n2. **异步请求的优化**：\n  * 使用正常的json数据格式进行交互；\n  * 部分常用数据的缓存；\n    > 可以将一些用户的基本信息等常用的信息做一个缓存，这样可以保证ajax请求的减少。同时，HTML5新增的storage的内容，也不用怕cookie暴露，引起的信息泄漏问题。\n\n  * 数据埋点和统计；\n","source":"_posts/前端性能优化.md","raw":"---\ntitle: 前端性能优化\ndate: 2019-08-22 09:00:00\ntags: 前端\ncategories: 前端\n---\n\n来自有凡分享的前端性能优化\n\n<!-- more -->\n\n![前端性能优化](/image/performance_optimization_01.jpeg \"前端性能优化\")\n\n性能优化可以准确地分为：网络方面、DOM操作及渲染方面、数据方面。\n\n## 网络方面\n\nweb应用，总是会有一部分的时间浪费在网络连接和资源下载方面。往往建立一次网络连接是需要时间成本的。而且浏览器同一时间所发送的网络请求数是有限的。\n\n1. **减少http请求**：\n  * 合并js文件；\n  * 合并css文件；\n  * 雪碧图的使用(css sprite)；\n  * 使用base64表示简单的图片；\n\n2. **减小资源体积**：\n  * gzip压缩，将 html 中重复的部分进行一个打包，多次复用的过程；\n  * js混淆，简单的压缩(将空白字符删除)、丑化(丑化的方法，就是将一些变量缩小)、或者可以使用php对js进行混淆加密；\n  * css压缩；\n  * 图片压缩，使用png等图片格式，减少矢量图、高清图等的使用；\n  \n3. **缓存**：\n  * DNS缓存；\n  * CDN部署与缓存；\n  * http缓存；\n\n4. **移动端优化**：\n  * 使用长cache，即设置较长的缓存时间，减少重定向；\n  * 首屏优化，保证首屏加载数据小于14kb；\n  * 不滥用web字体；\n\n## 渲染和DOM操作方面\n\n在网页初步加载时，获取到HTML文件之后，最初的工作是构建DOM和构建CSSOM两个树，之后将他们合并形成渲染树，最后对其进行打印。我们可以通过图片来看一下，简单的过程：\n\n![优化渲染](/image/performance_optimization_02.jpg \"优化渲染\")\n\n1. **优化网页渲染**：\n  * css的文件放在头部；\n    > 保证解析DOM的同时，解析css文件。因为，CSS（外链或内联）会阻塞整个DOM的渲染，然而DOM解析会正常进行，所以将css文件放在头部进行解析，可以加快网页的构建速度\n\n  * js文件放在尾部或者异步；\n    > js（外链或内联）会阻塞后续DOM的解析，后续DOM的渲染也将被阻塞，而且一旦js中遇到DOM元素的操作，很可能会影响\n\n  * 尽量避免內联样式；\n    > 可以有效的减少html的体积，一般考虑内联样式的时候，往往是样式本身体积比较小，往往加载网络资源的时间会大于它的时候\n\n2. **DOM操作优化**：\n  * 避免在document上直接进行频繁的DOM操作，使用classname代替大量的内联样式修改，对于复杂的UI元素，设置position为absolute或fixed；\n    > 希望 **减少回流和重绘**，进行一次DOM操作的代价是非常之大的\n\n  * 尽量使用css动画；\n    > css动画本身比较简单，而且相较于js的复杂动画，浏览器本身对其进行了优化\n\n  * 使用requestAnimationFrame代替setInterval操作；\n    > setInterval定时器会有一定的延时，对于变动性高的动画来说，会出现卡顿现象。而requestAnimationFrame正好解决的整个问题\n\n  * 适当使用canvas；\n  * 尽量减少css表达式的使用；\n    > 例子：left: expression(document.body.offsetWidth - 180\"px\")，css表达式频繁触发的特性，会拖累网页的性能，出现卡顿\n\n  * 使用事件代理；\n    > 往往对于具备冒泡性质的事件来说，使用事件代理不失为一种好的方法。举个例子：一段列表都需要设定点击事件，这时如果你给列表中的每一项设定监听，往往会导致整体的性能下降，但是如果你给整个列表设置一个事件，然后通过点击定位目标来触发相应的操作，往往性能就会得到改善\n\n3. **操作细节注意**：\n  * 避免图片或者iframe使用空src；\n  * 在css属性为0时，去掉单位；\n  * 禁止图像缩放；\n  * 正确的css前缀的使用；\n  * 移除空的css规则；\n  * 对于css中可继承的属性，如font-size，尽量使用继承，少一点设置；\n  * 缩短css选择器，多使用伪元素等帮助定位；\n\n4. **移动端优化**：\n  * 长列表滚动优化；\n    > IOS尽量使用局部滚动，android尽量使用全局滚动。同时，需要给body添加上-webkit-overflow-scrolling: touch来优化移动段的滚动\n\n  * 函数防抖和函数节流；\n    > **函数防抖**，当调用动作过n毫秒后，才会执行该动作，若在这n毫秒内又调用此动作则将重新计算执行时间；  \n    > **函数节流**，预先设定一个执行周期，当调用动作的时刻大于等于执行周期则执行该动作，然后进入下一个新周期\n\n  * 使用touchstart、touchend代替click；\n    > click在移动端会有300ms延时，这应该是一个常识呗\n\n  * HTML的viewport设置；\n    > 可以防止页面的缩放，来优化性能\n\n  * 开启GPU渲染加速；\n\n## 数据方面\n数据，也可以说是前端优化方面比较重要的一块内容。页面与用户的交互响应，往往伴随着数据交互，处理，以及ajax的异步请求等内容。\n\n1. **图片加载处理**：\n  * 图片预加载;\n    > 预加载的寓意就是提前加载内容。而图片的预加载往往会被用在图片资源比较大，即时加载时会导致很长的等待过程时，才会被使用的。常见场景：图片漫画展示时。往往会预加载一张到两张的图片。\n\n  * 图片懒加载;\n    > 常见的图片懒加载的方式就是：在最初给图片的src设置一个比较简单的图片，然后将图片的真实地址设置给自定义的属性，做一个占位，然后给图片设置监听事件，一旦图片到达视口范围，从图片的自定义属性中获取出真是地址，然后赋值给src，让其进行加载。\n\n  * 首屏加载时进度条的显示;\n\n2. **异步请求的优化**：\n  * 使用正常的json数据格式进行交互；\n  * 部分常用数据的缓存；\n    > 可以将一些用户的基本信息等常用的信息做一个缓存，这样可以保证ajax请求的减少。同时，HTML5新增的storage的内容，也不用怕cookie暴露，引起的信息泄漏问题。\n\n  * 数据埋点和统计；\n","slug":"前端性能优化","published":1,"updated":"2019-08-26T08:34:56.633Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl110029qotnpw52gmle","content":"<p>来自有凡分享的前端性能优化</p>\n<a id=\"more\"></a>\n<p><img src=\"/image/performance_optimization_01.jpeg\" alt=\"前端性能优化\" title=\"前端性能优化\"></p>\n<p>性能优化可以准确地分为：网络方面、DOM操作及渲染方面、数据方面。</p>\n<h2 id=\"网络方面\"><a href=\"#网络方面\" class=\"headerlink\" title=\"网络方面\"></a>网络方面</h2><p>web应用，总是会有一部分的时间浪费在网络连接和资源下载方面。往往建立一次网络连接是需要时间成本的。而且浏览器同一时间所发送的网络请求数是有限的。</p>\n<ol>\n<li><p><strong>减少http请求</strong>：</p>\n<ul>\n<li>合并js文件；</li>\n<li>合并css文件；</li>\n<li>雪碧图的使用(css sprite)；</li>\n<li>使用base64表示简单的图片；</li>\n</ul>\n</li>\n<li><p><strong>减小资源体积</strong>：</p>\n<ul>\n<li>gzip压缩，将 html 中重复的部分进行一个打包，多次复用的过程；</li>\n<li>js混淆，简单的压缩(将空白字符删除)、丑化(丑化的方法，就是将一些变量缩小)、或者可以使用php对js进行混淆加密；</li>\n<li>css压缩；</li>\n<li>图片压缩，使用png等图片格式，减少矢量图、高清图等的使用；</li>\n</ul>\n</li>\n<li><p><strong>缓存</strong>：</p>\n<ul>\n<li>DNS缓存；</li>\n<li>CDN部署与缓存；</li>\n<li>http缓存；</li>\n</ul>\n</li>\n<li><p><strong>移动端优化</strong>：</p>\n<ul>\n<li>使用长cache，即设置较长的缓存时间，减少重定向；</li>\n<li>首屏优化，保证首屏加载数据小于14kb；</li>\n<li>不滥用web字体；</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"渲染和DOM操作方面\"><a href=\"#渲染和DOM操作方面\" class=\"headerlink\" title=\"渲染和DOM操作方面\"></a>渲染和DOM操作方面</h2><p>在网页初步加载时，获取到HTML文件之后，最初的工作是构建DOM和构建CSSOM两个树，之后将他们合并形成渲染树，最后对其进行打印。我们可以通过图片来看一下，简单的过程：</p>\n<p><img src=\"/image/performance_optimization_02.jpg\" alt=\"优化渲染\" title=\"优化渲染\"></p>\n<ol>\n<li><p><strong>优化网页渲染</strong>：</p>\n<ul>\n<li><p>css的文件放在头部；</p>\n<blockquote>\n<p>保证解析DOM的同时，解析css文件。因为，CSS（外链或内联）会阻塞整个DOM的渲染，然而DOM解析会正常进行，所以将css文件放在头部进行解析，可以加快网页的构建速度</p>\n</blockquote>\n</li>\n<li><p>js文件放在尾部或者异步；</p>\n<blockquote>\n<p>js（外链或内联）会阻塞后续DOM的解析，后续DOM的渲染也将被阻塞，而且一旦js中遇到DOM元素的操作，很可能会影响</p>\n</blockquote>\n</li>\n<li><p>尽量避免內联样式；</p>\n<blockquote>\n<p>可以有效的减少html的体积，一般考虑内联样式的时候，往往是样式本身体积比较小，往往加载网络资源的时间会大于它的时候</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li><p><strong>DOM操作优化</strong>：</p>\n<ul>\n<li><p>避免在document上直接进行频繁的DOM操作，使用classname代替大量的内联样式修改，对于复杂的UI元素，设置position为absolute或fixed；</p>\n<blockquote>\n<p>希望 <strong>减少回流和重绘</strong>，进行一次DOM操作的代价是非常之大的</p>\n</blockquote>\n</li>\n<li><p>尽量使用css动画；</p>\n<blockquote>\n<p>css动画本身比较简单，而且相较于js的复杂动画，浏览器本身对其进行了优化</p>\n</blockquote>\n</li>\n<li><p>使用requestAnimationFrame代替setInterval操作；</p>\n<blockquote>\n<p>setInterval定时器会有一定的延时，对于变动性高的动画来说，会出现卡顿现象。而requestAnimationFrame正好解决的整个问题</p>\n</blockquote>\n</li>\n<li><p>适当使用canvas；</p>\n</li>\n<li><p>尽量减少css表达式的使用；</p>\n<blockquote>\n<p>例子：left: expression(document.body.offsetWidth - 180”px”)，css表达式频繁触发的特性，会拖累网页的性能，出现卡顿</p>\n</blockquote>\n</li>\n<li><p>使用事件代理；</p>\n<blockquote>\n<p>往往对于具备冒泡性质的事件来说，使用事件代理不失为一种好的方法。举个例子：一段列表都需要设定点击事件，这时如果你给列表中的每一项设定监听，往往会导致整体的性能下降，但是如果你给整个列表设置一个事件，然后通过点击定位目标来触发相应的操作，往往性能就会得到改善</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li><p><strong>操作细节注意</strong>：</p>\n<ul>\n<li>避免图片或者iframe使用空src；</li>\n<li>在css属性为0时，去掉单位；</li>\n<li>禁止图像缩放；</li>\n<li>正确的css前缀的使用；</li>\n<li>移除空的css规则；</li>\n<li>对于css中可继承的属性，如font-size，尽量使用继承，少一点设置；</li>\n<li>缩短css选择器，多使用伪元素等帮助定位；</li>\n</ul>\n</li>\n<li><p><strong>移动端优化</strong>：</p>\n<ul>\n<li><p>长列表滚动优化；</p>\n<blockquote>\n<p>IOS尽量使用局部滚动，android尽量使用全局滚动。同时，需要给body添加上-webkit-overflow-scrolling: touch来优化移动段的滚动</p>\n</blockquote>\n</li>\n<li><p>函数防抖和函数节流；</p>\n<blockquote>\n<p><strong>函数防抖</strong>，当调用动作过n毫秒后，才会执行该动作，若在这n毫秒内又调用此动作则将重新计算执行时间；<br><strong>函数节流</strong>，预先设定一个执行周期，当调用动作的时刻大于等于执行周期则执行该动作，然后进入下一个新周期</p>\n</blockquote>\n</li>\n<li><p>使用touchstart、touchend代替click；</p>\n<blockquote>\n<p>click在移动端会有300ms延时，这应该是一个常识呗</p>\n</blockquote>\n</li>\n<li><p>HTML的viewport设置；</p>\n<blockquote>\n<p>可以防止页面的缩放，来优化性能</p>\n</blockquote>\n</li>\n<li><p>开启GPU渲染加速；</p>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"数据方面\"><a href=\"#数据方面\" class=\"headerlink\" title=\"数据方面\"></a>数据方面</h2><p>数据，也可以说是前端优化方面比较重要的一块内容。页面与用户的交互响应，往往伴随着数据交互，处理，以及ajax的异步请求等内容。</p>\n<ol>\n<li><p><strong>图片加载处理</strong>：</p>\n<ul>\n<li><p>图片预加载;</p>\n<blockquote>\n<p>预加载的寓意就是提前加载内容。而图片的预加载往往会被用在图片资源比较大，即时加载时会导致很长的等待过程时，才会被使用的。常见场景：图片漫画展示时。往往会预加载一张到两张的图片。</p>\n</blockquote>\n</li>\n<li><p>图片懒加载;</p>\n<blockquote>\n<p>常见的图片懒加载的方式就是：在最初给图片的src设置一个比较简单的图片，然后将图片的真实地址设置给自定义的属性，做一个占位，然后给图片设置监听事件，一旦图片到达视口范围，从图片的自定义属性中获取出真是地址，然后赋值给src，让其进行加载。</p>\n</blockquote>\n</li>\n<li><p>首屏加载时进度条的显示;</p>\n</li>\n</ul>\n</li>\n<li><p><strong>异步请求的优化</strong>：</p>\n<ul>\n<li>使用正常的json数据格式进行交互；</li>\n<li><p>部分常用数据的缓存；</p>\n<blockquote>\n<p>可以将一些用户的基本信息等常用的信息做一个缓存，这样可以保证ajax请求的减少。同时，HTML5新增的storage的内容，也不用怕cookie暴露，引起的信息泄漏问题。</p>\n</blockquote>\n</li>\n<li><p>数据埋点和统计；</p>\n</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>来自有凡分享的前端性能优化</p>","more":"<p><img src=\"/image/performance_optimization_01.jpeg\" alt=\"前端性能优化\" title=\"前端性能优化\"></p>\n<p>性能优化可以准确地分为：网络方面、DOM操作及渲染方面、数据方面。</p>\n<h2 id=\"网络方面\"><a href=\"#网络方面\" class=\"headerlink\" title=\"网络方面\"></a>网络方面</h2><p>web应用，总是会有一部分的时间浪费在网络连接和资源下载方面。往往建立一次网络连接是需要时间成本的。而且浏览器同一时间所发送的网络请求数是有限的。</p>\n<ol>\n<li><p><strong>减少http请求</strong>：</p>\n<ul>\n<li>合并js文件；</li>\n<li>合并css文件；</li>\n<li>雪碧图的使用(css sprite)；</li>\n<li>使用base64表示简单的图片；</li>\n</ul>\n</li>\n<li><p><strong>减小资源体积</strong>：</p>\n<ul>\n<li>gzip压缩，将 html 中重复的部分进行一个打包，多次复用的过程；</li>\n<li>js混淆，简单的压缩(将空白字符删除)、丑化(丑化的方法，就是将一些变量缩小)、或者可以使用php对js进行混淆加密；</li>\n<li>css压缩；</li>\n<li>图片压缩，使用png等图片格式，减少矢量图、高清图等的使用；</li>\n</ul>\n</li>\n<li><p><strong>缓存</strong>：</p>\n<ul>\n<li>DNS缓存；</li>\n<li>CDN部署与缓存；</li>\n<li>http缓存；</li>\n</ul>\n</li>\n<li><p><strong>移动端优化</strong>：</p>\n<ul>\n<li>使用长cache，即设置较长的缓存时间，减少重定向；</li>\n<li>首屏优化，保证首屏加载数据小于14kb；</li>\n<li>不滥用web字体；</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"渲染和DOM操作方面\"><a href=\"#渲染和DOM操作方面\" class=\"headerlink\" title=\"渲染和DOM操作方面\"></a>渲染和DOM操作方面</h2><p>在网页初步加载时，获取到HTML文件之后，最初的工作是构建DOM和构建CSSOM两个树，之后将他们合并形成渲染树，最后对其进行打印。我们可以通过图片来看一下，简单的过程：</p>\n<p><img src=\"/image/performance_optimization_02.jpg\" alt=\"优化渲染\" title=\"优化渲染\"></p>\n<ol>\n<li><p><strong>优化网页渲染</strong>：</p>\n<ul>\n<li><p>css的文件放在头部；</p>\n<blockquote>\n<p>保证解析DOM的同时，解析css文件。因为，CSS（外链或内联）会阻塞整个DOM的渲染，然而DOM解析会正常进行，所以将css文件放在头部进行解析，可以加快网页的构建速度</p>\n</blockquote>\n</li>\n<li><p>js文件放在尾部或者异步；</p>\n<blockquote>\n<p>js（外链或内联）会阻塞后续DOM的解析，后续DOM的渲染也将被阻塞，而且一旦js中遇到DOM元素的操作，很可能会影响</p>\n</blockquote>\n</li>\n<li><p>尽量避免內联样式；</p>\n<blockquote>\n<p>可以有效的减少html的体积，一般考虑内联样式的时候，往往是样式本身体积比较小，往往加载网络资源的时间会大于它的时候</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li><p><strong>DOM操作优化</strong>：</p>\n<ul>\n<li><p>避免在document上直接进行频繁的DOM操作，使用classname代替大量的内联样式修改，对于复杂的UI元素，设置position为absolute或fixed；</p>\n<blockquote>\n<p>希望 <strong>减少回流和重绘</strong>，进行一次DOM操作的代价是非常之大的</p>\n</blockquote>\n</li>\n<li><p>尽量使用css动画；</p>\n<blockquote>\n<p>css动画本身比较简单，而且相较于js的复杂动画，浏览器本身对其进行了优化</p>\n</blockquote>\n</li>\n<li><p>使用requestAnimationFrame代替setInterval操作；</p>\n<blockquote>\n<p>setInterval定时器会有一定的延时，对于变动性高的动画来说，会出现卡顿现象。而requestAnimationFrame正好解决的整个问题</p>\n</blockquote>\n</li>\n<li><p>适当使用canvas；</p>\n</li>\n<li><p>尽量减少css表达式的使用；</p>\n<blockquote>\n<p>例子：left: expression(document.body.offsetWidth - 180”px”)，css表达式频繁触发的特性，会拖累网页的性能，出现卡顿</p>\n</blockquote>\n</li>\n<li><p>使用事件代理；</p>\n<blockquote>\n<p>往往对于具备冒泡性质的事件来说，使用事件代理不失为一种好的方法。举个例子：一段列表都需要设定点击事件，这时如果你给列表中的每一项设定监听，往往会导致整体的性能下降，但是如果你给整个列表设置一个事件，然后通过点击定位目标来触发相应的操作，往往性能就会得到改善</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li><p><strong>操作细节注意</strong>：</p>\n<ul>\n<li>避免图片或者iframe使用空src；</li>\n<li>在css属性为0时，去掉单位；</li>\n<li>禁止图像缩放；</li>\n<li>正确的css前缀的使用；</li>\n<li>移除空的css规则；</li>\n<li>对于css中可继承的属性，如font-size，尽量使用继承，少一点设置；</li>\n<li>缩短css选择器，多使用伪元素等帮助定位；</li>\n</ul>\n</li>\n<li><p><strong>移动端优化</strong>：</p>\n<ul>\n<li><p>长列表滚动优化；</p>\n<blockquote>\n<p>IOS尽量使用局部滚动，android尽量使用全局滚动。同时，需要给body添加上-webkit-overflow-scrolling: touch来优化移动段的滚动</p>\n</blockquote>\n</li>\n<li><p>函数防抖和函数节流；</p>\n<blockquote>\n<p><strong>函数防抖</strong>，当调用动作过n毫秒后，才会执行该动作，若在这n毫秒内又调用此动作则将重新计算执行时间；<br><strong>函数节流</strong>，预先设定一个执行周期，当调用动作的时刻大于等于执行周期则执行该动作，然后进入下一个新周期</p>\n</blockquote>\n</li>\n<li><p>使用touchstart、touchend代替click；</p>\n<blockquote>\n<p>click在移动端会有300ms延时，这应该是一个常识呗</p>\n</blockquote>\n</li>\n<li><p>HTML的viewport设置；</p>\n<blockquote>\n<p>可以防止页面的缩放，来优化性能</p>\n</blockquote>\n</li>\n<li><p>开启GPU渲染加速；</p>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"数据方面\"><a href=\"#数据方面\" class=\"headerlink\" title=\"数据方面\"></a>数据方面</h2><p>数据，也可以说是前端优化方面比较重要的一块内容。页面与用户的交互响应，往往伴随着数据交互，处理，以及ajax的异步请求等内容。</p>\n<ol>\n<li><p><strong>图片加载处理</strong>：</p>\n<ul>\n<li><p>图片预加载;</p>\n<blockquote>\n<p>预加载的寓意就是提前加载内容。而图片的预加载往往会被用在图片资源比较大，即时加载时会导致很长的等待过程时，才会被使用的。常见场景：图片漫画展示时。往往会预加载一张到两张的图片。</p>\n</blockquote>\n</li>\n<li><p>图片懒加载;</p>\n<blockquote>\n<p>常见的图片懒加载的方式就是：在最初给图片的src设置一个比较简单的图片，然后将图片的真实地址设置给自定义的属性，做一个占位，然后给图片设置监听事件，一旦图片到达视口范围，从图片的自定义属性中获取出真是地址，然后赋值给src，让其进行加载。</p>\n</blockquote>\n</li>\n<li><p>首屏加载时进度条的显示;</p>\n</li>\n</ul>\n</li>\n<li><p><strong>异步请求的优化</strong>：</p>\n<ul>\n<li>使用正常的json数据格式进行交互；</li>\n<li><p>部分常用数据的缓存；</p>\n<blockquote>\n<p>可以将一些用户的基本信息等常用的信息做一个缓存，这样可以保证ajax请求的减少。同时，HTML5新增的storage的内容，也不用怕cookie暴露，引起的信息泄漏问题。</p>\n</blockquote>\n</li>\n<li><p>数据埋点和统计；</p>\n</li>\n</ul>\n</li>\n</ol>"},{"title":"缓存应用基础知识","date":"2019-03-10T02:00:00.000Z","_content":"\n> 记录了一些学习缓存时的一些基础知识，主要是对于缓存使用要考虑到的一些问题，面试中也会经常问到。\n\n<!-- more -->\n\n## 缓存穿透\n缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。\n\n解决方法：从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。\n\n## 缓存击穿\n缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力\n\n解决方案：\n1. 设置热点数据永远不过期。\n2. 加互斥锁。\n\n## 缓存雪崩\n缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。\n\n解决方案：\n1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。\n2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。\n3. 设置热点数据永远不过期。","source":"_posts/缓存应用基础知识.md","raw":"---\ntitle: 缓存应用基础知识\ndate: 2019-03-10 10:00:00\ntags: redis\ncategories: 中间件\n---\n\n> 记录了一些学习缓存时的一些基础知识，主要是对于缓存使用要考虑到的一些问题，面试中也会经常问到。\n\n<!-- more -->\n\n## 缓存穿透\n缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。\n\n解决方法：从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。\n\n## 缓存击穿\n缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力\n\n解决方案：\n1. 设置热点数据永远不过期。\n2. 加互斥锁。\n\n## 缓存雪崩\n缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。\n\n解决方案：\n1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。\n2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。\n3. 设置热点数据永远不过期。","slug":"缓存应用基础知识","published":1,"updated":"2020-05-12T22:45:57.735Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl13002dqotnlquukrpv","content":"<blockquote>\n<p>记录了一些学习缓存时的一些基础知识，主要是对于缓存使用要考虑到的一些问题，面试中也会经常问到。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"缓存穿透\"><a href=\"#缓存穿透\" class=\"headerlink\" title=\"缓存穿透\"></a>缓存穿透</h2><p>缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</p>\n<p>解决方法：从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。</p>\n<h2 id=\"缓存击穿\"><a href=\"#缓存击穿\" class=\"headerlink\" title=\"缓存击穿\"></a>缓存击穿</h2><p>缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力</p>\n<p>解决方案：</p>\n<ol>\n<li>设置热点数据永远不过期。</li>\n<li>加互斥锁。</li>\n</ol>\n<h2 id=\"缓存雪崩\"><a href=\"#缓存雪崩\" class=\"headerlink\" title=\"缓存雪崩\"></a>缓存雪崩</h2><p>缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p>\n<p>解决方案：</p>\n<ol>\n<li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li>\n<li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。</li>\n<li>设置热点数据永远不过期。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>记录了一些学习缓存时的一些基础知识，主要是对于缓存使用要考虑到的一些问题，面试中也会经常问到。</p>\n</blockquote>","more":"<h2 id=\"缓存穿透\"><a href=\"#缓存穿透\" class=\"headerlink\" title=\"缓存穿透\"></a>缓存穿透</h2><p>缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</p>\n<p>解决方法：从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。</p>\n<h2 id=\"缓存击穿\"><a href=\"#缓存击穿\" class=\"headerlink\" title=\"缓存击穿\"></a>缓存击穿</h2><p>缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力</p>\n<p>解决方案：</p>\n<ol>\n<li>设置热点数据永远不过期。</li>\n<li>加互斥锁。</li>\n</ol>\n<h2 id=\"缓存雪崩\"><a href=\"#缓存雪崩\" class=\"headerlink\" title=\"缓存雪崩\"></a>缓存雪崩</h2><p>缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p>\n<p>解决方案：</p>\n<ol>\n<li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li>\n<li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。</li>\n<li>设置热点数据永远不过期。</li>\n</ol>"},{"title":"Redisson","date":"2020-02-08T02:00:00.000Z","_content":"\n\n<!-- more -->","source":"_posts/redisson.md","raw":"---\ntitle: Redisson\ndate: 2020-02-08 10:00:00\ntags: redisson\ncategories: 中间件\n---\n\n\n<!-- more -->","slug":"redisson","published":1,"updated":"2020-05-07T10:23:26.200Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl15002gqotn3kiytul0","content":"<a id=\"more\"></a>","site":{"data":{}},"excerpt":"","more":""},{"title":"JVM内存模型、调优与相关工具","date":"2020-03-21T02:00:00.000Z","_content":"\n摘自公司培训资料，记录下主要学习的有关JVM的内容。纯手打的，手都要抽筋了。\n<!-- more -->\n# 内存模型\n\n![JVM内存模型01-photo](/image/jvm/JVM7内存模型.png)\n\n![JVM内存模型02-photo](/image/jvm/JVM8内存模型.png)\n\n# 栈\n\n![JVM内存模型03-photo](/image/jvm/JVM_栈.png)\n\n- 本地方法栈(线程私有)：登记native方法，在Execution Engine执行时加载本地方法库\n- 程序计数器（线程私有）：就是一个指针，指向方法区中的方法字节码（用来存储指向下一条指令的地址,也即将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记。\n- 方法区(线程共享)：类的所有字段和方法字节码，以及一些特殊方法如构造函数，接口代码也在此定义。简单说，所有定义的方法的信息都保存在该区域，静态变量+常量+类信息(构造方法/接口定义)+运行时常量池都存在方法区中，虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。\n\n- Java栈（线程私有）： Java线程执行方法的内存模型，一个线程对应一个栈，每个方法在执行的同时都会创建一个栈帧（用于存储局部变量表，操作数栈，动态链接，方法出口等信息）不存在垃圾回收问题，只要线程一结束该栈就释放，生命周期和线程一致\n\nJVM对该区域规范了两种异常：\n1. 线程请求的栈深度大于虚拟机栈所允许的深度，将抛出StackOverFlowError异常\n2. 若虚拟机栈可动态扩展，当无法申请到足够内存空间时将抛出OutOfMemoryError，通过jvm参数–Xss指定栈空间，空间大小决定函数调用的深度\n\n\n# 堆\n1.7中堆分为永久代、新生代、旧生代。1.8与1.7最显著的区别就是去除了永久代，将永久代分为了常量池和方法区，方法区移动到了堆外称之为元空间，占用机器内存，不再占用堆内存。\n\n新生代：\nJDK1.7和1.8中绿色的部分称为新生代，新生代又分为Eden Space和2个Survivor Space，也叫From Space和To Space。其中Eden Space一般我们new的对象都会放在此处，Survivor Space用于Young GC时的存放还需要继续引用的对象。Eden:From:To的默认比例为8:1:1，由启动参数-XX:SurvivorRatio，默认为8。\n\n旧生代：\nJDK1.7和1.8中蓝色部分，用于存放在新生代中经过多次垃圾回收仍然存活的对象/继续引用的对象，从To Space全部移动到Old Generation。有一种情况当生成某个大对象，Eden Space空间不足，进行Young GC，此时如果Survivor空间不足，对象会直接放入Old Generation。\n\n注：线程分配内存不在堆内，而是在堆外，-Xss是在JVM方法栈中划分，所以对于线程比较多的应用应预留相对较多的堆外内存。一般Xmx设置为总机器内存的3/5（个人经验）,-Xmn为Xmx的3/8（sun推荐）。\n\n# Mate Space\n元数据区取代了永久代(jdk1.8以前)，本质和永久代类似，都是对JVM规范中方法区的实现，区别在于元数据区并不在虚拟机中，而是使用本地物理内存，永久代在虚拟机中，永久代逻辑结构上属于堆，但是物理上不属于堆，堆大小=新生代+老年代。元数据区也有可能发生O utOfMemory异常。\n\n- Jdk1.6及之前：有永久代, 常量池在方法区\n- Jdk1.7：有永久代，但已经逐步“去永久代”，常量池在堆\n- Jdk1.8及之后：无永久代，常量池在元空间\n\n元数据区的动态扩展，默认–XX:MetaspaceSize值为21MB的高水位线。一旦触及则Full GC将被触发并卸载没有用的类（类对应的类加载器不再存活），然后高水位线将会重置。新的高水位线的值取决于GC后释放的元空间。如果释放的空间少，这个高水位线则上升。如果释放空间过多，则高水位线下降。\n\n## 为什么jdk1.8用元数据区取代了永久代\n官方解释：移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代\n\n# GC\n\n![GC01-photo](/image/jvm/GC.png)\n\n## Minor GC(Young GC)\n发生在新生代，会造成应用的暂停，发生过程：\n1. 每个对象Eden Space分配内存，当Eden Space空间满，或者不能放入新产生的对象后，进行Young GC进行回收，并将回收后剩余的对象放入To Space，如果To Space空间不足以放入剩余的对象，超出空间的部分对象将直接放入Old Space。\n2. 第二次Young GC时，To Space会转换为From Space，将To Space和Eden Space的对象垃圾回收后放入From Space，此时From Space变为To Space\n3. 运行一段时间后，经过指定次数Young GC仍然存活（被引用）的对象，会放入到Old Space，次数由-XX:MaxTenuringThreshold决定，默认值15。\n\n## Major GC(Full GC)\n对新生代和老年代都按其GC配置类型进行GC。Full GC产生时，会造成应用暂停STW(Stop The World 所有java应用其他线程全部挂起)，且时间远远大于Young GC，是我们需要尽量避免或减少其触发频率。\n\n触发情况如下：\n1. 调用System.gc()\n2. 旧生代空间不足。旧生代在新生代转入对象、大数组时会出现空间不足现象，此时会进行Full GC。当Full GC后仍不能存放时，会抛出OOM。因此为了避免这两种情况下Full GC的产生，调优时应尽量让对象在Young GC时回收，即让对象在新生代多存活一段时间，使其能回收;不要创建过大的对象和数组。\n3. CMS GC时出现promotion failed和concurrent mode failure\n    - promotion filed：在进行Young GC时，Survivor Space放不下，对象只能放入旧生代，而此时旧生代也放不下，此时就会出现promotion failed错误。\n    - concurrent mode failure：在执行CMS GC过程中同时由对象放入Old Space，而此时Old Space空间不足，会粗线此类错误\n\n    优化措施：增加Survivor Space、Old Space空间，降低CMS GC产生的几率\n \n## CMS\nConcurrent Mark-Sweep 目标是尽量减少应用的暂停时间，减少full gc发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代\n\n1. 请求进行一次Full GC，如调用System.gc时\n2. 当没有设置UseCMSInitiatingOccupancyOnly时，会动态计算。如果完成CMS回收所需要的预计时间小于预计的CMS回收的分代填满的时间，就进行回收\n3. 调用should_concurrent_collect()方法返回true\n4. 如果预计增量式回收会失败时，也会触发一次回收\n5. 如果MetaSpace认为需要回收MetaSpace区域，也会触发一次CMS回收\n\nCMS GC是并发GC，可以和应用并发进行，所以大部分时间不会造成程序暂停。\n\n# 各代大小调优\n各代大小的调优，会直接影响Young GC和Full GC触发的时机和触发的频率，在代大小的调优上，最关键的几个参数为：\n\n参数 | 说明 |\n-- | -- |\n-Xms –Xmx                  | JVM能使用的最小内存和最大内存，通常设置为相同的值，避免运行时要不断的扩展JVM空间，造成性能上的损失 |\n–Xmn                       | 新生代大小 |\n–XX:SurvivorRatio          | 新生代中Eden、From、To的比例，默认8 | \n–XX:MaxTenuringThreshold   | 对象经历多少次Young GC后放入Old Space，默认15 | \n\n设置这些值时，应考虑的方面：\n1. 避免新生代设置过小\n    - Young GC频率过高\n    - 可能导致Young GC的对象直接进入旧年代，若此时进入旧年代的对象大于旧年代剩余空间，将会触发Full GC\n2. 避免新生代设置过大\n    - Old Space变小，Full GC频繁发生\n    - Young GC耗时大幅度增长\n3. 避免Survivor区过小/过大\n    - 调大SurvivorRatio值，Young GC的频率会下降，也会造成Survivor Space过小，如有Young GC后的对象没有被回收且大于Survivor空间，则会直接放入Old Space，引发Full GC的频率提高\n4. 适当设置新生代对象的存活周期，可充分的回收对象，避免对象进入Old Space\n\n# 调优工具\n以前在华为使用的IBM JDK，IHS生成的dump文件比较特别，要用IBM的HeapAnalyzer分析dump文件，用JavaCoreAnalyzer分析JavaCore文件。后来脱离了IBM后，还是要找一些可以更通用的分析调优工具。\n\n## profile\n对JVM调优时，JDK提供的工具不细致，推荐一款工具profile，既可实施监控JVM应用运行情况，也可以对Jmap抓取的内存文件进行分析。\n\n1. 抓取当前JVM内存快照： jmap -F -dump:live,file=jmap.heap[PID]\n2. OutOfMemoryError时自动生成dump文件，启动参数中加入：-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path\n\n使用起来比较简单\n![profile_01-photo](/image/jvm/profile_01.png)\n\n![profile_02-photo](/image/jvm/profile_02.png)\n\n![profile_03-photo](/image/jvm/profile_03.png)","source":"_posts/JVM内存模型.md","raw":"---\ntitle: JVM内存模型、调优与相关工具\ndate: 2020-03-21 10:00:00\ntags: JVM\ncategories: Java\n---\n\n摘自公司培训资料，记录下主要学习的有关JVM的内容。纯手打的，手都要抽筋了。\n<!-- more -->\n# 内存模型\n\n![JVM内存模型01-photo](/image/jvm/JVM7内存模型.png)\n\n![JVM内存模型02-photo](/image/jvm/JVM8内存模型.png)\n\n# 栈\n\n![JVM内存模型03-photo](/image/jvm/JVM_栈.png)\n\n- 本地方法栈(线程私有)：登记native方法，在Execution Engine执行时加载本地方法库\n- 程序计数器（线程私有）：就是一个指针，指向方法区中的方法字节码（用来存储指向下一条指令的地址,也即将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记。\n- 方法区(线程共享)：类的所有字段和方法字节码，以及一些特殊方法如构造函数，接口代码也在此定义。简单说，所有定义的方法的信息都保存在该区域，静态变量+常量+类信息(构造方法/接口定义)+运行时常量池都存在方法区中，虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。\n\n- Java栈（线程私有）： Java线程执行方法的内存模型，一个线程对应一个栈，每个方法在执行的同时都会创建一个栈帧（用于存储局部变量表，操作数栈，动态链接，方法出口等信息）不存在垃圾回收问题，只要线程一结束该栈就释放，生命周期和线程一致\n\nJVM对该区域规范了两种异常：\n1. 线程请求的栈深度大于虚拟机栈所允许的深度，将抛出StackOverFlowError异常\n2. 若虚拟机栈可动态扩展，当无法申请到足够内存空间时将抛出OutOfMemoryError，通过jvm参数–Xss指定栈空间，空间大小决定函数调用的深度\n\n\n# 堆\n1.7中堆分为永久代、新生代、旧生代。1.8与1.7最显著的区别就是去除了永久代，将永久代分为了常量池和方法区，方法区移动到了堆外称之为元空间，占用机器内存，不再占用堆内存。\n\n新生代：\nJDK1.7和1.8中绿色的部分称为新生代，新生代又分为Eden Space和2个Survivor Space，也叫From Space和To Space。其中Eden Space一般我们new的对象都会放在此处，Survivor Space用于Young GC时的存放还需要继续引用的对象。Eden:From:To的默认比例为8:1:1，由启动参数-XX:SurvivorRatio，默认为8。\n\n旧生代：\nJDK1.7和1.8中蓝色部分，用于存放在新生代中经过多次垃圾回收仍然存活的对象/继续引用的对象，从To Space全部移动到Old Generation。有一种情况当生成某个大对象，Eden Space空间不足，进行Young GC，此时如果Survivor空间不足，对象会直接放入Old Generation。\n\n注：线程分配内存不在堆内，而是在堆外，-Xss是在JVM方法栈中划分，所以对于线程比较多的应用应预留相对较多的堆外内存。一般Xmx设置为总机器内存的3/5（个人经验）,-Xmn为Xmx的3/8（sun推荐）。\n\n# Mate Space\n元数据区取代了永久代(jdk1.8以前)，本质和永久代类似，都是对JVM规范中方法区的实现，区别在于元数据区并不在虚拟机中，而是使用本地物理内存，永久代在虚拟机中，永久代逻辑结构上属于堆，但是物理上不属于堆，堆大小=新生代+老年代。元数据区也有可能发生O utOfMemory异常。\n\n- Jdk1.6及之前：有永久代, 常量池在方法区\n- Jdk1.7：有永久代，但已经逐步“去永久代”，常量池在堆\n- Jdk1.8及之后：无永久代，常量池在元空间\n\n元数据区的动态扩展，默认–XX:MetaspaceSize值为21MB的高水位线。一旦触及则Full GC将被触发并卸载没有用的类（类对应的类加载器不再存活），然后高水位线将会重置。新的高水位线的值取决于GC后释放的元空间。如果释放的空间少，这个高水位线则上升。如果释放空间过多，则高水位线下降。\n\n## 为什么jdk1.8用元数据区取代了永久代\n官方解释：移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代\n\n# GC\n\n![GC01-photo](/image/jvm/GC.png)\n\n## Minor GC(Young GC)\n发生在新生代，会造成应用的暂停，发生过程：\n1. 每个对象Eden Space分配内存，当Eden Space空间满，或者不能放入新产生的对象后，进行Young GC进行回收，并将回收后剩余的对象放入To Space，如果To Space空间不足以放入剩余的对象，超出空间的部分对象将直接放入Old Space。\n2. 第二次Young GC时，To Space会转换为From Space，将To Space和Eden Space的对象垃圾回收后放入From Space，此时From Space变为To Space\n3. 运行一段时间后，经过指定次数Young GC仍然存活（被引用）的对象，会放入到Old Space，次数由-XX:MaxTenuringThreshold决定，默认值15。\n\n## Major GC(Full GC)\n对新生代和老年代都按其GC配置类型进行GC。Full GC产生时，会造成应用暂停STW(Stop The World 所有java应用其他线程全部挂起)，且时间远远大于Young GC，是我们需要尽量避免或减少其触发频率。\n\n触发情况如下：\n1. 调用System.gc()\n2. 旧生代空间不足。旧生代在新生代转入对象、大数组时会出现空间不足现象，此时会进行Full GC。当Full GC后仍不能存放时，会抛出OOM。因此为了避免这两种情况下Full GC的产生，调优时应尽量让对象在Young GC时回收，即让对象在新生代多存活一段时间，使其能回收;不要创建过大的对象和数组。\n3. CMS GC时出现promotion failed和concurrent mode failure\n    - promotion filed：在进行Young GC时，Survivor Space放不下，对象只能放入旧生代，而此时旧生代也放不下，此时就会出现promotion failed错误。\n    - concurrent mode failure：在执行CMS GC过程中同时由对象放入Old Space，而此时Old Space空间不足，会粗线此类错误\n\n    优化措施：增加Survivor Space、Old Space空间，降低CMS GC产生的几率\n \n## CMS\nConcurrent Mark-Sweep 目标是尽量减少应用的暂停时间，减少full gc发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代\n\n1. 请求进行一次Full GC，如调用System.gc时\n2. 当没有设置UseCMSInitiatingOccupancyOnly时，会动态计算。如果完成CMS回收所需要的预计时间小于预计的CMS回收的分代填满的时间，就进行回收\n3. 调用should_concurrent_collect()方法返回true\n4. 如果预计增量式回收会失败时，也会触发一次回收\n5. 如果MetaSpace认为需要回收MetaSpace区域，也会触发一次CMS回收\n\nCMS GC是并发GC，可以和应用并发进行，所以大部分时间不会造成程序暂停。\n\n# 各代大小调优\n各代大小的调优，会直接影响Young GC和Full GC触发的时机和触发的频率，在代大小的调优上，最关键的几个参数为：\n\n参数 | 说明 |\n-- | -- |\n-Xms –Xmx                  | JVM能使用的最小内存和最大内存，通常设置为相同的值，避免运行时要不断的扩展JVM空间，造成性能上的损失 |\n–Xmn                       | 新生代大小 |\n–XX:SurvivorRatio          | 新生代中Eden、From、To的比例，默认8 | \n–XX:MaxTenuringThreshold   | 对象经历多少次Young GC后放入Old Space，默认15 | \n\n设置这些值时，应考虑的方面：\n1. 避免新生代设置过小\n    - Young GC频率过高\n    - 可能导致Young GC的对象直接进入旧年代，若此时进入旧年代的对象大于旧年代剩余空间，将会触发Full GC\n2. 避免新生代设置过大\n    - Old Space变小，Full GC频繁发生\n    - Young GC耗时大幅度增长\n3. 避免Survivor区过小/过大\n    - 调大SurvivorRatio值，Young GC的频率会下降，也会造成Survivor Space过小，如有Young GC后的对象没有被回收且大于Survivor空间，则会直接放入Old Space，引发Full GC的频率提高\n4. 适当设置新生代对象的存活周期，可充分的回收对象，避免对象进入Old Space\n\n# 调优工具\n以前在华为使用的IBM JDK，IHS生成的dump文件比较特别，要用IBM的HeapAnalyzer分析dump文件，用JavaCoreAnalyzer分析JavaCore文件。后来脱离了IBM后，还是要找一些可以更通用的分析调优工具。\n\n## profile\n对JVM调优时，JDK提供的工具不细致，推荐一款工具profile，既可实施监控JVM应用运行情况，也可以对Jmap抓取的内存文件进行分析。\n\n1. 抓取当前JVM内存快照： jmap -F -dump:live,file=jmap.heap[PID]\n2. OutOfMemoryError时自动生成dump文件，启动参数中加入：-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path\n\n使用起来比较简单\n![profile_01-photo](/image/jvm/profile_01.png)\n\n![profile_02-photo](/image/jvm/profile_02.png)\n\n![profile_03-photo](/image/jvm/profile_03.png)","slug":"JVM内存模型","published":1,"updated":"2020-05-20T16:04:55.979Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3h003yqotn8guopf4c","content":"<p>摘自公司培训资料，记录下主要学习的有关JVM的内容。纯手打的，手都要抽筋了。<br><a id=\"more\"></a></p>\n<h1 id=\"内存模型\"><a href=\"#内存模型\" class=\"headerlink\" title=\"内存模型\"></a>内存模型</h1><p><img src=\"/image/jvm/JVM7内存模型.png\" alt=\"JVM内存模型01-photo\"></p>\n<p><img src=\"/image/jvm/JVM8内存模型.png\" alt=\"JVM内存模型02-photo\"></p>\n<h1 id=\"栈\"><a href=\"#栈\" class=\"headerlink\" title=\"栈\"></a>栈</h1><p><img src=\"/image/jvm/JVM_栈.png\" alt=\"JVM内存模型03-photo\"></p>\n<ul>\n<li>本地方法栈(线程私有)：登记native方法，在Execution Engine执行时加载本地方法库</li>\n<li>程序计数器（线程私有）：就是一个指针，指向方法区中的方法字节码（用来存储指向下一条指令的地址,也即将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记。</li>\n<li><p>方法区(线程共享)：类的所有字段和方法字节码，以及一些特殊方法如构造函数，接口代码也在此定义。简单说，所有定义的方法的信息都保存在该区域，静态变量+常量+类信息(构造方法/接口定义)+运行时常量池都存在方法区中，虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。</p>\n</li>\n<li><p>Java栈（线程私有）： Java线程执行方法的内存模型，一个线程对应一个栈，每个方法在执行的同时都会创建一个栈帧（用于存储局部变量表，操作数栈，动态链接，方法出口等信息）不存在垃圾回收问题，只要线程一结束该栈就释放，生命周期和线程一致</p>\n</li>\n</ul>\n<p>JVM对该区域规范了两种异常：</p>\n<ol>\n<li>线程请求的栈深度大于虚拟机栈所允许的深度，将抛出StackOverFlowError异常</li>\n<li>若虚拟机栈可动态扩展，当无法申请到足够内存空间时将抛出OutOfMemoryError，通过jvm参数–Xss指定栈空间，空间大小决定函数调用的深度</li>\n</ol>\n<h1 id=\"堆\"><a href=\"#堆\" class=\"headerlink\" title=\"堆\"></a>堆</h1><p>1.7中堆分为永久代、新生代、旧生代。1.8与1.7最显著的区别就是去除了永久代，将永久代分为了常量池和方法区，方法区移动到了堆外称之为元空间，占用机器内存，不再占用堆内存。</p>\n<p>新生代：<br>JDK1.7和1.8中绿色的部分称为新生代，新生代又分为Eden Space和2个Survivor Space，也叫From Space和To Space。其中Eden Space一般我们new的对象都会放在此处，Survivor Space用于Young GC时的存放还需要继续引用的对象。Eden:From:To的默认比例为8:1:1，由启动参数-XX:SurvivorRatio，默认为8。</p>\n<p>旧生代：<br>JDK1.7和1.8中蓝色部分，用于存放在新生代中经过多次垃圾回收仍然存活的对象/继续引用的对象，从To Space全部移动到Old Generation。有一种情况当生成某个大对象，Eden Space空间不足，进行Young GC，此时如果Survivor空间不足，对象会直接放入Old Generation。</p>\n<p>注：线程分配内存不在堆内，而是在堆外，-Xss是在JVM方法栈中划分，所以对于线程比较多的应用应预留相对较多的堆外内存。一般Xmx设置为总机器内存的3/5（个人经验）,-Xmn为Xmx的3/8（sun推荐）。</p>\n<h1 id=\"Mate-Space\"><a href=\"#Mate-Space\" class=\"headerlink\" title=\"Mate Space\"></a>Mate Space</h1><p>元数据区取代了永久代(jdk1.8以前)，本质和永久代类似，都是对JVM规范中方法区的实现，区别在于元数据区并不在虚拟机中，而是使用本地物理内存，永久代在虚拟机中，永久代逻辑结构上属于堆，但是物理上不属于堆，堆大小=新生代+老年代。元数据区也有可能发生O utOfMemory异常。</p>\n<ul>\n<li>Jdk1.6及之前：有永久代, 常量池在方法区</li>\n<li>Jdk1.7：有永久代，但已经逐步“去永久代”，常量池在堆</li>\n<li>Jdk1.8及之后：无永久代，常量池在元空间</li>\n</ul>\n<p>元数据区的动态扩展，默认–XX:MetaspaceSize值为21MB的高水位线。一旦触及则Full GC将被触发并卸载没有用的类（类对应的类加载器不再存活），然后高水位线将会重置。新的高水位线的值取决于GC后释放的元空间。如果释放的空间少，这个高水位线则上升。如果释放空间过多，则高水位线下降。</p>\n<h2 id=\"为什么jdk1-8用元数据区取代了永久代\"><a href=\"#为什么jdk1-8用元数据区取代了永久代\" class=\"headerlink\" title=\"为什么jdk1.8用元数据区取代了永久代\"></a>为什么jdk1.8用元数据区取代了永久代</h2><p>官方解释：移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代</p>\n<h1 id=\"GC\"><a href=\"#GC\" class=\"headerlink\" title=\"GC\"></a>GC</h1><p><img src=\"/image/jvm/GC.png\" alt=\"GC01-photo\"></p>\n<h2 id=\"Minor-GC-Young-GC\"><a href=\"#Minor-GC-Young-GC\" class=\"headerlink\" title=\"Minor GC(Young GC)\"></a>Minor GC(Young GC)</h2><p>发生在新生代，会造成应用的暂停，发生过程：</p>\n<ol>\n<li>每个对象Eden Space分配内存，当Eden Space空间满，或者不能放入新产生的对象后，进行Young GC进行回收，并将回收后剩余的对象放入To Space，如果To Space空间不足以放入剩余的对象，超出空间的部分对象将直接放入Old Space。</li>\n<li>第二次Young GC时，To Space会转换为From Space，将To Space和Eden Space的对象垃圾回收后放入From Space，此时From Space变为To Space</li>\n<li>运行一段时间后，经过指定次数Young GC仍然存活（被引用）的对象，会放入到Old Space，次数由-XX:MaxTenuringThreshold决定，默认值15。</li>\n</ol>\n<h2 id=\"Major-GC-Full-GC\"><a href=\"#Major-GC-Full-GC\" class=\"headerlink\" title=\"Major GC(Full GC)\"></a>Major GC(Full GC)</h2><p>对新生代和老年代都按其GC配置类型进行GC。Full GC产生时，会造成应用暂停STW(Stop The World 所有java应用其他线程全部挂起)，且时间远远大于Young GC，是我们需要尽量避免或减少其触发频率。</p>\n<p>触发情况如下：</p>\n<ol>\n<li>调用System.gc()</li>\n<li>旧生代空间不足。旧生代在新生代转入对象、大数组时会出现空间不足现象，此时会进行Full GC。当Full GC后仍不能存放时，会抛出OOM。因此为了避免这两种情况下Full GC的产生，调优时应尽量让对象在Young GC时回收，即让对象在新生代多存活一段时间，使其能回收;不要创建过大的对象和数组。</li>\n<li><p>CMS GC时出现promotion failed和concurrent mode failure</p>\n<ul>\n<li>promotion filed：在进行Young GC时，Survivor Space放不下，对象只能放入旧生代，而此时旧生代也放不下，此时就会出现promotion failed错误。</li>\n<li><p>concurrent mode failure：在执行CMS GC过程中同时由对象放入Old Space，而此时Old Space空间不足，会粗线此类错误</p>\n<p>优化措施：增加Survivor Space、Old Space空间，降低CMS GC产生的几率</p>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"CMS\"><a href=\"#CMS\" class=\"headerlink\" title=\"CMS\"></a>CMS</h2><p>Concurrent Mark-Sweep 目标是尽量减少应用的暂停时间，减少full gc发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代</p>\n<ol>\n<li>请求进行一次Full GC，如调用System.gc时</li>\n<li>当没有设置UseCMSInitiatingOccupancyOnly时，会动态计算。如果完成CMS回收所需要的预计时间小于预计的CMS回收的分代填满的时间，就进行回收</li>\n<li>调用should_concurrent_collect()方法返回true</li>\n<li>如果预计增量式回收会失败时，也会触发一次回收</li>\n<li>如果MetaSpace认为需要回收MetaSpace区域，也会触发一次CMS回收</li>\n</ol>\n<p>CMS GC是并发GC，可以和应用并发进行，所以大部分时间不会造成程序暂停。</p>\n<h1 id=\"各代大小调优\"><a href=\"#各代大小调优\" class=\"headerlink\" title=\"各代大小调优\"></a>各代大小调优</h1><p>各代大小的调优，会直接影响Young GC和Full GC触发的时机和触发的频率，在代大小的调优上，最关键的几个参数为：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-Xms –Xmx</td>\n<td>JVM能使用的最小内存和最大内存，通常设置为相同的值，避免运行时要不断的扩展JVM空间，造成性能上的损失</td>\n<td></td>\n</tr>\n<tr>\n<td>–Xmn</td>\n<td>新生代大小</td>\n<td></td>\n</tr>\n<tr>\n<td>–XX:SurvivorRatio</td>\n<td>新生代中Eden、From、To的比例，默认8</td>\n<td></td>\n</tr>\n<tr>\n<td>–XX:MaxTenuringThreshold</td>\n<td>对象经历多少次Young GC后放入Old Space，默认15</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>设置这些值时，应考虑的方面：</p>\n<ol>\n<li>避免新生代设置过小<ul>\n<li>Young GC频率过高</li>\n<li>可能导致Young GC的对象直接进入旧年代，若此时进入旧年代的对象大于旧年代剩余空间，将会触发Full GC</li>\n</ul>\n</li>\n<li>避免新生代设置过大<ul>\n<li>Old Space变小，Full GC频繁发生</li>\n<li>Young GC耗时大幅度增长</li>\n</ul>\n</li>\n<li>避免Survivor区过小/过大<ul>\n<li>调大SurvivorRatio值，Young GC的频率会下降，也会造成Survivor Space过小，如有Young GC后的对象没有被回收且大于Survivor空间，则会直接放入Old Space，引发Full GC的频率提高</li>\n</ul>\n</li>\n<li>适当设置新生代对象的存活周期，可充分的回收对象，避免对象进入Old Space</li>\n</ol>\n<h1 id=\"调优工具\"><a href=\"#调优工具\" class=\"headerlink\" title=\"调优工具\"></a>调优工具</h1><p>以前在华为使用的IBM JDK，IHS生成的dump文件比较特别，要用IBM的HeapAnalyzer分析dump文件，用JavaCoreAnalyzer分析JavaCore文件。后来脱离了IBM后，还是要找一些可以更通用的分析调优工具。</p>\n<h2 id=\"profile\"><a href=\"#profile\" class=\"headerlink\" title=\"profile\"></a>profile</h2><p>对JVM调优时，JDK提供的工具不细致，推荐一款工具profile，既可实施监控JVM应用运行情况，也可以对Jmap抓取的内存文件进行分析。</p>\n<ol>\n<li>抓取当前JVM内存快照： jmap -F -dump:live,file=jmap.heap[PID]</li>\n<li>OutOfMemoryError时自动生成dump文件，启动参数中加入：-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path</li>\n</ol>\n<p>使用起来比较简单<br><img src=\"/image/jvm/profile_01.png\" alt=\"profile_01-photo\"></p>\n<p><img src=\"/image/jvm/profile_02.png\" alt=\"profile_02-photo\"></p>\n<p><img src=\"/image/jvm/profile_03.png\" alt=\"profile_03-photo\"></p>\n","site":{"data":{}},"excerpt":"<p>摘自公司培训资料，记录下主要学习的有关JVM的内容。纯手打的，手都要抽筋了。<br>","more":"</p>\n<h1 id=\"内存模型\"><a href=\"#内存模型\" class=\"headerlink\" title=\"内存模型\"></a>内存模型</h1><p><img src=\"/image/jvm/JVM7内存模型.png\" alt=\"JVM内存模型01-photo\"></p>\n<p><img src=\"/image/jvm/JVM8内存模型.png\" alt=\"JVM内存模型02-photo\"></p>\n<h1 id=\"栈\"><a href=\"#栈\" class=\"headerlink\" title=\"栈\"></a>栈</h1><p><img src=\"/image/jvm/JVM_栈.png\" alt=\"JVM内存模型03-photo\"></p>\n<ul>\n<li>本地方法栈(线程私有)：登记native方法，在Execution Engine执行时加载本地方法库</li>\n<li>程序计数器（线程私有）：就是一个指针，指向方法区中的方法字节码（用来存储指向下一条指令的地址,也即将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记。</li>\n<li><p>方法区(线程共享)：类的所有字段和方法字节码，以及一些特殊方法如构造函数，接口代码也在此定义。简单说，所有定义的方法的信息都保存在该区域，静态变量+常量+类信息(构造方法/接口定义)+运行时常量池都存在方法区中，虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。</p>\n</li>\n<li><p>Java栈（线程私有）： Java线程执行方法的内存模型，一个线程对应一个栈，每个方法在执行的同时都会创建一个栈帧（用于存储局部变量表，操作数栈，动态链接，方法出口等信息）不存在垃圾回收问题，只要线程一结束该栈就释放，生命周期和线程一致</p>\n</li>\n</ul>\n<p>JVM对该区域规范了两种异常：</p>\n<ol>\n<li>线程请求的栈深度大于虚拟机栈所允许的深度，将抛出StackOverFlowError异常</li>\n<li>若虚拟机栈可动态扩展，当无法申请到足够内存空间时将抛出OutOfMemoryError，通过jvm参数–Xss指定栈空间，空间大小决定函数调用的深度</li>\n</ol>\n<h1 id=\"堆\"><a href=\"#堆\" class=\"headerlink\" title=\"堆\"></a>堆</h1><p>1.7中堆分为永久代、新生代、旧生代。1.8与1.7最显著的区别就是去除了永久代，将永久代分为了常量池和方法区，方法区移动到了堆外称之为元空间，占用机器内存，不再占用堆内存。</p>\n<p>新生代：<br>JDK1.7和1.8中绿色的部分称为新生代，新生代又分为Eden Space和2个Survivor Space，也叫From Space和To Space。其中Eden Space一般我们new的对象都会放在此处，Survivor Space用于Young GC时的存放还需要继续引用的对象。Eden:From:To的默认比例为8:1:1，由启动参数-XX:SurvivorRatio，默认为8。</p>\n<p>旧生代：<br>JDK1.7和1.8中蓝色部分，用于存放在新生代中经过多次垃圾回收仍然存活的对象/继续引用的对象，从To Space全部移动到Old Generation。有一种情况当生成某个大对象，Eden Space空间不足，进行Young GC，此时如果Survivor空间不足，对象会直接放入Old Generation。</p>\n<p>注：线程分配内存不在堆内，而是在堆外，-Xss是在JVM方法栈中划分，所以对于线程比较多的应用应预留相对较多的堆外内存。一般Xmx设置为总机器内存的3/5（个人经验）,-Xmn为Xmx的3/8（sun推荐）。</p>\n<h1 id=\"Mate-Space\"><a href=\"#Mate-Space\" class=\"headerlink\" title=\"Mate Space\"></a>Mate Space</h1><p>元数据区取代了永久代(jdk1.8以前)，本质和永久代类似，都是对JVM规范中方法区的实现，区别在于元数据区并不在虚拟机中，而是使用本地物理内存，永久代在虚拟机中，永久代逻辑结构上属于堆，但是物理上不属于堆，堆大小=新生代+老年代。元数据区也有可能发生O utOfMemory异常。</p>\n<ul>\n<li>Jdk1.6及之前：有永久代, 常量池在方法区</li>\n<li>Jdk1.7：有永久代，但已经逐步“去永久代”，常量池在堆</li>\n<li>Jdk1.8及之后：无永久代，常量池在元空间</li>\n</ul>\n<p>元数据区的动态扩展，默认–XX:MetaspaceSize值为21MB的高水位线。一旦触及则Full GC将被触发并卸载没有用的类（类对应的类加载器不再存活），然后高水位线将会重置。新的高水位线的值取决于GC后释放的元空间。如果释放的空间少，这个高水位线则上升。如果释放空间过多，则高水位线下降。</p>\n<h2 id=\"为什么jdk1-8用元数据区取代了永久代\"><a href=\"#为什么jdk1-8用元数据区取代了永久代\" class=\"headerlink\" title=\"为什么jdk1.8用元数据区取代了永久代\"></a>为什么jdk1.8用元数据区取代了永久代</h2><p>官方解释：移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代</p>\n<h1 id=\"GC\"><a href=\"#GC\" class=\"headerlink\" title=\"GC\"></a>GC</h1><p><img src=\"/image/jvm/GC.png\" alt=\"GC01-photo\"></p>\n<h2 id=\"Minor-GC-Young-GC\"><a href=\"#Minor-GC-Young-GC\" class=\"headerlink\" title=\"Minor GC(Young GC)\"></a>Minor GC(Young GC)</h2><p>发生在新生代，会造成应用的暂停，发生过程：</p>\n<ol>\n<li>每个对象Eden Space分配内存，当Eden Space空间满，或者不能放入新产生的对象后，进行Young GC进行回收，并将回收后剩余的对象放入To Space，如果To Space空间不足以放入剩余的对象，超出空间的部分对象将直接放入Old Space。</li>\n<li>第二次Young GC时，To Space会转换为From Space，将To Space和Eden Space的对象垃圾回收后放入From Space，此时From Space变为To Space</li>\n<li>运行一段时间后，经过指定次数Young GC仍然存活（被引用）的对象，会放入到Old Space，次数由-XX:MaxTenuringThreshold决定，默认值15。</li>\n</ol>\n<h2 id=\"Major-GC-Full-GC\"><a href=\"#Major-GC-Full-GC\" class=\"headerlink\" title=\"Major GC(Full GC)\"></a>Major GC(Full GC)</h2><p>对新生代和老年代都按其GC配置类型进行GC。Full GC产生时，会造成应用暂停STW(Stop The World 所有java应用其他线程全部挂起)，且时间远远大于Young GC，是我们需要尽量避免或减少其触发频率。</p>\n<p>触发情况如下：</p>\n<ol>\n<li>调用System.gc()</li>\n<li>旧生代空间不足。旧生代在新生代转入对象、大数组时会出现空间不足现象，此时会进行Full GC。当Full GC后仍不能存放时，会抛出OOM。因此为了避免这两种情况下Full GC的产生，调优时应尽量让对象在Young GC时回收，即让对象在新生代多存活一段时间，使其能回收;不要创建过大的对象和数组。</li>\n<li><p>CMS GC时出现promotion failed和concurrent mode failure</p>\n<ul>\n<li>promotion filed：在进行Young GC时，Survivor Space放不下，对象只能放入旧生代，而此时旧生代也放不下，此时就会出现promotion failed错误。</li>\n<li><p>concurrent mode failure：在执行CMS GC过程中同时由对象放入Old Space，而此时Old Space空间不足，会粗线此类错误</p>\n<p>优化措施：增加Survivor Space、Old Space空间，降低CMS GC产生的几率</p>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"CMS\"><a href=\"#CMS\" class=\"headerlink\" title=\"CMS\"></a>CMS</h2><p>Concurrent Mark-Sweep 目标是尽量减少应用的暂停时间，减少full gc发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代</p>\n<ol>\n<li>请求进行一次Full GC，如调用System.gc时</li>\n<li>当没有设置UseCMSInitiatingOccupancyOnly时，会动态计算。如果完成CMS回收所需要的预计时间小于预计的CMS回收的分代填满的时间，就进行回收</li>\n<li>调用should_concurrent_collect()方法返回true</li>\n<li>如果预计增量式回收会失败时，也会触发一次回收</li>\n<li>如果MetaSpace认为需要回收MetaSpace区域，也会触发一次CMS回收</li>\n</ol>\n<p>CMS GC是并发GC，可以和应用并发进行，所以大部分时间不会造成程序暂停。</p>\n<h1 id=\"各代大小调优\"><a href=\"#各代大小调优\" class=\"headerlink\" title=\"各代大小调优\"></a>各代大小调优</h1><p>各代大小的调优，会直接影响Young GC和Full GC触发的时机和触发的频率，在代大小的调优上，最关键的几个参数为：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-Xms –Xmx</td>\n<td>JVM能使用的最小内存和最大内存，通常设置为相同的值，避免运行时要不断的扩展JVM空间，造成性能上的损失</td>\n<td></td>\n</tr>\n<tr>\n<td>–Xmn</td>\n<td>新生代大小</td>\n<td></td>\n</tr>\n<tr>\n<td>–XX:SurvivorRatio</td>\n<td>新生代中Eden、From、To的比例，默认8</td>\n<td></td>\n</tr>\n<tr>\n<td>–XX:MaxTenuringThreshold</td>\n<td>对象经历多少次Young GC后放入Old Space，默认15</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>设置这些值时，应考虑的方面：</p>\n<ol>\n<li>避免新生代设置过小<ul>\n<li>Young GC频率过高</li>\n<li>可能导致Young GC的对象直接进入旧年代，若此时进入旧年代的对象大于旧年代剩余空间，将会触发Full GC</li>\n</ul>\n</li>\n<li>避免新生代设置过大<ul>\n<li>Old Space变小，Full GC频繁发生</li>\n<li>Young GC耗时大幅度增长</li>\n</ul>\n</li>\n<li>避免Survivor区过小/过大<ul>\n<li>调大SurvivorRatio值，Young GC的频率会下降，也会造成Survivor Space过小，如有Young GC后的对象没有被回收且大于Survivor空间，则会直接放入Old Space，引发Full GC的频率提高</li>\n</ul>\n</li>\n<li>适当设置新生代对象的存活周期，可充分的回收对象，避免对象进入Old Space</li>\n</ol>\n<h1 id=\"调优工具\"><a href=\"#调优工具\" class=\"headerlink\" title=\"调优工具\"></a>调优工具</h1><p>以前在华为使用的IBM JDK，IHS生成的dump文件比较特别，要用IBM的HeapAnalyzer分析dump文件，用JavaCoreAnalyzer分析JavaCore文件。后来脱离了IBM后，还是要找一些可以更通用的分析调优工具。</p>\n<h2 id=\"profile\"><a href=\"#profile\" class=\"headerlink\" title=\"profile\"></a>profile</h2><p>对JVM调优时，JDK提供的工具不细致，推荐一款工具profile，既可实施监控JVM应用运行情况，也可以对Jmap抓取的内存文件进行分析。</p>\n<ol>\n<li>抓取当前JVM内存快照： jmap -F -dump:live,file=jmap.heap[PID]</li>\n<li>OutOfMemoryError时自动生成dump文件，启动参数中加入：-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path</li>\n</ol>\n<p>使用起来比较简单<br><img src=\"/image/jvm/profile_01.png\" alt=\"profile_01-photo\"></p>\n<p><img src=\"/image/jvm/profile_02.png\" alt=\"profile_02-photo\"></p>\n<p><img src=\"/image/jvm/profile_03.png\" alt=\"profile_03-photo\"></p>"},{"title":"SpringBoot自动装配原理","date":"2020-01-30T02:00:00.000Z","_content":"\n本文主要记录了学习SpringBoot启动原理及其相关注解知识\n<!-- more -->\n\n\n# @SpringBootApplication\n@SpringBootApplication注解是Spring Boot的核心注解，它其实是一个组合注解：\n``` java\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\n    excludeFilters = {@Filter(\n    type = FilterType.CUSTOM,\n    classes = {TypeExcludeFilter.class}\n), @Filter(\n    type = FilterType.CUSTOM,\n    classes = {AutoConfigurationExcludeFilter.class}\n)}\n)\npublic @interface SpringBootApplication {\n}\n```\n\n虽然定义使用了多个Annotation进行了原信息标注，但实际上重要的只有三个Annotation：\n- @Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration）\n- @EnableAutoConfiguration\n- @ComponentScan\n即 @SpringBootApplication = (默认属性)@Configuration + @EnableAutoConfiguration + @ComponentScan。\n\n## @Configuration\n@Configuration比较熟悉，就不详细赘述了，简单的记录一下。\n\n它就是JavaConfig形式的Spring Ioc容器的配置类使用的那个@Configuration，SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IoC容器的配置类。\n\n## @ComponentScan\n@ComponentScan这个注解在Spring中很重要，它对应XML配置中的元素，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。\n\n我们可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。\n\n注：所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。\n\n## @EnableAutoConfiguration\n@EnableAutoConfiguration这个注解比较重要，所以着重了解下该注解。\n\nSpring框架中有很多@Enable开头的自定义注解。比如@EnableScheduling、@EnableCaching、@EnableMBeanExport\n- @EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器。\n- @EnableMBeanExport是通过@Import将JMX相关的bean定义加载到IoC容器。\n\n@EnableAutoConfiguration其实原理也是类似的，借助@Import的支持，收集和注册特定场景相关的bean定义。借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器。\n\n@EnableAutoConfiguration会根据类路径中的jar依赖为项目进行自动配置，如：添加了spring-boot-starter-web依赖，会自动添加Tomcat和Spring MVC的依赖，Spring Boot会对Tomcat和Spring MVC进行自动配置。\n\n@EnableAutoConfiguration作为一个复合注解，其自身定义关键信息如下\n``` java\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@AutoConfigurationPackage\n@Import({AutoConfigurationImportSelector.class})\npublic @interface EnableAutoConfiguration {\n    String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\";\n\n    Class<?>[] exclude() default {};\n\n    String[] excludeName() default {};\n}\n```\n\n@Import(EnableAutoConfigurationImportSelector.class)，借助EnableAutoConfigurationImportSelector，@EnableAutoConfiguration可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。借助于Spring框架原有的一个工具类：SpringFactoriesLoader的支持，@EnableAutoConfiguration可以智能的自动配置\n\n## SpringFactoriesLoader\nSpringFactoriesLoader属于Spring框架私有的一种扩展方案，主要功能就是从指定的配置文件META-INF/spring.factories加载配置。\n``` java\n/**\n * General purpose factory loading mechanism for internal use within the framework.\n *\n * <p>{@code SpringFactoriesLoader} {@linkplain #loadFactories loads} and instantiates\n * factories of a given type from {@value #FACTORIES_RESOURCE_LOCATION} files which\n * may be present in multiple JAR files in the classpath. The {@code spring.factories}\n * file must be in {@link Properties} format, where the key is the fully qualified\n * name of the interface or abstract class, and the value is a comma-separated list of\n * implementation class names. For example:\n *\n * <pre class=\"code\">example.MyService=example.MyServiceImpl1,example.MyServiceImpl2</pre>\n *\n * where {@code example.MyService} is the name of the interface, and {@code MyServiceImpl1}\n * and {@code MyServiceImpl2} are two implementations.\n *\n * @author Arjen Poutsma\n * @author Juergen Hoeller\n * @author Sam Brannen\n * @since 3.2\n */\npublic final class SpringFactoriesLoader {\n\n\t/**\n\t * The location to look for factories.\n\t * <p>Can be present in multiple JAR files.\n\t */\n\tpublic static final String FACTORIES_RESOURCE_LOCATION = \"META-INF/spring.factories\";\n\n    ...\n}\n```\n配合@EnableAutoConfiguration使用的话，它更多是提供一种配置查找的功能支持，即根据@EnableAutoConfiguration的完整类名org.springframework.boot.autoconfigure.EnableAutoConfiguration作为查找的Key，获取对应的一组@Configuration类。\n\n### SPI机制\n全称为Service Provider Interface，java.util.ServiceLoader的文档里有比较详细的介绍。\n\n简单的总结下java SPI机制的思想。我们系统里抽象的各个模块，往往有很多不同的实现方案，比如日志模块的方案，xml解析模块、jdbc模块的方案等。面向的对象的设计里，我们一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。\n\njava SPI就是提供这样的一个机制：为某个接口寻找服务实现的机制。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。\n\n### Spring Factories实现原理\n- loadFactories 根据接口类获取其实现类的实例，这个方法返回的是对象列表。\n- loadFactoryNames 根据接口获取其接口类的名称，这个方法返回的是类名的列表。\n以上两个方法的关键都是从指定的ClassLoader中获取spring.factories文件，并解析得到类名列表。\n\n``` java\nprivate static Map<String, List<String>> loadSpringFactories(@Nullable ClassLoader classLoader) {\n    MultiValueMap<String, String> result = cache.get(classLoader);\n    if (result != null) {\n        return result;\n    }\n\n    try {\n        Enumeration<URL> urls = (classLoader != null ?\n                classLoader.getResources(FACTORIES_RESOURCE_LOCATION) :\n                ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));\n        result = new LinkedMultiValueMap<>();\n        while (urls.hasMoreElements()) {\n            URL url = urls.nextElement();\n            UrlResource resource = new UrlResource(url);\n            Properties properties = PropertiesLoaderUtils.loadProperties(resource);\n            for (Map.Entry<?, ?> entry : properties.entrySet()) {\n                String factoryClassName = ((String) entry.getKey()).trim();\n                for (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) {\n                    result.add(factoryClassName, factoryName.trim());\n                }\n            }\n        }\n        cache.put(classLoader, result);\n        return result;\n    }\n    catch (IOException ex) {\n        throw new IllegalArgumentException(\"Unable to load factories from location [\" +\n                FACTORIES_RESOURCE_LOCATION + \"]\", ex);\n    }\n}\n```\n从代码中我们可以知道，在这个方法中会遍历整个ClassLoader中所有jar包下的spring.factories文件。也就是说我们可以在自己的jar中配置spring.factories文件，不会影响到其它地方的配置，也不会被别人的配置覆盖。\n\nspring.factories的是通过Properties解析得到的，所以我们在写文件中的内容都是安装下面这种方式配置的：\n\n``` properties\ncom.xxx.interface=com.xxx.classname1,com.xxx.classname2\n```\n\n如果一个接口希望配置多个实现类，可以使用’,’进行分割。\n\n下面是spring-boot包中的配置信息，其中\"\\\"反斜杠是properties中的换行符。\n``` properties\n# PropertySource Loaders\norg.springframework.boot.env.PropertySourceLoader=\\\norg.springframework.boot.env.PropertiesPropertySourceLoader,\\\norg.springframework.boot.env.YamlPropertySourceLoader\n\n# Run Listeners\norg.springframework.boot.SpringApplicationRunListener=\\\norg.springframework.boot.context.event.EventPublishingRunListener\n\n# Error Reporters\norg.springframework.boot.SpringBootExceptionReporter=\\\norg.springframework.boot.diagnostics.FailureAnalyzers\n\n# Application Context Initializers\norg.springframework.context.ApplicationContextInitializer=\\\norg.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\\\norg.springframework.boot.context.ContextIdApplicationContextInitializer,\\\norg.springframework.boot.context.config.DelegatingApplicationContextInitializer,\\\norg.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer\n\n# Application Listeners\norg.springframework.context.ApplicationListener=\\\norg.springframework.boot.ClearCachesApplicationListener,\\\norg.springframework.boot.builder.ParentContextCloserApplicationListener,\\\norg.springframework.boot.context.FileEncodingApplicationListener,\\\norg.springframework.boot.context.config.AnsiOutputApplicationListener,\\\norg.springframework.boot.context.config.ConfigFileApplicationListener,\\\norg.springframework.boot.context.config.DelegatingApplicationListener,\\\norg.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\\norg.springframework.boot.context.logging.LoggingApplicationListener,\\\norg.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener\n\n# Environment Post Processors\norg.springframework.boot.env.EnvironmentPostProcessor=\\\norg.springframework.boot.cloud.CloudFoundryVcapEnvironmentPostProcessor,\\\norg.springframework.boot.env.SpringApplicationJsonEnvironmentPostProcessor,\\\norg.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor\n\n# Failure Analyzers\norg.springframework.boot.diagnostics.FailureAnalyzer=\\\norg.springframework.boot.diagnostics.analyzer.BeanCurrentlyInCreationFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.BeanDefinitionOverrideFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.BeanNotOfRequiredTypeFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.BindFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.BindValidationFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.UnboundConfigurationPropertyFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.ConnectorStartFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.NoSuchMethodFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.NoUniqueBeanDefinitionFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.PortInUseFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.ValidationExceptionFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyNameFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyValueFailureAnalyzer\n\n# FailureAnalysisReporters\norg.springframework.boot.diagnostics.FailureAnalysisReporter=\\\norg.springframework.boot.diagnostics.LoggingFailureAnalysisReporter\n```\n\n# 总结\n一张图概括下自动配置流程\n\n![springboot_01-photo](/image/springboot/springboot_01.png)\n\n# 参考资料\n* https://www.jianshu.com/p/00e49c607fa1\n* https://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&mid=2247485906&idx=1&sn=100197909bbc525ec1cda59335e5cf39&chksm=fc7a647ccb0ded6ae2db78f8dc9a590bb3fdcd64e7bcb0a150ec0fea21f5d01aff44807784aa&mpshare=1&scene=24&srcid=0421OP1NJXUfRzKypZ06i3lq&key=5298608d5b36fb0ddde4e783d3a1813c216d1f173991315391772a045722c6a7aeb2f51a367c88148803ffb619d7d5f91748416250c55cd1bb90cc4ea2b6aa96ad379abd55e38913c2e694905d0704d0&ascene=14&uin=OTYxNTUxNDAw&devicetype=Windows+10&version=62080079&lang=zh_CN&exportkey=AQtLZxi%2BoUNOzXTlOKebY0o%3D&pass_ticket=orqmBNb9hzmVq87z7roh7JPuzSCJKc5zAEn1sgS%2F75PvnlU9ZH%2BlbuwbJmG9cAbu","source":"_posts/SpringBoot自动装配原理.md","raw":"---\ntitle: SpringBoot自动装配原理\ndate: 2020-01-30 10:00:00\ntags: Java\ncategories: Java\n---\n\n本文主要记录了学习SpringBoot启动原理及其相关注解知识\n<!-- more -->\n\n\n# @SpringBootApplication\n@SpringBootApplication注解是Spring Boot的核心注解，它其实是一个组合注解：\n``` java\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\n    excludeFilters = {@Filter(\n    type = FilterType.CUSTOM,\n    classes = {TypeExcludeFilter.class}\n), @Filter(\n    type = FilterType.CUSTOM,\n    classes = {AutoConfigurationExcludeFilter.class}\n)}\n)\npublic @interface SpringBootApplication {\n}\n```\n\n虽然定义使用了多个Annotation进行了原信息标注，但实际上重要的只有三个Annotation：\n- @Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration）\n- @EnableAutoConfiguration\n- @ComponentScan\n即 @SpringBootApplication = (默认属性)@Configuration + @EnableAutoConfiguration + @ComponentScan。\n\n## @Configuration\n@Configuration比较熟悉，就不详细赘述了，简单的记录一下。\n\n它就是JavaConfig形式的Spring Ioc容器的配置类使用的那个@Configuration，SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IoC容器的配置类。\n\n## @ComponentScan\n@ComponentScan这个注解在Spring中很重要，它对应XML配置中的元素，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。\n\n我们可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。\n\n注：所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。\n\n## @EnableAutoConfiguration\n@EnableAutoConfiguration这个注解比较重要，所以着重了解下该注解。\n\nSpring框架中有很多@Enable开头的自定义注解。比如@EnableScheduling、@EnableCaching、@EnableMBeanExport\n- @EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器。\n- @EnableMBeanExport是通过@Import将JMX相关的bean定义加载到IoC容器。\n\n@EnableAutoConfiguration其实原理也是类似的，借助@Import的支持，收集和注册特定场景相关的bean定义。借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器。\n\n@EnableAutoConfiguration会根据类路径中的jar依赖为项目进行自动配置，如：添加了spring-boot-starter-web依赖，会自动添加Tomcat和Spring MVC的依赖，Spring Boot会对Tomcat和Spring MVC进行自动配置。\n\n@EnableAutoConfiguration作为一个复合注解，其自身定义关键信息如下\n``` java\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@AutoConfigurationPackage\n@Import({AutoConfigurationImportSelector.class})\npublic @interface EnableAutoConfiguration {\n    String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\";\n\n    Class<?>[] exclude() default {};\n\n    String[] excludeName() default {};\n}\n```\n\n@Import(EnableAutoConfigurationImportSelector.class)，借助EnableAutoConfigurationImportSelector，@EnableAutoConfiguration可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。借助于Spring框架原有的一个工具类：SpringFactoriesLoader的支持，@EnableAutoConfiguration可以智能的自动配置\n\n## SpringFactoriesLoader\nSpringFactoriesLoader属于Spring框架私有的一种扩展方案，主要功能就是从指定的配置文件META-INF/spring.factories加载配置。\n``` java\n/**\n * General purpose factory loading mechanism for internal use within the framework.\n *\n * <p>{@code SpringFactoriesLoader} {@linkplain #loadFactories loads} and instantiates\n * factories of a given type from {@value #FACTORIES_RESOURCE_LOCATION} files which\n * may be present in multiple JAR files in the classpath. The {@code spring.factories}\n * file must be in {@link Properties} format, where the key is the fully qualified\n * name of the interface or abstract class, and the value is a comma-separated list of\n * implementation class names. For example:\n *\n * <pre class=\"code\">example.MyService=example.MyServiceImpl1,example.MyServiceImpl2</pre>\n *\n * where {@code example.MyService} is the name of the interface, and {@code MyServiceImpl1}\n * and {@code MyServiceImpl2} are two implementations.\n *\n * @author Arjen Poutsma\n * @author Juergen Hoeller\n * @author Sam Brannen\n * @since 3.2\n */\npublic final class SpringFactoriesLoader {\n\n\t/**\n\t * The location to look for factories.\n\t * <p>Can be present in multiple JAR files.\n\t */\n\tpublic static final String FACTORIES_RESOURCE_LOCATION = \"META-INF/spring.factories\";\n\n    ...\n}\n```\n配合@EnableAutoConfiguration使用的话，它更多是提供一种配置查找的功能支持，即根据@EnableAutoConfiguration的完整类名org.springframework.boot.autoconfigure.EnableAutoConfiguration作为查找的Key，获取对应的一组@Configuration类。\n\n### SPI机制\n全称为Service Provider Interface，java.util.ServiceLoader的文档里有比较详细的介绍。\n\n简单的总结下java SPI机制的思想。我们系统里抽象的各个模块，往往有很多不同的实现方案，比如日志模块的方案，xml解析模块、jdbc模块的方案等。面向的对象的设计里，我们一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。\n\njava SPI就是提供这样的一个机制：为某个接口寻找服务实现的机制。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。\n\n### Spring Factories实现原理\n- loadFactories 根据接口类获取其实现类的实例，这个方法返回的是对象列表。\n- loadFactoryNames 根据接口获取其接口类的名称，这个方法返回的是类名的列表。\n以上两个方法的关键都是从指定的ClassLoader中获取spring.factories文件，并解析得到类名列表。\n\n``` java\nprivate static Map<String, List<String>> loadSpringFactories(@Nullable ClassLoader classLoader) {\n    MultiValueMap<String, String> result = cache.get(classLoader);\n    if (result != null) {\n        return result;\n    }\n\n    try {\n        Enumeration<URL> urls = (classLoader != null ?\n                classLoader.getResources(FACTORIES_RESOURCE_LOCATION) :\n                ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));\n        result = new LinkedMultiValueMap<>();\n        while (urls.hasMoreElements()) {\n            URL url = urls.nextElement();\n            UrlResource resource = new UrlResource(url);\n            Properties properties = PropertiesLoaderUtils.loadProperties(resource);\n            for (Map.Entry<?, ?> entry : properties.entrySet()) {\n                String factoryClassName = ((String) entry.getKey()).trim();\n                for (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) {\n                    result.add(factoryClassName, factoryName.trim());\n                }\n            }\n        }\n        cache.put(classLoader, result);\n        return result;\n    }\n    catch (IOException ex) {\n        throw new IllegalArgumentException(\"Unable to load factories from location [\" +\n                FACTORIES_RESOURCE_LOCATION + \"]\", ex);\n    }\n}\n```\n从代码中我们可以知道，在这个方法中会遍历整个ClassLoader中所有jar包下的spring.factories文件。也就是说我们可以在自己的jar中配置spring.factories文件，不会影响到其它地方的配置，也不会被别人的配置覆盖。\n\nspring.factories的是通过Properties解析得到的，所以我们在写文件中的内容都是安装下面这种方式配置的：\n\n``` properties\ncom.xxx.interface=com.xxx.classname1,com.xxx.classname2\n```\n\n如果一个接口希望配置多个实现类，可以使用’,’进行分割。\n\n下面是spring-boot包中的配置信息，其中\"\\\"反斜杠是properties中的换行符。\n``` properties\n# PropertySource Loaders\norg.springframework.boot.env.PropertySourceLoader=\\\norg.springframework.boot.env.PropertiesPropertySourceLoader,\\\norg.springframework.boot.env.YamlPropertySourceLoader\n\n# Run Listeners\norg.springframework.boot.SpringApplicationRunListener=\\\norg.springframework.boot.context.event.EventPublishingRunListener\n\n# Error Reporters\norg.springframework.boot.SpringBootExceptionReporter=\\\norg.springframework.boot.diagnostics.FailureAnalyzers\n\n# Application Context Initializers\norg.springframework.context.ApplicationContextInitializer=\\\norg.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\\\norg.springframework.boot.context.ContextIdApplicationContextInitializer,\\\norg.springframework.boot.context.config.DelegatingApplicationContextInitializer,\\\norg.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer\n\n# Application Listeners\norg.springframework.context.ApplicationListener=\\\norg.springframework.boot.ClearCachesApplicationListener,\\\norg.springframework.boot.builder.ParentContextCloserApplicationListener,\\\norg.springframework.boot.context.FileEncodingApplicationListener,\\\norg.springframework.boot.context.config.AnsiOutputApplicationListener,\\\norg.springframework.boot.context.config.ConfigFileApplicationListener,\\\norg.springframework.boot.context.config.DelegatingApplicationListener,\\\norg.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\\norg.springframework.boot.context.logging.LoggingApplicationListener,\\\norg.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener\n\n# Environment Post Processors\norg.springframework.boot.env.EnvironmentPostProcessor=\\\norg.springframework.boot.cloud.CloudFoundryVcapEnvironmentPostProcessor,\\\norg.springframework.boot.env.SpringApplicationJsonEnvironmentPostProcessor,\\\norg.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor\n\n# Failure Analyzers\norg.springframework.boot.diagnostics.FailureAnalyzer=\\\norg.springframework.boot.diagnostics.analyzer.BeanCurrentlyInCreationFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.BeanDefinitionOverrideFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.BeanNotOfRequiredTypeFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.BindFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.BindValidationFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.UnboundConfigurationPropertyFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.ConnectorStartFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.NoSuchMethodFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.NoUniqueBeanDefinitionFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.PortInUseFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.ValidationExceptionFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyNameFailureAnalyzer,\\\norg.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyValueFailureAnalyzer\n\n# FailureAnalysisReporters\norg.springframework.boot.diagnostics.FailureAnalysisReporter=\\\norg.springframework.boot.diagnostics.LoggingFailureAnalysisReporter\n```\n\n# 总结\n一张图概括下自动配置流程\n\n![springboot_01-photo](/image/springboot/springboot_01.png)\n\n# 参考资料\n* https://www.jianshu.com/p/00e49c607fa1\n* https://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&mid=2247485906&idx=1&sn=100197909bbc525ec1cda59335e5cf39&chksm=fc7a647ccb0ded6ae2db78f8dc9a590bb3fdcd64e7bcb0a150ec0fea21f5d01aff44807784aa&mpshare=1&scene=24&srcid=0421OP1NJXUfRzKypZ06i3lq&key=5298608d5b36fb0ddde4e783d3a1813c216d1f173991315391772a045722c6a7aeb2f51a367c88148803ffb619d7d5f91748416250c55cd1bb90cc4ea2b6aa96ad379abd55e38913c2e694905d0704d0&ascene=14&uin=OTYxNTUxNDAw&devicetype=Windows+10&version=62080079&lang=zh_CN&exportkey=AQtLZxi%2BoUNOzXTlOKebY0o%3D&pass_ticket=orqmBNb9hzmVq87z7roh7JPuzSCJKc5zAEn1sgS%2F75PvnlU9ZH%2BlbuwbJmG9cAbu","slug":"SpringBoot自动装配原理","published":1,"updated":"2020-05-07T09:53:03.538Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3j003zqotnqovf6pqo","content":"<p>本文主要记录了学习SpringBoot启动原理及其相关注解知识<br><a id=\"more\"></a></p>\n<h1 id=\"SpringBootApplication\"><a href=\"#SpringBootApplication\" class=\"headerlink\" title=\"@SpringBootApplication\"></a>@SpringBootApplication</h1><p>@SpringBootApplication注解是Spring Boot的核心注解，它其实是一个组合注解：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Target</span>(&#123;ElementType.TYPE&#125;)</span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class=\"line\"><span class=\"meta\">@Documented</span></span><br><span class=\"line\"><span class=\"meta\">@Inherited</span></span><br><span class=\"line\"><span class=\"meta\">@SpringBootConfiguration</span></span><br><span class=\"line\"><span class=\"meta\">@EnableAutoConfiguration</span></span><br><span class=\"line\"><span class=\"meta\">@ComponentScan</span>(</span><br><span class=\"line\">    excludeFilters = &#123;<span class=\"meta\">@Filter</span>(</span><br><span class=\"line\">    type = FilterType.CUSTOM,</span><br><span class=\"line\">    classes = &#123;TypeExcludeFilter.class&#125;</span><br><span class=\"line\">), <span class=\"meta\">@Filter</span>(</span><br><span class=\"line\">    type = FilterType.CUSTOM,</span><br><span class=\"line\">    classes = &#123;AutoConfigurationExcludeFilter.class&#125;</span><br><span class=\"line\">)&#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> SpringBootApplication &#123;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>虽然定义使用了多个Annotation进行了原信息标注，但实际上重要的只有三个Annotation：</p>\n<ul>\n<li>@Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration）</li>\n<li>@EnableAutoConfiguration</li>\n<li>@ComponentScan<br>即 @SpringBootApplication = (默认属性)@Configuration + @EnableAutoConfiguration + @ComponentScan。</li>\n</ul>\n<h2 id=\"Configuration\"><a href=\"#Configuration\" class=\"headerlink\" title=\"@Configuration\"></a>@Configuration</h2><p>@Configuration比较熟悉，就不详细赘述了，简单的记录一下。</p>\n<p>它就是JavaConfig形式的Spring Ioc容器的配置类使用的那个@Configuration，SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IoC容器的配置类。</p>\n<h2 id=\"ComponentScan\"><a href=\"#ComponentScan\" class=\"headerlink\" title=\"@ComponentScan\"></a>@ComponentScan</h2><p>@ComponentScan这个注解在Spring中很重要，它对应XML配置中的元素，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。</p>\n<p>我们可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。</p>\n<p>注：所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。</p>\n<h2 id=\"EnableAutoConfiguration\"><a href=\"#EnableAutoConfiguration\" class=\"headerlink\" title=\"@EnableAutoConfiguration\"></a>@EnableAutoConfiguration</h2><p>@EnableAutoConfiguration这个注解比较重要，所以着重了解下该注解。</p>\n<p>Spring框架中有很多@Enable开头的自定义注解。比如@EnableScheduling、@EnableCaching、@EnableMBeanExport</p>\n<ul>\n<li>@EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器。</li>\n<li>@EnableMBeanExport是通过@Import将JMX相关的bean定义加载到IoC容器。</li>\n</ul>\n<p>@EnableAutoConfiguration其实原理也是类似的，借助@Import的支持，收集和注册特定场景相关的bean定义。借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器。</p>\n<p>@EnableAutoConfiguration会根据类路径中的jar依赖为项目进行自动配置，如：添加了spring-boot-starter-web依赖，会自动添加Tomcat和Spring MVC的依赖，Spring Boot会对Tomcat和Spring MVC进行自动配置。</p>\n<p>@EnableAutoConfiguration作为一个复合注解，其自身定义关键信息如下<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Target</span>(&#123;ElementType.TYPE&#125;)</span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class=\"line\"><span class=\"meta\">@Documented</span></span><br><span class=\"line\"><span class=\"meta\">@Inherited</span></span><br><span class=\"line\"><span class=\"meta\">@AutoConfigurationPackage</span></span><br><span class=\"line\"><span class=\"meta\">@Import</span>(&#123;AutoConfigurationImportSelector.class&#125;)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> EnableAutoConfiguration &#123;</span><br><span class=\"line\">    String ENABLED_OVERRIDE_PROPERTY = <span class=\"string\">\"spring.boot.enableautoconfiguration\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    Class&lt;?&gt;[] exclude() <span class=\"keyword\">default</span> &#123;&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">    String[] excludeName() <span class=\"keyword\">default</span> &#123;&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>@Import(EnableAutoConfigurationImportSelector.class)，借助EnableAutoConfigurationImportSelector，@EnableAutoConfiguration可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。借助于Spring框架原有的一个工具类：SpringFactoriesLoader的支持，@EnableAutoConfiguration可以智能的自动配置</p>\n<h2 id=\"SpringFactoriesLoader\"><a href=\"#SpringFactoriesLoader\" class=\"headerlink\" title=\"SpringFactoriesLoader\"></a>SpringFactoriesLoader</h2><p>SpringFactoriesLoader属于Spring框架私有的一种扩展方案，主要功能就是从指定的配置文件META-INF/spring.factories加载配置。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * General purpose factory loading mechanism for internal use within the framework.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * &lt;p&gt;&#123;<span class=\"doctag\">@code</span> SpringFactoriesLoader&#125; &#123;<span class=\"doctag\">@linkplain</span> #loadFactories loads&#125; and instantiates</span></span><br><span class=\"line\"><span class=\"comment\"> * factories of a given type from &#123;<span class=\"doctag\">@value</span> #FACTORIES_RESOURCE_LOCATION&#125; files which</span></span><br><span class=\"line\"><span class=\"comment\"> * may be present in multiple JAR files in the classpath. The &#123;<span class=\"doctag\">@code</span> spring.factories&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * file must be in &#123;<span class=\"doctag\">@link</span> Properties&#125; format, where the key is the fully qualified</span></span><br><span class=\"line\"><span class=\"comment\"> * name of the interface or abstract class, and the value is a comma-separated list of</span></span><br><span class=\"line\"><span class=\"comment\"> * implementation class names. For example:</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * &lt;pre class=\"code\"&gt;example.MyService=example.MyServiceImpl1,example.MyServiceImpl2&lt;/pre&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * where &#123;<span class=\"doctag\">@code</span> example.MyService&#125; is the name of the interface, and &#123;<span class=\"doctag\">@code</span> MyServiceImpl1&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * and &#123;<span class=\"doctag\">@code</span> MyServiceImpl2&#125; are two implementations.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span> Arjen Poutsma</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span> Juergen Hoeller</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span> Sam Brannen</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@since</span> 3.2</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SpringFactoriesLoader</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">\t * The location to look for factories.</span></span><br><span class=\"line\"><span class=\"comment\">\t * &lt;p&gt;Can be present in multiple JAR files.</span></span><br><span class=\"line\"><span class=\"comment\">\t */</span></span><br><span class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> String FACTORIES_RESOURCE_LOCATION = <span class=\"string\">\"META-INF/spring.factories\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>配合@EnableAutoConfiguration使用的话，它更多是提供一种配置查找的功能支持，即根据@EnableAutoConfiguration的完整类名org.springframework.boot.autoconfigure.EnableAutoConfiguration作为查找的Key，获取对应的一组@Configuration类。</p>\n<h3 id=\"SPI机制\"><a href=\"#SPI机制\" class=\"headerlink\" title=\"SPI机制\"></a>SPI机制</h3><p>全称为Service Provider Interface，java.util.ServiceLoader的文档里有比较详细的介绍。</p>\n<p>简单的总结下java SPI机制的思想。我们系统里抽象的各个模块，往往有很多不同的实现方案，比如日志模块的方案，xml解析模块、jdbc模块的方案等。面向的对象的设计里，我们一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。</p>\n<p>java SPI就是提供这样的一个机制：为某个接口寻找服务实现的机制。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。</p>\n<h3 id=\"Spring-Factories实现原理\"><a href=\"#Spring-Factories实现原理\" class=\"headerlink\" title=\"Spring Factories实现原理\"></a>Spring Factories实现原理</h3><ul>\n<li>loadFactories 根据接口类获取其实现类的实例，这个方法返回的是对象列表。</li>\n<li>loadFactoryNames 根据接口获取其接口类的名称，这个方法返回的是类名的列表。<br>以上两个方法的关键都是从指定的ClassLoader中获取spring.factories文件，并解析得到类名列表。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(<span class=\"meta\">@Nullable</span> ClassLoader classLoader) &#123;</span><br><span class=\"line\">    MultiValueMap&lt;String, String&gt; result = cache.get(classLoader);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (result != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        Enumeration&lt;URL&gt; urls = (classLoader != <span class=\"keyword\">null</span> ?</span><br><span class=\"line\">                classLoader.getResources(FACTORIES_RESOURCE_LOCATION) :</span><br><span class=\"line\">                ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));</span><br><span class=\"line\">        result = <span class=\"keyword\">new</span> LinkedMultiValueMap&lt;&gt;();</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (urls.hasMoreElements()) &#123;</span><br><span class=\"line\">            URL url = urls.nextElement();</span><br><span class=\"line\">            UrlResource resource = <span class=\"keyword\">new</span> UrlResource(url);</span><br><span class=\"line\">            Properties properties = PropertiesLoaderUtils.loadProperties(resource);</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123;</span><br><span class=\"line\">                String factoryClassName = ((String) entry.getKey()).trim();</span><br><span class=\"line\">                <span class=\"keyword\">for</span> (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123;</span><br><span class=\"line\">                    result.add(factoryClassName, factoryName.trim());</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        cache.put(classLoader, result);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (IOException ex) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(<span class=\"string\">\"Unable to load factories from location [\"</span> +</span><br><span class=\"line\">                FACTORIES_RESOURCE_LOCATION + <span class=\"string\">\"]\"</span>, ex);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>从代码中我们可以知道，在这个方法中会遍历整个ClassLoader中所有jar包下的spring.factories文件。也就是说我们可以在自己的jar中配置spring.factories文件，不会影响到其它地方的配置，也不会被别人的配置覆盖。</p>\n<p>spring.factories的是通过Properties解析得到的，所以我们在写文件中的内容都是安装下面这种方式配置的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">com.xxx.interface=com.xxx.classname1,com.xxx.classname2</span><br></pre></td></tr></table></figure>\n<p>如果一个接口希望配置多个实现类，可以使用’,’进行分割。</p>\n<p>下面是spring-boot包中的配置信息，其中”\\”反斜杠是properties中的换行符。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># PropertySource Loaders</span><br><span class=\"line\">org.springframework.boot.env.PropertySourceLoader=\\</span><br><span class=\"line\">org.springframework.boot.env.PropertiesPropertySourceLoader,\\</span><br><span class=\"line\">org.springframework.boot.env.YamlPropertySourceLoader</span><br><span class=\"line\"></span><br><span class=\"line\"># Run Listeners</span><br><span class=\"line\">org.springframework.boot.SpringApplicationRunListener=\\</span><br><span class=\"line\">org.springframework.boot.context.event.EventPublishingRunListener</span><br><span class=\"line\"></span><br><span class=\"line\"># Error Reporters</span><br><span class=\"line\">org.springframework.boot.SpringBootExceptionReporter=\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.FailureAnalyzers</span><br><span class=\"line\"></span><br><span class=\"line\"># Application Context Initializers</span><br><span class=\"line\">org.springframework.context.ApplicationContextInitializer=\\</span><br><span class=\"line\">org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\\</span><br><span class=\"line\">org.springframework.boot.context.ContextIdApplicationContextInitializer,\\</span><br><span class=\"line\">org.springframework.boot.context.config.DelegatingApplicationContextInitializer,\\</span><br><span class=\"line\">org.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer</span><br><span class=\"line\"></span><br><span class=\"line\"># Application Listeners</span><br><span class=\"line\">org.springframework.context.ApplicationListener=\\</span><br><span class=\"line\">org.springframework.boot.ClearCachesApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.builder.ParentContextCloserApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.FileEncodingApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.config.AnsiOutputApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.config.ConfigFileApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.config.DelegatingApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.logging.LoggingApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener</span><br><span class=\"line\"></span><br><span class=\"line\"># Environment Post Processors</span><br><span class=\"line\">org.springframework.boot.env.EnvironmentPostProcessor=\\</span><br><span class=\"line\">org.springframework.boot.cloud.CloudFoundryVcapEnvironmentPostProcessor,\\</span><br><span class=\"line\">org.springframework.boot.env.SpringApplicationJsonEnvironmentPostProcessor,\\</span><br><span class=\"line\">org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor</span><br><span class=\"line\"></span><br><span class=\"line\"># Failure Analyzers</span><br><span class=\"line\">org.springframework.boot.diagnostics.FailureAnalyzer=\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BeanCurrentlyInCreationFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BeanDefinitionOverrideFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BeanNotOfRequiredTypeFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BindFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BindValidationFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.UnboundConfigurationPropertyFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.ConnectorStartFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.NoSuchMethodFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.NoUniqueBeanDefinitionFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.PortInUseFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.ValidationExceptionFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyNameFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyValueFailureAnalyzer</span><br><span class=\"line\"></span><br><span class=\"line\"># FailureAnalysisReporters</span><br><span class=\"line\">org.springframework.boot.diagnostics.FailureAnalysisReporter=\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>一张图概括下自动配置流程</p>\n<p><img src=\"/image/springboot/springboot_01.png\" alt=\"springboot_01-photo\"></p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://www.jianshu.com/p/00e49c607fa1\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/00e49c607fa1</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247485906&amp;idx=1&amp;sn=100197909bbc525ec1cda59335e5cf39&amp;chksm=fc7a647ccb0ded6ae2db78f8dc9a590bb3fdcd64e7bcb0a150ec0fea21f5d01aff44807784aa&amp;mpshare=1&amp;scene=24&amp;srcid=0421OP1NJXUfRzKypZ06i3lq&amp;key=5298608d5b36fb0ddde4e783d3a1813c216d1f173991315391772a045722c6a7aeb2f51a367c88148803ffb619d7d5f91748416250c55cd1bb90cc4ea2b6aa96ad379abd55e38913c2e694905d0704d0&amp;ascene=14&amp;uin=OTYxNTUxNDAw&amp;devicetype=Windows+10&amp;version=62080079&amp;lang=zh_CN&amp;exportkey=AQtLZxi%2BoUNOzXTlOKebY0o%3D&amp;pass_ticket=orqmBNb9hzmVq87z7roh7JPuzSCJKc5zAEn1sgS%2F75PvnlU9ZH%2BlbuwbJmG9cAbu\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247485906&amp;idx=1&amp;sn=100197909bbc525ec1cda59335e5cf39&amp;chksm=fc7a647ccb0ded6ae2db78f8dc9a590bb3fdcd64e7bcb0a150ec0fea21f5d01aff44807784aa&amp;mpshare=1&amp;scene=24&amp;srcid=0421OP1NJXUfRzKypZ06i3lq&amp;key=5298608d5b36fb0ddde4e783d3a1813c216d1f173991315391772a045722c6a7aeb2f51a367c88148803ffb619d7d5f91748416250c55cd1bb90cc4ea2b6aa96ad379abd55e38913c2e694905d0704d0&amp;ascene=14&amp;uin=OTYxNTUxNDAw&amp;devicetype=Windows+10&amp;version=62080079&amp;lang=zh_CN&amp;exportkey=AQtLZxi%2BoUNOzXTlOKebY0o%3D&amp;pass_ticket=orqmBNb9hzmVq87z7roh7JPuzSCJKc5zAEn1sgS%2F75PvnlU9ZH%2BlbuwbJmG9cAbu</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>本文主要记录了学习SpringBoot启动原理及其相关注解知识<br>","more":"</p>\n<h1 id=\"SpringBootApplication\"><a href=\"#SpringBootApplication\" class=\"headerlink\" title=\"@SpringBootApplication\"></a>@SpringBootApplication</h1><p>@SpringBootApplication注解是Spring Boot的核心注解，它其实是一个组合注解：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Target</span>(&#123;ElementType.TYPE&#125;)</span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class=\"line\"><span class=\"meta\">@Documented</span></span><br><span class=\"line\"><span class=\"meta\">@Inherited</span></span><br><span class=\"line\"><span class=\"meta\">@SpringBootConfiguration</span></span><br><span class=\"line\"><span class=\"meta\">@EnableAutoConfiguration</span></span><br><span class=\"line\"><span class=\"meta\">@ComponentScan</span>(</span><br><span class=\"line\">    excludeFilters = &#123;<span class=\"meta\">@Filter</span>(</span><br><span class=\"line\">    type = FilterType.CUSTOM,</span><br><span class=\"line\">    classes = &#123;TypeExcludeFilter.class&#125;</span><br><span class=\"line\">), <span class=\"meta\">@Filter</span>(</span><br><span class=\"line\">    type = FilterType.CUSTOM,</span><br><span class=\"line\">    classes = &#123;AutoConfigurationExcludeFilter.class&#125;</span><br><span class=\"line\">)&#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> SpringBootApplication &#123;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>虽然定义使用了多个Annotation进行了原信息标注，但实际上重要的只有三个Annotation：</p>\n<ul>\n<li>@Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration）</li>\n<li>@EnableAutoConfiguration</li>\n<li>@ComponentScan<br>即 @SpringBootApplication = (默认属性)@Configuration + @EnableAutoConfiguration + @ComponentScan。</li>\n</ul>\n<h2 id=\"Configuration\"><a href=\"#Configuration\" class=\"headerlink\" title=\"@Configuration\"></a>@Configuration</h2><p>@Configuration比较熟悉，就不详细赘述了，简单的记录一下。</p>\n<p>它就是JavaConfig形式的Spring Ioc容器的配置类使用的那个@Configuration，SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IoC容器的配置类。</p>\n<h2 id=\"ComponentScan\"><a href=\"#ComponentScan\" class=\"headerlink\" title=\"@ComponentScan\"></a>@ComponentScan</h2><p>@ComponentScan这个注解在Spring中很重要，它对应XML配置中的元素，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。</p>\n<p>我们可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。</p>\n<p>注：所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。</p>\n<h2 id=\"EnableAutoConfiguration\"><a href=\"#EnableAutoConfiguration\" class=\"headerlink\" title=\"@EnableAutoConfiguration\"></a>@EnableAutoConfiguration</h2><p>@EnableAutoConfiguration这个注解比较重要，所以着重了解下该注解。</p>\n<p>Spring框架中有很多@Enable开头的自定义注解。比如@EnableScheduling、@EnableCaching、@EnableMBeanExport</p>\n<ul>\n<li>@EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器。</li>\n<li>@EnableMBeanExport是通过@Import将JMX相关的bean定义加载到IoC容器。</li>\n</ul>\n<p>@EnableAutoConfiguration其实原理也是类似的，借助@Import的支持，收集和注册特定场景相关的bean定义。借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器。</p>\n<p>@EnableAutoConfiguration会根据类路径中的jar依赖为项目进行自动配置，如：添加了spring-boot-starter-web依赖，会自动添加Tomcat和Spring MVC的依赖，Spring Boot会对Tomcat和Spring MVC进行自动配置。</p>\n<p>@EnableAutoConfiguration作为一个复合注解，其自身定义关键信息如下<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Target</span>(&#123;ElementType.TYPE&#125;)</span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class=\"line\"><span class=\"meta\">@Documented</span></span><br><span class=\"line\"><span class=\"meta\">@Inherited</span></span><br><span class=\"line\"><span class=\"meta\">@AutoConfigurationPackage</span></span><br><span class=\"line\"><span class=\"meta\">@Import</span>(&#123;AutoConfigurationImportSelector.class&#125;)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> EnableAutoConfiguration &#123;</span><br><span class=\"line\">    String ENABLED_OVERRIDE_PROPERTY = <span class=\"string\">\"spring.boot.enableautoconfiguration\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    Class&lt;?&gt;[] exclude() <span class=\"keyword\">default</span> &#123;&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\">    String[] excludeName() <span class=\"keyword\">default</span> &#123;&#125;;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>@Import(EnableAutoConfigurationImportSelector.class)，借助EnableAutoConfigurationImportSelector，@EnableAutoConfiguration可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。借助于Spring框架原有的一个工具类：SpringFactoriesLoader的支持，@EnableAutoConfiguration可以智能的自动配置</p>\n<h2 id=\"SpringFactoriesLoader\"><a href=\"#SpringFactoriesLoader\" class=\"headerlink\" title=\"SpringFactoriesLoader\"></a>SpringFactoriesLoader</h2><p>SpringFactoriesLoader属于Spring框架私有的一种扩展方案，主要功能就是从指定的配置文件META-INF/spring.factories加载配置。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * General purpose factory loading mechanism for internal use within the framework.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * &lt;p&gt;&#123;<span class=\"doctag\">@code</span> SpringFactoriesLoader&#125; &#123;<span class=\"doctag\">@linkplain</span> #loadFactories loads&#125; and instantiates</span></span><br><span class=\"line\"><span class=\"comment\"> * factories of a given type from &#123;<span class=\"doctag\">@value</span> #FACTORIES_RESOURCE_LOCATION&#125; files which</span></span><br><span class=\"line\"><span class=\"comment\"> * may be present in multiple JAR files in the classpath. The &#123;<span class=\"doctag\">@code</span> spring.factories&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * file must be in &#123;<span class=\"doctag\">@link</span> Properties&#125; format, where the key is the fully qualified</span></span><br><span class=\"line\"><span class=\"comment\"> * name of the interface or abstract class, and the value is a comma-separated list of</span></span><br><span class=\"line\"><span class=\"comment\"> * implementation class names. For example:</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * &lt;pre class=\"code\"&gt;example.MyService=example.MyServiceImpl1,example.MyServiceImpl2&lt;/pre&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * where &#123;<span class=\"doctag\">@code</span> example.MyService&#125; is the name of the interface, and &#123;<span class=\"doctag\">@code</span> MyServiceImpl1&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * and &#123;<span class=\"doctag\">@code</span> MyServiceImpl2&#125; are two implementations.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span> Arjen Poutsma</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span> Juergen Hoeller</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@author</span> Sam Brannen</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@since</span> 3.2</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SpringFactoriesLoader</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">\t * The location to look for factories.</span></span><br><span class=\"line\"><span class=\"comment\">\t * &lt;p&gt;Can be present in multiple JAR files.</span></span><br><span class=\"line\"><span class=\"comment\">\t */</span></span><br><span class=\"line\">\t<span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> String FACTORIES_RESOURCE_LOCATION = <span class=\"string\">\"META-INF/spring.factories\"</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>配合@EnableAutoConfiguration使用的话，它更多是提供一种配置查找的功能支持，即根据@EnableAutoConfiguration的完整类名org.springframework.boot.autoconfigure.EnableAutoConfiguration作为查找的Key，获取对应的一组@Configuration类。</p>\n<h3 id=\"SPI机制\"><a href=\"#SPI机制\" class=\"headerlink\" title=\"SPI机制\"></a>SPI机制</h3><p>全称为Service Provider Interface，java.util.ServiceLoader的文档里有比较详细的介绍。</p>\n<p>简单的总结下java SPI机制的思想。我们系统里抽象的各个模块，往往有很多不同的实现方案，比如日志模块的方案，xml解析模块、jdbc模块的方案等。面向的对象的设计里，我们一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。</p>\n<p>java SPI就是提供这样的一个机制：为某个接口寻找服务实现的机制。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。</p>\n<h3 id=\"Spring-Factories实现原理\"><a href=\"#Spring-Factories实现原理\" class=\"headerlink\" title=\"Spring Factories实现原理\"></a>Spring Factories实现原理</h3><ul>\n<li>loadFactories 根据接口类获取其实现类的实例，这个方法返回的是对象列表。</li>\n<li>loadFactoryNames 根据接口获取其接口类的名称，这个方法返回的是类名的列表。<br>以上两个方法的关键都是从指定的ClassLoader中获取spring.factories文件，并解析得到类名列表。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(<span class=\"meta\">@Nullable</span> ClassLoader classLoader) &#123;</span><br><span class=\"line\">    MultiValueMap&lt;String, String&gt; result = cache.get(classLoader);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (result != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        Enumeration&lt;URL&gt; urls = (classLoader != <span class=\"keyword\">null</span> ?</span><br><span class=\"line\">                classLoader.getResources(FACTORIES_RESOURCE_LOCATION) :</span><br><span class=\"line\">                ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));</span><br><span class=\"line\">        result = <span class=\"keyword\">new</span> LinkedMultiValueMap&lt;&gt;();</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (urls.hasMoreElements()) &#123;</span><br><span class=\"line\">            URL url = urls.nextElement();</span><br><span class=\"line\">            UrlResource resource = <span class=\"keyword\">new</span> UrlResource(url);</span><br><span class=\"line\">            Properties properties = PropertiesLoaderUtils.loadProperties(resource);</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123;</span><br><span class=\"line\">                String factoryClassName = ((String) entry.getKey()).trim();</span><br><span class=\"line\">                <span class=\"keyword\">for</span> (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123;</span><br><span class=\"line\">                    result.add(factoryClassName, factoryName.trim());</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        cache.put(classLoader, result);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">catch</span> (IOException ex) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> IllegalArgumentException(<span class=\"string\">\"Unable to load factories from location [\"</span> +</span><br><span class=\"line\">                FACTORIES_RESOURCE_LOCATION + <span class=\"string\">\"]\"</span>, ex);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>从代码中我们可以知道，在这个方法中会遍历整个ClassLoader中所有jar包下的spring.factories文件。也就是说我们可以在自己的jar中配置spring.factories文件，不会影响到其它地方的配置，也不会被别人的配置覆盖。</p>\n<p>spring.factories的是通过Properties解析得到的，所以我们在写文件中的内容都是安装下面这种方式配置的：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">com.xxx.interface=com.xxx.classname1,com.xxx.classname2</span><br></pre></td></tr></table></figure>\n<p>如果一个接口希望配置多个实现类，可以使用’,’进行分割。</p>\n<p>下面是spring-boot包中的配置信息，其中”\\”反斜杠是properties中的换行符。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># PropertySource Loaders</span><br><span class=\"line\">org.springframework.boot.env.PropertySourceLoader=\\</span><br><span class=\"line\">org.springframework.boot.env.PropertiesPropertySourceLoader,\\</span><br><span class=\"line\">org.springframework.boot.env.YamlPropertySourceLoader</span><br><span class=\"line\"></span><br><span class=\"line\"># Run Listeners</span><br><span class=\"line\">org.springframework.boot.SpringApplicationRunListener=\\</span><br><span class=\"line\">org.springframework.boot.context.event.EventPublishingRunListener</span><br><span class=\"line\"></span><br><span class=\"line\"># Error Reporters</span><br><span class=\"line\">org.springframework.boot.SpringBootExceptionReporter=\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.FailureAnalyzers</span><br><span class=\"line\"></span><br><span class=\"line\"># Application Context Initializers</span><br><span class=\"line\">org.springframework.context.ApplicationContextInitializer=\\</span><br><span class=\"line\">org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\\</span><br><span class=\"line\">org.springframework.boot.context.ContextIdApplicationContextInitializer,\\</span><br><span class=\"line\">org.springframework.boot.context.config.DelegatingApplicationContextInitializer,\\</span><br><span class=\"line\">org.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer</span><br><span class=\"line\"></span><br><span class=\"line\"># Application Listeners</span><br><span class=\"line\">org.springframework.context.ApplicationListener=\\</span><br><span class=\"line\">org.springframework.boot.ClearCachesApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.builder.ParentContextCloserApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.FileEncodingApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.config.AnsiOutputApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.config.ConfigFileApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.config.DelegatingApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.context.logging.LoggingApplicationListener,\\</span><br><span class=\"line\">org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener</span><br><span class=\"line\"></span><br><span class=\"line\"># Environment Post Processors</span><br><span class=\"line\">org.springframework.boot.env.EnvironmentPostProcessor=\\</span><br><span class=\"line\">org.springframework.boot.cloud.CloudFoundryVcapEnvironmentPostProcessor,\\</span><br><span class=\"line\">org.springframework.boot.env.SpringApplicationJsonEnvironmentPostProcessor,\\</span><br><span class=\"line\">org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor</span><br><span class=\"line\"></span><br><span class=\"line\"># Failure Analyzers</span><br><span class=\"line\">org.springframework.boot.diagnostics.FailureAnalyzer=\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BeanCurrentlyInCreationFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BeanDefinitionOverrideFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BeanNotOfRequiredTypeFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BindFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.BindValidationFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.UnboundConfigurationPropertyFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.ConnectorStartFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.NoSuchMethodFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.NoUniqueBeanDefinitionFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.PortInUseFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.ValidationExceptionFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyNameFailureAnalyzer,\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyValueFailureAnalyzer</span><br><span class=\"line\"></span><br><span class=\"line\"># FailureAnalysisReporters</span><br><span class=\"line\">org.springframework.boot.diagnostics.FailureAnalysisReporter=\\</span><br><span class=\"line\">org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>一张图概括下自动配置流程</p>\n<p><img src=\"/image/springboot/springboot_01.png\" alt=\"springboot_01-photo\"></p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://www.jianshu.com/p/00e49c607fa1\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/00e49c607fa1</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247485906&amp;idx=1&amp;sn=100197909bbc525ec1cda59335e5cf39&amp;chksm=fc7a647ccb0ded6ae2db78f8dc9a590bb3fdcd64e7bcb0a150ec0fea21f5d01aff44807784aa&amp;mpshare=1&amp;scene=24&amp;srcid=0421OP1NJXUfRzKypZ06i3lq&amp;key=5298608d5b36fb0ddde4e783d3a1813c216d1f173991315391772a045722c6a7aeb2f51a367c88148803ffb619d7d5f91748416250c55cd1bb90cc4ea2b6aa96ad379abd55e38913c2e694905d0704d0&amp;ascene=14&amp;uin=OTYxNTUxNDAw&amp;devicetype=Windows+10&amp;version=62080079&amp;lang=zh_CN&amp;exportkey=AQtLZxi%2BoUNOzXTlOKebY0o%3D&amp;pass_ticket=orqmBNb9hzmVq87z7roh7JPuzSCJKc5zAEn1sgS%2F75PvnlU9ZH%2BlbuwbJmG9cAbu\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzU2MTI4MjI0MQ==&amp;mid=2247485906&amp;idx=1&amp;sn=100197909bbc525ec1cda59335e5cf39&amp;chksm=fc7a647ccb0ded6ae2db78f8dc9a590bb3fdcd64e7bcb0a150ec0fea21f5d01aff44807784aa&amp;mpshare=1&amp;scene=24&amp;srcid=0421OP1NJXUfRzKypZ06i3lq&amp;key=5298608d5b36fb0ddde4e783d3a1813c216d1f173991315391772a045722c6a7aeb2f51a367c88148803ffb619d7d5f91748416250c55cd1bb90cc4ea2b6aa96ad379abd55e38913c2e694905d0704d0&amp;ascene=14&amp;uin=OTYxNTUxNDAw&amp;devicetype=Windows+10&amp;version=62080079&amp;lang=zh_CN&amp;exportkey=AQtLZxi%2BoUNOzXTlOKebY0o%3D&amp;pass_ticket=orqmBNb9hzmVq87z7roh7JPuzSCJKc5zAEn1sgS%2F75PvnlU9ZH%2BlbuwbJmG9cAbu</a></li>\n</ul>"},{"title":"docker 架构","date":"2019-08-26T03:58:00.000Z","_content":"\n> 前段时间公司培训，运维大佬提供的材料，有列举出docker的基本架构，在学习docker和Kubernetes的时候，其实先学习内部架构和对象的话，更有助于提升对整体应用的理解。\n\n<!-- more -->\n## 概述\nDocker 是一个应用程序开发、部署、运行的平台，使用 go 语言开发。相较于传统的主机虚拟化，Docker提供了轻量级的应用隔离方案，并且为我们提供了应用程序快速扩容、缩容的能力。\n\nDocker依赖于LXC(Linux Containers)技术，充分利用了其中的Namespace这个内核级特性，实现了容器之间的资源隔离。本质上来看，每一个Docker容器就是宿主机进程，不同 Docker 容器就对应不同的宿主机进程，这样，不同容器（即不同进程）就可以采用 Namespace 资源隔离，使得每一个容器看起来都像是一个独立的小虚拟机\n\ndocker其它核心技术：\n\n- cgroup：资源控制\n- rootfs：文件系统隔离\n- aufs：高级分层文件系统(Advanced Multi-layered unification filesytem)\n\n## 架构\n### 静态部件描述\nDocker采用的是CS架构，包含了三个主要部分：dockerd守护进程、REST API接口层、cli接口层(管理容器、镜像、网络、存储等等)，docker client 通过Unix套接字或者网络接口访问 docker daemon，从而完成容器、镜像等内容的管理\n\n![](/image/DevOps/docker_01.png)\n\n### 流程描述\n![](/image/DevOps/docker_02.png)\n\n## 对象\n\n### 镜像\n镜像是一个用来构建容器的只读模版，通常一个镜像会依赖其他的镜像。例如我们编写的一个Node程序需要依赖Node环境，那在构建这个应用镜像时就需要依赖基础的Node镜像。\n\n我们可以创建自己的镜像，也可以使用仓库中已经创建好的镜像。创建镜像需要创建一个Dockerfile文件。每个Dockerfile定义镜像文件中的一层，当定义发生变化的时候，只需要更新这一层的文件即可。\n\n### 容器\n\n容器是一个运行时状态下的镜像，通过docker命令我们可以创建、启动、停止、删除容器\n\n> 启动我们的第一个容器：\n```\ndocker run --rm hello-world\n```\n\n1.  如果本地没有hello-world镜像，那么首先拉取镜像\n2.  自动创建一个容器，相当于命令dock container create\n3.  Docker分配一块文件系统给容器\n4.  Docker创建网络接口、分配网络地址\n5.  启动容器，并且执行目标入口命令\n6.  容器关闭并退出\n7.  容器销毁\n\n### 网络\n\nDocker的网络子系统是可插拔的，支持bridge、host、overlay、macvlan、none等网络模式\n\n*  bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将主机上的Docker容器连接到docker0虚拟网桥上，docker0网桥由docker后台服务启动时创建，默认在172.17.0.0/16段每一个容器运行时会生成一对veth网络设备直连，再通过网桥使得同一个主机上的容器间可以相互通信\n```\n+-------------------------------------------------------------------------------+\n|                                                                               |\n|       +---------------------------------------------------------------+       |\n|       |                           docker0                             |       |\n|       +---------------------------------------------------------------+       |\n|                             ↑               ↑                                 |\n|.............................|...............|.................................|\n|                             ↓               ↓                                 |\n|        +----------+    +-----------+   +-----------+    +-----------+         |\n|        |   veth2  |<-->|   veth1   |   |   veth3   |<-->|   veth4   |         |\n|        +----------+    +-----------+   +-----------+    +-----------+         |\n|             ↑                                                 ↑               |\n|             +-------------------------------------------------+               |\n|        172.16.17.2                                       172.16.17.3          |\n+-------------------------------------------------------------------------------+\n```\n\n* host模式下，容器会共享主机的network namespace，所以拥有主机的全部网络通信能力，通常用于docker容器测试\n\n### 存储\n\n默认情况下，容器中的应用生成的所有文件都存放在一个可写的容器层，意味着这些数据的生命周期和容器保持一致，这些文件与容器高度关联，因此会带来下面几个问题：\n\n* 不能在宿主机上很方便地访问容器中的文件\n* 无法在多个容器之间共享数据\n* 当容器删除时，容器中产生的数据将丢失\n\n为此，Docker提供了两种方案解决数据问题：\n* bind mount volumes：将host上已存在的目录或文件挂载到容器中使用\n* docker managed volumes：docker自己管理的数据卷存储\n\n对比一下两种方式各自的特点：\n\n- | bind mount Volumes | docker managed volumes\n- | - | -\nvolume 位置 | 可任意指定 | /var/lib/docker/volumes/...\n对已有mount point 影响 | 隐藏并替换为 volume | 原有数据复制到 volume<\n是否支持单个文件 | 支持 | 不支持，只能是目录\n权限控制 | 可设置为只读，默认为读写权限 |无控制，均为读写权限\n移植性 | 移植性弱，与 host path 绑定 | 移植性强，无需指定 host 目录\n\n不管使用哪种方式，容器内看起来都是一样的，或者作为一个文件夹存在、或者作为一个文件存在。\n\n上图说明了不同方式的区别，Volumes 是存在本地文件系统中的一部分，其他应用程序不能对这个文件系统进行修改，Linux下在/var/lib/docker/volumes。这是数据持久化的最好方案。Bind Mount 允许将主机中任何位置的数据挂载，这些数据的读写没有收到保护。tmps是存储在主机内存中的数据。\n\n## 常用操作\n### cli\n#### 下载镜像\n```\ndocker pull urlpath:[tag]\n```\n#### 查询镜像\n```\ndocker images\n```\n#### 运行镜像（启动容器）\n```\ndocker run [-d] \\\n  [--rm] \\\n  [--name {container_name}] \\\n  [-p {hostport:containerport}] \\\n  [-v {hostpath:containerpath}:[ro] ] \\\n  [-e \"key=value\"] \\\n  {image_name:[tag]}\n```\n\n* -d可以指定当前容器在后台运行，释放当前终端控制台不阻塞，用户可以继续往下输入命令\n* --rm可以指定容器停止即刻销毁删除\n* -p可以指定主机和容器的端口映射，可以重复指定多个映射\n* -v可以指定主机的存储目录挂载至容器中，可以重复指定多个挂载，默认读写，ro选项可以指定只读保护数据\n* * hostpath为绝对路径：开户bind mount模式\n* * hostpath为一个变量或连同“:”一起省略：开户docker managed模式\n* * 使用hostpath变量时只能为：[a-zA-Z0-9][a-zA-Z0-9_.-]\n* -e可以预置一些环境变量供容器使用，可以重复指定多个环境变量\n\n#### 构建镜像（打包）\n```\ndocker build -t {image_name}:[tag] [Dockerfile目录]\n```\n\n#### 查询容器\n```\ndocker ps [-a]\ndocker inspect {container_name|container_id}\n```\n\n#### 进入容器\n```\ndocker exec -ti {container_name|container_id} sh/bash ...\n```\n\n#### 查看容器日志\n```\ndocker logs {container_name|container_id} [--tail n] [-f]\n```\n\n#### 查看网络\n```\ndocker network ls\ndocker network inspect {network_name}\n```\n\n#### 查看存储\n```\ndocker volume ls\ndocker volume inspect {volume_name}\n```\n> 注：docker volume只能查看docker managed volumes，对于bind mount volumes只能通过docker inspect来查看\n\n### Restful api\n操作 | API\n- | -\n查询镜像 | curl -X GET http://{IP}:{PORT}/images/json\n查询容器 | curl -X GET http://{IP}:{PORT}/containers/json\n启动容器 | curl -X POST http://{IP}:{PORT}/images/create?fromImage=hello-world:lates</td>\n\n## 参考文档\n[https://yeasy.gitbooks.io/docker_practice/content/](https://yeasy.gitbooks.io/docker_practice/content/)","source":"_posts/docker_06_架构.md","raw":"---\ntitle: docker 架构\ndate: 2019-08-26 11:58:00\ntags: docker\ncategories: DevOps\n---\n\n> 前段时间公司培训，运维大佬提供的材料，有列举出docker的基本架构，在学习docker和Kubernetes的时候，其实先学习内部架构和对象的话，更有助于提升对整体应用的理解。\n\n<!-- more -->\n## 概述\nDocker 是一个应用程序开发、部署、运行的平台，使用 go 语言开发。相较于传统的主机虚拟化，Docker提供了轻量级的应用隔离方案，并且为我们提供了应用程序快速扩容、缩容的能力。\n\nDocker依赖于LXC(Linux Containers)技术，充分利用了其中的Namespace这个内核级特性，实现了容器之间的资源隔离。本质上来看，每一个Docker容器就是宿主机进程，不同 Docker 容器就对应不同的宿主机进程，这样，不同容器（即不同进程）就可以采用 Namespace 资源隔离，使得每一个容器看起来都像是一个独立的小虚拟机\n\ndocker其它核心技术：\n\n- cgroup：资源控制\n- rootfs：文件系统隔离\n- aufs：高级分层文件系统(Advanced Multi-layered unification filesytem)\n\n## 架构\n### 静态部件描述\nDocker采用的是CS架构，包含了三个主要部分：dockerd守护进程、REST API接口层、cli接口层(管理容器、镜像、网络、存储等等)，docker client 通过Unix套接字或者网络接口访问 docker daemon，从而完成容器、镜像等内容的管理\n\n![](/image/DevOps/docker_01.png)\n\n### 流程描述\n![](/image/DevOps/docker_02.png)\n\n## 对象\n\n### 镜像\n镜像是一个用来构建容器的只读模版，通常一个镜像会依赖其他的镜像。例如我们编写的一个Node程序需要依赖Node环境，那在构建这个应用镜像时就需要依赖基础的Node镜像。\n\n我们可以创建自己的镜像，也可以使用仓库中已经创建好的镜像。创建镜像需要创建一个Dockerfile文件。每个Dockerfile定义镜像文件中的一层，当定义发生变化的时候，只需要更新这一层的文件即可。\n\n### 容器\n\n容器是一个运行时状态下的镜像，通过docker命令我们可以创建、启动、停止、删除容器\n\n> 启动我们的第一个容器：\n```\ndocker run --rm hello-world\n```\n\n1.  如果本地没有hello-world镜像，那么首先拉取镜像\n2.  自动创建一个容器，相当于命令dock container create\n3.  Docker分配一块文件系统给容器\n4.  Docker创建网络接口、分配网络地址\n5.  启动容器，并且执行目标入口命令\n6.  容器关闭并退出\n7.  容器销毁\n\n### 网络\n\nDocker的网络子系统是可插拔的，支持bridge、host、overlay、macvlan、none等网络模式\n\n*  bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将主机上的Docker容器连接到docker0虚拟网桥上，docker0网桥由docker后台服务启动时创建，默认在172.17.0.0/16段每一个容器运行时会生成一对veth网络设备直连，再通过网桥使得同一个主机上的容器间可以相互通信\n```\n+-------------------------------------------------------------------------------+\n|                                                                               |\n|       +---------------------------------------------------------------+       |\n|       |                           docker0                             |       |\n|       +---------------------------------------------------------------+       |\n|                             ↑               ↑                                 |\n|.............................|...............|.................................|\n|                             ↓               ↓                                 |\n|        +----------+    +-----------+   +-----------+    +-----------+         |\n|        |   veth2  |<-->|   veth1   |   |   veth3   |<-->|   veth4   |         |\n|        +----------+    +-----------+   +-----------+    +-----------+         |\n|             ↑                                                 ↑               |\n|             +-------------------------------------------------+               |\n|        172.16.17.2                                       172.16.17.3          |\n+-------------------------------------------------------------------------------+\n```\n\n* host模式下，容器会共享主机的network namespace，所以拥有主机的全部网络通信能力，通常用于docker容器测试\n\n### 存储\n\n默认情况下，容器中的应用生成的所有文件都存放在一个可写的容器层，意味着这些数据的生命周期和容器保持一致，这些文件与容器高度关联，因此会带来下面几个问题：\n\n* 不能在宿主机上很方便地访问容器中的文件\n* 无法在多个容器之间共享数据\n* 当容器删除时，容器中产生的数据将丢失\n\n为此，Docker提供了两种方案解决数据问题：\n* bind mount volumes：将host上已存在的目录或文件挂载到容器中使用\n* docker managed volumes：docker自己管理的数据卷存储\n\n对比一下两种方式各自的特点：\n\n- | bind mount Volumes | docker managed volumes\n- | - | -\nvolume 位置 | 可任意指定 | /var/lib/docker/volumes/...\n对已有mount point 影响 | 隐藏并替换为 volume | 原有数据复制到 volume<\n是否支持单个文件 | 支持 | 不支持，只能是目录\n权限控制 | 可设置为只读，默认为读写权限 |无控制，均为读写权限\n移植性 | 移植性弱，与 host path 绑定 | 移植性强，无需指定 host 目录\n\n不管使用哪种方式，容器内看起来都是一样的，或者作为一个文件夹存在、或者作为一个文件存在。\n\n上图说明了不同方式的区别，Volumes 是存在本地文件系统中的一部分，其他应用程序不能对这个文件系统进行修改，Linux下在/var/lib/docker/volumes。这是数据持久化的最好方案。Bind Mount 允许将主机中任何位置的数据挂载，这些数据的读写没有收到保护。tmps是存储在主机内存中的数据。\n\n## 常用操作\n### cli\n#### 下载镜像\n```\ndocker pull urlpath:[tag]\n```\n#### 查询镜像\n```\ndocker images\n```\n#### 运行镜像（启动容器）\n```\ndocker run [-d] \\\n  [--rm] \\\n  [--name {container_name}] \\\n  [-p {hostport:containerport}] \\\n  [-v {hostpath:containerpath}:[ro] ] \\\n  [-e \"key=value\"] \\\n  {image_name:[tag]}\n```\n\n* -d可以指定当前容器在后台运行，释放当前终端控制台不阻塞，用户可以继续往下输入命令\n* --rm可以指定容器停止即刻销毁删除\n* -p可以指定主机和容器的端口映射，可以重复指定多个映射\n* -v可以指定主机的存储目录挂载至容器中，可以重复指定多个挂载，默认读写，ro选项可以指定只读保护数据\n* * hostpath为绝对路径：开户bind mount模式\n* * hostpath为一个变量或连同“:”一起省略：开户docker managed模式\n* * 使用hostpath变量时只能为：[a-zA-Z0-9][a-zA-Z0-9_.-]\n* -e可以预置一些环境变量供容器使用，可以重复指定多个环境变量\n\n#### 构建镜像（打包）\n```\ndocker build -t {image_name}:[tag] [Dockerfile目录]\n```\n\n#### 查询容器\n```\ndocker ps [-a]\ndocker inspect {container_name|container_id}\n```\n\n#### 进入容器\n```\ndocker exec -ti {container_name|container_id} sh/bash ...\n```\n\n#### 查看容器日志\n```\ndocker logs {container_name|container_id} [--tail n] [-f]\n```\n\n#### 查看网络\n```\ndocker network ls\ndocker network inspect {network_name}\n```\n\n#### 查看存储\n```\ndocker volume ls\ndocker volume inspect {volume_name}\n```\n> 注：docker volume只能查看docker managed volumes，对于bind mount volumes只能通过docker inspect来查看\n\n### Restful api\n操作 | API\n- | -\n查询镜像 | curl -X GET http://{IP}:{PORT}/images/json\n查询容器 | curl -X GET http://{IP}:{PORT}/containers/json\n启动容器 | curl -X POST http://{IP}:{PORT}/images/create?fromImage=hello-world:lates</td>\n\n## 参考文档\n[https://yeasy.gitbooks.io/docker_practice/content/](https://yeasy.gitbooks.io/docker_practice/content/)","slug":"docker_06_架构","published":1,"updated":"2019-08-29T08:56:36.451Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3l0041qotni75x53h4","content":"<blockquote>\n<p>前段时间公司培训，运维大佬提供的材料，有列举出docker的基本架构，在学习docker和Kubernetes的时候，其实先学习内部架构和对象的话，更有助于提升对整体应用的理解。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Docker 是一个应用程序开发、部署、运行的平台，使用 go 语言开发。相较于传统的主机虚拟化，Docker提供了轻量级的应用隔离方案，并且为我们提供了应用程序快速扩容、缩容的能力。</p>\n<p>Docker依赖于LXC(Linux Containers)技术，充分利用了其中的Namespace这个内核级特性，实现了容器之间的资源隔离。本质上来看，每一个Docker容器就是宿主机进程，不同 Docker 容器就对应不同的宿主机进程，这样，不同容器（即不同进程）就可以采用 Namespace 资源隔离，使得每一个容器看起来都像是一个独立的小虚拟机</p>\n<p>docker其它核心技术：</p>\n<ul>\n<li>cgroup：资源控制</li>\n<li>rootfs：文件系统隔离</li>\n<li>aufs：高级分层文件系统(Advanced Multi-layered unification filesytem)</li>\n</ul>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><h3 id=\"静态部件描述\"><a href=\"#静态部件描述\" class=\"headerlink\" title=\"静态部件描述\"></a>静态部件描述</h3><p>Docker采用的是CS架构，包含了三个主要部分：dockerd守护进程、REST API接口层、cli接口层(管理容器、镜像、网络、存储等等)，docker client 通过Unix套接字或者网络接口访问 docker daemon，从而完成容器、镜像等内容的管理</p>\n<p><img src=\"/image/DevOps/docker_01.png\" alt=\"\"></p>\n<h3 id=\"流程描述\"><a href=\"#流程描述\" class=\"headerlink\" title=\"流程描述\"></a>流程描述</h3><p><img src=\"/image/DevOps/docker_02.png\" alt=\"\"></p>\n<h2 id=\"对象\"><a href=\"#对象\" class=\"headerlink\" title=\"对象\"></a>对象</h2><h3 id=\"镜像\"><a href=\"#镜像\" class=\"headerlink\" title=\"镜像\"></a>镜像</h3><p>镜像是一个用来构建容器的只读模版，通常一个镜像会依赖其他的镜像。例如我们编写的一个Node程序需要依赖Node环境，那在构建这个应用镜像时就需要依赖基础的Node镜像。</p>\n<p>我们可以创建自己的镜像，也可以使用仓库中已经创建好的镜像。创建镜像需要创建一个Dockerfile文件。每个Dockerfile定义镜像文件中的一层，当定义发生变化的时候，只需要更新这一层的文件即可。</p>\n<h3 id=\"容器\"><a href=\"#容器\" class=\"headerlink\" title=\"容器\"></a>容器</h3><p>容器是一个运行时状态下的镜像，通过docker命令我们可以创建、启动、停止、删除容器</p>\n<blockquote>\n<p>启动我们的第一个容器：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run --rm hello-world</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<ol>\n<li>如果本地没有hello-world镜像，那么首先拉取镜像</li>\n<li>自动创建一个容器，相当于命令dock container create</li>\n<li>Docker分配一块文件系统给容器</li>\n<li>Docker创建网络接口、分配网络地址</li>\n<li>启动容器，并且执行目标入口命令</li>\n<li>容器关闭并退出</li>\n<li>容器销毁</li>\n</ol>\n<h3 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h3><p>Docker的网络子系统是可插拔的，支持bridge、host、overlay、macvlan、none等网络模式</p>\n<ul>\n<li><p>bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将主机上的Docker容器连接到docker0虚拟网桥上，docker0网桥由docker后台服务启动时创建，默认在172.17.0.0/16段每一个容器运行时会生成一对veth网络设备直连，再通过网桥使得同一个主机上的容器间可以相互通信</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+-------------------------------------------------------------------------------+</span><br><span class=\"line\">|                                                                               |</span><br><span class=\"line\">|       +---------------------------------------------------------------+       |</span><br><span class=\"line\">|       |                           docker0                             |       |</span><br><span class=\"line\">|       +---------------------------------------------------------------+       |</span><br><span class=\"line\">|                             ↑               ↑                                 |</span><br><span class=\"line\">|.............................|...............|.................................|</span><br><span class=\"line\">|                             ↓               ↓                                 |</span><br><span class=\"line\">|        +----------+    +-----------+   +-----------+    +-----------+         |</span><br><span class=\"line\">|        |   veth2  |&lt;--&gt;|   veth1   |   |   veth3   |&lt;--&gt;|   veth4   |         |</span><br><span class=\"line\">|        +----------+    +-----------+   +-----------+    +-----------+         |</span><br><span class=\"line\">|             ↑                                                 ↑               |</span><br><span class=\"line\">|             +-------------------------------------------------+               |</span><br><span class=\"line\">|        172.16.17.2                                       172.16.17.3          |</span><br><span class=\"line\">+-------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>host模式下，容器会共享主机的network namespace，所以拥有主机的全部网络通信能力，通常用于docker容器测试</p>\n</li>\n</ul>\n<h3 id=\"存储\"><a href=\"#存储\" class=\"headerlink\" title=\"存储\"></a>存储</h3><p>默认情况下，容器中的应用生成的所有文件都存放在一个可写的容器层，意味着这些数据的生命周期和容器保持一致，这些文件与容器高度关联，因此会带来下面几个问题：</p>\n<ul>\n<li>不能在宿主机上很方便地访问容器中的文件</li>\n<li>无法在多个容器之间共享数据</li>\n<li>当容器删除时，容器中产生的数据将丢失</li>\n</ul>\n<p>为此，Docker提供了两种方案解决数据问题：</p>\n<ul>\n<li>bind mount volumes：将host上已存在的目录或文件挂载到容器中使用</li>\n<li>docker managed volumes：docker自己管理的数据卷存储</li>\n</ul>\n<p>对比一下两种方式各自的特点：</p>\n<table>\n<thead>\n<tr>\n<th>-</th>\n<th>bind mount Volumes</th>\n<th>docker managed volumes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>volume 位置</td>\n<td>可任意指定</td>\n<td>/var/lib/docker/volumes/…</td>\n</tr>\n<tr>\n<td>对已有mount point 影响</td>\n<td>隐藏并替换为 volume</td>\n<td>原有数据复制到 volume&lt;</td>\n</tr>\n<tr>\n<td>是否支持单个文件</td>\n<td>支持</td>\n<td>不支持，只能是目录</td>\n</tr>\n<tr>\n<td>权限控制</td>\n<td>可设置为只读，默认为读写权限</td>\n<td>无控制，均为读写权限</td>\n</tr>\n<tr>\n<td>移植性</td>\n<td>移植性弱，与 host path 绑定</td>\n<td>移植性强，无需指定 host 目录</td>\n</tr>\n</tbody>\n</table>\n<p>不管使用哪种方式，容器内看起来都是一样的，或者作为一个文件夹存在、或者作为一个文件存在。</p>\n<p>上图说明了不同方式的区别，Volumes 是存在本地文件系统中的一部分，其他应用程序不能对这个文件系统进行修改，Linux下在/var/lib/docker/volumes。这是数据持久化的最好方案。Bind Mount 允许将主机中任何位置的数据挂载，这些数据的读写没有收到保护。tmps是存储在主机内存中的数据。</p>\n<h2 id=\"常用操作\"><a href=\"#常用操作\" class=\"headerlink\" title=\"常用操作\"></a>常用操作</h2><h3 id=\"cli\"><a href=\"#cli\" class=\"headerlink\" title=\"cli\"></a>cli</h3><h4 id=\"下载镜像\"><a href=\"#下载镜像\" class=\"headerlink\" title=\"下载镜像\"></a>下载镜像</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull urlpath:[tag]</span><br></pre></td></tr></table></figure>\n<h4 id=\"查询镜像\"><a href=\"#查询镜像\" class=\"headerlink\" title=\"查询镜像\"></a>查询镜像</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker images</span><br></pre></td></tr></table></figure>\n<h4 id=\"运行镜像（启动容器）\"><a href=\"#运行镜像（启动容器）\" class=\"headerlink\" title=\"运行镜像（启动容器）\"></a>运行镜像（启动容器）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run [-d] \\</span><br><span class=\"line\">  [--rm] \\</span><br><span class=\"line\">  [--name &#123;container_name&#125;] \\</span><br><span class=\"line\">  [-p &#123;hostport:containerport&#125;] \\</span><br><span class=\"line\">  [-v &#123;hostpath:containerpath&#125;:[ro] ] \\</span><br><span class=\"line\">  [-e &quot;key=value&quot;] \\</span><br><span class=\"line\">  &#123;image_name:[tag]&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>-d可以指定当前容器在后台运行，释放当前终端控制台不阻塞，用户可以继续往下输入命令</li>\n<li>–rm可以指定容器停止即刻销毁删除</li>\n<li>-p可以指定主机和容器的端口映射，可以重复指定多个映射</li>\n<li>-v可以指定主机的存储目录挂载至容器中，可以重复指定多个挂载，默认读写，ro选项可以指定只读保护数据</li>\n<li><ul>\n<li>hostpath为绝对路径：开户bind mount模式</li>\n</ul>\n</li>\n<li><ul>\n<li>hostpath为一个变量或连同“:”一起省略：开户docker managed模式</li>\n</ul>\n</li>\n<li><ul>\n<li>使用hostpath变量时只能为：[a-zA-Z0-9][a-zA-Z0-9_.-]</li>\n</ul>\n</li>\n<li>-e可以预置一些环境变量供容器使用，可以重复指定多个环境变量</li>\n</ul>\n<h4 id=\"构建镜像（打包）\"><a href=\"#构建镜像（打包）\" class=\"headerlink\" title=\"构建镜像（打包）\"></a>构建镜像（打包）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker build -t &#123;image_name&#125;:[tag] [Dockerfile目录]</span><br></pre></td></tr></table></figure>\n<h4 id=\"查询容器\"><a href=\"#查询容器\" class=\"headerlink\" title=\"查询容器\"></a>查询容器</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker ps [-a]</span><br><span class=\"line\">docker inspect &#123;container_name|container_id&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"进入容器\"><a href=\"#进入容器\" class=\"headerlink\" title=\"进入容器\"></a>进入容器</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -ti &#123;container_name|container_id&#125; sh/bash ...</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看容器日志\"><a href=\"#查看容器日志\" class=\"headerlink\" title=\"查看容器日志\"></a>查看容器日志</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker logs &#123;container_name|container_id&#125; [--tail n] [-f]</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看网络\"><a href=\"#查看网络\" class=\"headerlink\" title=\"查看网络\"></a>查看网络</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker network ls</span><br><span class=\"line\">docker network inspect &#123;network_name&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看存储\"><a href=\"#查看存储\" class=\"headerlink\" title=\"查看存储\"></a>查看存储</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker volume ls</span><br><span class=\"line\">docker volume inspect &#123;volume_name&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>注：docker volume只能查看docker managed volumes，对于bind mount volumes只能通过docker inspect来查看</p>\n</blockquote>\n<h3 id=\"Restful-api\"><a href=\"#Restful-api\" class=\"headerlink\" title=\"Restful api\"></a>Restful api</h3><table>\n<thead>\n<tr>\n<th>操作</th>\n<th>API</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>查询镜像</td>\n<td>curl -X GET http://{IP}:{PORT}/images/json</td>\n</tr>\n<tr>\n<td>查询容器</td>\n<td>curl -X GET http://{IP}:{PORT}/containers/json</td>\n</tr>\n<tr>\n<td>启动容器</td>\n<td>curl -X POST http://{IP}:{PORT}/images/create?fromImage=hello-world:lates</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"https://yeasy.gitbooks.io/docker_practice/content/\" target=\"_blank\" rel=\"noopener\">https://yeasy.gitbooks.io/docker_practice/content/</a></p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>前段时间公司培训，运维大佬提供的材料，有列举出docker的基本架构，在学习docker和Kubernetes的时候，其实先学习内部架构和对象的话，更有助于提升对整体应用的理解。</p>\n</blockquote>","more":"<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Docker 是一个应用程序开发、部署、运行的平台，使用 go 语言开发。相较于传统的主机虚拟化，Docker提供了轻量级的应用隔离方案，并且为我们提供了应用程序快速扩容、缩容的能力。</p>\n<p>Docker依赖于LXC(Linux Containers)技术，充分利用了其中的Namespace这个内核级特性，实现了容器之间的资源隔离。本质上来看，每一个Docker容器就是宿主机进程，不同 Docker 容器就对应不同的宿主机进程，这样，不同容器（即不同进程）就可以采用 Namespace 资源隔离，使得每一个容器看起来都像是一个独立的小虚拟机</p>\n<p>docker其它核心技术：</p>\n<ul>\n<li>cgroup：资源控制</li>\n<li>rootfs：文件系统隔离</li>\n<li>aufs：高级分层文件系统(Advanced Multi-layered unification filesytem)</li>\n</ul>\n<h2 id=\"架构\"><a href=\"#架构\" class=\"headerlink\" title=\"架构\"></a>架构</h2><h3 id=\"静态部件描述\"><a href=\"#静态部件描述\" class=\"headerlink\" title=\"静态部件描述\"></a>静态部件描述</h3><p>Docker采用的是CS架构，包含了三个主要部分：dockerd守护进程、REST API接口层、cli接口层(管理容器、镜像、网络、存储等等)，docker client 通过Unix套接字或者网络接口访问 docker daemon，从而完成容器、镜像等内容的管理</p>\n<p><img src=\"/image/DevOps/docker_01.png\" alt=\"\"></p>\n<h3 id=\"流程描述\"><a href=\"#流程描述\" class=\"headerlink\" title=\"流程描述\"></a>流程描述</h3><p><img src=\"/image/DevOps/docker_02.png\" alt=\"\"></p>\n<h2 id=\"对象\"><a href=\"#对象\" class=\"headerlink\" title=\"对象\"></a>对象</h2><h3 id=\"镜像\"><a href=\"#镜像\" class=\"headerlink\" title=\"镜像\"></a>镜像</h3><p>镜像是一个用来构建容器的只读模版，通常一个镜像会依赖其他的镜像。例如我们编写的一个Node程序需要依赖Node环境，那在构建这个应用镜像时就需要依赖基础的Node镜像。</p>\n<p>我们可以创建自己的镜像，也可以使用仓库中已经创建好的镜像。创建镜像需要创建一个Dockerfile文件。每个Dockerfile定义镜像文件中的一层，当定义发生变化的时候，只需要更新这一层的文件即可。</p>\n<h3 id=\"容器\"><a href=\"#容器\" class=\"headerlink\" title=\"容器\"></a>容器</h3><p>容器是一个运行时状态下的镜像，通过docker命令我们可以创建、启动、停止、删除容器</p>\n<blockquote>\n<p>启动我们的第一个容器：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run --rm hello-world</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<ol>\n<li>如果本地没有hello-world镜像，那么首先拉取镜像</li>\n<li>自动创建一个容器，相当于命令dock container create</li>\n<li>Docker分配一块文件系统给容器</li>\n<li>Docker创建网络接口、分配网络地址</li>\n<li>启动容器，并且执行目标入口命令</li>\n<li>容器关闭并退出</li>\n<li>容器销毁</li>\n</ol>\n<h3 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h3><p>Docker的网络子系统是可插拔的，支持bridge、host、overlay、macvlan、none等网络模式</p>\n<ul>\n<li><p>bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将主机上的Docker容器连接到docker0虚拟网桥上，docker0网桥由docker后台服务启动时创建，默认在172.17.0.0/16段每一个容器运行时会生成一对veth网络设备直连，再通过网桥使得同一个主机上的容器间可以相互通信</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+-------------------------------------------------------------------------------+</span><br><span class=\"line\">|                                                                               |</span><br><span class=\"line\">|       +---------------------------------------------------------------+       |</span><br><span class=\"line\">|       |                           docker0                             |       |</span><br><span class=\"line\">|       +---------------------------------------------------------------+       |</span><br><span class=\"line\">|                             ↑               ↑                                 |</span><br><span class=\"line\">|.............................|...............|.................................|</span><br><span class=\"line\">|                             ↓               ↓                                 |</span><br><span class=\"line\">|        +----------+    +-----------+   +-----------+    +-----------+         |</span><br><span class=\"line\">|        |   veth2  |&lt;--&gt;|   veth1   |   |   veth3   |&lt;--&gt;|   veth4   |         |</span><br><span class=\"line\">|        +----------+    +-----------+   +-----------+    +-----------+         |</span><br><span class=\"line\">|             ↑                                                 ↑               |</span><br><span class=\"line\">|             +-------------------------------------------------+               |</span><br><span class=\"line\">|        172.16.17.2                                       172.16.17.3          |</span><br><span class=\"line\">+-------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>host模式下，容器会共享主机的network namespace，所以拥有主机的全部网络通信能力，通常用于docker容器测试</p>\n</li>\n</ul>\n<h3 id=\"存储\"><a href=\"#存储\" class=\"headerlink\" title=\"存储\"></a>存储</h3><p>默认情况下，容器中的应用生成的所有文件都存放在一个可写的容器层，意味着这些数据的生命周期和容器保持一致，这些文件与容器高度关联，因此会带来下面几个问题：</p>\n<ul>\n<li>不能在宿主机上很方便地访问容器中的文件</li>\n<li>无法在多个容器之间共享数据</li>\n<li>当容器删除时，容器中产生的数据将丢失</li>\n</ul>\n<p>为此，Docker提供了两种方案解决数据问题：</p>\n<ul>\n<li>bind mount volumes：将host上已存在的目录或文件挂载到容器中使用</li>\n<li>docker managed volumes：docker自己管理的数据卷存储</li>\n</ul>\n<p>对比一下两种方式各自的特点：</p>\n<table>\n<thead>\n<tr>\n<th>-</th>\n<th>bind mount Volumes</th>\n<th>docker managed volumes</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>volume 位置</td>\n<td>可任意指定</td>\n<td>/var/lib/docker/volumes/…</td>\n</tr>\n<tr>\n<td>对已有mount point 影响</td>\n<td>隐藏并替换为 volume</td>\n<td>原有数据复制到 volume&lt;</td>\n</tr>\n<tr>\n<td>是否支持单个文件</td>\n<td>支持</td>\n<td>不支持，只能是目录</td>\n</tr>\n<tr>\n<td>权限控制</td>\n<td>可设置为只读，默认为读写权限</td>\n<td>无控制，均为读写权限</td>\n</tr>\n<tr>\n<td>移植性</td>\n<td>移植性弱，与 host path 绑定</td>\n<td>移植性强，无需指定 host 目录</td>\n</tr>\n</tbody>\n</table>\n<p>不管使用哪种方式，容器内看起来都是一样的，或者作为一个文件夹存在、或者作为一个文件存在。</p>\n<p>上图说明了不同方式的区别，Volumes 是存在本地文件系统中的一部分，其他应用程序不能对这个文件系统进行修改，Linux下在/var/lib/docker/volumes。这是数据持久化的最好方案。Bind Mount 允许将主机中任何位置的数据挂载，这些数据的读写没有收到保护。tmps是存储在主机内存中的数据。</p>\n<h2 id=\"常用操作\"><a href=\"#常用操作\" class=\"headerlink\" title=\"常用操作\"></a>常用操作</h2><h3 id=\"cli\"><a href=\"#cli\" class=\"headerlink\" title=\"cli\"></a>cli</h3><h4 id=\"下载镜像\"><a href=\"#下载镜像\" class=\"headerlink\" title=\"下载镜像\"></a>下载镜像</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker pull urlpath:[tag]</span><br></pre></td></tr></table></figure>\n<h4 id=\"查询镜像\"><a href=\"#查询镜像\" class=\"headerlink\" title=\"查询镜像\"></a>查询镜像</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker images</span><br></pre></td></tr></table></figure>\n<h4 id=\"运行镜像（启动容器）\"><a href=\"#运行镜像（启动容器）\" class=\"headerlink\" title=\"运行镜像（启动容器）\"></a>运行镜像（启动容器）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run [-d] \\</span><br><span class=\"line\">  [--rm] \\</span><br><span class=\"line\">  [--name &#123;container_name&#125;] \\</span><br><span class=\"line\">  [-p &#123;hostport:containerport&#125;] \\</span><br><span class=\"line\">  [-v &#123;hostpath:containerpath&#125;:[ro] ] \\</span><br><span class=\"line\">  [-e &quot;key=value&quot;] \\</span><br><span class=\"line\">  &#123;image_name:[tag]&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>-d可以指定当前容器在后台运行，释放当前终端控制台不阻塞，用户可以继续往下输入命令</li>\n<li>–rm可以指定容器停止即刻销毁删除</li>\n<li>-p可以指定主机和容器的端口映射，可以重复指定多个映射</li>\n<li>-v可以指定主机的存储目录挂载至容器中，可以重复指定多个挂载，默认读写，ro选项可以指定只读保护数据</li>\n<li><ul>\n<li>hostpath为绝对路径：开户bind mount模式</li>\n</ul>\n</li>\n<li><ul>\n<li>hostpath为一个变量或连同“:”一起省略：开户docker managed模式</li>\n</ul>\n</li>\n<li><ul>\n<li>使用hostpath变量时只能为：[a-zA-Z0-9][a-zA-Z0-9_.-]</li>\n</ul>\n</li>\n<li>-e可以预置一些环境变量供容器使用，可以重复指定多个环境变量</li>\n</ul>\n<h4 id=\"构建镜像（打包）\"><a href=\"#构建镜像（打包）\" class=\"headerlink\" title=\"构建镜像（打包）\"></a>构建镜像（打包）</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker build -t &#123;image_name&#125;:[tag] [Dockerfile目录]</span><br></pre></td></tr></table></figure>\n<h4 id=\"查询容器\"><a href=\"#查询容器\" class=\"headerlink\" title=\"查询容器\"></a>查询容器</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker ps [-a]</span><br><span class=\"line\">docker inspect &#123;container_name|container_id&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"进入容器\"><a href=\"#进入容器\" class=\"headerlink\" title=\"进入容器\"></a>进入容器</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker exec -ti &#123;container_name|container_id&#125; sh/bash ...</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看容器日志\"><a href=\"#查看容器日志\" class=\"headerlink\" title=\"查看容器日志\"></a>查看容器日志</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker logs &#123;container_name|container_id&#125; [--tail n] [-f]</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看网络\"><a href=\"#查看网络\" class=\"headerlink\" title=\"查看网络\"></a>查看网络</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker network ls</span><br><span class=\"line\">docker network inspect &#123;network_name&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看存储\"><a href=\"#查看存储\" class=\"headerlink\" title=\"查看存储\"></a>查看存储</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker volume ls</span><br><span class=\"line\">docker volume inspect &#123;volume_name&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>注：docker volume只能查看docker managed volumes，对于bind mount volumes只能通过docker inspect来查看</p>\n</blockquote>\n<h3 id=\"Restful-api\"><a href=\"#Restful-api\" class=\"headerlink\" title=\"Restful api\"></a>Restful api</h3><table>\n<thead>\n<tr>\n<th>操作</th>\n<th>API</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>查询镜像</td>\n<td>curl -X GET http://{IP}:{PORT}/images/json</td>\n</tr>\n<tr>\n<td>查询容器</td>\n<td>curl -X GET http://{IP}:{PORT}/containers/json</td>\n</tr>\n<tr>\n<td>启动容器</td>\n<td>curl -X POST http://{IP}:{PORT}/images/create?fromImage=hello-world:lates</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h2><p><a href=\"https://yeasy.gitbooks.io/docker_practice/content/\" target=\"_blank\" rel=\"noopener\">https://yeasy.gitbooks.io/docker_practice/content/</a></p>"},{"title":"docker 存储","date":"2019-08-28T02:45:00.000Z","_content":"\n> 在通过docker创建mysql的过程中，遇到了一些关于docker存储的知识盲区，趁着上次临时学的东西还没忘，尽快学习下关于docker存储的知识。\n\n<!-- more -->\n在使用docker过程中，往往需要对数据进行持久化，或者需要在多个容器之间共享数据，这就涉及到了容器的数据管理存储操作。\n\n容器中管理数据的主要方式有两种：\n- 数据卷(Data Volnumes): 容器内数据直接映射到本地主机环境\n- 数据容器卷(Date Volnume Containers): 使用特定容器维护数据卷\n\n# 数据卷\n数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mount操作。\n\n数据卷可以提供很多有用的特性，如下所示：\n- 数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便\n- 对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作\n- 对数据卷的更新不会影响镜像，解耦了应用和数据\n- 卷会一直存在，直到没有容器使用，可以安全地卸载它\n\n## 创建数据卷\n在用docker run命令的时候，使用-v标记可以在容器内创建一个数据卷。多次重复使用-v标记可以创建多个数据卷。\n\n下面使用training/webapp镜像创建一个web容器，并创建一个数据卷挂载到容器的/webapp目录：\n```\n$ docker run -d -P --name web -v /webapp training/webapp python app.py\n```\n## 挂载一个主机目录作为数据卷\n使用-v标记也可以指定挂载一个本地的已有目录到容器中去作为数据卷\n```\n$ docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py\n```\n上面的命令加载主机的/src/webapp目录到容器的/opt/webapp目录。\n\n这个功能在进行测试的时候十分方便，比如用户可以将一些程序或数据放到本地目录中，然后在容器内运行和使用。另外，本地目录的路径必须是绝对路径，如果目录不存在Docker，会自动创建。\n\nDocker挂载数据卷的默认权限是读写（rw），用户也可以通过ro指定为只读：\n```\n$ docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py\n```\n加了:ro之后，容器内对所挂载数据卷内的数据就无法修改了。\n\n## 挂载一个本地主机文件作为数据卷\n-v标记也可以从主机挂载单个文件到容器中作为数据卷（不推荐）。\n```\n$ docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash\n```\n这样就可以记录在容器输入过的命令历史了。\n\n# 数据卷容器\n如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。\n\n首先，创建一个数据卷容器dbdata，并在其中创建一个数据卷挂载到/dbdata：\n```\n$ docker run -it -v /dbdata --name dbdata ubuntu\nroot@3ed94f279b6f:/#\n```\n\n查看/dbdata目录：\n```\nroot@3ed94f279b6f:/# ls\nbin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  \n    sbin  srv  sys  tmp  usr  var\n```\n\n然后，可以在其他容器中使用--volumes-from来挂载dbdata容器中的数据卷，例如创建db1和db2两个容器，并从dbdata容器挂载数据卷：\n```\n$ docker run -it --volumes-from dbdata --name db1 ubuntu\n$ docker run -it --volumes-from dbdata --name db2 ubuntu\n```\n此时，容器db1和db2都挂载同一个数据卷到相同的/dbdata目录。三个容器任何一方在该目录下的写入，其他容器都可以看到。\n\n例如，在dbdata容器中创建一个test文件，如下所示：\n```\nroot@3ed94f279b6f:/# cd /dbdata\nroot@3ed94f279b6f:/dbdata# touch test\nroot@3ed94f279b6f:/dbdata# ls\ntest\n```\n\n在db1容器内查看它：\n```\n$ docker run -it --volumes-from dbdata --name db1  ubuntu\nroot@4128d2d804b4:/# ls\nbin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  \n    sbin  srv  sys  tmp  usr  var\nroot@4128d2d804b4:/# ls dbdata/\ntest\n```\n\n可以多次使用--volumes-from参数来从多个容器挂载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。\n\n## 注意\n使用--volumes-from参数所挂载数据卷的容器自身并不需要保持在运行状态。\n\n如果删除了挂载的容器(包括dbdata、db1和db2)，数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用docker rm-v命令来指定同时删除关联的容器。\n\n# 利用数据卷容器来迁移数据\n可以利用数据卷容器对其中的数据卷进行备份、恢复，以实现数据的迁移\n## 备份\n使用下面的命令来备份dbdata数据卷容器内的数据卷：\n```\n$ docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata\n```\n这个命令稍微有点复杂，具体分析一下。首先利用ubuntu镜像创建了一个容器worker。使用--volumes-from dbdata参数来让worker容器挂载dbdata容器的数据卷（即dbdata数据卷）；使用-v$(pwd):/backup参数来挂载本地的当前目录到worker容器的/backup目录。\n\nworker容器启动后，使用了tar cvf/backup/backup.tar/dbdata命令来将/dbdata下内容备份为容器内的/backup/backup.tar，即宿主主机当前目录下的backup.tar。\n\n## 恢复\n如果要将数据恢复到一个容器，可以按照下面的步骤操作。首先创建一个带有数据卷的容器dbdata2：\n```\n$ docker run -v /dbdata --name dbdata2 ubuntu /bin/bash\n```\n\n然后创建另一个新的容器，挂载dbdata2的容器，并使用untar解压备份文件到所挂载的容器卷中：\n```\n$ docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf\n/backup/backup.tar\n```\n\n## 总结\n以上都是从书中直接抄来的，总结下其实就是：\n\n容器的数据存储方式就是使用数据卷。数据卷可以创建在容器内部，也可以挂载宿主机的目录或文件到容器中作为数据卷使用。\n\n一般如果需要对数据进行持久化，则为了数据安全考虑，会选择挂载宿主机目录到容器中作为数据卷来进行存储。\n\n如果不需要数据进行持久化，则直接在容器中创建数据卷即可。\n\n不建议挂载宿主机某个文件到容器中使用。\n\n可以通过数据卷容器实现容器之间的数据共享，数据备份与恢复。\n\n数据是非常重要的资源，docker在设计上充分考虑了这点，为数据的管理做了充分的支持。数据卷和数据卷容器提供了共享、备份、恢复即使是容器运行时出现了故障，也不同担心数据丢失。同时解耦了数据与容器。\n\n## 总结之前搭建mysql时候进行数据持久化遇到的问题\n\n挂载可以挂载文件夹、也可以挂载文件\n\n挂载文件夹的话，文件夹下的内容修改了，会同步修改容器中的内容\n\n但是如果挂载文件的话，这个文件如果inode修改了，比如用vim，vim修改了之后，wq保存了文件，文件的inode就会修改，这时host的这个挂载的文件就和容器的不同步了\n\n之前搭建mysql挂载配置文件遇到的坑，一般应用镜像都会提供给可配置或者需要持久化的信息一个可以挂载的文件入口，可能和以前的配置不一样。\n\nmysql5.6这个官方镜像，默认的配置就和普通我们启动的mysql的配置文件不太一样。他默认my.cnf 中是\n```\n!includedir /etc/mysql/conf.d/\n!includedir /etc/mysql/mysql.conf.d/\n```\nconf.d/ mysql.conf.d/这两个文件夹 就可以用来挂载配置的\n\n所以做法就是，先在宿主机配置好conf.d/路径下的三个配置文件和mysql.conf.d/下的配置文件，然后docker run的时候挂载这两个路径\n\n\n# 参考资料\n* 《Docker技术入门与实战》\n* https://www.cnblogs.com/breezey/p/9589288.html","source":"_posts/docker_08_存储.md","raw":"---\ntitle: docker 存储\ndate: 2019-08-28 10:45:00\ntags: docker\ncategories: DevOps\n---\n\n> 在通过docker创建mysql的过程中，遇到了一些关于docker存储的知识盲区，趁着上次临时学的东西还没忘，尽快学习下关于docker存储的知识。\n\n<!-- more -->\n在使用docker过程中，往往需要对数据进行持久化，或者需要在多个容器之间共享数据，这就涉及到了容器的数据管理存储操作。\n\n容器中管理数据的主要方式有两种：\n- 数据卷(Data Volnumes): 容器内数据直接映射到本地主机环境\n- 数据容器卷(Date Volnume Containers): 使用特定容器维护数据卷\n\n# 数据卷\n数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mount操作。\n\n数据卷可以提供很多有用的特性，如下所示：\n- 数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便\n- 对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作\n- 对数据卷的更新不会影响镜像，解耦了应用和数据\n- 卷会一直存在，直到没有容器使用，可以安全地卸载它\n\n## 创建数据卷\n在用docker run命令的时候，使用-v标记可以在容器内创建一个数据卷。多次重复使用-v标记可以创建多个数据卷。\n\n下面使用training/webapp镜像创建一个web容器，并创建一个数据卷挂载到容器的/webapp目录：\n```\n$ docker run -d -P --name web -v /webapp training/webapp python app.py\n```\n## 挂载一个主机目录作为数据卷\n使用-v标记也可以指定挂载一个本地的已有目录到容器中去作为数据卷\n```\n$ docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py\n```\n上面的命令加载主机的/src/webapp目录到容器的/opt/webapp目录。\n\n这个功能在进行测试的时候十分方便，比如用户可以将一些程序或数据放到本地目录中，然后在容器内运行和使用。另外，本地目录的路径必须是绝对路径，如果目录不存在Docker，会自动创建。\n\nDocker挂载数据卷的默认权限是读写（rw），用户也可以通过ro指定为只读：\n```\n$ docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py\n```\n加了:ro之后，容器内对所挂载数据卷内的数据就无法修改了。\n\n## 挂载一个本地主机文件作为数据卷\n-v标记也可以从主机挂载单个文件到容器中作为数据卷（不推荐）。\n```\n$ docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash\n```\n这样就可以记录在容器输入过的命令历史了。\n\n# 数据卷容器\n如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。\n\n首先，创建一个数据卷容器dbdata，并在其中创建一个数据卷挂载到/dbdata：\n```\n$ docker run -it -v /dbdata --name dbdata ubuntu\nroot@3ed94f279b6f:/#\n```\n\n查看/dbdata目录：\n```\nroot@3ed94f279b6f:/# ls\nbin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  \n    sbin  srv  sys  tmp  usr  var\n```\n\n然后，可以在其他容器中使用--volumes-from来挂载dbdata容器中的数据卷，例如创建db1和db2两个容器，并从dbdata容器挂载数据卷：\n```\n$ docker run -it --volumes-from dbdata --name db1 ubuntu\n$ docker run -it --volumes-from dbdata --name db2 ubuntu\n```\n此时，容器db1和db2都挂载同一个数据卷到相同的/dbdata目录。三个容器任何一方在该目录下的写入，其他容器都可以看到。\n\n例如，在dbdata容器中创建一个test文件，如下所示：\n```\nroot@3ed94f279b6f:/# cd /dbdata\nroot@3ed94f279b6f:/dbdata# touch test\nroot@3ed94f279b6f:/dbdata# ls\ntest\n```\n\n在db1容器内查看它：\n```\n$ docker run -it --volumes-from dbdata --name db1  ubuntu\nroot@4128d2d804b4:/# ls\nbin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  \n    sbin  srv  sys  tmp  usr  var\nroot@4128d2d804b4:/# ls dbdata/\ntest\n```\n\n可以多次使用--volumes-from参数来从多个容器挂载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。\n\n## 注意\n使用--volumes-from参数所挂载数据卷的容器自身并不需要保持在运行状态。\n\n如果删除了挂载的容器(包括dbdata、db1和db2)，数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用docker rm-v命令来指定同时删除关联的容器。\n\n# 利用数据卷容器来迁移数据\n可以利用数据卷容器对其中的数据卷进行备份、恢复，以实现数据的迁移\n## 备份\n使用下面的命令来备份dbdata数据卷容器内的数据卷：\n```\n$ docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata\n```\n这个命令稍微有点复杂，具体分析一下。首先利用ubuntu镜像创建了一个容器worker。使用--volumes-from dbdata参数来让worker容器挂载dbdata容器的数据卷（即dbdata数据卷）；使用-v$(pwd):/backup参数来挂载本地的当前目录到worker容器的/backup目录。\n\nworker容器启动后，使用了tar cvf/backup/backup.tar/dbdata命令来将/dbdata下内容备份为容器内的/backup/backup.tar，即宿主主机当前目录下的backup.tar。\n\n## 恢复\n如果要将数据恢复到一个容器，可以按照下面的步骤操作。首先创建一个带有数据卷的容器dbdata2：\n```\n$ docker run -v /dbdata --name dbdata2 ubuntu /bin/bash\n```\n\n然后创建另一个新的容器，挂载dbdata2的容器，并使用untar解压备份文件到所挂载的容器卷中：\n```\n$ docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf\n/backup/backup.tar\n```\n\n## 总结\n以上都是从书中直接抄来的，总结下其实就是：\n\n容器的数据存储方式就是使用数据卷。数据卷可以创建在容器内部，也可以挂载宿主机的目录或文件到容器中作为数据卷使用。\n\n一般如果需要对数据进行持久化，则为了数据安全考虑，会选择挂载宿主机目录到容器中作为数据卷来进行存储。\n\n如果不需要数据进行持久化，则直接在容器中创建数据卷即可。\n\n不建议挂载宿主机某个文件到容器中使用。\n\n可以通过数据卷容器实现容器之间的数据共享，数据备份与恢复。\n\n数据是非常重要的资源，docker在设计上充分考虑了这点，为数据的管理做了充分的支持。数据卷和数据卷容器提供了共享、备份、恢复即使是容器运行时出现了故障，也不同担心数据丢失。同时解耦了数据与容器。\n\n## 总结之前搭建mysql时候进行数据持久化遇到的问题\n\n挂载可以挂载文件夹、也可以挂载文件\n\n挂载文件夹的话，文件夹下的内容修改了，会同步修改容器中的内容\n\n但是如果挂载文件的话，这个文件如果inode修改了，比如用vim，vim修改了之后，wq保存了文件，文件的inode就会修改，这时host的这个挂载的文件就和容器的不同步了\n\n之前搭建mysql挂载配置文件遇到的坑，一般应用镜像都会提供给可配置或者需要持久化的信息一个可以挂载的文件入口，可能和以前的配置不一样。\n\nmysql5.6这个官方镜像，默认的配置就和普通我们启动的mysql的配置文件不太一样。他默认my.cnf 中是\n```\n!includedir /etc/mysql/conf.d/\n!includedir /etc/mysql/mysql.conf.d/\n```\nconf.d/ mysql.conf.d/这两个文件夹 就可以用来挂载配置的\n\n所以做法就是，先在宿主机配置好conf.d/路径下的三个配置文件和mysql.conf.d/下的配置文件，然后docker run的时候挂载这两个路径\n\n\n# 参考资料\n* 《Docker技术入门与实战》\n* https://www.cnblogs.com/breezey/p/9589288.html","slug":"docker_08_存储","published":1,"updated":"2019-09-05T09:07:51.645Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3m0043qotnzbpiacar","content":"<blockquote>\n<p>在通过docker创建mysql的过程中，遇到了一些关于docker存储的知识盲区，趁着上次临时学的东西还没忘，尽快学习下关于docker存储的知识。</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>在使用docker过程中，往往需要对数据进行持久化，或者需要在多个容器之间共享数据，这就涉及到了容器的数据管理存储操作。</p>\n<p>容器中管理数据的主要方式有两种：</p>\n<ul>\n<li>数据卷(Data Volnumes): 容器内数据直接映射到本地主机环境</li>\n<li>数据容器卷(Date Volnume Containers): 使用特定容器维护数据卷</li>\n</ul>\n<h1 id=\"数据卷\"><a href=\"#数据卷\" class=\"headerlink\" title=\"数据卷\"></a>数据卷</h1><p>数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mount操作。</p>\n<p>数据卷可以提供很多有用的特性，如下所示：</p>\n<ul>\n<li>数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便</li>\n<li>对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作</li>\n<li>对数据卷的更新不会影响镜像，解耦了应用和数据</li>\n<li>卷会一直存在，直到没有容器使用，可以安全地卸载它</li>\n</ul>\n<h2 id=\"创建数据卷\"><a href=\"#创建数据卷\" class=\"headerlink\" title=\"创建数据卷\"></a>创建数据卷</h2><p>在用docker run命令的时候，使用-v标记可以在容器内创建一个数据卷。多次重复使用-v标记可以创建多个数据卷。</p>\n<p>下面使用training/webapp镜像创建一个web容器，并创建一个数据卷挂载到容器的/webapp目录：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -d -P --name web -v /webapp training/webapp python app.py</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"挂载一个主机目录作为数据卷\"><a href=\"#挂载一个主机目录作为数据卷\" class=\"headerlink\" title=\"挂载一个主机目录作为数据卷\"></a>挂载一个主机目录作为数据卷</h2><p>使用-v标记也可以指定挂载一个本地的已有目录到容器中去作为数据卷<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py</span><br></pre></td></tr></table></figure></p>\n<p>上面的命令加载主机的/src/webapp目录到容器的/opt/webapp目录。</p>\n<p>这个功能在进行测试的时候十分方便，比如用户可以将一些程序或数据放到本地目录中，然后在容器内运行和使用。另外，本地目录的路径必须是绝对路径，如果目录不存在Docker，会自动创建。</p>\n<p>Docker挂载数据卷的默认权限是读写（rw），用户也可以通过ro指定为只读：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py</span><br></pre></td></tr></table></figure></p>\n<p>加了:ro之后，容器内对所挂载数据卷内的数据就无法修改了。</p>\n<h2 id=\"挂载一个本地主机文件作为数据卷\"><a href=\"#挂载一个本地主机文件作为数据卷\" class=\"headerlink\" title=\"挂载一个本地主机文件作为数据卷\"></a>挂载一个本地主机文件作为数据卷</h2><p>-v标记也可以从主机挂载单个文件到容器中作为数据卷（不推荐）。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash</span><br></pre></td></tr></table></figure></p>\n<p>这样就可以记录在容器输入过的命令历史了。</p>\n<h1 id=\"数据卷容器\"><a href=\"#数据卷容器\" class=\"headerlink\" title=\"数据卷容器\"></a>数据卷容器</h1><p>如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。</p>\n<p>首先，创建一个数据卷容器dbdata，并在其中创建一个数据卷挂载到/dbdata：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -it -v /dbdata --name dbdata ubuntu</span><br><span class=\"line\">root@3ed94f279b6f:/#</span><br></pre></td></tr></table></figure></p>\n<p>查看/dbdata目录：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@3ed94f279b6f:/# ls</span><br><span class=\"line\">bin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  </span><br><span class=\"line\">    sbin  srv  sys  tmp  usr  var</span><br></pre></td></tr></table></figure></p>\n<p>然后，可以在其他容器中使用–volumes-from来挂载dbdata容器中的数据卷，例如创建db1和db2两个容器，并从dbdata容器挂载数据卷：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -it --volumes-from dbdata --name db1 ubuntu</span><br><span class=\"line\">$ docker run -it --volumes-from dbdata --name db2 ubuntu</span><br></pre></td></tr></table></figure></p>\n<p>此时，容器db1和db2都挂载同一个数据卷到相同的/dbdata目录。三个容器任何一方在该目录下的写入，其他容器都可以看到。</p>\n<p>例如，在dbdata容器中创建一个test文件，如下所示：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@3ed94f279b6f:/# cd /dbdata</span><br><span class=\"line\">root@3ed94f279b6f:/dbdata# touch test</span><br><span class=\"line\">root@3ed94f279b6f:/dbdata# ls</span><br><span class=\"line\">test</span><br></pre></td></tr></table></figure></p>\n<p>在db1容器内查看它：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -it --volumes-from dbdata --name db1  ubuntu</span><br><span class=\"line\">root@4128d2d804b4:/# ls</span><br><span class=\"line\">bin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  </span><br><span class=\"line\">    sbin  srv  sys  tmp  usr  var</span><br><span class=\"line\">root@4128d2d804b4:/# ls dbdata/</span><br><span class=\"line\">test</span><br></pre></td></tr></table></figure></p>\n<p>可以多次使用–volumes-from参数来从多个容器挂载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。</p>\n<h2 id=\"注意\"><a href=\"#注意\" class=\"headerlink\" title=\"注意\"></a>注意</h2><p>使用–volumes-from参数所挂载数据卷的容器自身并不需要保持在运行状态。</p>\n<p>如果删除了挂载的容器(包括dbdata、db1和db2)，数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用docker rm-v命令来指定同时删除关联的容器。</p>\n<h1 id=\"利用数据卷容器来迁移数据\"><a href=\"#利用数据卷容器来迁移数据\" class=\"headerlink\" title=\"利用数据卷容器来迁移数据\"></a>利用数据卷容器来迁移数据</h1><p>可以利用数据卷容器对其中的数据卷进行备份、恢复，以实现数据的迁移</p>\n<h2 id=\"备份\"><a href=\"#备份\" class=\"headerlink\" title=\"备份\"></a>备份</h2><p>使用下面的命令来备份dbdata数据卷容器内的数据卷：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata</span><br></pre></td></tr></table></figure></p>\n<p>这个命令稍微有点复杂，具体分析一下。首先利用ubuntu镜像创建了一个容器worker。使用–volumes-from dbdata参数来让worker容器挂载dbdata容器的数据卷（即dbdata数据卷）；使用-v$(pwd):/backup参数来挂载本地的当前目录到worker容器的/backup目录。</p>\n<p>worker容器启动后，使用了tar cvf/backup/backup.tar/dbdata命令来将/dbdata下内容备份为容器内的/backup/backup.tar，即宿主主机当前目录下的backup.tar。</p>\n<h2 id=\"恢复\"><a href=\"#恢复\" class=\"headerlink\" title=\"恢复\"></a>恢复</h2><p>如果要将数据恢复到一个容器，可以按照下面的步骤操作。首先创建一个带有数据卷的容器dbdata2：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -v /dbdata --name dbdata2 ubuntu /bin/bash</span><br></pre></td></tr></table></figure></p>\n<p>然后创建另一个新的容器，挂载dbdata2的容器，并使用untar解压备份文件到所挂载的容器卷中：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf</span><br><span class=\"line\">/backup/backup.tar</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>以上都是从书中直接抄来的，总结下其实就是：</p>\n<p>容器的数据存储方式就是使用数据卷。数据卷可以创建在容器内部，也可以挂载宿主机的目录或文件到容器中作为数据卷使用。</p>\n<p>一般如果需要对数据进行持久化，则为了数据安全考虑，会选择挂载宿主机目录到容器中作为数据卷来进行存储。</p>\n<p>如果不需要数据进行持久化，则直接在容器中创建数据卷即可。</p>\n<p>不建议挂载宿主机某个文件到容器中使用。</p>\n<p>可以通过数据卷容器实现容器之间的数据共享，数据备份与恢复。</p>\n<p>数据是非常重要的资源，docker在设计上充分考虑了这点，为数据的管理做了充分的支持。数据卷和数据卷容器提供了共享、备份、恢复即使是容器运行时出现了故障，也不同担心数据丢失。同时解耦了数据与容器。</p>\n<h2 id=\"总结之前搭建mysql时候进行数据持久化遇到的问题\"><a href=\"#总结之前搭建mysql时候进行数据持久化遇到的问题\" class=\"headerlink\" title=\"总结之前搭建mysql时候进行数据持久化遇到的问题\"></a>总结之前搭建mysql时候进行数据持久化遇到的问题</h2><p>挂载可以挂载文件夹、也可以挂载文件</p>\n<p>挂载文件夹的话，文件夹下的内容修改了，会同步修改容器中的内容</p>\n<p>但是如果挂载文件的话，这个文件如果inode修改了，比如用vim，vim修改了之后，wq保存了文件，文件的inode就会修改，这时host的这个挂载的文件就和容器的不同步了</p>\n<p>之前搭建mysql挂载配置文件遇到的坑，一般应用镜像都会提供给可配置或者需要持久化的信息一个可以挂载的文件入口，可能和以前的配置不一样。</p>\n<p>mysql5.6这个官方镜像，默认的配置就和普通我们启动的mysql的配置文件不太一样。他默认my.cnf 中是<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">!includedir /etc/mysql/conf.d/</span><br><span class=\"line\">!includedir /etc/mysql/mysql.conf.d/</span><br></pre></td></tr></table></figure></p>\n<p>conf.d/ mysql.conf.d/这两个文件夹 就可以用来挂载配置的</p>\n<p>所以做法就是，先在宿主机配置好conf.d/路径下的三个配置文件和mysql.conf.d/下的配置文件，然后docker run的时候挂载这两个路径</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li>《Docker技术入门与实战》</li>\n<li><a href=\"https://www.cnblogs.com/breezey/p/9589288.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/breezey/p/9589288.html</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>在通过docker创建mysql的过程中，遇到了一些关于docker存储的知识盲区，趁着上次临时学的东西还没忘，尽快学习下关于docker存储的知识。</p>\n</blockquote>","more":"<p>在使用docker过程中，往往需要对数据进行持久化，或者需要在多个容器之间共享数据，这就涉及到了容器的数据管理存储操作。</p>\n<p>容器中管理数据的主要方式有两种：</p>\n<ul>\n<li>数据卷(Data Volnumes): 容器内数据直接映射到本地主机环境</li>\n<li>数据容器卷(Date Volnume Containers): 使用特定容器维护数据卷</li>\n</ul>\n<h1 id=\"数据卷\"><a href=\"#数据卷\" class=\"headerlink\" title=\"数据卷\"></a>数据卷</h1><p>数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mount操作。</p>\n<p>数据卷可以提供很多有用的特性，如下所示：</p>\n<ul>\n<li>数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便</li>\n<li>对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作</li>\n<li>对数据卷的更新不会影响镜像，解耦了应用和数据</li>\n<li>卷会一直存在，直到没有容器使用，可以安全地卸载它</li>\n</ul>\n<h2 id=\"创建数据卷\"><a href=\"#创建数据卷\" class=\"headerlink\" title=\"创建数据卷\"></a>创建数据卷</h2><p>在用docker run命令的时候，使用-v标记可以在容器内创建一个数据卷。多次重复使用-v标记可以创建多个数据卷。</p>\n<p>下面使用training/webapp镜像创建一个web容器，并创建一个数据卷挂载到容器的/webapp目录：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -d -P --name web -v /webapp training/webapp python app.py</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"挂载一个主机目录作为数据卷\"><a href=\"#挂载一个主机目录作为数据卷\" class=\"headerlink\" title=\"挂载一个主机目录作为数据卷\"></a>挂载一个主机目录作为数据卷</h2><p>使用-v标记也可以指定挂载一个本地的已有目录到容器中去作为数据卷<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py</span><br></pre></td></tr></table></figure></p>\n<p>上面的命令加载主机的/src/webapp目录到容器的/opt/webapp目录。</p>\n<p>这个功能在进行测试的时候十分方便，比如用户可以将一些程序或数据放到本地目录中，然后在容器内运行和使用。另外，本地目录的路径必须是绝对路径，如果目录不存在Docker，会自动创建。</p>\n<p>Docker挂载数据卷的默认权限是读写（rw），用户也可以通过ro指定为只读：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py</span><br></pre></td></tr></table></figure></p>\n<p>加了:ro之后，容器内对所挂载数据卷内的数据就无法修改了。</p>\n<h2 id=\"挂载一个本地主机文件作为数据卷\"><a href=\"#挂载一个本地主机文件作为数据卷\" class=\"headerlink\" title=\"挂载一个本地主机文件作为数据卷\"></a>挂载一个本地主机文件作为数据卷</h2><p>-v标记也可以从主机挂载单个文件到容器中作为数据卷（不推荐）。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash</span><br></pre></td></tr></table></figure></p>\n<p>这样就可以记录在容器输入过的命令历史了。</p>\n<h1 id=\"数据卷容器\"><a href=\"#数据卷容器\" class=\"headerlink\" title=\"数据卷容器\"></a>数据卷容器</h1><p>如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。</p>\n<p>首先，创建一个数据卷容器dbdata，并在其中创建一个数据卷挂载到/dbdata：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -it -v /dbdata --name dbdata ubuntu</span><br><span class=\"line\">root@3ed94f279b6f:/#</span><br></pre></td></tr></table></figure></p>\n<p>查看/dbdata目录：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@3ed94f279b6f:/# ls</span><br><span class=\"line\">bin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  </span><br><span class=\"line\">    sbin  srv  sys  tmp  usr  var</span><br></pre></td></tr></table></figure></p>\n<p>然后，可以在其他容器中使用–volumes-from来挂载dbdata容器中的数据卷，例如创建db1和db2两个容器，并从dbdata容器挂载数据卷：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -it --volumes-from dbdata --name db1 ubuntu</span><br><span class=\"line\">$ docker run -it --volumes-from dbdata --name db2 ubuntu</span><br></pre></td></tr></table></figure></p>\n<p>此时，容器db1和db2都挂载同一个数据卷到相同的/dbdata目录。三个容器任何一方在该目录下的写入，其他容器都可以看到。</p>\n<p>例如，在dbdata容器中创建一个test文件，如下所示：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@3ed94f279b6f:/# cd /dbdata</span><br><span class=\"line\">root@3ed94f279b6f:/dbdata# touch test</span><br><span class=\"line\">root@3ed94f279b6f:/dbdata# ls</span><br><span class=\"line\">test</span><br></pre></td></tr></table></figure></p>\n<p>在db1容器内查看它：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -it --volumes-from dbdata --name db1  ubuntu</span><br><span class=\"line\">root@4128d2d804b4:/# ls</span><br><span class=\"line\">bin  boot  dbdata  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  </span><br><span class=\"line\">    sbin  srv  sys  tmp  usr  var</span><br><span class=\"line\">root@4128d2d804b4:/# ls dbdata/</span><br><span class=\"line\">test</span><br></pre></td></tr></table></figure></p>\n<p>可以多次使用–volumes-from参数来从多个容器挂载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。</p>\n<h2 id=\"注意\"><a href=\"#注意\" class=\"headerlink\" title=\"注意\"></a>注意</h2><p>使用–volumes-from参数所挂载数据卷的容器自身并不需要保持在运行状态。</p>\n<p>如果删除了挂载的容器(包括dbdata、db1和db2)，数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用docker rm-v命令来指定同时删除关联的容器。</p>\n<h1 id=\"利用数据卷容器来迁移数据\"><a href=\"#利用数据卷容器来迁移数据\" class=\"headerlink\" title=\"利用数据卷容器来迁移数据\"></a>利用数据卷容器来迁移数据</h1><p>可以利用数据卷容器对其中的数据卷进行备份、恢复，以实现数据的迁移</p>\n<h2 id=\"备份\"><a href=\"#备份\" class=\"headerlink\" title=\"备份\"></a>备份</h2><p>使用下面的命令来备份dbdata数据卷容器内的数据卷：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdata</span><br></pre></td></tr></table></figure></p>\n<p>这个命令稍微有点复杂，具体分析一下。首先利用ubuntu镜像创建了一个容器worker。使用–volumes-from dbdata参数来让worker容器挂载dbdata容器的数据卷（即dbdata数据卷）；使用-v$(pwd):/backup参数来挂载本地的当前目录到worker容器的/backup目录。</p>\n<p>worker容器启动后，使用了tar cvf/backup/backup.tar/dbdata命令来将/dbdata下内容备份为容器内的/backup/backup.tar，即宿主主机当前目录下的backup.tar。</p>\n<h2 id=\"恢复\"><a href=\"#恢复\" class=\"headerlink\" title=\"恢复\"></a>恢复</h2><p>如果要将数据恢复到一个容器，可以按照下面的步骤操作。首先创建一个带有数据卷的容器dbdata2：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run -v /dbdata --name dbdata2 ubuntu /bin/bash</span><br></pre></td></tr></table></figure></p>\n<p>然后创建另一个新的容器，挂载dbdata2的容器，并使用untar解压备份文件到所挂载的容器卷中：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf</span><br><span class=\"line\">/backup/backup.tar</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>以上都是从书中直接抄来的，总结下其实就是：</p>\n<p>容器的数据存储方式就是使用数据卷。数据卷可以创建在容器内部，也可以挂载宿主机的目录或文件到容器中作为数据卷使用。</p>\n<p>一般如果需要对数据进行持久化，则为了数据安全考虑，会选择挂载宿主机目录到容器中作为数据卷来进行存储。</p>\n<p>如果不需要数据进行持久化，则直接在容器中创建数据卷即可。</p>\n<p>不建议挂载宿主机某个文件到容器中使用。</p>\n<p>可以通过数据卷容器实现容器之间的数据共享，数据备份与恢复。</p>\n<p>数据是非常重要的资源，docker在设计上充分考虑了这点，为数据的管理做了充分的支持。数据卷和数据卷容器提供了共享、备份、恢复即使是容器运行时出现了故障，也不同担心数据丢失。同时解耦了数据与容器。</p>\n<h2 id=\"总结之前搭建mysql时候进行数据持久化遇到的问题\"><a href=\"#总结之前搭建mysql时候进行数据持久化遇到的问题\" class=\"headerlink\" title=\"总结之前搭建mysql时候进行数据持久化遇到的问题\"></a>总结之前搭建mysql时候进行数据持久化遇到的问题</h2><p>挂载可以挂载文件夹、也可以挂载文件</p>\n<p>挂载文件夹的话，文件夹下的内容修改了，会同步修改容器中的内容</p>\n<p>但是如果挂载文件的话，这个文件如果inode修改了，比如用vim，vim修改了之后，wq保存了文件，文件的inode就会修改，这时host的这个挂载的文件就和容器的不同步了</p>\n<p>之前搭建mysql挂载配置文件遇到的坑，一般应用镜像都会提供给可配置或者需要持久化的信息一个可以挂载的文件入口，可能和以前的配置不一样。</p>\n<p>mysql5.6这个官方镜像，默认的配置就和普通我们启动的mysql的配置文件不太一样。他默认my.cnf 中是<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">!includedir /etc/mysql/conf.d/</span><br><span class=\"line\">!includedir /etc/mysql/mysql.conf.d/</span><br></pre></td></tr></table></figure></p>\n<p>conf.d/ mysql.conf.d/这两个文件夹 就可以用来挂载配置的</p>\n<p>所以做法就是，先在宿主机配置好conf.d/路径下的三个配置文件和mysql.conf.d/下的配置文件，然后docker run的时候挂载这两个路径</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li>《Docker技术入门与实战》</li>\n<li><a href=\"https://www.cnblogs.com/breezey/p/9589288.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/breezey/p/9589288.html</a></li>\n</ul>"},{"title":"docker 安装MySql","date":"2019-08-22T03:00:00.000Z","_content":"\n> 最近被安排做数据迁移，因为刚换电脑，正好需要装一个mysql，想着正好直接用docker装一个试试\n\n<!-- more -->\n\n需要先获取mysql的docker镜像，获取的方式有两种，一种是直接获取docker hub上别人构建好的镜像，另一种是通过dockerfile构建镜像。\n\ndockerfile之后会单独学习一下，这里就说下通过官方提供的docker镜像构建。\n\n## 获取镜像\n在docker hub上查找mysql的镜像。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker search mysql\nNAME                              DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\nmysql                             MySQL is a widely used, open-source relation…   8511                [OK]\nmariadb                           MariaDB is a community-developed fork of MyS…   2951                [OK]\nmysql/mysql-server                Optimized MySQL Server Docker images. Create…   628                                     [OK]\ncentos/mysql-57-centos7           MySQL 5.7 SQL database server                   62\ncenturylink/mysql                 Image containing mysql. Optimized to be link…   61                                      [OK]\nmysql/mysql-cluster               Experimental MySQL Cluster Docker images. Cr…   50\ndeitch/mysql-backup               Automated and scheduled mysql database dumps…   41                                      [OK]\ntutum/mysql                       Base docker image to run a MySQL database se…   33\nbitnami/mysql                     Bitnami MySQL Docker Image                      31                                      [OK]\nschickling/mysql-backup-s3        Backup MySQL to S3 (supports periodic backup…   28                                      [OK]\nlinuxserver/mysql                 A Mysql container, brought to you by LinuxSe…   21\nprom/mysqld-exporter                                                              20                                      [OK]\ncentos/mysql-56-centos7           MySQL 5.6 SQL database server                   15\ncircleci/mysql                    MySQL is a widely used, open-source relation…   14\nmysql/mysql-router                MySQL Router provides transparent routing be…   12\narey/mysql-client                 Run a MySQL client from a docker container      10                                      [OK]\nopenshift/mysql-55-centos7        DEPRECATED: A Centos7 based MySQL v5.5 image…   6\nimega/mysql-client                Size: 36 MB, alpine:3.5, Mysql client: 10.1.…   6                                       [OK]\nyloeffler/mysql-backup            This image runs mysqldump to backup data usi…   6                                       [OK]\nfradelg/mysql-cron-backup         MySQL/MariaDB database backup using cron tas…   4                                       [OK]\ngenschsa/mysql-employees          MySQL Employee Sample Database                  2                                       [OK]\nansibleplaybookbundle/mysql-apb   An APB which deploys RHSCL MySQL                1                                       [OK]\njelastic/mysql                    An image of the MySQL database server mainta…   1\nmonasca/mysql-init                A minimal decoupled init container for mysql    0\nwiddpim/mysql-client              Dockerized MySQL Client (5.7) including Curl…   0                                       [OK]\n```\n\n因为我们使用的mysql是5.5版本的，所以直接就pull 5.5版本的\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker pull mysql:5.5\n5.5: Pulling from library/mysql\n743f2d6c1f65: Pull complete\n3f0c413ee255: Pull complete\naef1ef8f1aac: Pull complete\nf9ee573e34cb: Pull complete\n3f237e01f153: Pull complete\n03da1e065b16: Pull complete\n04087a801070: Pull complete\n7efd5395ab31: Pull complete\n1b5cc03aaac8: Pull complete\n2b7adaec9998: Pull complete\n385b8f96a9ba: Pull complete\nDigest: sha256:12da85ab88aedfdf39455872fb044f607c32fdc233cd59f1d26769fbf439b045\nStatus: Downloaded newer image for mysql:5.5\n```\n这里如果下载的很慢，可以参考上一节文末讲到的如果修改公共仓库地址的那个。\n\n现在看下本地镜像仓库，已经存在了。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nmysql               5.6                 732765f8c7d2        8 days ago          257MB\nmysql               5.5                 d404d78aa797        3 months ago        205MB\nhello-world         latest              fce289e99eb9        7 months ago        1.84kB\nubuntu              15.10               9b9cb95443b5        3 years ago         137MB\ntraining/webapp     latest              6fae60ef3446        4 years ago         349MB\n```\n\n## 使用镜像\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -p 3306:3306 --privileged=true --name mymysql -v $PWD/mysql/conf.d:/etc/mysql/conf.d -v $PWD/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d -v $PWD/mysql/logs:/logs -v $PWD/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.5\n11e8f339f568\n```\n这里我是直接学习了别人启动使用的参数\n- -d 后台运行\n- -p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。\n- --privileged=true：容器内的root拥有真正root权限，否则容器内root只是外部普通用户权限\n- --name 容器命名\n- -v $PWD/mysql/conf:/etc/mysql/conf.d：将主机当前目录下的 /mysql/conf 挂载到容器的 /etc/mysql/conf.d。\n- -v $PWD/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d：将主机当前目录下的/mysql/mysql.conf.d 挂载到容器的 /mysql/mysql.conf.d。\n- -v $PWD/logs:/logs：将主机当前目录下的 /mysql/logs 目录挂载到容器的 /logs。\n- -v $PWD/data:/var/lib/mysql ：将主机当前目录下的/mysql/data目录挂载到容器的 /var/lib/mysql 。\n- -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。\n\n这里为什么要将logs、data、conf挂在到宿主机的硬盘呢，是因为容器的存储是与容器的生命周期有关的，如果该mysql所属的容器关闭或出现其他问题，可能会导致数据丢失，数据库对于数据十分敏感，所以可以使用这种方式解决docker容器数据持久化的问题。\n\nmysql5.6的这个镜像的配置文件中有!includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/，这两个路径就是上面挂载的路径。所以和平时修改my.cnf不同，只修改挂载卷目录下的配置文件也是可以达到同样效果的。\n\n之后会单独学习下docker的存储相关的知识。\n\n### 其他配置方式\n关于配置，其实还可以通过标签（flags）传递至mysql进程。这样就可以脱离cnf配置文件，对容器进行弹性的定制。\n\n比如，如果需要修改默认编码方式，将所有编码方式修改为utf8mb4，则可以用下面这行命令\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run --name mymysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci\n```\n如果需要查看可用选项的完整列表，可以执行\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -it --rm mysql:tag --verbose --help\n```\n\n## 查看运行容器\n查看下已经启动好了，现在可以通过外部客户端工具链接访问下看看了。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES\n11e8f339f568        mysql:5.5           \"docker-entrypoint.s…\"   6 hours ago         Up 6 hours          0.0.0.0:3306->3306/tcp   mymysql\n```\n\n因为我提前在/mysql/conf.d和/mysql/mysql.conf.d/配置四个配置文件，主要是客户端和服务端的编码格式的，所以先访问容器，查看下mysql的配置有没有生效。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker exec -it mymysql bash\nroot@1254821edc4c:/# mysql -uroot -p123456\nWarning: Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 5\nServer version: 5.6.45 MySQL Community Server (GPL)\n\nCopyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql> show variables like '%char%';\n+--------------------------+----------------------------+\n| Variable_name            | Value                      |\n+--------------------------+----------------------------+\n| character_set_client     | utf8mb4                    |\n| character_set_connection | utf8mb4                    |\n| character_set_database   | utf8mb4                    |\n| character_set_filesystem | binary                     |\n| character_set_results    | utf8mb4                    |\n| character_set_server     | utf8mb4                    |\n| character_set_system     | utf8                       |\n| character_sets_dir       | /usr/share/mysql/charsets/ |\n+--------------------------+----------------------------+\n8 rows in set (0.00 sec)\n```\n可以看出是已经生效的了。","source":"_posts/docker_06_mysql.md","raw":"---\ntitle: docker 安装MySql\ndate: 2019-08-22 11:00:00\ntags: docker\ncategories: DevOps\n---\n\n> 最近被安排做数据迁移，因为刚换电脑，正好需要装一个mysql，想着正好直接用docker装一个试试\n\n<!-- more -->\n\n需要先获取mysql的docker镜像，获取的方式有两种，一种是直接获取docker hub上别人构建好的镜像，另一种是通过dockerfile构建镜像。\n\ndockerfile之后会单独学习一下，这里就说下通过官方提供的docker镜像构建。\n\n## 获取镜像\n在docker hub上查找mysql的镜像。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker search mysql\nNAME                              DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED\nmysql                             MySQL is a widely used, open-source relation…   8511                [OK]\nmariadb                           MariaDB is a community-developed fork of MyS…   2951                [OK]\nmysql/mysql-server                Optimized MySQL Server Docker images. Create…   628                                     [OK]\ncentos/mysql-57-centos7           MySQL 5.7 SQL database server                   62\ncenturylink/mysql                 Image containing mysql. Optimized to be link…   61                                      [OK]\nmysql/mysql-cluster               Experimental MySQL Cluster Docker images. Cr…   50\ndeitch/mysql-backup               Automated and scheduled mysql database dumps…   41                                      [OK]\ntutum/mysql                       Base docker image to run a MySQL database se…   33\nbitnami/mysql                     Bitnami MySQL Docker Image                      31                                      [OK]\nschickling/mysql-backup-s3        Backup MySQL to S3 (supports periodic backup…   28                                      [OK]\nlinuxserver/mysql                 A Mysql container, brought to you by LinuxSe…   21\nprom/mysqld-exporter                                                              20                                      [OK]\ncentos/mysql-56-centos7           MySQL 5.6 SQL database server                   15\ncircleci/mysql                    MySQL is a widely used, open-source relation…   14\nmysql/mysql-router                MySQL Router provides transparent routing be…   12\narey/mysql-client                 Run a MySQL client from a docker container      10                                      [OK]\nopenshift/mysql-55-centos7        DEPRECATED: A Centos7 based MySQL v5.5 image…   6\nimega/mysql-client                Size: 36 MB, alpine:3.5, Mysql client: 10.1.…   6                                       [OK]\nyloeffler/mysql-backup            This image runs mysqldump to backup data usi…   6                                       [OK]\nfradelg/mysql-cron-backup         MySQL/MariaDB database backup using cron tas…   4                                       [OK]\ngenschsa/mysql-employees          MySQL Employee Sample Database                  2                                       [OK]\nansibleplaybookbundle/mysql-apb   An APB which deploys RHSCL MySQL                1                                       [OK]\njelastic/mysql                    An image of the MySQL database server mainta…   1\nmonasca/mysql-init                A minimal decoupled init container for mysql    0\nwiddpim/mysql-client              Dockerized MySQL Client (5.7) including Curl…   0                                       [OK]\n```\n\n因为我们使用的mysql是5.5版本的，所以直接就pull 5.5版本的\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker pull mysql:5.5\n5.5: Pulling from library/mysql\n743f2d6c1f65: Pull complete\n3f0c413ee255: Pull complete\naef1ef8f1aac: Pull complete\nf9ee573e34cb: Pull complete\n3f237e01f153: Pull complete\n03da1e065b16: Pull complete\n04087a801070: Pull complete\n7efd5395ab31: Pull complete\n1b5cc03aaac8: Pull complete\n2b7adaec9998: Pull complete\n385b8f96a9ba: Pull complete\nDigest: sha256:12da85ab88aedfdf39455872fb044f607c32fdc233cd59f1d26769fbf439b045\nStatus: Downloaded newer image for mysql:5.5\n```\n这里如果下载的很慢，可以参考上一节文末讲到的如果修改公共仓库地址的那个。\n\n现在看下本地镜像仓库，已经存在了。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nmysql               5.6                 732765f8c7d2        8 days ago          257MB\nmysql               5.5                 d404d78aa797        3 months ago        205MB\nhello-world         latest              fce289e99eb9        7 months ago        1.84kB\nubuntu              15.10               9b9cb95443b5        3 years ago         137MB\ntraining/webapp     latest              6fae60ef3446        4 years ago         349MB\n```\n\n## 使用镜像\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -p 3306:3306 --privileged=true --name mymysql -v $PWD/mysql/conf.d:/etc/mysql/conf.d -v $PWD/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d -v $PWD/mysql/logs:/logs -v $PWD/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.5\n11e8f339f568\n```\n这里我是直接学习了别人启动使用的参数\n- -d 后台运行\n- -p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。\n- --privileged=true：容器内的root拥有真正root权限，否则容器内root只是外部普通用户权限\n- --name 容器命名\n- -v $PWD/mysql/conf:/etc/mysql/conf.d：将主机当前目录下的 /mysql/conf 挂载到容器的 /etc/mysql/conf.d。\n- -v $PWD/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d：将主机当前目录下的/mysql/mysql.conf.d 挂载到容器的 /mysql/mysql.conf.d。\n- -v $PWD/logs:/logs：将主机当前目录下的 /mysql/logs 目录挂载到容器的 /logs。\n- -v $PWD/data:/var/lib/mysql ：将主机当前目录下的/mysql/data目录挂载到容器的 /var/lib/mysql 。\n- -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。\n\n这里为什么要将logs、data、conf挂在到宿主机的硬盘呢，是因为容器的存储是与容器的生命周期有关的，如果该mysql所属的容器关闭或出现其他问题，可能会导致数据丢失，数据库对于数据十分敏感，所以可以使用这种方式解决docker容器数据持久化的问题。\n\nmysql5.6的这个镜像的配置文件中有!includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/，这两个路径就是上面挂载的路径。所以和平时修改my.cnf不同，只修改挂载卷目录下的配置文件也是可以达到同样效果的。\n\n之后会单独学习下docker的存储相关的知识。\n\n### 其他配置方式\n关于配置，其实还可以通过标签（flags）传递至mysql进程。这样就可以脱离cnf配置文件，对容器进行弹性的定制。\n\n比如，如果需要修改默认编码方式，将所有编码方式修改为utf8mb4，则可以用下面这行命令\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run --name mymysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci\n```\n如果需要查看可用选项的完整列表，可以执行\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -it --rm mysql:tag --verbose --help\n```\n\n## 查看运行容器\n查看下已经启动好了，现在可以通过外部客户端工具链接访问下看看了。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES\n11e8f339f568        mysql:5.5           \"docker-entrypoint.s…\"   6 hours ago         Up 6 hours          0.0.0.0:3306->3306/tcp   mymysql\n```\n\n因为我提前在/mysql/conf.d和/mysql/mysql.conf.d/配置四个配置文件，主要是客户端和服务端的编码格式的，所以先访问容器，查看下mysql的配置有没有生效。\n```\n[root@iZwz91w0kp029z0dmueicoZ /root]#docker exec -it mymysql bash\nroot@1254821edc4c:/# mysql -uroot -p123456\nWarning: Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 5\nServer version: 5.6.45 MySQL Community Server (GPL)\n\nCopyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql> show variables like '%char%';\n+--------------------------+----------------------------+\n| Variable_name            | Value                      |\n+--------------------------+----------------------------+\n| character_set_client     | utf8mb4                    |\n| character_set_connection | utf8mb4                    |\n| character_set_database   | utf8mb4                    |\n| character_set_filesystem | binary                     |\n| character_set_results    | utf8mb4                    |\n| character_set_server     | utf8mb4                    |\n| character_set_system     | utf8                       |\n| character_sets_dir       | /usr/share/mysql/charsets/ |\n+--------------------------+----------------------------+\n8 rows in set (0.00 sec)\n```\n可以看出是已经生效的了。","slug":"docker_06_mysql","published":1,"updated":"2019-09-05T03:16:31.805Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3p0046qotnkfo5cuvb","content":"<blockquote>\n<p>最近被安排做数据迁移，因为刚换电脑，正好需要装一个mysql，想着正好直接用docker装一个试试</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>需要先获取mysql的docker镜像，获取的方式有两种，一种是直接获取docker hub上别人构建好的镜像，另一种是通过dockerfile构建镜像。</p>\n<p>dockerfile之后会单独学习一下，这里就说下通过官方提供的docker镜像构建。</p>\n<h2 id=\"获取镜像\"><a href=\"#获取镜像\" class=\"headerlink\" title=\"获取镜像\"></a>获取镜像</h2><p>在docker hub上查找mysql的镜像。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker search mysql</span><br><span class=\"line\">NAME                              DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class=\"line\">mysql                             MySQL is a widely used, open-source relation…   8511                [OK]</span><br><span class=\"line\">mariadb                           MariaDB is a community-developed fork of MyS…   2951                [OK]</span><br><span class=\"line\">mysql/mysql-server                Optimized MySQL Server Docker images. Create…   628                                     [OK]</span><br><span class=\"line\">centos/mysql-57-centos7           MySQL 5.7 SQL database server                   62</span><br><span class=\"line\">centurylink/mysql                 Image containing mysql. Optimized to be link…   61                                      [OK]</span><br><span class=\"line\">mysql/mysql-cluster               Experimental MySQL Cluster Docker images. Cr…   50</span><br><span class=\"line\">deitch/mysql-backup               Automated and scheduled mysql database dumps…   41                                      [OK]</span><br><span class=\"line\">tutum/mysql                       Base docker image to run a MySQL database se…   33</span><br><span class=\"line\">bitnami/mysql                     Bitnami MySQL Docker Image                      31                                      [OK]</span><br><span class=\"line\">schickling/mysql-backup-s3        Backup MySQL to S3 (supports periodic backup…   28                                      [OK]</span><br><span class=\"line\">linuxserver/mysql                 A Mysql container, brought to you by LinuxSe…   21</span><br><span class=\"line\">prom/mysqld-exporter                                                              20                                      [OK]</span><br><span class=\"line\">centos/mysql-56-centos7           MySQL 5.6 SQL database server                   15</span><br><span class=\"line\">circleci/mysql                    MySQL is a widely used, open-source relation…   14</span><br><span class=\"line\">mysql/mysql-router                MySQL Router provides transparent routing be…   12</span><br><span class=\"line\">arey/mysql-client                 Run a MySQL client from a docker container      10                                      [OK]</span><br><span class=\"line\">openshift/mysql-55-centos7        DEPRECATED: A Centos7 based MySQL v5.5 image…   6</span><br><span class=\"line\">imega/mysql-client                Size: 36 MB, alpine:3.5, Mysql client: 10.1.…   6                                       [OK]</span><br><span class=\"line\">yloeffler/mysql-backup            This image runs mysqldump to backup data usi…   6                                       [OK]</span><br><span class=\"line\">fradelg/mysql-cron-backup         MySQL/MariaDB database backup using cron tas…   4                                       [OK]</span><br><span class=\"line\">genschsa/mysql-employees          MySQL Employee Sample Database                  2                                       [OK]</span><br><span class=\"line\">ansibleplaybookbundle/mysql-apb   An APB which deploys RHSCL MySQL                1                                       [OK]</span><br><span class=\"line\">jelastic/mysql                    An image of the MySQL database server mainta…   1</span><br><span class=\"line\">monasca/mysql-init                A minimal decoupled init container for mysql    0</span><br><span class=\"line\">widdpim/mysql-client              Dockerized MySQL Client (5.7) including Curl…   0                                       [OK]</span><br></pre></td></tr></table></figure></p>\n<p>因为我们使用的mysql是5.5版本的，所以直接就pull 5.5版本的<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker pull mysql:5.5</span><br><span class=\"line\">5.5: Pulling from library/mysql</span><br><span class=\"line\">743f2d6c1f65: Pull complete</span><br><span class=\"line\">3f0c413ee255: Pull complete</span><br><span class=\"line\">aef1ef8f1aac: Pull complete</span><br><span class=\"line\">f9ee573e34cb: Pull complete</span><br><span class=\"line\">3f237e01f153: Pull complete</span><br><span class=\"line\">03da1e065b16: Pull complete</span><br><span class=\"line\">04087a801070: Pull complete</span><br><span class=\"line\">7efd5395ab31: Pull complete</span><br><span class=\"line\">1b5cc03aaac8: Pull complete</span><br><span class=\"line\">2b7adaec9998: Pull complete</span><br><span class=\"line\">385b8f96a9ba: Pull complete</span><br><span class=\"line\">Digest: sha256:12da85ab88aedfdf39455872fb044f607c32fdc233cd59f1d26769fbf439b045</span><br><span class=\"line\">Status: Downloaded newer image for mysql:5.5</span><br></pre></td></tr></table></figure></p>\n<p>这里如果下载的很慢，可以参考上一节文末讲到的如果修改公共仓库地址的那个。</p>\n<p>现在看下本地镜像仓库，已经存在了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker images</span><br><span class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">mysql               5.6                 732765f8c7d2        8 days ago          257MB</span><br><span class=\"line\">mysql               5.5                 d404d78aa797        3 months ago        205MB</span><br><span class=\"line\">hello-world         latest              fce289e99eb9        7 months ago        1.84kB</span><br><span class=\"line\">ubuntu              15.10               9b9cb95443b5        3 years ago         137MB</span><br><span class=\"line\">training/webapp     latest              6fae60ef3446        4 years ago         349MB</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"使用镜像\"><a href=\"#使用镜像\" class=\"headerlink\" title=\"使用镜像\"></a>使用镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -p 3306:3306 --privileged=true --name mymysql -v $PWD/mysql/conf.d:/etc/mysql/conf.d -v $PWD/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d -v $PWD/mysql/logs:/logs -v $PWD/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.5</span><br><span class=\"line\">11e8f339f568</span><br></pre></td></tr></table></figure>\n<p>这里我是直接学习了别人启动使用的参数</p>\n<ul>\n<li>-d 后台运行</li>\n<li>-p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。</li>\n<li>–privileged=true：容器内的root拥有真正root权限，否则容器内root只是外部普通用户权限</li>\n<li>–name 容器命名</li>\n<li>-v $PWD/mysql/conf:/etc/mysql/conf.d：将主机当前目录下的 /mysql/conf 挂载到容器的 /etc/mysql/conf.d。</li>\n<li>-v $PWD/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d：将主机当前目录下的/mysql/mysql.conf.d 挂载到容器的 /mysql/mysql.conf.d。</li>\n<li>-v $PWD/logs:/logs：将主机当前目录下的 /mysql/logs 目录挂载到容器的 /logs。</li>\n<li>-v $PWD/data:/var/lib/mysql ：将主机当前目录下的/mysql/data目录挂载到容器的 /var/lib/mysql 。</li>\n<li>-e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。</li>\n</ul>\n<p>这里为什么要将logs、data、conf挂在到宿主机的硬盘呢，是因为容器的存储是与容器的生命周期有关的，如果该mysql所属的容器关闭或出现其他问题，可能会导致数据丢失，数据库对于数据十分敏感，所以可以使用这种方式解决docker容器数据持久化的问题。</p>\n<p>mysql5.6的这个镜像的配置文件中有!includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/，这两个路径就是上面挂载的路径。所以和平时修改my.cnf不同，只修改挂载卷目录下的配置文件也是可以达到同样效果的。</p>\n<p>之后会单独学习下docker的存储相关的知识。</p>\n<h3 id=\"其他配置方式\"><a href=\"#其他配置方式\" class=\"headerlink\" title=\"其他配置方式\"></a>其他配置方式</h3><p>关于配置，其实还可以通过标签（flags）传递至mysql进程。这样就可以脱离cnf配置文件，对容器进行弹性的定制。</p>\n<p>比如，如果需要修改默认编码方式，将所有编码方式修改为utf8mb4，则可以用下面这行命令<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run --name mymysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci</span><br></pre></td></tr></table></figure></p>\n<p>如果需要查看可用选项的完整列表，可以执行<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -it --rm mysql:tag --verbose --help</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"查看运行容器\"><a href=\"#查看运行容器\" class=\"headerlink\" title=\"查看运行容器\"></a>查看运行容器</h2><p>查看下已经启动好了，现在可以通过外部客户端工具链接访问下看看了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class=\"line\">11e8f339f568        mysql:5.5           &quot;docker-entrypoint.s…&quot;   6 hours ago         Up 6 hours          0.0.0.0:3306-&gt;3306/tcp   mymysql</span><br></pre></td></tr></table></figure></p>\n<p>因为我提前在/mysql/conf.d和/mysql/mysql.conf.d/配置四个配置文件，主要是客户端和服务端的编码格式的，所以先访问容器，查看下mysql的配置有没有生效。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker exec -it mymysql bash</span><br><span class=\"line\">root@1254821edc4c:/# mysql -uroot -p123456</span><br><span class=\"line\">Warning: Using a password on the command line interface can be insecure.</span><br><span class=\"line\">Welcome to the MySQL monitor.  Commands end with ; or \\g.</span><br><span class=\"line\">Your MySQL connection id is 5</span><br><span class=\"line\">Server version: 5.6.45 MySQL Community Server (GPL)</span><br><span class=\"line\"></span><br><span class=\"line\">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class=\"line\"></span><br><span class=\"line\">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class=\"line\">affiliates. Other names may be trademarks of their respective</span><br><span class=\"line\">owners.</span><br><span class=\"line\"></span><br><span class=\"line\">Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show variables like &apos;%char%&apos;;</span><br><span class=\"line\">+--------------------------+----------------------------+</span><br><span class=\"line\">| Variable_name            | Value                      |</span><br><span class=\"line\">+--------------------------+----------------------------+</span><br><span class=\"line\">| character_set_client     | utf8mb4                    |</span><br><span class=\"line\">| character_set_connection | utf8mb4                    |</span><br><span class=\"line\">| character_set_database   | utf8mb4                    |</span><br><span class=\"line\">| character_set_filesystem | binary                     |</span><br><span class=\"line\">| character_set_results    | utf8mb4                    |</span><br><span class=\"line\">| character_set_server     | utf8mb4                    |</span><br><span class=\"line\">| character_set_system     | utf8                       |</span><br><span class=\"line\">| character_sets_dir       | /usr/share/mysql/charsets/ |</span><br><span class=\"line\">+--------------------------+----------------------------+</span><br><span class=\"line\">8 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>可以看出是已经生效的了。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>最近被安排做数据迁移，因为刚换电脑，正好需要装一个mysql，想着正好直接用docker装一个试试</p>\n</blockquote>","more":"<p>需要先获取mysql的docker镜像，获取的方式有两种，一种是直接获取docker hub上别人构建好的镜像，另一种是通过dockerfile构建镜像。</p>\n<p>dockerfile之后会单独学习一下，这里就说下通过官方提供的docker镜像构建。</p>\n<h2 id=\"获取镜像\"><a href=\"#获取镜像\" class=\"headerlink\" title=\"获取镜像\"></a>获取镜像</h2><p>在docker hub上查找mysql的镜像。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker search mysql</span><br><span class=\"line\">NAME                              DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class=\"line\">mysql                             MySQL is a widely used, open-source relation…   8511                [OK]</span><br><span class=\"line\">mariadb                           MariaDB is a community-developed fork of MyS…   2951                [OK]</span><br><span class=\"line\">mysql/mysql-server                Optimized MySQL Server Docker images. Create…   628                                     [OK]</span><br><span class=\"line\">centos/mysql-57-centos7           MySQL 5.7 SQL database server                   62</span><br><span class=\"line\">centurylink/mysql                 Image containing mysql. Optimized to be link…   61                                      [OK]</span><br><span class=\"line\">mysql/mysql-cluster               Experimental MySQL Cluster Docker images. Cr…   50</span><br><span class=\"line\">deitch/mysql-backup               Automated and scheduled mysql database dumps…   41                                      [OK]</span><br><span class=\"line\">tutum/mysql                       Base docker image to run a MySQL database se…   33</span><br><span class=\"line\">bitnami/mysql                     Bitnami MySQL Docker Image                      31                                      [OK]</span><br><span class=\"line\">schickling/mysql-backup-s3        Backup MySQL to S3 (supports periodic backup…   28                                      [OK]</span><br><span class=\"line\">linuxserver/mysql                 A Mysql container, brought to you by LinuxSe…   21</span><br><span class=\"line\">prom/mysqld-exporter                                                              20                                      [OK]</span><br><span class=\"line\">centos/mysql-56-centos7           MySQL 5.6 SQL database server                   15</span><br><span class=\"line\">circleci/mysql                    MySQL is a widely used, open-source relation…   14</span><br><span class=\"line\">mysql/mysql-router                MySQL Router provides transparent routing be…   12</span><br><span class=\"line\">arey/mysql-client                 Run a MySQL client from a docker container      10                                      [OK]</span><br><span class=\"line\">openshift/mysql-55-centos7        DEPRECATED: A Centos7 based MySQL v5.5 image…   6</span><br><span class=\"line\">imega/mysql-client                Size: 36 MB, alpine:3.5, Mysql client: 10.1.…   6                                       [OK]</span><br><span class=\"line\">yloeffler/mysql-backup            This image runs mysqldump to backup data usi…   6                                       [OK]</span><br><span class=\"line\">fradelg/mysql-cron-backup         MySQL/MariaDB database backup using cron tas…   4                                       [OK]</span><br><span class=\"line\">genschsa/mysql-employees          MySQL Employee Sample Database                  2                                       [OK]</span><br><span class=\"line\">ansibleplaybookbundle/mysql-apb   An APB which deploys RHSCL MySQL                1                                       [OK]</span><br><span class=\"line\">jelastic/mysql                    An image of the MySQL database server mainta…   1</span><br><span class=\"line\">monasca/mysql-init                A minimal decoupled init container for mysql    0</span><br><span class=\"line\">widdpim/mysql-client              Dockerized MySQL Client (5.7) including Curl…   0                                       [OK]</span><br></pre></td></tr></table></figure></p>\n<p>因为我们使用的mysql是5.5版本的，所以直接就pull 5.5版本的<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker pull mysql:5.5</span><br><span class=\"line\">5.5: Pulling from library/mysql</span><br><span class=\"line\">743f2d6c1f65: Pull complete</span><br><span class=\"line\">3f0c413ee255: Pull complete</span><br><span class=\"line\">aef1ef8f1aac: Pull complete</span><br><span class=\"line\">f9ee573e34cb: Pull complete</span><br><span class=\"line\">3f237e01f153: Pull complete</span><br><span class=\"line\">03da1e065b16: Pull complete</span><br><span class=\"line\">04087a801070: Pull complete</span><br><span class=\"line\">7efd5395ab31: Pull complete</span><br><span class=\"line\">1b5cc03aaac8: Pull complete</span><br><span class=\"line\">2b7adaec9998: Pull complete</span><br><span class=\"line\">385b8f96a9ba: Pull complete</span><br><span class=\"line\">Digest: sha256:12da85ab88aedfdf39455872fb044f607c32fdc233cd59f1d26769fbf439b045</span><br><span class=\"line\">Status: Downloaded newer image for mysql:5.5</span><br></pre></td></tr></table></figure></p>\n<p>这里如果下载的很慢，可以参考上一节文末讲到的如果修改公共仓库地址的那个。</p>\n<p>现在看下本地镜像仓库，已经存在了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker images</span><br><span class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">mysql               5.6                 732765f8c7d2        8 days ago          257MB</span><br><span class=\"line\">mysql               5.5                 d404d78aa797        3 months ago        205MB</span><br><span class=\"line\">hello-world         latest              fce289e99eb9        7 months ago        1.84kB</span><br><span class=\"line\">ubuntu              15.10               9b9cb95443b5        3 years ago         137MB</span><br><span class=\"line\">training/webapp     latest              6fae60ef3446        4 years ago         349MB</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"使用镜像\"><a href=\"#使用镜像\" class=\"headerlink\" title=\"使用镜像\"></a>使用镜像</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -d -p 3306:3306 --privileged=true --name mymysql -v $PWD/mysql/conf.d:/etc/mysql/conf.d -v $PWD/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d -v $PWD/mysql/logs:/logs -v $PWD/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.5</span><br><span class=\"line\">11e8f339f568</span><br></pre></td></tr></table></figure>\n<p>这里我是直接学习了别人启动使用的参数</p>\n<ul>\n<li>-d 后台运行</li>\n<li>-p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。</li>\n<li>–privileged=true：容器内的root拥有真正root权限，否则容器内root只是外部普通用户权限</li>\n<li>–name 容器命名</li>\n<li>-v $PWD/mysql/conf:/etc/mysql/conf.d：将主机当前目录下的 /mysql/conf 挂载到容器的 /etc/mysql/conf.d。</li>\n<li>-v $PWD/mysql/mysql.conf.d:/etc/mysql/mysql.conf.d：将主机当前目录下的/mysql/mysql.conf.d 挂载到容器的 /mysql/mysql.conf.d。</li>\n<li>-v $PWD/logs:/logs：将主机当前目录下的 /mysql/logs 目录挂载到容器的 /logs。</li>\n<li>-v $PWD/data:/var/lib/mysql ：将主机当前目录下的/mysql/data目录挂载到容器的 /var/lib/mysql 。</li>\n<li>-e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。</li>\n</ul>\n<p>这里为什么要将logs、data、conf挂在到宿主机的硬盘呢，是因为容器的存储是与容器的生命周期有关的，如果该mysql所属的容器关闭或出现其他问题，可能会导致数据丢失，数据库对于数据十分敏感，所以可以使用这种方式解决docker容器数据持久化的问题。</p>\n<p>mysql5.6的这个镜像的配置文件中有!includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/，这两个路径就是上面挂载的路径。所以和平时修改my.cnf不同，只修改挂载卷目录下的配置文件也是可以达到同样效果的。</p>\n<p>之后会单独学习下docker的存储相关的知识。</p>\n<h3 id=\"其他配置方式\"><a href=\"#其他配置方式\" class=\"headerlink\" title=\"其他配置方式\"></a>其他配置方式</h3><p>关于配置，其实还可以通过标签（flags）传递至mysql进程。这样就可以脱离cnf配置文件，对容器进行弹性的定制。</p>\n<p>比如，如果需要修改默认编码方式，将所有编码方式修改为utf8mb4，则可以用下面这行命令<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run --name mymysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci</span><br></pre></td></tr></table></figure></p>\n<p>如果需要查看可用选项的完整列表，可以执行<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker run -it --rm mysql:tag --verbose --help</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"查看运行容器\"><a href=\"#查看运行容器\" class=\"headerlink\" title=\"查看运行容器\"></a>查看运行容器</h2><p>查看下已经启动好了，现在可以通过外部客户端工具链接访问下看看了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker ps</span><br><span class=\"line\">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class=\"line\">11e8f339f568        mysql:5.5           &quot;docker-entrypoint.s…&quot;   6 hours ago         Up 6 hours          0.0.0.0:3306-&gt;3306/tcp   mymysql</span><br></pre></td></tr></table></figure></p>\n<p>因为我提前在/mysql/conf.d和/mysql/mysql.conf.d/配置四个配置文件，主要是客户端和服务端的编码格式的，所以先访问容器，查看下mysql的配置有没有生效。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@iZwz91w0kp029z0dmueicoZ /root]#docker exec -it mymysql bash</span><br><span class=\"line\">root@1254821edc4c:/# mysql -uroot -p123456</span><br><span class=\"line\">Warning: Using a password on the command line interface can be insecure.</span><br><span class=\"line\">Welcome to the MySQL monitor.  Commands end with ; or \\g.</span><br><span class=\"line\">Your MySQL connection id is 5</span><br><span class=\"line\">Server version: 5.6.45 MySQL Community Server (GPL)</span><br><span class=\"line\"></span><br><span class=\"line\">Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span><br><span class=\"line\"></span><br><span class=\"line\">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class=\"line\">affiliates. Other names may be trademarks of their respective</span><br><span class=\"line\">owners.</span><br><span class=\"line\"></span><br><span class=\"line\">Type &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; show variables like &apos;%char%&apos;;</span><br><span class=\"line\">+--------------------------+----------------------------+</span><br><span class=\"line\">| Variable_name            | Value                      |</span><br><span class=\"line\">+--------------------------+----------------------------+</span><br><span class=\"line\">| character_set_client     | utf8mb4                    |</span><br><span class=\"line\">| character_set_connection | utf8mb4                    |</span><br><span class=\"line\">| character_set_database   | utf8mb4                    |</span><br><span class=\"line\">| character_set_filesystem | binary                     |</span><br><span class=\"line\">| character_set_results    | utf8mb4                    |</span><br><span class=\"line\">| character_set_server     | utf8mb4                    |</span><br><span class=\"line\">| character_set_system     | utf8                       |</span><br><span class=\"line\">| character_sets_dir       | /usr/share/mysql/charsets/ |</span><br><span class=\"line\">+--------------------------+----------------------------+</span><br><span class=\"line\">8 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>\n<p>可以看出是已经生效的了。</p>"},{"title":"Lambda、函数式接口、引用表达式","date":"2018-11-21T06:00:01.000Z","_content":"\n# Lambda、函数式接口、引用表达式\n\n## 写在前面\n>最近在学习Stream的api，发现Java推出的函数式接口、Lambda表达式、引用表达式等大都服务于Stream的api使用，但其实并不一定，所以收集整理了下关于相关特性的用法。\n在这只会讲解下基本的用法，关于函数编程框架的详细解读，大家可以参考下这篇 [Java8 函数式编程探秘](http://www.importnew.com/27901.html \"Java8 函数式编程探秘\")，介绍的非常全面。\n\n<!-- more -->\n\n## 函数式接口\n先讲一个注解 ***@FunctionalInterface***\n\n```java\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.TYPE)\npublic @interface FunctionalInterface {}\n```\n\n@FunctionalInterface 注解要求接口有且只有一个抽象方法，JDK中有许多类用到该注解，比如 Runnable，它只有一个 Run 方法。（注：默认方法并不是抽象方法）\n\n```java\n@FunctionalInterface\npublic interface Runnable {\n    /**\n     * When an object implementing interface <code>Runnable</code> is used\n     * to create a thread, starting the thread causes the object's\n     * <code>run</code> method to be called in that separately executing\n     * thread.\n     * <p>\n     * The general contract of the method <code>run</code> is that it may\n     * take any action whatsoever.\n     *\n     * @see     java.lang.Thread#run()\n     */\n    public abstract void run();\n}\n```\nJava8中接口可以定义静态方法，直接通过类名调用，并且接口中可以通过default为抽象方法提供默认的实现。接口继承接口时，如果默认方法相同，则需要进行重写\n\nJava8推出的Lambda表达式只能针对函数式接口使用。\n\n\n## Lambda的语法\n\n首先Lambda可以认为是一种特殊的匿名内部类，其次lambda只能用于函数式接口。\n\nlambda语法：\n\n```java\n([形参列表，不带数据类型])-> {\n    //执行语句\n    [return..;]\n}\n```\n\n要注意的点：\n1. 如果形参列表是空的，只需要保留（）即可\n2. 如果没有返回值。只需要在{}写执行语句即可\n3. 如果接口的抽象方法只有一个形参，（）可以省略，只需要参数的名称即可\n4. 如果执行语句只有一行，可以省略{}，但是如果有返回值时，情况特殊。\n5. 如果函数式接口的方法有返回值，必须给定返回值，如果执行语句只有一句，还可以简写，即省去大括号和return以及最后的；号。\n6. 形参列表的数据类型会自动推断，只需要参数名称。\n\neg:\n\n```java\npublic class TestLambda {\n     public static void main(String[] args) {\n           TestLanmdaInterface1 t1 = new TestLanmdaInterface1() {\n                @Override\n                public void test() {\n                     System.out.println(\"使用匿名内部类\");\n \n                }\n           };\n           //与上面的匿名内部类执行效果一样\n           //右边的类型会自动根据左边的类型进行判断\n           TestLanmdaInterface1 t2 = () -> {\n                System.out.println(\"使用lanbda\");\n           };\n           t1.test();\n           t2.test();\n \n           //如果执行语句只有一行，可以省略大括号\n           TestLanmdaInterface1 t3 = () -> System.out.println(\"省略执行语句大括号，使用lanbda\");\n           t3.test();\n \n           TestLanmdaInterface2 t4 = (s) -> System.out.println(\"使用lanbda表达式，带1个参数，参数为：\"+s);\n           t4.test(\"字符串参数1\");\n \n           TestLanmdaInterface2 t5 = s -> System.out.println(\"使用lanbda表达式，只带1个参数，可省略参数的圆括号，参数为：\"+s);\n           t5.test(\"字符串参数2\");\n \n           TestLanmdaInterface3 t6 = (s,i) -> System.out.println(\"使用lanbda表达式，带两个参数，不可以省略圆括号，参数为：\"+s+\"  \"+ i);\n           t6.test(\"字符串参数3\",50);\n     }\n}\n \n@FunctionalInterface\ninterface TestLanmdaInterface1 {\n     //不带参数的抽象方法\n     void test();\n}\n@FunctionalInterface\ninterface TestLanmdaInterface2 {\n     //带参数的抽象方法\n     void test(String str);\n}\n@FunctionalInterface\ninterface TestLanmdaInterface3 {\n     //带多个参数的抽象方法\n     void test(String str,int num);\n}\n```\n\n```java\n@FunctionalInterface\ninterface IDemo {\n    void doSomething();\n}\n\nclass Demo {\n    public void doSomething(IDemo c) {\n        System.out.println(c);\n        c.doSomething();\n    }\n}\n\npublic class Test {\n\n    public static void main(String[] args) {\n        Demo demo = new Demo();\n        demo.doSomething(new IDemo() {\n            @Override\n            public void doSomething() {\n                System.out.println(\"使用匿名内部类实现\");\n\n            }\n        });\n        demo.doSomething(() -> System.out.println(\"使用lambda表达式实现\"));\n        /*\n        demo.doSomething(() -> {\n            System.out.println(\"使用lambda表达式实现\");\n            System.out.println(\"使用lambda表达式实现\");\n        });\n        */\n    }\n```\n\n可以看出，lambda表达式和匿名内部类并不完全相同\n\n观察生成的class文件可以看出，lambda表达式并不会生成额外的.class文件，而匿名内部类会生成Test$1.class\n```java\ncn.lb.Test$1@4554617c\n使用匿名内部类实现\ncn.lb.Test$$Lambda$1/1324119927@404b9385\n使用lambda表达式实现\n```\n\n\n## 函数式接口引用表达式\n\n* 引用实例方法：\n    自动把调用方法的时候的参数，全部传给引用的方法\n\n```java\n<函数式接口> <变量名> = <实例> :: <实例方法名>\n//自动把实参传递给引用的实例方法\n<变量名>.<接口方法>（[实参]）\n```\n* 引用类方法（静态方法）：\n    自动把调用方法的时候的参数，全部传给引用的方法\n\n* 引用类的实例方法：\n    定义、调用接口方法的时候需要多一个参数，并且参数的类型必须和引用实例方法的类型必须一致，把第一个参数作为引用的实例，后面的每个参数全部传递给引用的方法。\n\n```java\ninterface <函数式接口> {\n    <返回值> <方法名>(<类名><名称> [,其它参数...])    \n}\n<变量名>.<方法名>（<类名的实例>[,其它参数]）\n```\n\neg:\n```java\npublic class TestMethodRef {\n    public static void main(String[] args) {\n        MethodRef r1 = (s) -> System.out.println(s);\n        r1.test(\"普通方式\");\n\n        //使用方法的引用：实例方法的引用\n        //System.out是一个实例  out是PrintStream 类型，有println方法\n        MethodRef r2 = System.out::println;\n        r2.test(\"方法引用\");\n\n        //MethodRef1 r3 =(a)-> Arrays.sort(a);\n        //引用类方法\n        MethodRef1 r3 = Arrays::sort;\n        int[] a = new int[]{4, 12, 23, 1, 3};\n        r3.test(a);\n        //将排序后的数组输出\n        r1.test(Arrays.toString(a));\n\n        //引用类的实例方法\n        MethodRef2 r4 = PrintStream::println;\n        //第二个之后的参数作为引用方法的参数\n        r4.test(System.out, \"第二个参数\");\n\n        //引用构造器\n        MethodRef3 r5 = String::new;\n        String test = r5.test(new char[]{'测', '试', '构', '造', '器', '引', '用'});\n        System.out.println(test);\n        //普通情况\n        MethodRef3 r6 = (c) -> {\n            return new String(c);\n        };\n        String test2 = r6.test(new char[]{'测', '试', '构', '造', '器', '引', '用'});\n        System.out.println(test2);\n    }\n}\n\ninterface MethodRef {\n    void test(String s);\n}\n\ninterface MethodRef1 {\n    void test(int[] arr);\n}\n\ninterface MethodRef2 {\n    void test(PrintStream out, String str);\n}\n\n//测试构造器引用\ninterface MethodRef3 {\n    String test(char[] chars);\n}\n\n```\n\n## 参考资料\n\n* https://blog.csdn.net/zymx14/article/details/70175746\n* https://blog.csdn.net/kegaofei/article/details/80582356\n* https://edu.aliyun.com/lesson_1012_9096?spm=5176.10731542.0.0.xGlbkv#_9096\n* http://www.importnew.com/27901.html\n* http://www.importnew.com/10360.html","source":"_posts/lambda、函数式接口、引用表达式.md","raw":"---\ntitle: Lambda、函数式接口、引用表达式\ndate: 2018-11-21 14:00:01\ntags: Java\ncategories: Java\n---\n\n# Lambda、函数式接口、引用表达式\n\n## 写在前面\n>最近在学习Stream的api，发现Java推出的函数式接口、Lambda表达式、引用表达式等大都服务于Stream的api使用，但其实并不一定，所以收集整理了下关于相关特性的用法。\n在这只会讲解下基本的用法，关于函数编程框架的详细解读，大家可以参考下这篇 [Java8 函数式编程探秘](http://www.importnew.com/27901.html \"Java8 函数式编程探秘\")，介绍的非常全面。\n\n<!-- more -->\n\n## 函数式接口\n先讲一个注解 ***@FunctionalInterface***\n\n```java\n@Documented\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.TYPE)\npublic @interface FunctionalInterface {}\n```\n\n@FunctionalInterface 注解要求接口有且只有一个抽象方法，JDK中有许多类用到该注解，比如 Runnable，它只有一个 Run 方法。（注：默认方法并不是抽象方法）\n\n```java\n@FunctionalInterface\npublic interface Runnable {\n    /**\n     * When an object implementing interface <code>Runnable</code> is used\n     * to create a thread, starting the thread causes the object's\n     * <code>run</code> method to be called in that separately executing\n     * thread.\n     * <p>\n     * The general contract of the method <code>run</code> is that it may\n     * take any action whatsoever.\n     *\n     * @see     java.lang.Thread#run()\n     */\n    public abstract void run();\n}\n```\nJava8中接口可以定义静态方法，直接通过类名调用，并且接口中可以通过default为抽象方法提供默认的实现。接口继承接口时，如果默认方法相同，则需要进行重写\n\nJava8推出的Lambda表达式只能针对函数式接口使用。\n\n\n## Lambda的语法\n\n首先Lambda可以认为是一种特殊的匿名内部类，其次lambda只能用于函数式接口。\n\nlambda语法：\n\n```java\n([形参列表，不带数据类型])-> {\n    //执行语句\n    [return..;]\n}\n```\n\n要注意的点：\n1. 如果形参列表是空的，只需要保留（）即可\n2. 如果没有返回值。只需要在{}写执行语句即可\n3. 如果接口的抽象方法只有一个形参，（）可以省略，只需要参数的名称即可\n4. 如果执行语句只有一行，可以省略{}，但是如果有返回值时，情况特殊。\n5. 如果函数式接口的方法有返回值，必须给定返回值，如果执行语句只有一句，还可以简写，即省去大括号和return以及最后的；号。\n6. 形参列表的数据类型会自动推断，只需要参数名称。\n\neg:\n\n```java\npublic class TestLambda {\n     public static void main(String[] args) {\n           TestLanmdaInterface1 t1 = new TestLanmdaInterface1() {\n                @Override\n                public void test() {\n                     System.out.println(\"使用匿名内部类\");\n \n                }\n           };\n           //与上面的匿名内部类执行效果一样\n           //右边的类型会自动根据左边的类型进行判断\n           TestLanmdaInterface1 t2 = () -> {\n                System.out.println(\"使用lanbda\");\n           };\n           t1.test();\n           t2.test();\n \n           //如果执行语句只有一行，可以省略大括号\n           TestLanmdaInterface1 t3 = () -> System.out.println(\"省略执行语句大括号，使用lanbda\");\n           t3.test();\n \n           TestLanmdaInterface2 t4 = (s) -> System.out.println(\"使用lanbda表达式，带1个参数，参数为：\"+s);\n           t4.test(\"字符串参数1\");\n \n           TestLanmdaInterface2 t5 = s -> System.out.println(\"使用lanbda表达式，只带1个参数，可省略参数的圆括号，参数为：\"+s);\n           t5.test(\"字符串参数2\");\n \n           TestLanmdaInterface3 t6 = (s,i) -> System.out.println(\"使用lanbda表达式，带两个参数，不可以省略圆括号，参数为：\"+s+\"  \"+ i);\n           t6.test(\"字符串参数3\",50);\n     }\n}\n \n@FunctionalInterface\ninterface TestLanmdaInterface1 {\n     //不带参数的抽象方法\n     void test();\n}\n@FunctionalInterface\ninterface TestLanmdaInterface2 {\n     //带参数的抽象方法\n     void test(String str);\n}\n@FunctionalInterface\ninterface TestLanmdaInterface3 {\n     //带多个参数的抽象方法\n     void test(String str,int num);\n}\n```\n\n```java\n@FunctionalInterface\ninterface IDemo {\n    void doSomething();\n}\n\nclass Demo {\n    public void doSomething(IDemo c) {\n        System.out.println(c);\n        c.doSomething();\n    }\n}\n\npublic class Test {\n\n    public static void main(String[] args) {\n        Demo demo = new Demo();\n        demo.doSomething(new IDemo() {\n            @Override\n            public void doSomething() {\n                System.out.println(\"使用匿名内部类实现\");\n\n            }\n        });\n        demo.doSomething(() -> System.out.println(\"使用lambda表达式实现\"));\n        /*\n        demo.doSomething(() -> {\n            System.out.println(\"使用lambda表达式实现\");\n            System.out.println(\"使用lambda表达式实现\");\n        });\n        */\n    }\n```\n\n可以看出，lambda表达式和匿名内部类并不完全相同\n\n观察生成的class文件可以看出，lambda表达式并不会生成额外的.class文件，而匿名内部类会生成Test$1.class\n```java\ncn.lb.Test$1@4554617c\n使用匿名内部类实现\ncn.lb.Test$$Lambda$1/1324119927@404b9385\n使用lambda表达式实现\n```\n\n\n## 函数式接口引用表达式\n\n* 引用实例方法：\n    自动把调用方法的时候的参数，全部传给引用的方法\n\n```java\n<函数式接口> <变量名> = <实例> :: <实例方法名>\n//自动把实参传递给引用的实例方法\n<变量名>.<接口方法>（[实参]）\n```\n* 引用类方法（静态方法）：\n    自动把调用方法的时候的参数，全部传给引用的方法\n\n* 引用类的实例方法：\n    定义、调用接口方法的时候需要多一个参数，并且参数的类型必须和引用实例方法的类型必须一致，把第一个参数作为引用的实例，后面的每个参数全部传递给引用的方法。\n\n```java\ninterface <函数式接口> {\n    <返回值> <方法名>(<类名><名称> [,其它参数...])    \n}\n<变量名>.<方法名>（<类名的实例>[,其它参数]）\n```\n\neg:\n```java\npublic class TestMethodRef {\n    public static void main(String[] args) {\n        MethodRef r1 = (s) -> System.out.println(s);\n        r1.test(\"普通方式\");\n\n        //使用方法的引用：实例方法的引用\n        //System.out是一个实例  out是PrintStream 类型，有println方法\n        MethodRef r2 = System.out::println;\n        r2.test(\"方法引用\");\n\n        //MethodRef1 r3 =(a)-> Arrays.sort(a);\n        //引用类方法\n        MethodRef1 r3 = Arrays::sort;\n        int[] a = new int[]{4, 12, 23, 1, 3};\n        r3.test(a);\n        //将排序后的数组输出\n        r1.test(Arrays.toString(a));\n\n        //引用类的实例方法\n        MethodRef2 r4 = PrintStream::println;\n        //第二个之后的参数作为引用方法的参数\n        r4.test(System.out, \"第二个参数\");\n\n        //引用构造器\n        MethodRef3 r5 = String::new;\n        String test = r5.test(new char[]{'测', '试', '构', '造', '器', '引', '用'});\n        System.out.println(test);\n        //普通情况\n        MethodRef3 r6 = (c) -> {\n            return new String(c);\n        };\n        String test2 = r6.test(new char[]{'测', '试', '构', '造', '器', '引', '用'});\n        System.out.println(test2);\n    }\n}\n\ninterface MethodRef {\n    void test(String s);\n}\n\ninterface MethodRef1 {\n    void test(int[] arr);\n}\n\ninterface MethodRef2 {\n    void test(PrintStream out, String str);\n}\n\n//测试构造器引用\ninterface MethodRef3 {\n    String test(char[] chars);\n}\n\n```\n\n## 参考资料\n\n* https://blog.csdn.net/zymx14/article/details/70175746\n* https://blog.csdn.net/kegaofei/article/details/80582356\n* https://edu.aliyun.com/lesson_1012_9096?spm=5176.10731542.0.0.xGlbkv#_9096\n* http://www.importnew.com/27901.html\n* http://www.importnew.com/10360.html","slug":"lambda、函数式接口、引用表达式","published":1,"updated":"2019-08-26T07:52:07.332Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3r0049qotni0qanwer","content":"<h1 id=\"Lambda、函数式接口、引用表达式\"><a href=\"#Lambda、函数式接口、引用表达式\" class=\"headerlink\" title=\"Lambda、函数式接口、引用表达式\"></a>Lambda、函数式接口、引用表达式</h1><h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><blockquote>\n<p>最近在学习Stream的api，发现Java推出的函数式接口、Lambda表达式、引用表达式等大都服务于Stream的api使用，但其实并不一定，所以收集整理了下关于相关特性的用法。<br>在这只会讲解下基本的用法，关于函数编程框架的详细解读，大家可以参考下这篇 <a href=\"http://www.importnew.com/27901.html\" title=\"Java8 函数式编程探秘\" target=\"_blank\" rel=\"noopener\">Java8 函数式编程探秘</a>，介绍的非常全面。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"函数式接口\"><a href=\"#函数式接口\" class=\"headerlink\" title=\"函数式接口\"></a>函数式接口</h2><p>先讲一个注解 <strong><em>@FunctionalInterface</em></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Documented</span></span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class=\"line\"><span class=\"meta\">@Target</span>(ElementType.TYPE)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> FunctionalInterface &#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>@FunctionalInterface 注解要求接口有且只有一个抽象方法，JDK中有许多类用到该注解，比如 Runnable，它只有一个 Run 方法。（注：默认方法并不是抽象方法）</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Runnable</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used</span></span><br><span class=\"line\"><span class=\"comment\">     * to create a thread, starting the thread causes the object's</span></span><br><span class=\"line\"><span class=\"comment\">     * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing</span></span><br><span class=\"line\"><span class=\"comment\">     * thread.</span></span><br><span class=\"line\"><span class=\"comment\">     * &lt;p&gt;</span></span><br><span class=\"line\"><span class=\"comment\">     * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may</span></span><br><span class=\"line\"><span class=\"comment\">     * take any action whatsoever.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@see</span>     java.lang.Thread#run()</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Java8中接口可以定义静态方法，直接通过类名调用，并且接口中可以通过default为抽象方法提供默认的实现。接口继承接口时，如果默认方法相同，则需要进行重写</p>\n<p>Java8推出的Lambda表达式只能针对函数式接口使用。</p>\n<h2 id=\"Lambda的语法\"><a href=\"#Lambda的语法\" class=\"headerlink\" title=\"Lambda的语法\"></a>Lambda的语法</h2><p>首先Lambda可以认为是一种特殊的匿名内部类，其次lambda只能用于函数式接口。</p>\n<p>lambda语法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">([形参列表，不带数据类型])-&gt; &#123;</span><br><span class=\"line\">    <span class=\"comment\">//执行语句</span></span><br><span class=\"line\">    [<span class=\"keyword\">return</span>..;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>要注意的点：</p>\n<ol>\n<li>如果形参列表是空的，只需要保留（）即可</li>\n<li>如果没有返回值。只需要在{}写执行语句即可</li>\n<li>如果接口的抽象方法只有一个形参，（）可以省略，只需要参数的名称即可</li>\n<li>如果执行语句只有一行，可以省略{}，但是如果有返回值时，情况特殊。</li>\n<li>如果函数式接口的方法有返回值，必须给定返回值，如果执行语句只有一句，还可以简写，即省去大括号和return以及最后的；号。</li>\n<li>形参列表的数据类型会自动推断，只需要参数名称。</li>\n</ol>\n<p>eg:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TestLambda</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">           TestLanmdaInterface1 t1 = <span class=\"keyword\">new</span> TestLanmdaInterface1() &#123;</span><br><span class=\"line\">                <span class=\"meta\">@Override</span></span><br><span class=\"line\">                <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">                     System.out.println(<span class=\"string\">\"使用匿名内部类\"</span>);</span><br><span class=\"line\"> </span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">           &#125;;</span><br><span class=\"line\">           <span class=\"comment\">//与上面的匿名内部类执行效果一样</span></span><br><span class=\"line\">           <span class=\"comment\">//右边的类型会自动根据左边的类型进行判断</span></span><br><span class=\"line\">           TestLanmdaInterface1 t2 = () -&gt; &#123;</span><br><span class=\"line\">                System.out.println(<span class=\"string\">\"使用lanbda\"</span>);</span><br><span class=\"line\">           &#125;;</span><br><span class=\"line\">           t1.test();</span><br><span class=\"line\">           t2.test();</span><br><span class=\"line\"> </span><br><span class=\"line\">           <span class=\"comment\">//如果执行语句只有一行，可以省略大括号</span></span><br><span class=\"line\">           TestLanmdaInterface1 t3 = () -&gt; System.out.println(<span class=\"string\">\"省略执行语句大括号，使用lanbda\"</span>);</span><br><span class=\"line\">           t3.test();</span><br><span class=\"line\"> </span><br><span class=\"line\">           TestLanmdaInterface2 t4 = (s) -&gt; System.out.println(<span class=\"string\">\"使用lanbda表达式，带1个参数，参数为：\"</span>+s);</span><br><span class=\"line\">           t4.test(<span class=\"string\">\"字符串参数1\"</span>);</span><br><span class=\"line\"> </span><br><span class=\"line\">           TestLanmdaInterface2 t5 = s -&gt; System.out.println(<span class=\"string\">\"使用lanbda表达式，只带1个参数，可省略参数的圆括号，参数为：\"</span>+s);</span><br><span class=\"line\">           t5.test(<span class=\"string\">\"字符串参数2\"</span>);</span><br><span class=\"line\"> </span><br><span class=\"line\">           TestLanmdaInterface3 t6 = (s,i) -&gt; System.out.println(<span class=\"string\">\"使用lanbda表达式，带两个参数，不可以省略圆括号，参数为：\"</span>+s+<span class=\"string\">\"  \"</span>+ i);</span><br><span class=\"line\">           t6.test(<span class=\"string\">\"字符串参数3\"</span>,<span class=\"number\">50</span>);</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">TestLanmdaInterface1</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"comment\">//不带参数的抽象方法</span></span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">TestLanmdaInterface2</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"comment\">//带参数的抽象方法</span></span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(String str)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">TestLanmdaInterface3</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"comment\">//带多个参数的抽象方法</span></span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(String str,<span class=\"keyword\">int</span> num)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">IDemo</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Demo</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">(IDemo c)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(c);</span><br><span class=\"line\">        c.doSomething();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Test</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Demo demo = <span class=\"keyword\">new</span> Demo();</span><br><span class=\"line\">        demo.doSomething(<span class=\"keyword\">new</span> IDemo() &#123;</span><br><span class=\"line\">            <span class=\"meta\">@Override</span></span><br><span class=\"line\">            <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">                System.out.println(<span class=\"string\">\"使用匿名内部类实现\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">        demo.doSomething(() -&gt; System.out.println(<span class=\"string\">\"使用lambda表达式实现\"</span>));</span><br><span class=\"line\">        <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">        demo.doSomething(() -&gt; &#123;</span></span><br><span class=\"line\"><span class=\"comment\">            System.out.println(\"使用lambda表达式实现\");</span></span><br><span class=\"line\"><span class=\"comment\">            System.out.println(\"使用lambda表达式实现\");</span></span><br><span class=\"line\"><span class=\"comment\">        &#125;);</span></span><br><span class=\"line\"><span class=\"comment\">        */</span></span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p>可以看出，lambda表达式和匿名内部类并不完全相同</p>\n<p>观察生成的class文件可以看出，lambda表达式并不会生成额外的.class文件，而匿名内部类会生成Test$1.class<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cn.lb.Test$<span class=\"number\">1</span>@<span class=\"number\">4554617</span>c</span><br><span class=\"line\">使用匿名内部类实现</span><br><span class=\"line\">cn.lb.Test$$Lambda$<span class=\"number\">1</span>/<span class=\"number\">1324119927</span>@<span class=\"number\">404</span>b9385</span><br><span class=\"line\">使用lambda表达式实现</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"函数式接口引用表达式\"><a href=\"#函数式接口引用表达式\" class=\"headerlink\" title=\"函数式接口引用表达式\"></a>函数式接口引用表达式</h2><ul>\n<li>引用实例方法：<br>  自动把调用方法的时候的参数，全部传给引用的方法</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;函数式接口&gt; &lt;变量名&gt; = &lt;实例&gt; :: &lt;实例方法名&gt;</span><br><span class=\"line\"><span class=\"comment\">//自动把实参传递给引用的实例方法</span></span><br><span class=\"line\">&lt;变量名&gt;.&lt;接口方法&gt;（[实参]）</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>引用类方法（静态方法）：<br>  自动把调用方法的时候的参数，全部传给引用的方法</p>\n</li>\n<li><p>引用类的实例方法：<br>  定义、调用接口方法的时候需要多一个参数，并且参数的类型必须和引用实例方法的类型必须一致，把第一个参数作为引用的实例，后面的每个参数全部传递给引用的方法。</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> &lt;函数式接口&gt; </span>&#123;</span><br><span class=\"line\">    &lt;返回值&gt; &lt;方法名&gt;(&lt;类名&gt;&lt;名称&gt; [,其它参数...])    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&lt;变量名&gt;.&lt;方法名&gt;（&lt;类名的实例&gt;[,其它参数]）</span><br></pre></td></tr></table></figure>\n<p>eg:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TestMethodRef</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        MethodRef r1 = (s) -&gt; System.out.println(s);</span><br><span class=\"line\">        r1.test(<span class=\"string\">\"普通方式\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//使用方法的引用：实例方法的引用</span></span><br><span class=\"line\">        <span class=\"comment\">//System.out是一个实例  out是PrintStream 类型，有println方法</span></span><br><span class=\"line\">        MethodRef r2 = System.out::println;</span><br><span class=\"line\">        r2.test(<span class=\"string\">\"方法引用\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//MethodRef1 r3 =(a)-&gt; Arrays.sort(a);</span></span><br><span class=\"line\">        <span class=\"comment\">//引用类方法</span></span><br><span class=\"line\">        MethodRef1 r3 = Arrays::sort;</span><br><span class=\"line\">        <span class=\"keyword\">int</span>[] a = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[]&#123;<span class=\"number\">4</span>, <span class=\"number\">12</span>, <span class=\"number\">23</span>, <span class=\"number\">1</span>, <span class=\"number\">3</span>&#125;;</span><br><span class=\"line\">        r3.test(a);</span><br><span class=\"line\">        <span class=\"comment\">//将排序后的数组输出</span></span><br><span class=\"line\">        r1.test(Arrays.toString(a));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//引用类的实例方法</span></span><br><span class=\"line\">        MethodRef2 r4 = PrintStream::println;</span><br><span class=\"line\">        <span class=\"comment\">//第二个之后的参数作为引用方法的参数</span></span><br><span class=\"line\">        r4.test(System.out, <span class=\"string\">\"第二个参数\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//引用构造器</span></span><br><span class=\"line\">        MethodRef3 r5 = String::<span class=\"keyword\">new</span>;</span><br><span class=\"line\">        String test = r5.test(<span class=\"keyword\">new</span> <span class=\"keyword\">char</span>[]&#123;<span class=\"string\">'测'</span>, <span class=\"string\">'试'</span>, <span class=\"string\">'构'</span>, <span class=\"string\">'造'</span>, <span class=\"string\">'器'</span>, <span class=\"string\">'引'</span>, <span class=\"string\">'用'</span>&#125;);</span><br><span class=\"line\">        System.out.println(test);</span><br><span class=\"line\">        <span class=\"comment\">//普通情况</span></span><br><span class=\"line\">        MethodRef3 r6 = (c) -&gt; &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> String(c);</span><br><span class=\"line\">        &#125;;</span><br><span class=\"line\">        String test2 = r6.test(<span class=\"keyword\">new</span> <span class=\"keyword\">char</span>[]&#123;<span class=\"string\">'测'</span>, <span class=\"string\">'试'</span>, <span class=\"string\">'构'</span>, <span class=\"string\">'造'</span>, <span class=\"string\">'器'</span>, <span class=\"string\">'引'</span>, <span class=\"string\">'用'</span>&#125;);</span><br><span class=\"line\">        System.out.println(test2);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MethodRef</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(String s)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MethodRef1</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(<span class=\"keyword\">int</span>[] arr)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MethodRef2</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(PrintStream out, String str)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//测试构造器引用</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MethodRef3</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\">String <span class=\"title\">test</span><span class=\"params\">(<span class=\"keyword\">char</span>[] chars)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://blog.csdn.net/zymx14/article/details/70175746\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zymx14/article/details/70175746</a></li>\n<li><a href=\"https://blog.csdn.net/kegaofei/article/details/80582356\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/kegaofei/article/details/80582356</a></li>\n<li><a href=\"https://edu.aliyun.com/lesson_1012_9096?spm=5176.10731542.0.0.xGlbkv#_9096\" target=\"_blank\" rel=\"noopener\">https://edu.aliyun.com/lesson_1012_9096?spm=5176.10731542.0.0.xGlbkv#_9096</a></li>\n<li><a href=\"http://www.importnew.com/27901.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/27901.html</a></li>\n<li><a href=\"http://www.importnew.com/10360.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/10360.html</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"Lambda、函数式接口、引用表达式\"><a href=\"#Lambda、函数式接口、引用表达式\" class=\"headerlink\" title=\"Lambda、函数式接口、引用表达式\"></a>Lambda、函数式接口、引用表达式</h1><h2 id=\"写在前面\"><a href=\"#写在前面\" class=\"headerlink\" title=\"写在前面\"></a>写在前面</h2><blockquote>\n<p>最近在学习Stream的api，发现Java推出的函数式接口、Lambda表达式、引用表达式等大都服务于Stream的api使用，但其实并不一定，所以收集整理了下关于相关特性的用法。<br>在这只会讲解下基本的用法，关于函数编程框架的详细解读，大家可以参考下这篇 <a href=\"http://www.importnew.com/27901.html\" title=\"Java8 函数式编程探秘\" target=\"_blank\" rel=\"noopener\">Java8 函数式编程探秘</a>，介绍的非常全面。</p>\n</blockquote>","more":"<h2 id=\"函数式接口\"><a href=\"#函数式接口\" class=\"headerlink\" title=\"函数式接口\"></a>函数式接口</h2><p>先讲一个注解 <strong><em>@FunctionalInterface</em></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Documented</span></span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class=\"line\"><span class=\"meta\">@Target</span>(ElementType.TYPE)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> FunctionalInterface &#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>@FunctionalInterface 注解要求接口有且只有一个抽象方法，JDK中有许多类用到该注解，比如 Runnable，它只有一个 Run 方法。（注：默认方法并不是抽象方法）</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">Runnable</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used</span></span><br><span class=\"line\"><span class=\"comment\">     * to create a thread, starting the thread causes the object's</span></span><br><span class=\"line\"><span class=\"comment\">     * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing</span></span><br><span class=\"line\"><span class=\"comment\">     * thread.</span></span><br><span class=\"line\"><span class=\"comment\">     * &lt;p&gt;</span></span><br><span class=\"line\"><span class=\"comment\">     * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may</span></span><br><span class=\"line\"><span class=\"comment\">     * take any action whatsoever.</span></span><br><span class=\"line\"><span class=\"comment\">     *</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@see</span>     java.lang.Thread#run()</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">abstract</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Java8中接口可以定义静态方法，直接通过类名调用，并且接口中可以通过default为抽象方法提供默认的实现。接口继承接口时，如果默认方法相同，则需要进行重写</p>\n<p>Java8推出的Lambda表达式只能针对函数式接口使用。</p>\n<h2 id=\"Lambda的语法\"><a href=\"#Lambda的语法\" class=\"headerlink\" title=\"Lambda的语法\"></a>Lambda的语法</h2><p>首先Lambda可以认为是一种特殊的匿名内部类，其次lambda只能用于函数式接口。</p>\n<p>lambda语法：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">([形参列表，不带数据类型])-&gt; &#123;</span><br><span class=\"line\">    <span class=\"comment\">//执行语句</span></span><br><span class=\"line\">    [<span class=\"keyword\">return</span>..;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>要注意的点：</p>\n<ol>\n<li>如果形参列表是空的，只需要保留（）即可</li>\n<li>如果没有返回值。只需要在{}写执行语句即可</li>\n<li>如果接口的抽象方法只有一个形参，（）可以省略，只需要参数的名称即可</li>\n<li>如果执行语句只有一行，可以省略{}，但是如果有返回值时，情况特殊。</li>\n<li>如果函数式接口的方法有返回值，必须给定返回值，如果执行语句只有一句，还可以简写，即省去大括号和return以及最后的；号。</li>\n<li>形参列表的数据类型会自动推断，只需要参数名称。</li>\n</ol>\n<p>eg:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TestLambda</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">           TestLanmdaInterface1 t1 = <span class=\"keyword\">new</span> TestLanmdaInterface1() &#123;</span><br><span class=\"line\">                <span class=\"meta\">@Override</span></span><br><span class=\"line\">                <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">                     System.out.println(<span class=\"string\">\"使用匿名内部类\"</span>);</span><br><span class=\"line\"> </span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">           &#125;;</span><br><span class=\"line\">           <span class=\"comment\">//与上面的匿名内部类执行效果一样</span></span><br><span class=\"line\">           <span class=\"comment\">//右边的类型会自动根据左边的类型进行判断</span></span><br><span class=\"line\">           TestLanmdaInterface1 t2 = () -&gt; &#123;</span><br><span class=\"line\">                System.out.println(<span class=\"string\">\"使用lanbda\"</span>);</span><br><span class=\"line\">           &#125;;</span><br><span class=\"line\">           t1.test();</span><br><span class=\"line\">           t2.test();</span><br><span class=\"line\"> </span><br><span class=\"line\">           <span class=\"comment\">//如果执行语句只有一行，可以省略大括号</span></span><br><span class=\"line\">           TestLanmdaInterface1 t3 = () -&gt; System.out.println(<span class=\"string\">\"省略执行语句大括号，使用lanbda\"</span>);</span><br><span class=\"line\">           t3.test();</span><br><span class=\"line\"> </span><br><span class=\"line\">           TestLanmdaInterface2 t4 = (s) -&gt; System.out.println(<span class=\"string\">\"使用lanbda表达式，带1个参数，参数为：\"</span>+s);</span><br><span class=\"line\">           t4.test(<span class=\"string\">\"字符串参数1\"</span>);</span><br><span class=\"line\"> </span><br><span class=\"line\">           TestLanmdaInterface2 t5 = s -&gt; System.out.println(<span class=\"string\">\"使用lanbda表达式，只带1个参数，可省略参数的圆括号，参数为：\"</span>+s);</span><br><span class=\"line\">           t5.test(<span class=\"string\">\"字符串参数2\"</span>);</span><br><span class=\"line\"> </span><br><span class=\"line\">           TestLanmdaInterface3 t6 = (s,i) -&gt; System.out.println(<span class=\"string\">\"使用lanbda表达式，带两个参数，不可以省略圆括号，参数为：\"</span>+s+<span class=\"string\">\"  \"</span>+ i);</span><br><span class=\"line\">           t6.test(<span class=\"string\">\"字符串参数3\"</span>,<span class=\"number\">50</span>);</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">TestLanmdaInterface1</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"comment\">//不带参数的抽象方法</span></span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">TestLanmdaInterface2</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"comment\">//带参数的抽象方法</span></span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(String str)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">TestLanmdaInterface3</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"comment\">//带多个参数的抽象方法</span></span><br><span class=\"line\">     <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(String str,<span class=\"keyword\">int</span> num)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@FunctionalInterface</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">IDemo</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Demo</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">(IDemo c)</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(c);</span><br><span class=\"line\">        c.doSomething();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Test</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        Demo demo = <span class=\"keyword\">new</span> Demo();</span><br><span class=\"line\">        demo.doSomething(<span class=\"keyword\">new</span> IDemo() &#123;</span><br><span class=\"line\">            <span class=\"meta\">@Override</span></span><br><span class=\"line\">            <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">                System.out.println(<span class=\"string\">\"使用匿名内部类实现\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">        demo.doSomething(() -&gt; System.out.println(<span class=\"string\">\"使用lambda表达式实现\"</span>));</span><br><span class=\"line\">        <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">        demo.doSomething(() -&gt; &#123;</span></span><br><span class=\"line\"><span class=\"comment\">            System.out.println(\"使用lambda表达式实现\");</span></span><br><span class=\"line\"><span class=\"comment\">            System.out.println(\"使用lambda表达式实现\");</span></span><br><span class=\"line\"><span class=\"comment\">        &#125;);</span></span><br><span class=\"line\"><span class=\"comment\">        */</span></span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<p>可以看出，lambda表达式和匿名内部类并不完全相同</p>\n<p>观察生成的class文件可以看出，lambda表达式并不会生成额外的.class文件，而匿名内部类会生成Test$1.class<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cn.lb.Test$<span class=\"number\">1</span>@<span class=\"number\">4554617</span>c</span><br><span class=\"line\">使用匿名内部类实现</span><br><span class=\"line\">cn.lb.Test$$Lambda$<span class=\"number\">1</span>/<span class=\"number\">1324119927</span>@<span class=\"number\">404</span>b9385</span><br><span class=\"line\">使用lambda表达式实现</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"函数式接口引用表达式\"><a href=\"#函数式接口引用表达式\" class=\"headerlink\" title=\"函数式接口引用表达式\"></a>函数式接口引用表达式</h2><ul>\n<li>引用实例方法：<br>  自动把调用方法的时候的参数，全部传给引用的方法</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;函数式接口&gt; &lt;变量名&gt; = &lt;实例&gt; :: &lt;实例方法名&gt;</span><br><span class=\"line\"><span class=\"comment\">//自动把实参传递给引用的实例方法</span></span><br><span class=\"line\">&lt;变量名&gt;.&lt;接口方法&gt;（[实参]）</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>引用类方法（静态方法）：<br>  自动把调用方法的时候的参数，全部传给引用的方法</p>\n</li>\n<li><p>引用类的实例方法：<br>  定义、调用接口方法的时候需要多一个参数，并且参数的类型必须和引用实例方法的类型必须一致，把第一个参数作为引用的实例，后面的每个参数全部传递给引用的方法。</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> &lt;函数式接口&gt; </span>&#123;</span><br><span class=\"line\">    &lt;返回值&gt; &lt;方法名&gt;(&lt;类名&gt;&lt;名称&gt; [,其它参数...])    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\">&lt;变量名&gt;.&lt;方法名&gt;（&lt;类名的实例&gt;[,其它参数]）</span><br></pre></td></tr></table></figure>\n<p>eg:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TestMethodRef</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        MethodRef r1 = (s) -&gt; System.out.println(s);</span><br><span class=\"line\">        r1.test(<span class=\"string\">\"普通方式\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//使用方法的引用：实例方法的引用</span></span><br><span class=\"line\">        <span class=\"comment\">//System.out是一个实例  out是PrintStream 类型，有println方法</span></span><br><span class=\"line\">        MethodRef r2 = System.out::println;</span><br><span class=\"line\">        r2.test(<span class=\"string\">\"方法引用\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//MethodRef1 r3 =(a)-&gt; Arrays.sort(a);</span></span><br><span class=\"line\">        <span class=\"comment\">//引用类方法</span></span><br><span class=\"line\">        MethodRef1 r3 = Arrays::sort;</span><br><span class=\"line\">        <span class=\"keyword\">int</span>[] a = <span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[]&#123;<span class=\"number\">4</span>, <span class=\"number\">12</span>, <span class=\"number\">23</span>, <span class=\"number\">1</span>, <span class=\"number\">3</span>&#125;;</span><br><span class=\"line\">        r3.test(a);</span><br><span class=\"line\">        <span class=\"comment\">//将排序后的数组输出</span></span><br><span class=\"line\">        r1.test(Arrays.toString(a));</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//引用类的实例方法</span></span><br><span class=\"line\">        MethodRef2 r4 = PrintStream::println;</span><br><span class=\"line\">        <span class=\"comment\">//第二个之后的参数作为引用方法的参数</span></span><br><span class=\"line\">        r4.test(System.out, <span class=\"string\">\"第二个参数\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">//引用构造器</span></span><br><span class=\"line\">        MethodRef3 r5 = String::<span class=\"keyword\">new</span>;</span><br><span class=\"line\">        String test = r5.test(<span class=\"keyword\">new</span> <span class=\"keyword\">char</span>[]&#123;<span class=\"string\">'测'</span>, <span class=\"string\">'试'</span>, <span class=\"string\">'构'</span>, <span class=\"string\">'造'</span>, <span class=\"string\">'器'</span>, <span class=\"string\">'引'</span>, <span class=\"string\">'用'</span>&#125;);</span><br><span class=\"line\">        System.out.println(test);</span><br><span class=\"line\">        <span class=\"comment\">//普通情况</span></span><br><span class=\"line\">        MethodRef3 r6 = (c) -&gt; &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> String(c);</span><br><span class=\"line\">        &#125;;</span><br><span class=\"line\">        String test2 = r6.test(<span class=\"keyword\">new</span> <span class=\"keyword\">char</span>[]&#123;<span class=\"string\">'测'</span>, <span class=\"string\">'试'</span>, <span class=\"string\">'构'</span>, <span class=\"string\">'造'</span>, <span class=\"string\">'器'</span>, <span class=\"string\">'引'</span>, <span class=\"string\">'用'</span>&#125;);</span><br><span class=\"line\">        System.out.println(test2);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MethodRef</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(String s)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MethodRef1</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(<span class=\"keyword\">int</span>[] arr)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MethodRef2</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">(PrintStream out, String str)</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//测试构造器引用</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">MethodRef3</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\">String <span class=\"title\">test</span><span class=\"params\">(<span class=\"keyword\">char</span>[] chars)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://blog.csdn.net/zymx14/article/details/70175746\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zymx14/article/details/70175746</a></li>\n<li><a href=\"https://blog.csdn.net/kegaofei/article/details/80582356\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/kegaofei/article/details/80582356</a></li>\n<li><a href=\"https://edu.aliyun.com/lesson_1012_9096?spm=5176.10731542.0.0.xGlbkv#_9096\" target=\"_blank\" rel=\"noopener\">https://edu.aliyun.com/lesson_1012_9096?spm=5176.10731542.0.0.xGlbkv#_9096</a></li>\n<li><a href=\"http://www.importnew.com/27901.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/27901.html</a></li>\n<li><a href=\"http://www.importnew.com/10360.html\" target=\"_blank\" rel=\"noopener\">http://www.importnew.com/10360.html</a></li>\n</ul>"},{"title":"load balancing","date":"2018-09-04T05:54:17.000Z","_content":"\n---\n## 什么是负载均衡？\n讲到负载均衡是什么，首先要讨论下负载均衡出现的背景。\n* CPU的发展单核心高频->多核心多线程技术\n* 单体架构->集群架构->分布式架构\n\n---\n## 关键字\n* 效率提升\n* 横向扩容（集群）  \n* 平衡、防止单体过载\n* 空间换时间\n\n---\n## 概念\n负载均衡（Load balancing）：在计算中，负载平衡改善了跨多个计算资源（例如计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器）的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间，并避免任何单个资源的过载。使用具有负载平衡而不是单个组件的多个组件可以通过冗余提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。\n\n将负载（工作任务）进行平衡、分摊到多个操作单元上进行执行。需要我们注意的是：它并不属于网络基础架构，而是属于一种网络优化设备。它是建立在现有的网络基础架构之上，给企业提供了更廉价更有效的扩展选择。\n\n个人总结：将负载进行平衡，将特定的业务(网络服务、网络流量等)分担给多个服务器或网络设备。\n\n<!-- more -->\n\n---\n## 为了解决的问题\n流量堵塞、效率缓慢、运行不畅，提高业务的处理能力，服务的高可用性。\n\n---\n## 硬件负载均衡&软件负载均衡\n硬件负载均衡不做讨论。列举一些产品：\n* F5 BIG-IP负载均衡器（LTM）\n* 思科\n* Radware的AppDirector系列\n* ...\n\n---\n## 网络七层协议\n1. 物理层 \n2. 数据链路层\n3. 网络层\n4. 传输层\n5. 会话层\n6. 表示层\n7. 应用层\n\n---\n## 负载均衡的场景\n### 浏览器发送请求后发生了什么？\n* DNS服务器，DNS本身是一个基于UDP协议的网络协议，查询IP地址信息。\n* 浏览器获得真正的IP、port、通过TCP协议发起网络访问\n* Web Server（协议处理、静态文件、动态内容）\n* 调用不同服务、不同接口等进行处理\n* 响应\n\n### 全局负载均衡系统（GSLB）\n全局负载均衡主要用于在多个区域拥有自己服务器的站点，为了使全球用户只以一个IP地址或域名就能访问到离自己最近的服务器，从而获得最快的访问速度。\n* 内容分发网络（CDN）\n* DNS轮询\n![DNS-photo](/image/loadbalancing/DNS.png)\n利用DNS处理域名解析请求的同时进行负载均衡是另一种常用的方案。在DNS服务器中配置多个A记录，如：xxx IN A 114.100.80.1、xxx IN A 114.100.80.2、xxx IN A 114.100.80.3.\n每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。\n\n* HTTP重定向\n\n### 服务器负载均衡系统（SLB）\n* 数据链路层负载均衡\n![LVS-photo](/image/loadbalancing/LVS.png)\n\n数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡。\n\n这种数据传输方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改目的的mac地址，通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一样，从而达到负载均衡，这种负载均衡方式又称为直接路由方式（DR）.\n\n在上图中，用户请求到达负载均衡服务器后，负载均衡服务器将请求数据的目的mac地址修改为真是WEB服务器的mac地址，并不修改数据包目标IP地址，因此数据可以正常到达目标WEB服务器，该服务器在处理完数据后可以经过网管服务器而不是负载均衡服务器直接到达用户浏览器。\n\n使用三角传输模式的链路层负载均衡是目前大型网站所使用的最广的一种负载均衡手段。在linux平台上最好的链路层负载均衡开源产品是LVS(linux virtual server)。\n\n* IP负载均衡（SNAT）\n![IP-photo](/image/loadbalancing/IP.png)\n\nIP负载均衡：即在网络层通过修改请求目标地址进行负载均衡。\n\n用户请求数据包到达负载均衡服务器后，负载均衡服务器在操作系统内核进行获取网络数据包，根据负载均衡算法计算得到一台真实的WEB服务器地址，然后将数据包的IP地址修改为真实的WEB服务器地址，不需要通过用户进程处理。真实的WEB服务器处理完毕后，相应数据包回到负载均衡服务器，负载均衡服务器再将数据包源地址修改为自身的IP地址发送给用户浏览器。\n\n这里的关键在于真实WEB服务器相应数据包如何返回给负载均衡服务器，一种是负载均衡服务器在修改目的IP地址的同时修改源地址，将数据包源地址改为自身的IP，即源地址转换（SNAT），另一种方案是将负载均衡服务器同时作为真实物理服务器的网关服务器，这样所有的数据都会到达负载均衡服务器。\n\nIP负载均衡在内核进程完成数据分发，较反向代理均衡有更好的处理性能。但由于所有请求响应的数据包都需要经过负载均衡服务器，因此负载均衡的网卡带宽成为系统的瓶颈。\n\n---\n\n## 常用的负载均衡\n* FW-F5-IHS-核心（三层）交换机-WAS\n![F5-photo](/image/loadbalancing/F5_ISH_WAS.png)\n* VIP-Nginx-Keepalived-webserver\n![Nginx-photo](/image/loadbalancing/Nginx-Keepalived.png)\n\n---\n\n### 服务底层负载均衡\n* 分布系统中服务的负载均衡，如SpringCloud Ribbon、Zookeeper。\n---\n\n## 网络分层中的负载均衡区别\n服务器负载均衡根据LB设备处理到的报文层次，分为四层服务器负载均衡和七层负载均衡。\n\n* 技术原理上的区别\n\n四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。\n以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP)，直接转发给该服务器。\nTCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。\n\n七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。\n以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。\n\n![layer4&7-photo](/image/loadbalancing/loadbalancing_layer4&7.jpeg)\n\n* 应用场景的需求\n\n七层应用负载的好处，是使得整个网络更\"智能化\", 例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术。\n将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，(例如Nginx或者Apache)上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。\n\n* 安全性\n\n是否真的可以提高安全性\n\n是否有足够的灵活度\n\n---\n## 正向代理&反向代理\n* 正向代理（forward proxy） ，一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并制定目标（原始服务器），然后代理向原始服务器转发请求并将获得的内容返回给客户端，客户端才能使用正向代理。我们平时说的代理就是指正向代理。 简单一点：A向C借钱，由于一些情况不能直接向C借钱，于是A想了一个办法，他让B去向C借钱，这样B就代替A向C借钱，A就得到了C的钱，C并不知道A的存在，B就充当了A的代理人的角色。 \n\n* 反向代理（Reverse Proxy），以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求的客户端，此时代理服务器对外表现为一个反向代理服务器。理解起来有些抽象，可以这么说：A向B借钱，B没有拿自己的钱，而是悄悄地向C借钱，拿到钱之后再交给A,A以为是B的钱，他并不知道C的存在。 \n---\n## 服务端负载均衡&客户端负载均衡\n---\n## 负载均衡服务\n* 四层：F5、LVS\n* 七层：Nginx、HAproxy\n* 协调：Keepalived\n---\n## 负载均衡云服务\n* 阿里SLB\n* Amazon ELB\n* Citrix ADC\n* 腾讯 CLB\n* Radware的AppDirector\n---\n## 负载均衡组件\n* zookeeper\n* spring-cloud-ribbon客户端负载均衡\n* spring-cloud-zuul实现反向代理和负载均衡\n---\n## 负载均衡策咯\n* 轮循(Round Robin) & 加权轮循(Weighted Round Robin)\n* 最少连接数(Least Connection)\n* 最少连接数慢启动时间(Least Connection Slow Start Time)\n* 基于代理的自适应负载均衡(Agent Based Adaptive Balancing)\n* 固定权重(Fixed Weighted)\n* 加权响应(Weighted Response)\n* 源IP哈希(Source IP Hash)\n\n---\n## 参考资料\n* Load Balancing (computing) WIKI：https://en.wikipedia.org/wiki/Load_balancing_(computing)\n* 四层/七层负载均衡区别：https://www.jianshu.com/p/fa937b8e6712\n* 软/硬件负载均衡产品知多少：https://www.cnblogs.com/lcword/p/5773296.html\n* 全局负载均衡与CDN网络简介：https://blog.csdn.net/u010340143/article/details/9062213\n* 大型网络-负载均衡架构：http://www.cnblogs.com/and/p/3366400.html\n* Nginx实现负载均衡+keepalived实现Nginx高可用：https://www.cnblogs.com/youzhibing/p/7327342.html\n* 正向代理&反向代理：https://blog.csdn.net/zt15732625878/article/details/78941268\n* 常见负载均衡算法：https://www.cnblogs.com/will-shun/archive/2017/09/22/7574644.html","source":"_posts/load-balancing.md","raw":"---\ntitle: load balancing\ndate: 2018-09-04 13:54:17\ntags: 负载均衡\ncategories: 其他\n---\n\n---\n## 什么是负载均衡？\n讲到负载均衡是什么，首先要讨论下负载均衡出现的背景。\n* CPU的发展单核心高频->多核心多线程技术\n* 单体架构->集群架构->分布式架构\n\n---\n## 关键字\n* 效率提升\n* 横向扩容（集群）  \n* 平衡、防止单体过载\n* 空间换时间\n\n---\n## 概念\n负载均衡（Load balancing）：在计算中，负载平衡改善了跨多个计算资源（例如计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器）的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间，并避免任何单个资源的过载。使用具有负载平衡而不是单个组件的多个组件可以通过冗余提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。\n\n将负载（工作任务）进行平衡、分摊到多个操作单元上进行执行。需要我们注意的是：它并不属于网络基础架构，而是属于一种网络优化设备。它是建立在现有的网络基础架构之上，给企业提供了更廉价更有效的扩展选择。\n\n个人总结：将负载进行平衡，将特定的业务(网络服务、网络流量等)分担给多个服务器或网络设备。\n\n<!-- more -->\n\n---\n## 为了解决的问题\n流量堵塞、效率缓慢、运行不畅，提高业务的处理能力，服务的高可用性。\n\n---\n## 硬件负载均衡&软件负载均衡\n硬件负载均衡不做讨论。列举一些产品：\n* F5 BIG-IP负载均衡器（LTM）\n* 思科\n* Radware的AppDirector系列\n* ...\n\n---\n## 网络七层协议\n1. 物理层 \n2. 数据链路层\n3. 网络层\n4. 传输层\n5. 会话层\n6. 表示层\n7. 应用层\n\n---\n## 负载均衡的场景\n### 浏览器发送请求后发生了什么？\n* DNS服务器，DNS本身是一个基于UDP协议的网络协议，查询IP地址信息。\n* 浏览器获得真正的IP、port、通过TCP协议发起网络访问\n* Web Server（协议处理、静态文件、动态内容）\n* 调用不同服务、不同接口等进行处理\n* 响应\n\n### 全局负载均衡系统（GSLB）\n全局负载均衡主要用于在多个区域拥有自己服务器的站点，为了使全球用户只以一个IP地址或域名就能访问到离自己最近的服务器，从而获得最快的访问速度。\n* 内容分发网络（CDN）\n* DNS轮询\n![DNS-photo](/image/loadbalancing/DNS.png)\n利用DNS处理域名解析请求的同时进行负载均衡是另一种常用的方案。在DNS服务器中配置多个A记录，如：xxx IN A 114.100.80.1、xxx IN A 114.100.80.2、xxx IN A 114.100.80.3.\n每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。\n\n* HTTP重定向\n\n### 服务器负载均衡系统（SLB）\n* 数据链路层负载均衡\n![LVS-photo](/image/loadbalancing/LVS.png)\n\n数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡。\n\n这种数据传输方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改目的的mac地址，通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一样，从而达到负载均衡，这种负载均衡方式又称为直接路由方式（DR）.\n\n在上图中，用户请求到达负载均衡服务器后，负载均衡服务器将请求数据的目的mac地址修改为真是WEB服务器的mac地址，并不修改数据包目标IP地址，因此数据可以正常到达目标WEB服务器，该服务器在处理完数据后可以经过网管服务器而不是负载均衡服务器直接到达用户浏览器。\n\n使用三角传输模式的链路层负载均衡是目前大型网站所使用的最广的一种负载均衡手段。在linux平台上最好的链路层负载均衡开源产品是LVS(linux virtual server)。\n\n* IP负载均衡（SNAT）\n![IP-photo](/image/loadbalancing/IP.png)\n\nIP负载均衡：即在网络层通过修改请求目标地址进行负载均衡。\n\n用户请求数据包到达负载均衡服务器后，负载均衡服务器在操作系统内核进行获取网络数据包，根据负载均衡算法计算得到一台真实的WEB服务器地址，然后将数据包的IP地址修改为真实的WEB服务器地址，不需要通过用户进程处理。真实的WEB服务器处理完毕后，相应数据包回到负载均衡服务器，负载均衡服务器再将数据包源地址修改为自身的IP地址发送给用户浏览器。\n\n这里的关键在于真实WEB服务器相应数据包如何返回给负载均衡服务器，一种是负载均衡服务器在修改目的IP地址的同时修改源地址，将数据包源地址改为自身的IP，即源地址转换（SNAT），另一种方案是将负载均衡服务器同时作为真实物理服务器的网关服务器，这样所有的数据都会到达负载均衡服务器。\n\nIP负载均衡在内核进程完成数据分发，较反向代理均衡有更好的处理性能。但由于所有请求响应的数据包都需要经过负载均衡服务器，因此负载均衡的网卡带宽成为系统的瓶颈。\n\n---\n\n## 常用的负载均衡\n* FW-F5-IHS-核心（三层）交换机-WAS\n![F5-photo](/image/loadbalancing/F5_ISH_WAS.png)\n* VIP-Nginx-Keepalived-webserver\n![Nginx-photo](/image/loadbalancing/Nginx-Keepalived.png)\n\n---\n\n### 服务底层负载均衡\n* 分布系统中服务的负载均衡，如SpringCloud Ribbon、Zookeeper。\n---\n\n## 网络分层中的负载均衡区别\n服务器负载均衡根据LB设备处理到的报文层次，分为四层服务器负载均衡和七层负载均衡。\n\n* 技术原理上的区别\n\n四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。\n以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP)，直接转发给该服务器。\nTCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。\n\n七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。\n以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。\n\n![layer4&7-photo](/image/loadbalancing/loadbalancing_layer4&7.jpeg)\n\n* 应用场景的需求\n\n七层应用负载的好处，是使得整个网络更\"智能化\", 例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术。\n将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，(例如Nginx或者Apache)上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。\n\n* 安全性\n\n是否真的可以提高安全性\n\n是否有足够的灵活度\n\n---\n## 正向代理&反向代理\n* 正向代理（forward proxy） ，一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并制定目标（原始服务器），然后代理向原始服务器转发请求并将获得的内容返回给客户端，客户端才能使用正向代理。我们平时说的代理就是指正向代理。 简单一点：A向C借钱，由于一些情况不能直接向C借钱，于是A想了一个办法，他让B去向C借钱，这样B就代替A向C借钱，A就得到了C的钱，C并不知道A的存在，B就充当了A的代理人的角色。 \n\n* 反向代理（Reverse Proxy），以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求的客户端，此时代理服务器对外表现为一个反向代理服务器。理解起来有些抽象，可以这么说：A向B借钱，B没有拿自己的钱，而是悄悄地向C借钱，拿到钱之后再交给A,A以为是B的钱，他并不知道C的存在。 \n---\n## 服务端负载均衡&客户端负载均衡\n---\n## 负载均衡服务\n* 四层：F5、LVS\n* 七层：Nginx、HAproxy\n* 协调：Keepalived\n---\n## 负载均衡云服务\n* 阿里SLB\n* Amazon ELB\n* Citrix ADC\n* 腾讯 CLB\n* Radware的AppDirector\n---\n## 负载均衡组件\n* zookeeper\n* spring-cloud-ribbon客户端负载均衡\n* spring-cloud-zuul实现反向代理和负载均衡\n---\n## 负载均衡策咯\n* 轮循(Round Robin) & 加权轮循(Weighted Round Robin)\n* 最少连接数(Least Connection)\n* 最少连接数慢启动时间(Least Connection Slow Start Time)\n* 基于代理的自适应负载均衡(Agent Based Adaptive Balancing)\n* 固定权重(Fixed Weighted)\n* 加权响应(Weighted Response)\n* 源IP哈希(Source IP Hash)\n\n---\n## 参考资料\n* Load Balancing (computing) WIKI：https://en.wikipedia.org/wiki/Load_balancing_(computing)\n* 四层/七层负载均衡区别：https://www.jianshu.com/p/fa937b8e6712\n* 软/硬件负载均衡产品知多少：https://www.cnblogs.com/lcword/p/5773296.html\n* 全局负载均衡与CDN网络简介：https://blog.csdn.net/u010340143/article/details/9062213\n* 大型网络-负载均衡架构：http://www.cnblogs.com/and/p/3366400.html\n* Nginx实现负载均衡+keepalived实现Nginx高可用：https://www.cnblogs.com/youzhibing/p/7327342.html\n* 正向代理&反向代理：https://blog.csdn.net/zt15732625878/article/details/78941268\n* 常见负载均衡算法：https://www.cnblogs.com/will-shun/archive/2017/09/22/7574644.html","slug":"load-balancing","published":1,"updated":"2019-08-26T07:56:46.829Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3t004cqotnmhgx0zrn","content":"<hr>\n<h2 id=\"什么是负载均衡？\"><a href=\"#什么是负载均衡？\" class=\"headerlink\" title=\"什么是负载均衡？\"></a>什么是负载均衡？</h2><p>讲到负载均衡是什么，首先要讨论下负载均衡出现的背景。</p>\n<ul>\n<li>CPU的发展单核心高频-&gt;多核心多线程技术</li>\n<li>单体架构-&gt;集群架构-&gt;分布式架构</li>\n</ul>\n<hr>\n<h2 id=\"关键字\"><a href=\"#关键字\" class=\"headerlink\" title=\"关键字\"></a>关键字</h2><ul>\n<li>效率提升</li>\n<li>横向扩容（集群）  </li>\n<li>平衡、防止单体过载</li>\n<li>空间换时间</li>\n</ul>\n<hr>\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><p>负载均衡（Load balancing）：在计算中，负载平衡改善了跨多个计算资源（例如计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器）的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间，并避免任何单个资源的过载。使用具有负载平衡而不是单个组件的多个组件可以通过冗余提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。</p>\n<p>将负载（工作任务）进行平衡、分摊到多个操作单元上进行执行。需要我们注意的是：它并不属于网络基础架构，而是属于一种网络优化设备。它是建立在现有的网络基础架构之上，给企业提供了更廉价更有效的扩展选择。</p>\n<p>个人总结：将负载进行平衡，将特定的业务(网络服务、网络流量等)分担给多个服务器或网络设备。</p>\n<a id=\"more\"></a>\n<hr>\n<h2 id=\"为了解决的问题\"><a href=\"#为了解决的问题\" class=\"headerlink\" title=\"为了解决的问题\"></a>为了解决的问题</h2><p>流量堵塞、效率缓慢、运行不畅，提高业务的处理能力，服务的高可用性。</p>\n<hr>\n<h2 id=\"硬件负载均衡-amp-软件负载均衡\"><a href=\"#硬件负载均衡-amp-软件负载均衡\" class=\"headerlink\" title=\"硬件负载均衡&amp;软件负载均衡\"></a>硬件负载均衡&amp;软件负载均衡</h2><p>硬件负载均衡不做讨论。列举一些产品：</p>\n<ul>\n<li>F5 BIG-IP负载均衡器（LTM）</li>\n<li>思科</li>\n<li>Radware的AppDirector系列</li>\n<li>…</li>\n</ul>\n<hr>\n<h2 id=\"网络七层协议\"><a href=\"#网络七层协议\" class=\"headerlink\" title=\"网络七层协议\"></a>网络七层协议</h2><ol>\n<li>物理层 </li>\n<li>数据链路层</li>\n<li>网络层</li>\n<li>传输层</li>\n<li>会话层</li>\n<li>表示层</li>\n<li>应用层</li>\n</ol>\n<hr>\n<h2 id=\"负载均衡的场景\"><a href=\"#负载均衡的场景\" class=\"headerlink\" title=\"负载均衡的场景\"></a>负载均衡的场景</h2><h3 id=\"浏览器发送请求后发生了什么？\"><a href=\"#浏览器发送请求后发生了什么？\" class=\"headerlink\" title=\"浏览器发送请求后发生了什么？\"></a>浏览器发送请求后发生了什么？</h3><ul>\n<li>DNS服务器，DNS本身是一个基于UDP协议的网络协议，查询IP地址信息。</li>\n<li>浏览器获得真正的IP、port、通过TCP协议发起网络访问</li>\n<li>Web Server（协议处理、静态文件、动态内容）</li>\n<li>调用不同服务、不同接口等进行处理</li>\n<li>响应</li>\n</ul>\n<h3 id=\"全局负载均衡系统（GSLB）\"><a href=\"#全局负载均衡系统（GSLB）\" class=\"headerlink\" title=\"全局负载均衡系统（GSLB）\"></a>全局负载均衡系统（GSLB）</h3><p>全局负载均衡主要用于在多个区域拥有自己服务器的站点，为了使全球用户只以一个IP地址或域名就能访问到离自己最近的服务器，从而获得最快的访问速度。</p>\n<ul>\n<li>内容分发网络（CDN）</li>\n<li><p>DNS轮询<br><img src=\"/image/loadbalancing/DNS.png\" alt=\"DNS-photo\"><br>利用DNS处理域名解析请求的同时进行负载均衡是另一种常用的方案。在DNS服务器中配置多个A记录，如：xxx IN A 114.100.80.1、xxx IN A 114.100.80.2、xxx IN A 114.100.80.3.<br>每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。</p>\n</li>\n<li><p>HTTP重定向</p>\n</li>\n</ul>\n<h3 id=\"服务器负载均衡系统（SLB）\"><a href=\"#服务器负载均衡系统（SLB）\" class=\"headerlink\" title=\"服务器负载均衡系统（SLB）\"></a>服务器负载均衡系统（SLB）</h3><ul>\n<li>数据链路层负载均衡<br><img src=\"/image/loadbalancing/LVS.png\" alt=\"LVS-photo\"></li>\n</ul>\n<p>数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡。</p>\n<p>这种数据传输方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改目的的mac地址，通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一样，从而达到负载均衡，这种负载均衡方式又称为直接路由方式（DR）.</p>\n<p>在上图中，用户请求到达负载均衡服务器后，负载均衡服务器将请求数据的目的mac地址修改为真是WEB服务器的mac地址，并不修改数据包目标IP地址，因此数据可以正常到达目标WEB服务器，该服务器在处理完数据后可以经过网管服务器而不是负载均衡服务器直接到达用户浏览器。</p>\n<p>使用三角传输模式的链路层负载均衡是目前大型网站所使用的最广的一种负载均衡手段。在linux平台上最好的链路层负载均衡开源产品是LVS(linux virtual server)。</p>\n<ul>\n<li>IP负载均衡（SNAT）<br><img src=\"/image/loadbalancing/IP.png\" alt=\"IP-photo\"></li>\n</ul>\n<p>IP负载均衡：即在网络层通过修改请求目标地址进行负载均衡。</p>\n<p>用户请求数据包到达负载均衡服务器后，负载均衡服务器在操作系统内核进行获取网络数据包，根据负载均衡算法计算得到一台真实的WEB服务器地址，然后将数据包的IP地址修改为真实的WEB服务器地址，不需要通过用户进程处理。真实的WEB服务器处理完毕后，相应数据包回到负载均衡服务器，负载均衡服务器再将数据包源地址修改为自身的IP地址发送给用户浏览器。</p>\n<p>这里的关键在于真实WEB服务器相应数据包如何返回给负载均衡服务器，一种是负载均衡服务器在修改目的IP地址的同时修改源地址，将数据包源地址改为自身的IP，即源地址转换（SNAT），另一种方案是将负载均衡服务器同时作为真实物理服务器的网关服务器，这样所有的数据都会到达负载均衡服务器。</p>\n<p>IP负载均衡在内核进程完成数据分发，较反向代理均衡有更好的处理性能。但由于所有请求响应的数据包都需要经过负载均衡服务器，因此负载均衡的网卡带宽成为系统的瓶颈。</p>\n<hr>\n<h2 id=\"常用的负载均衡\"><a href=\"#常用的负载均衡\" class=\"headerlink\" title=\"常用的负载均衡\"></a>常用的负载均衡</h2><ul>\n<li>FW-F5-IHS-核心（三层）交换机-WAS<br><img src=\"/image/loadbalancing/F5_ISH_WAS.png\" alt=\"F5-photo\"></li>\n<li>VIP-Nginx-Keepalived-webserver<br><img src=\"/image/loadbalancing/Nginx-Keepalived.png\" alt=\"Nginx-photo\"></li>\n</ul>\n<hr>\n<h3 id=\"服务底层负载均衡\"><a href=\"#服务底层负载均衡\" class=\"headerlink\" title=\"服务底层负载均衡\"></a>服务底层负载均衡</h3><ul>\n<li>分布系统中服务的负载均衡，如SpringCloud Ribbon、Zookeeper。</li>\n</ul>\n<hr>\n<h2 id=\"网络分层中的负载均衡区别\"><a href=\"#网络分层中的负载均衡区别\" class=\"headerlink\" title=\"网络分层中的负载均衡区别\"></a>网络分层中的负载均衡区别</h2><p>服务器负载均衡根据LB设备处理到的报文层次，分为四层服务器负载均衡和七层负载均衡。</p>\n<ul>\n<li>技术原理上的区别</li>\n</ul>\n<p>四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。<br>以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP)，直接转发给该服务器。<br>TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。</p>\n<p>七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。<br>以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。</p>\n<p><img src=\"/image/loadbalancing/loadbalancing_layer4&amp;7.jpeg\" alt=\"layer4&amp;7-photo\"></p>\n<ul>\n<li>应用场景的需求</li>\n</ul>\n<p>七层应用负载的好处，是使得整个网络更”智能化”, 例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术。<br>将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，(例如Nginx或者Apache)上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。</p>\n<ul>\n<li>安全性</li>\n</ul>\n<p>是否真的可以提高安全性</p>\n<p>是否有足够的灵活度</p>\n<hr>\n<h2 id=\"正向代理-amp-反向代理\"><a href=\"#正向代理-amp-反向代理\" class=\"headerlink\" title=\"正向代理&amp;反向代理\"></a>正向代理&amp;反向代理</h2><ul>\n<li><p>正向代理（forward proxy） ，一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并制定目标（原始服务器），然后代理向原始服务器转发请求并将获得的内容返回给客户端，客户端才能使用正向代理。我们平时说的代理就是指正向代理。 简单一点：A向C借钱，由于一些情况不能直接向C借钱，于是A想了一个办法，他让B去向C借钱，这样B就代替A向C借钱，A就得到了C的钱，C并不知道A的存在，B就充当了A的代理人的角色。 </p>\n</li>\n<li><p>反向代理（Reverse Proxy），以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求的客户端，此时代理服务器对外表现为一个反向代理服务器。理解起来有些抽象，可以这么说：A向B借钱，B没有拿自己的钱，而是悄悄地向C借钱，拿到钱之后再交给A,A以为是B的钱，他并不知道C的存在。 </p>\n</li>\n</ul>\n<hr>\n<h2 id=\"服务端负载均衡-amp-客户端负载均衡\"><a href=\"#服务端负载均衡-amp-客户端负载均衡\" class=\"headerlink\" title=\"服务端负载均衡&amp;客户端负载均衡\"></a>服务端负载均衡&amp;客户端负载均衡</h2><hr>\n<h2 id=\"负载均衡服务\"><a href=\"#负载均衡服务\" class=\"headerlink\" title=\"负载均衡服务\"></a>负载均衡服务</h2><ul>\n<li>四层：F5、LVS</li>\n<li>七层：Nginx、HAproxy</li>\n<li>协调：Keepalived</li>\n</ul>\n<hr>\n<h2 id=\"负载均衡云服务\"><a href=\"#负载均衡云服务\" class=\"headerlink\" title=\"负载均衡云服务\"></a>负载均衡云服务</h2><ul>\n<li>阿里SLB</li>\n<li>Amazon ELB</li>\n<li>Citrix ADC</li>\n<li>腾讯 CLB</li>\n<li>Radware的AppDirector</li>\n</ul>\n<hr>\n<h2 id=\"负载均衡组件\"><a href=\"#负载均衡组件\" class=\"headerlink\" title=\"负载均衡组件\"></a>负载均衡组件</h2><ul>\n<li>zookeeper</li>\n<li>spring-cloud-ribbon客户端负载均衡</li>\n<li>spring-cloud-zuul实现反向代理和负载均衡</li>\n</ul>\n<hr>\n<h2 id=\"负载均衡策咯\"><a href=\"#负载均衡策咯\" class=\"headerlink\" title=\"负载均衡策咯\"></a>负载均衡策咯</h2><ul>\n<li>轮循(Round Robin) &amp; 加权轮循(Weighted Round Robin)</li>\n<li>最少连接数(Least Connection)</li>\n<li>最少连接数慢启动时间(Least Connection Slow Start Time)</li>\n<li>基于代理的自适应负载均衡(Agent Based Adaptive Balancing)</li>\n<li>固定权重(Fixed Weighted)</li>\n<li>加权响应(Weighted Response)</li>\n<li>源IP哈希(Source IP Hash)</li>\n</ul>\n<hr>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>Load Balancing (computing) WIKI：<a href=\"https://en.wikipedia.org/wiki/Load_balancing_(computing)\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Load_balancing_(computing)</a></li>\n<li>四层/七层负载均衡区别：<a href=\"https://www.jianshu.com/p/fa937b8e6712\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/fa937b8e6712</a></li>\n<li>软/硬件负载均衡产品知多少：<a href=\"https://www.cnblogs.com/lcword/p/5773296.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lcword/p/5773296.html</a></li>\n<li>全局负载均衡与CDN网络简介：<a href=\"https://blog.csdn.net/u010340143/article/details/9062213\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u010340143/article/details/9062213</a></li>\n<li>大型网络-负载均衡架构：<a href=\"http://www.cnblogs.com/and/p/3366400.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/and/p/3366400.html</a></li>\n<li>Nginx实现负载均衡+keepalived实现Nginx高可用：<a href=\"https://www.cnblogs.com/youzhibing/p/7327342.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/youzhibing/p/7327342.html</a></li>\n<li>正向代理&amp;反向代理：<a href=\"https://blog.csdn.net/zt15732625878/article/details/78941268\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zt15732625878/article/details/78941268</a></li>\n<li>常见负载均衡算法：<a href=\"https://www.cnblogs.com/will-shun/archive/2017/09/22/7574644.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/will-shun/archive/2017/09/22/7574644.html</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<hr>\n<h2 id=\"什么是负载均衡？\"><a href=\"#什么是负载均衡？\" class=\"headerlink\" title=\"什么是负载均衡？\"></a>什么是负载均衡？</h2><p>讲到负载均衡是什么，首先要讨论下负载均衡出现的背景。</p>\n<ul>\n<li>CPU的发展单核心高频-&gt;多核心多线程技术</li>\n<li>单体架构-&gt;集群架构-&gt;分布式架构</li>\n</ul>\n<hr>\n<h2 id=\"关键字\"><a href=\"#关键字\" class=\"headerlink\" title=\"关键字\"></a>关键字</h2><ul>\n<li>效率提升</li>\n<li>横向扩容（集群）  </li>\n<li>平衡、防止单体过载</li>\n<li>空间换时间</li>\n</ul>\n<hr>\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><p>负载均衡（Load balancing）：在计算中，负载平衡改善了跨多个计算资源（例如计算机，计算机集群，网络链接，中央处理单元或磁盘驱动器）的工作负载分布。负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间，并避免任何单个资源的过载。使用具有负载平衡而不是单个组件的多个组件可以通过冗余提高可靠性和可用性。负载平衡通常涉及专用软件或硬件，例如多层交换机或域名系统服务器进程。</p>\n<p>将负载（工作任务）进行平衡、分摊到多个操作单元上进行执行。需要我们注意的是：它并不属于网络基础架构，而是属于一种网络优化设备。它是建立在现有的网络基础架构之上，给企业提供了更廉价更有效的扩展选择。</p>\n<p>个人总结：将负载进行平衡，将特定的业务(网络服务、网络流量等)分担给多个服务器或网络设备。</p>","more":"<hr>\n<h2 id=\"为了解决的问题\"><a href=\"#为了解决的问题\" class=\"headerlink\" title=\"为了解决的问题\"></a>为了解决的问题</h2><p>流量堵塞、效率缓慢、运行不畅，提高业务的处理能力，服务的高可用性。</p>\n<hr>\n<h2 id=\"硬件负载均衡-amp-软件负载均衡\"><a href=\"#硬件负载均衡-amp-软件负载均衡\" class=\"headerlink\" title=\"硬件负载均衡&amp;软件负载均衡\"></a>硬件负载均衡&amp;软件负载均衡</h2><p>硬件负载均衡不做讨论。列举一些产品：</p>\n<ul>\n<li>F5 BIG-IP负载均衡器（LTM）</li>\n<li>思科</li>\n<li>Radware的AppDirector系列</li>\n<li>…</li>\n</ul>\n<hr>\n<h2 id=\"网络七层协议\"><a href=\"#网络七层协议\" class=\"headerlink\" title=\"网络七层协议\"></a>网络七层协议</h2><ol>\n<li>物理层 </li>\n<li>数据链路层</li>\n<li>网络层</li>\n<li>传输层</li>\n<li>会话层</li>\n<li>表示层</li>\n<li>应用层</li>\n</ol>\n<hr>\n<h2 id=\"负载均衡的场景\"><a href=\"#负载均衡的场景\" class=\"headerlink\" title=\"负载均衡的场景\"></a>负载均衡的场景</h2><h3 id=\"浏览器发送请求后发生了什么？\"><a href=\"#浏览器发送请求后发生了什么？\" class=\"headerlink\" title=\"浏览器发送请求后发生了什么？\"></a>浏览器发送请求后发生了什么？</h3><ul>\n<li>DNS服务器，DNS本身是一个基于UDP协议的网络协议，查询IP地址信息。</li>\n<li>浏览器获得真正的IP、port、通过TCP协议发起网络访问</li>\n<li>Web Server（协议处理、静态文件、动态内容）</li>\n<li>调用不同服务、不同接口等进行处理</li>\n<li>响应</li>\n</ul>\n<h3 id=\"全局负载均衡系统（GSLB）\"><a href=\"#全局负载均衡系统（GSLB）\" class=\"headerlink\" title=\"全局负载均衡系统（GSLB）\"></a>全局负载均衡系统（GSLB）</h3><p>全局负载均衡主要用于在多个区域拥有自己服务器的站点，为了使全球用户只以一个IP地址或域名就能访问到离自己最近的服务器，从而获得最快的访问速度。</p>\n<ul>\n<li>内容分发网络（CDN）</li>\n<li><p>DNS轮询<br><img src=\"/image/loadbalancing/DNS.png\" alt=\"DNS-photo\"><br>利用DNS处理域名解析请求的同时进行负载均衡是另一种常用的方案。在DNS服务器中配置多个A记录，如：xxx IN A 114.100.80.1、xxx IN A 114.100.80.2、xxx IN A 114.100.80.3.<br>每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。</p>\n</li>\n<li><p>HTTP重定向</p>\n</li>\n</ul>\n<h3 id=\"服务器负载均衡系统（SLB）\"><a href=\"#服务器负载均衡系统（SLB）\" class=\"headerlink\" title=\"服务器负载均衡系统（SLB）\"></a>服务器负载均衡系统（SLB）</h3><ul>\n<li>数据链路层负载均衡<br><img src=\"/image/loadbalancing/LVS.png\" alt=\"LVS-photo\"></li>\n</ul>\n<p>数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡。</p>\n<p>这种数据传输方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改目的的mac地址，通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一样，从而达到负载均衡，这种负载均衡方式又称为直接路由方式（DR）.</p>\n<p>在上图中，用户请求到达负载均衡服务器后，负载均衡服务器将请求数据的目的mac地址修改为真是WEB服务器的mac地址，并不修改数据包目标IP地址，因此数据可以正常到达目标WEB服务器，该服务器在处理完数据后可以经过网管服务器而不是负载均衡服务器直接到达用户浏览器。</p>\n<p>使用三角传输模式的链路层负载均衡是目前大型网站所使用的最广的一种负载均衡手段。在linux平台上最好的链路层负载均衡开源产品是LVS(linux virtual server)。</p>\n<ul>\n<li>IP负载均衡（SNAT）<br><img src=\"/image/loadbalancing/IP.png\" alt=\"IP-photo\"></li>\n</ul>\n<p>IP负载均衡：即在网络层通过修改请求目标地址进行负载均衡。</p>\n<p>用户请求数据包到达负载均衡服务器后，负载均衡服务器在操作系统内核进行获取网络数据包，根据负载均衡算法计算得到一台真实的WEB服务器地址，然后将数据包的IP地址修改为真实的WEB服务器地址，不需要通过用户进程处理。真实的WEB服务器处理完毕后，相应数据包回到负载均衡服务器，负载均衡服务器再将数据包源地址修改为自身的IP地址发送给用户浏览器。</p>\n<p>这里的关键在于真实WEB服务器相应数据包如何返回给负载均衡服务器，一种是负载均衡服务器在修改目的IP地址的同时修改源地址，将数据包源地址改为自身的IP，即源地址转换（SNAT），另一种方案是将负载均衡服务器同时作为真实物理服务器的网关服务器，这样所有的数据都会到达负载均衡服务器。</p>\n<p>IP负载均衡在内核进程完成数据分发，较反向代理均衡有更好的处理性能。但由于所有请求响应的数据包都需要经过负载均衡服务器，因此负载均衡的网卡带宽成为系统的瓶颈。</p>\n<hr>\n<h2 id=\"常用的负载均衡\"><a href=\"#常用的负载均衡\" class=\"headerlink\" title=\"常用的负载均衡\"></a>常用的负载均衡</h2><ul>\n<li>FW-F5-IHS-核心（三层）交换机-WAS<br><img src=\"/image/loadbalancing/F5_ISH_WAS.png\" alt=\"F5-photo\"></li>\n<li>VIP-Nginx-Keepalived-webserver<br><img src=\"/image/loadbalancing/Nginx-Keepalived.png\" alt=\"Nginx-photo\"></li>\n</ul>\n<hr>\n<h3 id=\"服务底层负载均衡\"><a href=\"#服务底层负载均衡\" class=\"headerlink\" title=\"服务底层负载均衡\"></a>服务底层负载均衡</h3><ul>\n<li>分布系统中服务的负载均衡，如SpringCloud Ribbon、Zookeeper。</li>\n</ul>\n<hr>\n<h2 id=\"网络分层中的负载均衡区别\"><a href=\"#网络分层中的负载均衡区别\" class=\"headerlink\" title=\"网络分层中的负载均衡区别\"></a>网络分层中的负载均衡区别</h2><p>服务器负载均衡根据LB设备处理到的报文层次，分为四层服务器负载均衡和七层负载均衡。</p>\n<ul>\n<li>技术原理上的区别</li>\n</ul>\n<p>四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。<br>以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP)，直接转发给该服务器。<br>TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。</p>\n<p>七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。<br>以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。</p>\n<p><img src=\"/image/loadbalancing/loadbalancing_layer4&amp;7.jpeg\" alt=\"layer4&amp;7-photo\"></p>\n<ul>\n<li>应用场景的需求</li>\n</ul>\n<p>七层应用负载的好处，是使得整个网络更”智能化”, 例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术。<br>将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改，极大的提升了应用系统在网络层的灵活性。很多在后台，(例如Nginx或者Apache)上部署的功能可以前移到负载均衡设备上，例如客户请求中的Header重写，服务器响应中的关键字过滤或者内容插入等功能。</p>\n<ul>\n<li>安全性</li>\n</ul>\n<p>是否真的可以提高安全性</p>\n<p>是否有足够的灵活度</p>\n<hr>\n<h2 id=\"正向代理-amp-反向代理\"><a href=\"#正向代理-amp-反向代理\" class=\"headerlink\" title=\"正向代理&amp;反向代理\"></a>正向代理&amp;反向代理</h2><ul>\n<li><p>正向代理（forward proxy） ，一个位于客户端和原始服务器之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并制定目标（原始服务器），然后代理向原始服务器转发请求并将获得的内容返回给客户端，客户端才能使用正向代理。我们平时说的代理就是指正向代理。 简单一点：A向C借钱，由于一些情况不能直接向C借钱，于是A想了一个办法，他让B去向C借钱，这样B就代替A向C借钱，A就得到了C的钱，C并不知道A的存在，B就充当了A的代理人的角色。 </p>\n</li>\n<li><p>反向代理（Reverse Proxy），以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求的客户端，此时代理服务器对外表现为一个反向代理服务器。理解起来有些抽象，可以这么说：A向B借钱，B没有拿自己的钱，而是悄悄地向C借钱，拿到钱之后再交给A,A以为是B的钱，他并不知道C的存在。 </p>\n</li>\n</ul>\n<hr>\n<h2 id=\"服务端负载均衡-amp-客户端负载均衡\"><a href=\"#服务端负载均衡-amp-客户端负载均衡\" class=\"headerlink\" title=\"服务端负载均衡&amp;客户端负载均衡\"></a>服务端负载均衡&amp;客户端负载均衡</h2><hr>\n<h2 id=\"负载均衡服务\"><a href=\"#负载均衡服务\" class=\"headerlink\" title=\"负载均衡服务\"></a>负载均衡服务</h2><ul>\n<li>四层：F5、LVS</li>\n<li>七层：Nginx、HAproxy</li>\n<li>协调：Keepalived</li>\n</ul>\n<hr>\n<h2 id=\"负载均衡云服务\"><a href=\"#负载均衡云服务\" class=\"headerlink\" title=\"负载均衡云服务\"></a>负载均衡云服务</h2><ul>\n<li>阿里SLB</li>\n<li>Amazon ELB</li>\n<li>Citrix ADC</li>\n<li>腾讯 CLB</li>\n<li>Radware的AppDirector</li>\n</ul>\n<hr>\n<h2 id=\"负载均衡组件\"><a href=\"#负载均衡组件\" class=\"headerlink\" title=\"负载均衡组件\"></a>负载均衡组件</h2><ul>\n<li>zookeeper</li>\n<li>spring-cloud-ribbon客户端负载均衡</li>\n<li>spring-cloud-zuul实现反向代理和负载均衡</li>\n</ul>\n<hr>\n<h2 id=\"负载均衡策咯\"><a href=\"#负载均衡策咯\" class=\"headerlink\" title=\"负载均衡策咯\"></a>负载均衡策咯</h2><ul>\n<li>轮循(Round Robin) &amp; 加权轮循(Weighted Round Robin)</li>\n<li>最少连接数(Least Connection)</li>\n<li>最少连接数慢启动时间(Least Connection Slow Start Time)</li>\n<li>基于代理的自适应负载均衡(Agent Based Adaptive Balancing)</li>\n<li>固定权重(Fixed Weighted)</li>\n<li>加权响应(Weighted Response)</li>\n<li>源IP哈希(Source IP Hash)</li>\n</ul>\n<hr>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>Load Balancing (computing) WIKI：<a href=\"https://en.wikipedia.org/wiki/Load_balancing_(computing)\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Load_balancing_(computing)</a></li>\n<li>四层/七层负载均衡区别：<a href=\"https://www.jianshu.com/p/fa937b8e6712\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/fa937b8e6712</a></li>\n<li>软/硬件负载均衡产品知多少：<a href=\"https://www.cnblogs.com/lcword/p/5773296.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lcword/p/5773296.html</a></li>\n<li>全局负载均衡与CDN网络简介：<a href=\"https://blog.csdn.net/u010340143/article/details/9062213\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u010340143/article/details/9062213</a></li>\n<li>大型网络-负载均衡架构：<a href=\"http://www.cnblogs.com/and/p/3366400.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/and/p/3366400.html</a></li>\n<li>Nginx实现负载均衡+keepalived实现Nginx高可用：<a href=\"https://www.cnblogs.com/youzhibing/p/7327342.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/youzhibing/p/7327342.html</a></li>\n<li>正向代理&amp;反向代理：<a href=\"https://blog.csdn.net/zt15732625878/article/details/78941268\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zt15732625878/article/details/78941268</a></li>\n<li>常见负载均衡算法：<a href=\"https://www.cnblogs.com/will-shun/archive/2017/09/22/7574644.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/will-shun/archive/2017/09/22/7574644.html</a></li>\n</ul>"},{"title":"关于parallelStream并发安全的思考","date":"2019-04-26T10:00:00.000Z","_content":"\n今天工作中遇到了关于使用parallelStream导致的并发安全问题，使用三个ArrayList容器进行数据交集等处理时，由于数据较多，希望通过并行流提高处理效率，但没考虑过线程安全问题。\n\n解决的方法非常简单，正确的使用map、collect、reduce，或者使用线程安全容器、加锁即可。\n\n但其实是使用时没有仔细了解相关的使用知识导致应用出现问题。搜了下确实有很多相关资料，需要仔细了解相关API的使用才可以避免相关问题的出现。\n\n本文内容全部摘自其他博客等文章内容，具体地址在本文结尾。\n\n<!-- more -->\n\n## 背景\nJava8的stream接口极大地减少了for循环写法的复杂性，stream提供了map/reduce/collect等一系列聚合接口，还支持并发操作：parallelStream。\n\n在爬虫开发过程中，经常会遇到遍历一个很大的集合做重复的操作，这时候如果使用串行执行会相当耗时，因此一般会采用多线程来提速。Java8的paralleStream用fork/join框架提供了并发执行能力。但是如果使用不当，很容易陷入误区。\n\n## Java8的paralleStream是线程安全的吗\n先来两个简单的例子\n``` java\npublic class ParallelStreamTest {\n    private static final int COUNT = 1000;\n\n    public static void main(String[] args) {\n        List<RiderDto> orilist = new ArrayList<RiderDto>();\n        for (int i = 0; i < COUNT; i++) {\n            orilist.add(init());\n        }\n        final List<RiderDto> copeList = new ArrayList<RiderDto>();\n        orilist.parallelStream().forEach(rider -> {\n            RiderDto t = new RiderDto();\n            t.setId(rider.getId());\n            t.setCityId(rider.getCityId());\n            copeList.add(t);\n        });\n        System.out.println(\"orilist size:\" + orilist.size());\n        System.out.println(\"copeList size:\" + copeList.size());\n        System.out.println(\"compare copeList and list,result:\" + (copeList.size() == orilist.size()));\n    }\n\n    private static RiderDto init() {\n        RiderDto t = new RiderDto();\n        Random random = new Random();\n        t.setId(random.nextInt(2 ^ 20));\n        t.setCityId(random.nextInt(1000));\n        return t;\n    }\n\n    static class RiderDto implements Serializable {\n        private static final long serialVersionUID = 1;\n        private Integer cityId;\n        private Integer id;\n\n    }\n}\n```\n多次运行输出如下：\n``` java\norilist size:1000\ncopeList size:998\ncompare copeList and orilist,result:false\n\norilist size:1000\ncopeList size:981\ncompare copeList and orilist,result:false\n\norilist size:1000\ncopeList size:1000\ncompare copeList and orilist,result:true\n```\n``` java\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:598)\n\tat java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:677)\n\tat java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:735)\n\tat java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)\n\tat java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)\n\tat java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)\n\tat java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)\n\tat com.dianwoba.test.ParallelStreamTest.main(ParallelStreamTest.java:17)\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 244\n\tat java.util.ArrayList.add(ArrayList.java:459)\n\tat com.dianwoba.test.ParallelStreamTest.lambda$0(ParallelStreamTest.java:21)\n\tat java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)\n\tat java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)\n\tat java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)\n\tat java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)\n```\n\n在下面的代码中采用stream的forEach接口对1-10000进行遍历，分别插入到3个ArrayList中。其中对第一个list的插入采用串行遍历，第二个使用paralleStream，第三个使用paralleStream的同时用ReentryLock对插入列表操作进行同步：\n\n``` java\nprivate static List<Integer> list1 = new ArrayList<>();\nprivate static List<Integer> list2 = new ArrayList<>();\nprivate static List<Integer> list3 = new ArrayList<>();\nprivate static Lock lock = new ReentrantLock();\n\npublic static void main(String[] args) {\n    IntStream.range(0, 10000).forEach(list1::add);\n\n    IntStream.range(0, 10000).parallel().forEach(list2::add);\n\n    IntStream.range(0, 10000).forEach(i -> {\n    lock.lock();\n    try {\n        list3.add(i);\n    }finally {\n        lock.unlock();\n    }\n    });\n\n    System.out.println(\"串行执行的大小：\" + list1.size());\n    System.out.println(\"并行执行的大小：\" + list2.size());\n    System.out.println(\"加锁并行执行的大小：\" + list3.size());\n}\n```\n执行结果：\n``` java\n串行执行的大小：10000\n并行执行的大小：9595\n加锁并行执行的大小：10000\n```\n\nparallelStream是一个并行执行的流，其使用 fork/join （ForkJoinPool）并行方式来拆分任务和加速处理过程。研究parallelStream之前，搞清楚ForkJoinPool是很有必要的。\n\nForkJoinPool的核心是采用分治法的思想，将一个大任务拆分为若干互不依赖的子任务，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务。同时，为了最大限度地提高并行处理能力，采用了工作窃取算法来运行任务，也就是说当某个线程处理完自己工作队列中的任务后，尝试当其他线程的工作队列中窃取一个任务来执行，直到所有任务处理完毕。所以为了减少线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。\n\n到这里，我们知道parallelStream使用多线程并行处理数据，关于多线程，有个老生常谈的问题，线程安全。正如上面的分析，demo中list会被拆分为多个小任务，每个任务只负责处理一小部分数据，然后多线程并发地处理这些任务。问题就在于ArrayList不是线程安全的容器，并发调用add就会发生线程安全的问题。\n\n那么既然paralleStream不是线程安全的，是不是在其中的进行的非原子操作都要加锁呢？我在stackOverflow上找到了答案：\n* https://codereview.stackexchange.com/questions/60401/using-java-8-parallel-streams\n* https://stackoverflow.com/questions/22350288/parallel-streams-collectors-and-thread-safety\n\n在上面两个问题的解答中，证实paralleStream的forEach接口确实不能保证同步，同时也提出了解决方案：使用collect和reduce接口。\n* http://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html\n\n在Javadoc中也对stream的并发操作进行了相关介绍：\n``` java\nThe Collections Framework provides synchronization wrappers, which add automatic synchronization to an arbitrary collection, making it thread-safe.\n```\nCollections框架提供了同步的包装，使得其中的操作线程安全。\n\n所以下一步，来看看collect接口如何使用。\n\n## stream的collect接口\n闲话不多说直接上源码吧，Stream.java中的collect方法句柄：\n``` java\n<R, A> R collect(Collector<? super T, A, R> collector);\n```\n\n在该实现方法中，参数是一个Collector对象，可以使用Collectors类的静态方法构造Collector对象，比如Collectors.toList()，toSet(),toMap()，etc，这块很容易查到API故不细说了。\n\n除此之外，我们如果要在collect接口中做更多的事，就需要自定义实现Collector接口，需要实现以下方法：\n``` java\nSupplier<A> supplier();\nBiConsumer<A, T> accumulator();\nBinaryOperator<A> combiner();\nFunction<A, R> finisher();\nSet<Characteristics> characteristics();\n```\n要轻松理解这三个参数，要先知道fork/join是怎么运转的，一图以蔽之：\n\n![parallelStream_01](/image/parallelStream_01.png)\n\n简单地说就是大任务拆分成小任务，分别用不同线程去完成，然后把结果合并后返回。所以第一步是拆分，第二步是分开运算，第三步是合并。这三个步骤分别对应的就是Collector的supplier,accumulator和combiner。talk is cheap show me the code，下面用一个例子来说明：\n\n输入是一个10个整型数字的ArrayList，通过计算转换成double类型的Set，首先定义一个计算组件：\n\nCompute.java:\n``` java\npublic class Compute {\n    public Double compute(int num) {\n        return (double) (2 * num);\n    }\n}\n```\n接下来在Main.java中定义输入的类型为ArrayList的nums和类型为Set的输出结果result：\n``` java\nprivate List<Integer> nums = new ArrayList<>();\nprivate Set<Double> result = new HashSet<>();\n```\n定义转换list的run方法，实现Collector接口，调用内部类Container中的方法，其中characteristics()方法返回空set即可：\n``` java\npublic void run() {\n    // 填充原始数据，nums中填充0-9 10个数\n    IntStream.range(0, 10).forEach(nums::add);\n    //实现Collector接口\n    result = nums.stream().parallel().collect(new Collector<Integer, Container, Set<Double>>() {\n\n    @Override\n    public Supplier<Container> supplier() {\n        return Container::new;\n    }\n\n    @Override\n    public BiConsumer<Container, Integer> accumulator() {\n        return Container::accumulate;\n    }\n\n    @Override\n    public BinaryOperator<Container> combiner() {\n        return Container::combine;\n    }\n\n    @Override\n    public Function<Container, Set<Double>> finisher() {\n        return Container::getResult;\n    }\n\n    @Override\n    public Set<Characteristics> characteristics() {\n        // 固定写法\n        return Collections.emptySet();\n    }\n    });\n}\n```\n构造内部类Container，该类的作用是一个存放输入的容器，定义了三个方法：\n\n* accumulate方法对输入数据进行处理并存入本地的结果\n* combine方法将其他容器的结果合并到本地的结果中\n* getResult方法返回本地的结果\n\nContainer.java:\n``` java\nclass Container {\n    // 定义本地的result\n    public Set<Double> set;\n\n    public Container() {\n        this.set = new HashSet<>();\n    }\n\n    public Container accumulate(int num) {\n        this.set.add(compute.compute(num));\n        return this;\n    }\n\n    public Container combine(Container container) {\n        this.set.addAll(container.set);\n        return this;\n    }\n\n    public Set<Double> getResult() {\n        return this.set;\n    }\n}\n```\n在Main.java中编写测试方法：\n``` java\npublic static void main(String[] args) {\n    Main main = new Main();\n    main.run();\n    System.out.println(\"原始数据：\");\n    main.nums.forEach(i -> System.out.print(i + \" \"));\n    System.out.println(\"\\n\\ncollect方法加工后的数据：\");\n    main.result.forEach(i -> System.out.print(i + \" \"));\n}\n```\n输出：\n``` java\n原始数据：\n0 1 2 3 4 5 6 7 8 9 \n\ncollect方法加工后的数据：\n0.0 2.0 4.0 8.0 16.0 18.0 10.0 6.0 12.0 14.0 \n```\n我们将10个整型数值的list转成了10个double类型的set，至此验证成功～\n## 一言蔽之\n总结就是paralleStream里直接去修改变量是非线程安全的，但是采用collect和reduce操作就是满足线程安全的了。\n\n## 相关资料\n* https://www.infoq.cn/article/fork-join-introduction\n* https://blog.csdn.net/io_field/article/details/54971555\n* https://www.cnblogs.com/puyangsky/p/7608741.html\n* https://my.oschina.net/7001/blog/1475500","source":"_posts/parallelStream.md","raw":"---\ntitle: 关于parallelStream并发安全的思考\ndate: 2019-04-26 18:00:00\ntags: Java\ncategories: Java\n---\n\n今天工作中遇到了关于使用parallelStream导致的并发安全问题，使用三个ArrayList容器进行数据交集等处理时，由于数据较多，希望通过并行流提高处理效率，但没考虑过线程安全问题。\n\n解决的方法非常简单，正确的使用map、collect、reduce，或者使用线程安全容器、加锁即可。\n\n但其实是使用时没有仔细了解相关的使用知识导致应用出现问题。搜了下确实有很多相关资料，需要仔细了解相关API的使用才可以避免相关问题的出现。\n\n本文内容全部摘自其他博客等文章内容，具体地址在本文结尾。\n\n<!-- more -->\n\n## 背景\nJava8的stream接口极大地减少了for循环写法的复杂性，stream提供了map/reduce/collect等一系列聚合接口，还支持并发操作：parallelStream。\n\n在爬虫开发过程中，经常会遇到遍历一个很大的集合做重复的操作，这时候如果使用串行执行会相当耗时，因此一般会采用多线程来提速。Java8的paralleStream用fork/join框架提供了并发执行能力。但是如果使用不当，很容易陷入误区。\n\n## Java8的paralleStream是线程安全的吗\n先来两个简单的例子\n``` java\npublic class ParallelStreamTest {\n    private static final int COUNT = 1000;\n\n    public static void main(String[] args) {\n        List<RiderDto> orilist = new ArrayList<RiderDto>();\n        for (int i = 0; i < COUNT; i++) {\n            orilist.add(init());\n        }\n        final List<RiderDto> copeList = new ArrayList<RiderDto>();\n        orilist.parallelStream().forEach(rider -> {\n            RiderDto t = new RiderDto();\n            t.setId(rider.getId());\n            t.setCityId(rider.getCityId());\n            copeList.add(t);\n        });\n        System.out.println(\"orilist size:\" + orilist.size());\n        System.out.println(\"copeList size:\" + copeList.size());\n        System.out.println(\"compare copeList and list,result:\" + (copeList.size() == orilist.size()));\n    }\n\n    private static RiderDto init() {\n        RiderDto t = new RiderDto();\n        Random random = new Random();\n        t.setId(random.nextInt(2 ^ 20));\n        t.setCityId(random.nextInt(1000));\n        return t;\n    }\n\n    static class RiderDto implements Serializable {\n        private static final long serialVersionUID = 1;\n        private Integer cityId;\n        private Integer id;\n\n    }\n}\n```\n多次运行输出如下：\n``` java\norilist size:1000\ncopeList size:998\ncompare copeList and orilist,result:false\n\norilist size:1000\ncopeList size:981\ncompare copeList and orilist,result:false\n\norilist size:1000\ncopeList size:1000\ncompare copeList and orilist,result:true\n```\n``` java\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n\tat java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:598)\n\tat java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:677)\n\tat java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:735)\n\tat java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)\n\tat java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)\n\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)\n\tat java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)\n\tat java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)\n\tat com.dianwoba.test.ParallelStreamTest.main(ParallelStreamTest.java:17)\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 244\n\tat java.util.ArrayList.add(ArrayList.java:459)\n\tat com.dianwoba.test.ParallelStreamTest.lambda$0(ParallelStreamTest.java:21)\n\tat java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)\n\tat java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374)\n\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)\n\tat java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)\n\tat java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)\n\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)\n\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)\n\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)\n\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)\n```\n\n在下面的代码中采用stream的forEach接口对1-10000进行遍历，分别插入到3个ArrayList中。其中对第一个list的插入采用串行遍历，第二个使用paralleStream，第三个使用paralleStream的同时用ReentryLock对插入列表操作进行同步：\n\n``` java\nprivate static List<Integer> list1 = new ArrayList<>();\nprivate static List<Integer> list2 = new ArrayList<>();\nprivate static List<Integer> list3 = new ArrayList<>();\nprivate static Lock lock = new ReentrantLock();\n\npublic static void main(String[] args) {\n    IntStream.range(0, 10000).forEach(list1::add);\n\n    IntStream.range(0, 10000).parallel().forEach(list2::add);\n\n    IntStream.range(0, 10000).forEach(i -> {\n    lock.lock();\n    try {\n        list3.add(i);\n    }finally {\n        lock.unlock();\n    }\n    });\n\n    System.out.println(\"串行执行的大小：\" + list1.size());\n    System.out.println(\"并行执行的大小：\" + list2.size());\n    System.out.println(\"加锁并行执行的大小：\" + list3.size());\n}\n```\n执行结果：\n``` java\n串行执行的大小：10000\n并行执行的大小：9595\n加锁并行执行的大小：10000\n```\n\nparallelStream是一个并行执行的流，其使用 fork/join （ForkJoinPool）并行方式来拆分任务和加速处理过程。研究parallelStream之前，搞清楚ForkJoinPool是很有必要的。\n\nForkJoinPool的核心是采用分治法的思想，将一个大任务拆分为若干互不依赖的子任务，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务。同时，为了最大限度地提高并行处理能力，采用了工作窃取算法来运行任务，也就是说当某个线程处理完自己工作队列中的任务后，尝试当其他线程的工作队列中窃取一个任务来执行，直到所有任务处理完毕。所以为了减少线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。\n\n到这里，我们知道parallelStream使用多线程并行处理数据，关于多线程，有个老生常谈的问题，线程安全。正如上面的分析，demo中list会被拆分为多个小任务，每个任务只负责处理一小部分数据，然后多线程并发地处理这些任务。问题就在于ArrayList不是线程安全的容器，并发调用add就会发生线程安全的问题。\n\n那么既然paralleStream不是线程安全的，是不是在其中的进行的非原子操作都要加锁呢？我在stackOverflow上找到了答案：\n* https://codereview.stackexchange.com/questions/60401/using-java-8-parallel-streams\n* https://stackoverflow.com/questions/22350288/parallel-streams-collectors-and-thread-safety\n\n在上面两个问题的解答中，证实paralleStream的forEach接口确实不能保证同步，同时也提出了解决方案：使用collect和reduce接口。\n* http://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html\n\n在Javadoc中也对stream的并发操作进行了相关介绍：\n``` java\nThe Collections Framework provides synchronization wrappers, which add automatic synchronization to an arbitrary collection, making it thread-safe.\n```\nCollections框架提供了同步的包装，使得其中的操作线程安全。\n\n所以下一步，来看看collect接口如何使用。\n\n## stream的collect接口\n闲话不多说直接上源码吧，Stream.java中的collect方法句柄：\n``` java\n<R, A> R collect(Collector<? super T, A, R> collector);\n```\n\n在该实现方法中，参数是一个Collector对象，可以使用Collectors类的静态方法构造Collector对象，比如Collectors.toList()，toSet(),toMap()，etc，这块很容易查到API故不细说了。\n\n除此之外，我们如果要在collect接口中做更多的事，就需要自定义实现Collector接口，需要实现以下方法：\n``` java\nSupplier<A> supplier();\nBiConsumer<A, T> accumulator();\nBinaryOperator<A> combiner();\nFunction<A, R> finisher();\nSet<Characteristics> characteristics();\n```\n要轻松理解这三个参数，要先知道fork/join是怎么运转的，一图以蔽之：\n\n![parallelStream_01](/image/parallelStream_01.png)\n\n简单地说就是大任务拆分成小任务，分别用不同线程去完成，然后把结果合并后返回。所以第一步是拆分，第二步是分开运算，第三步是合并。这三个步骤分别对应的就是Collector的supplier,accumulator和combiner。talk is cheap show me the code，下面用一个例子来说明：\n\n输入是一个10个整型数字的ArrayList，通过计算转换成double类型的Set，首先定义一个计算组件：\n\nCompute.java:\n``` java\npublic class Compute {\n    public Double compute(int num) {\n        return (double) (2 * num);\n    }\n}\n```\n接下来在Main.java中定义输入的类型为ArrayList的nums和类型为Set的输出结果result：\n``` java\nprivate List<Integer> nums = new ArrayList<>();\nprivate Set<Double> result = new HashSet<>();\n```\n定义转换list的run方法，实现Collector接口，调用内部类Container中的方法，其中characteristics()方法返回空set即可：\n``` java\npublic void run() {\n    // 填充原始数据，nums中填充0-9 10个数\n    IntStream.range(0, 10).forEach(nums::add);\n    //实现Collector接口\n    result = nums.stream().parallel().collect(new Collector<Integer, Container, Set<Double>>() {\n\n    @Override\n    public Supplier<Container> supplier() {\n        return Container::new;\n    }\n\n    @Override\n    public BiConsumer<Container, Integer> accumulator() {\n        return Container::accumulate;\n    }\n\n    @Override\n    public BinaryOperator<Container> combiner() {\n        return Container::combine;\n    }\n\n    @Override\n    public Function<Container, Set<Double>> finisher() {\n        return Container::getResult;\n    }\n\n    @Override\n    public Set<Characteristics> characteristics() {\n        // 固定写法\n        return Collections.emptySet();\n    }\n    });\n}\n```\n构造内部类Container，该类的作用是一个存放输入的容器，定义了三个方法：\n\n* accumulate方法对输入数据进行处理并存入本地的结果\n* combine方法将其他容器的结果合并到本地的结果中\n* getResult方法返回本地的结果\n\nContainer.java:\n``` java\nclass Container {\n    // 定义本地的result\n    public Set<Double> set;\n\n    public Container() {\n        this.set = new HashSet<>();\n    }\n\n    public Container accumulate(int num) {\n        this.set.add(compute.compute(num));\n        return this;\n    }\n\n    public Container combine(Container container) {\n        this.set.addAll(container.set);\n        return this;\n    }\n\n    public Set<Double> getResult() {\n        return this.set;\n    }\n}\n```\n在Main.java中编写测试方法：\n``` java\npublic static void main(String[] args) {\n    Main main = new Main();\n    main.run();\n    System.out.println(\"原始数据：\");\n    main.nums.forEach(i -> System.out.print(i + \" \"));\n    System.out.println(\"\\n\\ncollect方法加工后的数据：\");\n    main.result.forEach(i -> System.out.print(i + \" \"));\n}\n```\n输出：\n``` java\n原始数据：\n0 1 2 3 4 5 6 7 8 9 \n\ncollect方法加工后的数据：\n0.0 2.0 4.0 8.0 16.0 18.0 10.0 6.0 12.0 14.0 \n```\n我们将10个整型数值的list转成了10个double类型的set，至此验证成功～\n## 一言蔽之\n总结就是paralleStream里直接去修改变量是非线程安全的，但是采用collect和reduce操作就是满足线程安全的了。\n\n## 相关资料\n* https://www.infoq.cn/article/fork-join-introduction\n* https://blog.csdn.net/io_field/article/details/54971555\n* https://www.cnblogs.com/puyangsky/p/7608741.html\n* https://my.oschina.net/7001/blog/1475500","slug":"parallelStream","published":1,"updated":"2019-08-26T07:52:45.157Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3v004fqotni7tv4a5k","content":"<p>今天工作中遇到了关于使用parallelStream导致的并发安全问题，使用三个ArrayList容器进行数据交集等处理时，由于数据较多，希望通过并行流提高处理效率，但没考虑过线程安全问题。</p>\n<p>解决的方法非常简单，正确的使用map、collect、reduce，或者使用线程安全容器、加锁即可。</p>\n<p>但其实是使用时没有仔细了解相关的使用知识导致应用出现问题。搜了下确实有很多相关资料，需要仔细了解相关API的使用才可以避免相关问题的出现。</p>\n<p>本文内容全部摘自其他博客等文章内容，具体地址在本文结尾。</p>\n<a id=\"more\"></a>\n<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>Java8的stream接口极大地减少了for循环写法的复杂性，stream提供了map/reduce/collect等一系列聚合接口，还支持并发操作：parallelStream。</p>\n<p>在爬虫开发过程中，经常会遇到遍历一个很大的集合做重复的操作，这时候如果使用串行执行会相当耗时，因此一般会采用多线程来提速。Java8的paralleStream用fork/join框架提供了并发执行能力。但是如果使用不当，很容易陷入误区。</p>\n<h2 id=\"Java8的paralleStream是线程安全的吗\"><a href=\"#Java8的paralleStream是线程安全的吗\" class=\"headerlink\" title=\"Java8的paralleStream是线程安全的吗\"></a>Java8的paralleStream是线程安全的吗</h2><p>先来两个简单的例子<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ParallelStreamTest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> COUNT = <span class=\"number\">1000</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        List&lt;RiderDto&gt; orilist = <span class=\"keyword\">new</span> ArrayList&lt;RiderDto&gt;();</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; COUNT; i++) &#123;</span><br><span class=\"line\">            orilist.add(init());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> List&lt;RiderDto&gt; copeList = <span class=\"keyword\">new</span> ArrayList&lt;RiderDto&gt;();</span><br><span class=\"line\">        orilist.parallelStream().forEach(rider -&gt; &#123;</span><br><span class=\"line\">            RiderDto t = <span class=\"keyword\">new</span> RiderDto();</span><br><span class=\"line\">            t.setId(rider.getId());</span><br><span class=\"line\">            t.setCityId(rider.getCityId());</span><br><span class=\"line\">            copeList.add(t);</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"orilist size:\"</span> + orilist.size());</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"copeList size:\"</span> + copeList.size());</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"compare copeList and list,result:\"</span> + (copeList.size() == orilist.size()));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> RiderDto <span class=\"title\">init</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        RiderDto t = <span class=\"keyword\">new</span> RiderDto();</span><br><span class=\"line\">        Random random = <span class=\"keyword\">new</span> Random();</span><br><span class=\"line\">        t.setId(random.nextInt(<span class=\"number\">2</span> ^ <span class=\"number\">20</span>));</span><br><span class=\"line\">        t.setCityId(random.nextInt(<span class=\"number\">1000</span>));</span><br><span class=\"line\">        <span class=\"keyword\">return</span> t;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RiderDto</span> <span class=\"keyword\">implements</span> <span class=\"title\">Serializable</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> serialVersionUID = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> Integer cityId;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> Integer id;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>多次运行输出如下：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">orilist size:<span class=\"number\">1000</span></span><br><span class=\"line\">copeList size:<span class=\"number\">998</span></span><br><span class=\"line\">compare copeList and orilist,result:<span class=\"keyword\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\">orilist size:<span class=\"number\">1000</span></span><br><span class=\"line\">copeList size:<span class=\"number\">981</span></span><br><span class=\"line\">compare copeList and orilist,result:<span class=\"keyword\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\">orilist size:<span class=\"number\">1000</span></span><br><span class=\"line\">copeList size:<span class=\"number\">1000</span></span><br><span class=\"line\">compare copeList and orilist,result:<span class=\"keyword\">true</span></span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Exception in thread <span class=\"string\">\"main\"</span> java.lang.ArrayIndexOutOfBoundsException</span><br><span class=\"line\">\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class=\"line\">\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:<span class=\"number\">62</span>)</span><br><span class=\"line\">\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:<span class=\"number\">45</span>)</span><br><span class=\"line\">\tat java.lang.reflect.Constructor.newInstance(Constructor.java:<span class=\"number\">423</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:<span class=\"number\">598</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:<span class=\"number\">677</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:<span class=\"number\">735</span>)</span><br><span class=\"line\">\tat java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:<span class=\"number\">160</span>)</span><br><span class=\"line\">\tat java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:<span class=\"number\">174</span>)</span><br><span class=\"line\">\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:<span class=\"number\">233</span>)</span><br><span class=\"line\">\tat java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:<span class=\"number\">418</span>)</span><br><span class=\"line\">\tat java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:<span class=\"number\">583</span>)</span><br><span class=\"line\">\tat com.dianwoba.test.ParallelStreamTest.main(ParallelStreamTest.java:<span class=\"number\">17</span>)</span><br><span class=\"line\">Caused by: java.lang.ArrayIndexOutOfBoundsException: <span class=\"number\">244</span></span><br><span class=\"line\">\tat java.util.ArrayList.add(ArrayList.java:<span class=\"number\">459</span>)</span><br><span class=\"line\">\tat com.dianwoba.test.ParallelStreamTest.lambda$<span class=\"number\">0</span>(ParallelStreamTest.java:<span class=\"number\">21</span>)</span><br><span class=\"line\">\tat java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:<span class=\"number\">184</span>)</span><br><span class=\"line\">\tat java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:<span class=\"number\">1374</span>)</span><br><span class=\"line\">\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:<span class=\"number\">481</span>)</span><br><span class=\"line\">\tat java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:<span class=\"number\">291</span>)</span><br><span class=\"line\">\tat java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:<span class=\"number\">731</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:<span class=\"number\">289</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:<span class=\"number\">1056</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:<span class=\"number\">1692</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:<span class=\"number\">157</span>)</span><br></pre></td></tr></table></figure>\n<p>在下面的代码中采用stream的forEach接口对1-10000进行遍历，分别插入到3个ArrayList中。其中对第一个list的插入采用串行遍历，第二个使用paralleStream，第三个使用paralleStream的同时用ReentryLock对插入列表操作进行同步：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> List&lt;Integer&gt; list1 = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> List&lt;Integer&gt; list2 = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> List&lt;Integer&gt; list3 = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Lock lock = <span class=\"keyword\">new</span> ReentrantLock();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    IntStream.range(<span class=\"number\">0</span>, <span class=\"number\">10000</span>).forEach(list1::add);</span><br><span class=\"line\"></span><br><span class=\"line\">    IntStream.range(<span class=\"number\">0</span>, <span class=\"number\">10000</span>).parallel().forEach(list2::add);</span><br><span class=\"line\"></span><br><span class=\"line\">    IntStream.range(<span class=\"number\">0</span>, <span class=\"number\">10000</span>).forEach(i -&gt; &#123;</span><br><span class=\"line\">    lock.lock();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        list3.add(i);</span><br><span class=\"line\">    &#125;<span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        lock.unlock();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"串行执行的大小：\"</span> + list1.size());</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"并行执行的大小：\"</span> + list2.size());</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"加锁并行执行的大小：\"</span> + list3.size());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行结果：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">串行执行的大小：<span class=\"number\">10000</span></span><br><span class=\"line\">并行执行的大小：<span class=\"number\">9595</span></span><br><span class=\"line\">加锁并行执行的大小：<span class=\"number\">10000</span></span><br></pre></td></tr></table></figure></p>\n<p>parallelStream是一个并行执行的流，其使用 fork/join （ForkJoinPool）并行方式来拆分任务和加速处理过程。研究parallelStream之前，搞清楚ForkJoinPool是很有必要的。</p>\n<p>ForkJoinPool的核心是采用分治法的思想，将一个大任务拆分为若干互不依赖的子任务，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务。同时，为了最大限度地提高并行处理能力，采用了工作窃取算法来运行任务，也就是说当某个线程处理完自己工作队列中的任务后，尝试当其他线程的工作队列中窃取一个任务来执行，直到所有任务处理完毕。所以为了减少线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。</p>\n<p>到这里，我们知道parallelStream使用多线程并行处理数据，关于多线程，有个老生常谈的问题，线程安全。正如上面的分析，demo中list会被拆分为多个小任务，每个任务只负责处理一小部分数据，然后多线程并发地处理这些任务。问题就在于ArrayList不是线程安全的容器，并发调用add就会发生线程安全的问题。</p>\n<p>那么既然paralleStream不是线程安全的，是不是在其中的进行的非原子操作都要加锁呢？我在stackOverflow上找到了答案：</p>\n<ul>\n<li><a href=\"https://codereview.stackexchange.com/questions/60401/using-java-8-parallel-streams\" target=\"_blank\" rel=\"noopener\">https://codereview.stackexchange.com/questions/60401/using-java-8-parallel-streams</a></li>\n<li><a href=\"https://stackoverflow.com/questions/22350288/parallel-streams-collectors-and-thread-safety\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/22350288/parallel-streams-collectors-and-thread-safety</a></li>\n</ul>\n<p>在上面两个问题的解答中，证实paralleStream的forEach接口确实不能保证同步，同时也提出了解决方案：使用collect和reduce接口。</p>\n<ul>\n<li><a href=\"http://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html\" target=\"_blank\" rel=\"noopener\">http://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html</a></li>\n</ul>\n<p>在Javadoc中也对stream的并发操作进行了相关介绍：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">The Collections Framework provides synchronization wrappers, which add automatic synchronization to an arbitrary collection, making it thread-safe.</span><br></pre></td></tr></table></figure></p>\n<p>Collections框架提供了同步的包装，使得其中的操作线程安全。</p>\n<p>所以下一步，来看看collect接口如何使用。</p>\n<h2 id=\"stream的collect接口\"><a href=\"#stream的collect接口\" class=\"headerlink\" title=\"stream的collect接口\"></a>stream的collect接口</h2><p>闲话不多说直接上源码吧，Stream.java中的collect方法句柄：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;R, A&gt; <span class=\"function\">R <span class=\"title\">collect</span><span class=\"params\">(Collector&lt;? <span class=\"keyword\">super</span> T, A, R&gt; collector)</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>在该实现方法中，参数是一个Collector对象，可以使用Collectors类的静态方法构造Collector对象，比如Collectors.toList()，toSet(),toMap()，etc，这块很容易查到API故不细说了。</p>\n<p>除此之外，我们如果要在collect接口中做更多的事，就需要自定义实现Collector接口，需要实现以下方法：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Supplier&lt;A&gt; <span class=\"title\">supplier</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"function\">BiConsumer&lt;A, T&gt; <span class=\"title\">accumulator</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"function\">BinaryOperator&lt;A&gt; <span class=\"title\">combiner</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"function\">Function&lt;A, R&gt; <span class=\"title\">finisher</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"function\">Set&lt;Characteristics&gt; <span class=\"title\">characteristics</span><span class=\"params\">()</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>要轻松理解这三个参数，要先知道fork/join是怎么运转的，一图以蔽之：</p>\n<p><img src=\"/image/parallelStream_01.png\" alt=\"parallelStream_01\"></p>\n<p>简单地说就是大任务拆分成小任务，分别用不同线程去完成，然后把结果合并后返回。所以第一步是拆分，第二步是分开运算，第三步是合并。这三个步骤分别对应的就是Collector的supplier,accumulator和combiner。talk is cheap show me the code，下面用一个例子来说明：</p>\n<p>输入是一个10个整型数字的ArrayList，通过计算转换成double类型的Set，首先定义一个计算组件：</p>\n<p>Compute.java:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Compute</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Double <span class=\"title\">compute</span><span class=\"params\">(<span class=\"keyword\">int</span> num)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (<span class=\"keyword\">double</span>) (<span class=\"number\">2</span> * num);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>接下来在Main.java中定义输入的类型为ArrayList的nums和类型为Set的输出结果result：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> List&lt;Integer&gt; nums = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">private</span> Set&lt;Double&gt; result = <span class=\"keyword\">new</span> HashSet&lt;&gt;();</span><br></pre></td></tr></table></figure></p>\n<p>定义转换list的run方法，实现Collector接口，调用内部类Container中的方法，其中characteristics()方法返回空set即可：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 填充原始数据，nums中填充0-9 10个数</span></span><br><span class=\"line\">    IntStream.range(<span class=\"number\">0</span>, <span class=\"number\">10</span>).forEach(nums::add);</span><br><span class=\"line\">    <span class=\"comment\">//实现Collector接口</span></span><br><span class=\"line\">    result = nums.stream().parallel().collect(<span class=\"keyword\">new</span> Collector&lt;Integer, Container, Set&lt;Double&gt;&gt;() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Supplier&lt;Container&gt; <span class=\"title\">supplier</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Container::<span class=\"keyword\">new</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> BiConsumer&lt;Container, Integer&gt; <span class=\"title\">accumulator</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Container::accumulate;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> BinaryOperator&lt;Container&gt; <span class=\"title\">combiner</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Container::combine;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> Function&lt;Container, Set&lt;Double&gt;&gt; finisher() &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Container::getResult;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Set&lt;Characteristics&gt; <span class=\"title\">characteristics</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 固定写法</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> Collections.emptySet();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>构造内部类Container，该类的作用是一个存放输入的容器，定义了三个方法：</p>\n<ul>\n<li>accumulate方法对输入数据进行处理并存入本地的结果</li>\n<li>combine方法将其他容器的结果合并到本地的结果中</li>\n<li>getResult方法返回本地的结果</li>\n</ul>\n<p>Container.java:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Container</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 定义本地的result</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> Set&lt;Double&gt; set;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Container</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.set = <span class=\"keyword\">new</span> HashSet&lt;&gt;();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Container <span class=\"title\">accumulate</span><span class=\"params\">(<span class=\"keyword\">int</span> num)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.set.add(compute.compute(num));</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Container <span class=\"title\">combine</span><span class=\"params\">(Container container)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.set.addAll(container.set);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Set&lt;Double&gt; <span class=\"title\">getResult</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.set;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>在Main.java中编写测试方法：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    Main main = <span class=\"keyword\">new</span> Main();</span><br><span class=\"line\">    main.run();</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"原始数据：\"</span>);</span><br><span class=\"line\">    main.nums.forEach(i -&gt; System.out.print(i + <span class=\"string\">\" \"</span>));</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"\\n\\ncollect方法加工后的数据：\"</span>);</span><br><span class=\"line\">    main.result.forEach(i -&gt; System.out.print(i + <span class=\"string\">\" \"</span>));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>输出：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原始数据：</span><br><span class=\"line\"><span class=\"number\">0</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span> <span class=\"number\">5</span> <span class=\"number\">6</span> <span class=\"number\">7</span> <span class=\"number\">8</span> <span class=\"number\">9</span> </span><br><span class=\"line\"></span><br><span class=\"line\">collect方法加工后的数据：</span><br><span class=\"line\"><span class=\"number\">0.0</span> <span class=\"number\">2.0</span> <span class=\"number\">4.0</span> <span class=\"number\">8.0</span> <span class=\"number\">16.0</span> <span class=\"number\">18.0</span> <span class=\"number\">10.0</span> <span class=\"number\">6.0</span> <span class=\"number\">12.0</span> <span class=\"number\">14.0</span></span><br></pre></td></tr></table></figure></p>\n<p>我们将10个整型数值的list转成了10个double类型的set，至此验证成功～</p>\n<h2 id=\"一言蔽之\"><a href=\"#一言蔽之\" class=\"headerlink\" title=\"一言蔽之\"></a>一言蔽之</h2><p>总结就是paralleStream里直接去修改变量是非线程安全的，但是采用collect和reduce操作就是满足线程安全的了。</p>\n<h2 id=\"相关资料\"><a href=\"#相关资料\" class=\"headerlink\" title=\"相关资料\"></a>相关资料</h2><ul>\n<li><a href=\"https://www.infoq.cn/article/fork-join-introduction\" target=\"_blank\" rel=\"noopener\">https://www.infoq.cn/article/fork-join-introduction</a></li>\n<li><a href=\"https://blog.csdn.net/io_field/article/details/54971555\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/io_field/article/details/54971555</a></li>\n<li><a href=\"https://www.cnblogs.com/puyangsky/p/7608741.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/puyangsky/p/7608741.html</a></li>\n<li><a href=\"https://my.oschina.net/7001/blog/1475500\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/7001/blog/1475500</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>今天工作中遇到了关于使用parallelStream导致的并发安全问题，使用三个ArrayList容器进行数据交集等处理时，由于数据较多，希望通过并行流提高处理效率，但没考虑过线程安全问题。</p>\n<p>解决的方法非常简单，正确的使用map、collect、reduce，或者使用线程安全容器、加锁即可。</p>\n<p>但其实是使用时没有仔细了解相关的使用知识导致应用出现问题。搜了下确实有很多相关资料，需要仔细了解相关API的使用才可以避免相关问题的出现。</p>\n<p>本文内容全部摘自其他博客等文章内容，具体地址在本文结尾。</p>","more":"<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>Java8的stream接口极大地减少了for循环写法的复杂性，stream提供了map/reduce/collect等一系列聚合接口，还支持并发操作：parallelStream。</p>\n<p>在爬虫开发过程中，经常会遇到遍历一个很大的集合做重复的操作，这时候如果使用串行执行会相当耗时，因此一般会采用多线程来提速。Java8的paralleStream用fork/join框架提供了并发执行能力。但是如果使用不当，很容易陷入误区。</p>\n<h2 id=\"Java8的paralleStream是线程安全的吗\"><a href=\"#Java8的paralleStream是线程安全的吗\" class=\"headerlink\" title=\"Java8的paralleStream是线程安全的吗\"></a>Java8的paralleStream是线程安全的吗</h2><p>先来两个简单的例子<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ParallelStreamTest</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> COUNT = <span class=\"number\">1000</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        List&lt;RiderDto&gt; orilist = <span class=\"keyword\">new</span> ArrayList&lt;RiderDto&gt;();</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; COUNT; i++) &#123;</span><br><span class=\"line\">            orilist.add(init());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> List&lt;RiderDto&gt; copeList = <span class=\"keyword\">new</span> ArrayList&lt;RiderDto&gt;();</span><br><span class=\"line\">        orilist.parallelStream().forEach(rider -&gt; &#123;</span><br><span class=\"line\">            RiderDto t = <span class=\"keyword\">new</span> RiderDto();</span><br><span class=\"line\">            t.setId(rider.getId());</span><br><span class=\"line\">            t.setCityId(rider.getCityId());</span><br><span class=\"line\">            copeList.add(t);</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"orilist size:\"</span> + orilist.size());</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"copeList size:\"</span> + copeList.size());</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"compare copeList and list,result:\"</span> + (copeList.size() == orilist.size()));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> RiderDto <span class=\"title\">init</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        RiderDto t = <span class=\"keyword\">new</span> RiderDto();</span><br><span class=\"line\">        Random random = <span class=\"keyword\">new</span> Random();</span><br><span class=\"line\">        t.setId(random.nextInt(<span class=\"number\">2</span> ^ <span class=\"number\">20</span>));</span><br><span class=\"line\">        t.setCityId(random.nextInt(<span class=\"number\">1000</span>));</span><br><span class=\"line\">        <span class=\"keyword\">return</span> t;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">static</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">RiderDto</span> <span class=\"keyword\">implements</span> <span class=\"title\">Serializable</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">long</span> serialVersionUID = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> Integer cityId;</span><br><span class=\"line\">        <span class=\"keyword\">private</span> Integer id;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>多次运行输出如下：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">orilist size:<span class=\"number\">1000</span></span><br><span class=\"line\">copeList size:<span class=\"number\">998</span></span><br><span class=\"line\">compare copeList and orilist,result:<span class=\"keyword\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\">orilist size:<span class=\"number\">1000</span></span><br><span class=\"line\">copeList size:<span class=\"number\">981</span></span><br><span class=\"line\">compare copeList and orilist,result:<span class=\"keyword\">false</span></span><br><span class=\"line\"></span><br><span class=\"line\">orilist size:<span class=\"number\">1000</span></span><br><span class=\"line\">copeList size:<span class=\"number\">1000</span></span><br><span class=\"line\">compare copeList and orilist,result:<span class=\"keyword\">true</span></span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Exception in thread <span class=\"string\">\"main\"</span> java.lang.ArrayIndexOutOfBoundsException</span><br><span class=\"line\">\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class=\"line\">\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:<span class=\"number\">62</span>)</span><br><span class=\"line\">\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:<span class=\"number\">45</span>)</span><br><span class=\"line\">\tat java.lang.reflect.Constructor.newInstance(Constructor.java:<span class=\"number\">423</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinTask.getThrowableException(ForkJoinTask.java:<span class=\"number\">598</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinTask.reportException(ForkJoinTask.java:<span class=\"number\">677</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:<span class=\"number\">735</span>)</span><br><span class=\"line\">\tat java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:<span class=\"number\">160</span>)</span><br><span class=\"line\">\tat java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:<span class=\"number\">174</span>)</span><br><span class=\"line\">\tat java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:<span class=\"number\">233</span>)</span><br><span class=\"line\">\tat java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:<span class=\"number\">418</span>)</span><br><span class=\"line\">\tat java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:<span class=\"number\">583</span>)</span><br><span class=\"line\">\tat com.dianwoba.test.ParallelStreamTest.main(ParallelStreamTest.java:<span class=\"number\">17</span>)</span><br><span class=\"line\">Caused by: java.lang.ArrayIndexOutOfBoundsException: <span class=\"number\">244</span></span><br><span class=\"line\">\tat java.util.ArrayList.add(ArrayList.java:<span class=\"number\">459</span>)</span><br><span class=\"line\">\tat com.dianwoba.test.ParallelStreamTest.lambda$<span class=\"number\">0</span>(ParallelStreamTest.java:<span class=\"number\">21</span>)</span><br><span class=\"line\">\tat java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:<span class=\"number\">184</span>)</span><br><span class=\"line\">\tat java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:<span class=\"number\">1374</span>)</span><br><span class=\"line\">\tat java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:<span class=\"number\">481</span>)</span><br><span class=\"line\">\tat java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:<span class=\"number\">291</span>)</span><br><span class=\"line\">\tat java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:<span class=\"number\">731</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:<span class=\"number\">289</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:<span class=\"number\">1056</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:<span class=\"number\">1692</span>)</span><br><span class=\"line\">\tat java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:<span class=\"number\">157</span>)</span><br></pre></td></tr></table></figure>\n<p>在下面的代码中采用stream的forEach接口对1-10000进行遍历，分别插入到3个ArrayList中。其中对第一个list的插入采用串行遍历，第二个使用paralleStream，第三个使用paralleStream的同时用ReentryLock对插入列表操作进行同步：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> List&lt;Integer&gt; list1 = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> List&lt;Integer&gt; list2 = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> List&lt;Integer&gt; list3 = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Lock lock = <span class=\"keyword\">new</span> ReentrantLock();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    IntStream.range(<span class=\"number\">0</span>, <span class=\"number\">10000</span>).forEach(list1::add);</span><br><span class=\"line\"></span><br><span class=\"line\">    IntStream.range(<span class=\"number\">0</span>, <span class=\"number\">10000</span>).parallel().forEach(list2::add);</span><br><span class=\"line\"></span><br><span class=\"line\">    IntStream.range(<span class=\"number\">0</span>, <span class=\"number\">10000</span>).forEach(i -&gt; &#123;</span><br><span class=\"line\">    lock.lock();</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        list3.add(i);</span><br><span class=\"line\">    &#125;<span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        lock.unlock();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"串行执行的大小：\"</span> + list1.size());</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"并行执行的大小：\"</span> + list2.size());</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"加锁并行执行的大小：\"</span> + list3.size());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>执行结果：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">串行执行的大小：<span class=\"number\">10000</span></span><br><span class=\"line\">并行执行的大小：<span class=\"number\">9595</span></span><br><span class=\"line\">加锁并行执行的大小：<span class=\"number\">10000</span></span><br></pre></td></tr></table></figure></p>\n<p>parallelStream是一个并行执行的流，其使用 fork/join （ForkJoinPool）并行方式来拆分任务和加速处理过程。研究parallelStream之前，搞清楚ForkJoinPool是很有必要的。</p>\n<p>ForkJoinPool的核心是采用分治法的思想，将一个大任务拆分为若干互不依赖的子任务，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务。同时，为了最大限度地提高并行处理能力，采用了工作窃取算法来运行任务，也就是说当某个线程处理完自己工作队列中的任务后，尝试当其他线程的工作队列中窃取一个任务来执行，直到所有任务处理完毕。所以为了减少线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。</p>\n<p>到这里，我们知道parallelStream使用多线程并行处理数据，关于多线程，有个老生常谈的问题，线程安全。正如上面的分析，demo中list会被拆分为多个小任务，每个任务只负责处理一小部分数据，然后多线程并发地处理这些任务。问题就在于ArrayList不是线程安全的容器，并发调用add就会发生线程安全的问题。</p>\n<p>那么既然paralleStream不是线程安全的，是不是在其中的进行的非原子操作都要加锁呢？我在stackOverflow上找到了答案：</p>\n<ul>\n<li><a href=\"https://codereview.stackexchange.com/questions/60401/using-java-8-parallel-streams\" target=\"_blank\" rel=\"noopener\">https://codereview.stackexchange.com/questions/60401/using-java-8-parallel-streams</a></li>\n<li><a href=\"https://stackoverflow.com/questions/22350288/parallel-streams-collectors-and-thread-safety\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/22350288/parallel-streams-collectors-and-thread-safety</a></li>\n</ul>\n<p>在上面两个问题的解答中，证实paralleStream的forEach接口确实不能保证同步，同时也提出了解决方案：使用collect和reduce接口。</p>\n<ul>\n<li><a href=\"http://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html\" target=\"_blank\" rel=\"noopener\">http://docs.oracle.com/javase/tutorial/collections/streams/parallelism.html</a></li>\n</ul>\n<p>在Javadoc中也对stream的并发操作进行了相关介绍：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">The Collections Framework provides synchronization wrappers, which add automatic synchronization to an arbitrary collection, making it thread-safe.</span><br></pre></td></tr></table></figure></p>\n<p>Collections框架提供了同步的包装，使得其中的操作线程安全。</p>\n<p>所以下一步，来看看collect接口如何使用。</p>\n<h2 id=\"stream的collect接口\"><a href=\"#stream的collect接口\" class=\"headerlink\" title=\"stream的collect接口\"></a>stream的collect接口</h2><p>闲话不多说直接上源码吧，Stream.java中的collect方法句柄：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;R, A&gt; <span class=\"function\">R <span class=\"title\">collect</span><span class=\"params\">(Collector&lt;? <span class=\"keyword\">super</span> T, A, R&gt; collector)</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>在该实现方法中，参数是一个Collector对象，可以使用Collectors类的静态方法构造Collector对象，比如Collectors.toList()，toSet(),toMap()，etc，这块很容易查到API故不细说了。</p>\n<p>除此之外，我们如果要在collect接口中做更多的事，就需要自定义实现Collector接口，需要实现以下方法：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">Supplier&lt;A&gt; <span class=\"title\">supplier</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"function\">BiConsumer&lt;A, T&gt; <span class=\"title\">accumulator</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"function\">BinaryOperator&lt;A&gt; <span class=\"title\">combiner</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"function\">Function&lt;A, R&gt; <span class=\"title\">finisher</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\"><span class=\"function\">Set&lt;Characteristics&gt; <span class=\"title\">characteristics</span><span class=\"params\">()</span></span>;</span><br></pre></td></tr></table></figure></p>\n<p>要轻松理解这三个参数，要先知道fork/join是怎么运转的，一图以蔽之：</p>\n<p><img src=\"/image/parallelStream_01.png\" alt=\"parallelStream_01\"></p>\n<p>简单地说就是大任务拆分成小任务，分别用不同线程去完成，然后把结果合并后返回。所以第一步是拆分，第二步是分开运算，第三步是合并。这三个步骤分别对应的就是Collector的supplier,accumulator和combiner。talk is cheap show me the code，下面用一个例子来说明：</p>\n<p>输入是一个10个整型数字的ArrayList，通过计算转换成double类型的Set，首先定义一个计算组件：</p>\n<p>Compute.java:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Compute</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Double <span class=\"title\">compute</span><span class=\"params\">(<span class=\"keyword\">int</span> num)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (<span class=\"keyword\">double</span>) (<span class=\"number\">2</span> * num);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>接下来在Main.java中定义输入的类型为ArrayList的nums和类型为Set的输出结果result：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> List&lt;Integer&gt; nums = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">private</span> Set&lt;Double&gt; result = <span class=\"keyword\">new</span> HashSet&lt;&gt;();</span><br></pre></td></tr></table></figure></p>\n<p>定义转换list的run方法，实现Collector接口，调用内部类Container中的方法，其中characteristics()方法返回空set即可：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 填充原始数据，nums中填充0-9 10个数</span></span><br><span class=\"line\">    IntStream.range(<span class=\"number\">0</span>, <span class=\"number\">10</span>).forEach(nums::add);</span><br><span class=\"line\">    <span class=\"comment\">//实现Collector接口</span></span><br><span class=\"line\">    result = nums.stream().parallel().collect(<span class=\"keyword\">new</span> Collector&lt;Integer, Container, Set&lt;Double&gt;&gt;() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Supplier&lt;Container&gt; <span class=\"title\">supplier</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Container::<span class=\"keyword\">new</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> BiConsumer&lt;Container, Integer&gt; <span class=\"title\">accumulator</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Container::accumulate;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> BinaryOperator&lt;Container&gt; <span class=\"title\">combiner</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Container::combine;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> Function&lt;Container, Set&lt;Double&gt;&gt; finisher() &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Container::getResult;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Set&lt;Characteristics&gt; <span class=\"title\">characteristics</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 固定写法</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> Collections.emptySet();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>构造内部类Container，该类的作用是一个存放输入的容器，定义了三个方法：</p>\n<ul>\n<li>accumulate方法对输入数据进行处理并存入本地的结果</li>\n<li>combine方法将其他容器的结果合并到本地的结果中</li>\n<li>getResult方法返回本地的结果</li>\n</ul>\n<p>Container.java:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Container</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 定义本地的result</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> Set&lt;Double&gt; set;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Container</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.set = <span class=\"keyword\">new</span> HashSet&lt;&gt;();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Container <span class=\"title\">accumulate</span><span class=\"params\">(<span class=\"keyword\">int</span> num)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.set.add(compute.compute(num));</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Container <span class=\"title\">combine</span><span class=\"params\">(Container container)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.set.addAll(container.set);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Set&lt;Double&gt; <span class=\"title\">getResult</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">this</span>.set;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>在Main.java中编写测试方法：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    Main main = <span class=\"keyword\">new</span> Main();</span><br><span class=\"line\">    main.run();</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"原始数据：\"</span>);</span><br><span class=\"line\">    main.nums.forEach(i -&gt; System.out.print(i + <span class=\"string\">\" \"</span>));</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"\\n\\ncollect方法加工后的数据：\"</span>);</span><br><span class=\"line\">    main.result.forEach(i -&gt; System.out.print(i + <span class=\"string\">\" \"</span>));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>输出：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">原始数据：</span><br><span class=\"line\"><span class=\"number\">0</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span> <span class=\"number\">5</span> <span class=\"number\">6</span> <span class=\"number\">7</span> <span class=\"number\">8</span> <span class=\"number\">9</span> </span><br><span class=\"line\"></span><br><span class=\"line\">collect方法加工后的数据：</span><br><span class=\"line\"><span class=\"number\">0.0</span> <span class=\"number\">2.0</span> <span class=\"number\">4.0</span> <span class=\"number\">8.0</span> <span class=\"number\">16.0</span> <span class=\"number\">18.0</span> <span class=\"number\">10.0</span> <span class=\"number\">6.0</span> <span class=\"number\">12.0</span> <span class=\"number\">14.0</span></span><br></pre></td></tr></table></figure></p>\n<p>我们将10个整型数值的list转成了10个double类型的set，至此验证成功～</p>\n<h2 id=\"一言蔽之\"><a href=\"#一言蔽之\" class=\"headerlink\" title=\"一言蔽之\"></a>一言蔽之</h2><p>总结就是paralleStream里直接去修改变量是非线程安全的，但是采用collect和reduce操作就是满足线程安全的了。</p>\n<h2 id=\"相关资料\"><a href=\"#相关资料\" class=\"headerlink\" title=\"相关资料\"></a>相关资料</h2><ul>\n<li><a href=\"https://www.infoq.cn/article/fork-join-introduction\" target=\"_blank\" rel=\"noopener\">https://www.infoq.cn/article/fork-join-introduction</a></li>\n<li><a href=\"https://blog.csdn.net/io_field/article/details/54971555\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/io_field/article/details/54971555</a></li>\n<li><a href=\"https://www.cnblogs.com/puyangsky/p/7608741.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/puyangsky/p/7608741.html</a></li>\n<li><a href=\"https://my.oschina.net/7001/blog/1475500\" target=\"_blank\" rel=\"noopener\">https://my.oschina.net/7001/blog/1475500</a></li>\n</ul>"},{"title":"MySQL存储结构和性能优化","date":"2020-01-15T02:00:00.000Z","_content":"\n记录下学习MySQL存储结构以及相关性能优化的基础知识\n<!-- more -->\n\n# btree、b+tree区别\n## btree\n\n![mysql01-photo](/image/mysql/btree.png)\n\n## b+tree\n\n![mysql02-photo](/image/mysql/b+tree.png)\n\n# InnoDB、MyISAM区别\n## MyISAM\n\n![mysql03-photo](/image/mysql/mysql_myISAM.png)\n\n## InnoDB\n\n![mysql04-photo](/image/mysql/mysql_InnoDB.png)\n\n## 对比表格\n对比内容 | MyISAM | Innodb |\n-- | -- | -- |\n存储结构 | 三个文件存储：firm（表定义文件）、myd（数据文件）、myi（索引文件） | 两个文件存储：firm（表定义文件）、idb（数据、索引文件）\n外键 | 不支持 | 支持 |\n事务 | 不支持 | 支持 |\n锁支持 | 表级锁 | 表、行级锁 |\n哈希索引 | 不支持 | 支持 |\n全文索引 | 支持 | 不支持 |\n记录存储结构 | 按记录插入顺序保存 | 按主键有序保存 |\n索引实现方式 | 聚簇索引，堆表 | 非聚簇索引，是索引组织表 |\n叶子节点根保存内容 | 行数据地址 | 具体的行数据 |\n\n# explain \n## type\n- ALL 扫描全表数据\n- index 遍历索引\n- range 索引范围查找\n- index_subquery 在子查询中使用 ref\n- unique_subquery 在子查询中使用 eq_ref\n- ref_or_null 对Null进行索引的优化的 ref\n- fulltext 使用全文索引\n- ref 使用非唯一索引查找数据\n- eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。\n\n## extra部分重要解释\n- Using index：查询的列被索引覆盖，并且where筛选条件是索引的前导列，是性能高的表现。一般是使用了覆盖索引(索引包含了所有查询的字段)。对于innodb来说，如果是辅助索引性能会有不少提高。\n- Using where Using index：查询的列被索引覆盖，并且where筛选条件是索引列之一但是不是索引的前导列，意味着无法直接通过索引查找来查询到符合条件的数据\n- Using index condition：与Using where类似，查询的列不完全被索引覆盖，where条件中是一个前导列的范围；\n- Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。\n    例如 distinct、group by、order by但列未创建索引等情况\n\n- Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。\n\n# 索引优化简单总结\n1. 全值匹配\n2. 最佳左前缀法则\n3. 不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描\n4. 存储引擎不能使用索引中范围条件右边的列\n5. 尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少select *语句\n6. mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描\n7. is null,is not null 也无法使用索引\n8. like以通配符开头（'$abc...'）mysql索引失效会变成全表扫描操作\n    问题：解决like'%字符串%'索引不被使用的方法？\n    - 使用覆盖索引，查询字段必须是建立覆盖索引字段\n    - 当覆盖索引指向的字段是varchar(380)及380以上的字段时，覆盖索引会失效\n\n9. 字符串不加单引号索引失效\n10. 少用or或in,非主键索引会失效，主键索引有时会生效,用它连接时很多情况下索引会失效\n\n![mysql05-photo](/image/mysql/mysql_index.png)\n\n## in和exists\nmysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。\n1. 如果查询的两个表大小相当，那么用in和exists差别不大。\n2. 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。\n3. not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。\n\n## 总结\n- MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。\n- order by满足两种情况会使用Using index。\n    - .order by语句使用索引最左前列。\n    - .使用where子句与order by子句条件列组合满足索引最左前列。\n- 尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。\n- 如果order by的条件不在索引列上，就会产生Using filesort。\n- group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最佳左前缀法则。注意where高于having，能写在where中的限定条件就不要去having限定了。\n\n# 锁\n关闭自动提交模式\n```\nSET AUTOCOMMIT=0;\n```\n\n- START TRANSACTION、BEGIN开启事务\n- COMMIT提交当前事务\n- ROLLBACK回滚当前事务\n\n## 锁的分类\n- 从性能上分为乐观锁(用版本对比来实现)和悲观锁\n- 从对数据库操作的类型，分为读锁和写锁(都属于悲观锁)\n    - 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响\n    - 写锁（排它锁）：当前写操作没有完成前，它会阻断其他写锁和读锁\n- 从对数据操作的粒度分，分为表锁和行锁\n\n\n## 表锁（偏读）\n表锁偏向MyISAM存储引擎，开销小，加锁快，无死锁，锁定粒度大，发生锁冲突的概率最高，并发度最低\n\n手动增加表锁\n``` linux\nlock table 表名称 read(write),表名称2 read(write);\n```\n\n查看表上加过的锁\n```\nshow open tables;\n```\n\n删除表锁\n```\nunlock tables;\n```\n\n### 读锁\n- 当前session和其他session都可以读该表\n- 当前session中插入或者更新锁定的表都会报错\n- 其他session插入或更新则会等待\n\n### 写锁\n- 当前session对该表的增删改查都没有问题\n- 其他session对该表的所有操作被阻塞\n\n### 小结\nMyISAM在执行查询语句(SELECT)前,会自动给涉及的所有表加读锁,在执行增删改操作前,会自动给涉及的表加写锁。\n\n1. 对MyISAM表的读操作(加读锁) ,不会阻寒其他进程对同一表的读请求,但会阻赛对同一表的写请求。只有当读锁释放后,才会执行其它进程的写操作。\n2. 对MylSAM表的写操作(加写锁) ,会阻塞其他进程对同一表的读和写操作,只有当写锁释放后,才会执行其它进程的读写操作\n\n简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。\n\n## 行锁（偏写）\n行锁偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB与MYISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。\n\nACID、和事务四种隔离级别，带来的三种问题就不写了。\n\n常看当前数据库的事务隔离级别:\n```\nshow variables like 'tx_isolation';\n```\n\n设置事务隔离级别：\n```\nset tx_isolation='REPEATABLE-READ';\n```\n\n可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。\n\nmysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。\n\n## 间隙锁\n```\nupdate table_name set id > start and id < end ;\n```\n这时如果其他的session执行insert或update id= start和end区间的数据，就会阻塞\n\n## 锁分析\n通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况\n```\nshow status like'innodb_row_lock%';\n```\n\n对各个状态量的说明如下：\n- Innodb_row_lock_current_waits: 当前正在等待锁定的数量\n- Innodb_row_lock_time: 从系统启动到现在锁定总时间长度\n- Innodb_row_lock_time_avg: 每次等待所花平均时间\n- Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间\n- Innodb_row_lock_waits:系统启动后到现在总共等待的次数\n\n对于这5个状态变量，比较重要的主要是：\n- Innodb_row_lock_time_avg （等待平均时长）\n- Innodb_row_lock_waits （等待总次数）\n- Innodb_row_lock_time（等待总时长）\n\n尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。\n\n## 死锁\n相互等待即会产生死锁 wait-for graph\n\n查看近期死锁日志信息\n```\nshow engine innodb status; \n```\n大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁\n\n## 关于锁的优化\n- 尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁\n- 合理设计索引，尽量缩小锁的范围\n- 尽可能减少检索条件，避免间隙锁\n- 尽量控制事务大小，减少锁定资源量和时间长度\n- 尽可能低级别事务隔离","source":"_posts/mysql性能优化学习笔记.md","raw":"---\ntitle: MySQL存储结构和性能优化\ndate: 2020-01-15 10:00:00\ntags: MySQL\ncategories: 数据库\n---\n\n记录下学习MySQL存储结构以及相关性能优化的基础知识\n<!-- more -->\n\n# btree、b+tree区别\n## btree\n\n![mysql01-photo](/image/mysql/btree.png)\n\n## b+tree\n\n![mysql02-photo](/image/mysql/b+tree.png)\n\n# InnoDB、MyISAM区别\n## MyISAM\n\n![mysql03-photo](/image/mysql/mysql_myISAM.png)\n\n## InnoDB\n\n![mysql04-photo](/image/mysql/mysql_InnoDB.png)\n\n## 对比表格\n对比内容 | MyISAM | Innodb |\n-- | -- | -- |\n存储结构 | 三个文件存储：firm（表定义文件）、myd（数据文件）、myi（索引文件） | 两个文件存储：firm（表定义文件）、idb（数据、索引文件）\n外键 | 不支持 | 支持 |\n事务 | 不支持 | 支持 |\n锁支持 | 表级锁 | 表、行级锁 |\n哈希索引 | 不支持 | 支持 |\n全文索引 | 支持 | 不支持 |\n记录存储结构 | 按记录插入顺序保存 | 按主键有序保存 |\n索引实现方式 | 聚簇索引，堆表 | 非聚簇索引，是索引组织表 |\n叶子节点根保存内容 | 行数据地址 | 具体的行数据 |\n\n# explain \n## type\n- ALL 扫描全表数据\n- index 遍历索引\n- range 索引范围查找\n- index_subquery 在子查询中使用 ref\n- unique_subquery 在子查询中使用 eq_ref\n- ref_or_null 对Null进行索引的优化的 ref\n- fulltext 使用全文索引\n- ref 使用非唯一索引查找数据\n- eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。\n\n## extra部分重要解释\n- Using index：查询的列被索引覆盖，并且where筛选条件是索引的前导列，是性能高的表现。一般是使用了覆盖索引(索引包含了所有查询的字段)。对于innodb来说，如果是辅助索引性能会有不少提高。\n- Using where Using index：查询的列被索引覆盖，并且where筛选条件是索引列之一但是不是索引的前导列，意味着无法直接通过索引查找来查询到符合条件的数据\n- Using index condition：与Using where类似，查询的列不完全被索引覆盖，where条件中是一个前导列的范围；\n- Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。\n    例如 distinct、group by、order by但列未创建索引等情况\n\n- Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。\n\n# 索引优化简单总结\n1. 全值匹配\n2. 最佳左前缀法则\n3. 不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描\n4. 存储引擎不能使用索引中范围条件右边的列\n5. 尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少select *语句\n6. mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描\n7. is null,is not null 也无法使用索引\n8. like以通配符开头（'$abc...'）mysql索引失效会变成全表扫描操作\n    问题：解决like'%字符串%'索引不被使用的方法？\n    - 使用覆盖索引，查询字段必须是建立覆盖索引字段\n    - 当覆盖索引指向的字段是varchar(380)及380以上的字段时，覆盖索引会失效\n\n9. 字符串不加单引号索引失效\n10. 少用or或in,非主键索引会失效，主键索引有时会生效,用它连接时很多情况下索引会失效\n\n![mysql05-photo](/image/mysql/mysql_index.png)\n\n## in和exists\nmysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。\n1. 如果查询的两个表大小相当，那么用in和exists差别不大。\n2. 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。\n3. not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。\n\n## 总结\n- MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。\n- order by满足两种情况会使用Using index。\n    - .order by语句使用索引最左前列。\n    - .使用where子句与order by子句条件列组合满足索引最左前列。\n- 尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。\n- 如果order by的条件不在索引列上，就会产生Using filesort。\n- group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最佳左前缀法则。注意where高于having，能写在where中的限定条件就不要去having限定了。\n\n# 锁\n关闭自动提交模式\n```\nSET AUTOCOMMIT=0;\n```\n\n- START TRANSACTION、BEGIN开启事务\n- COMMIT提交当前事务\n- ROLLBACK回滚当前事务\n\n## 锁的分类\n- 从性能上分为乐观锁(用版本对比来实现)和悲观锁\n- 从对数据库操作的类型，分为读锁和写锁(都属于悲观锁)\n    - 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响\n    - 写锁（排它锁）：当前写操作没有完成前，它会阻断其他写锁和读锁\n- 从对数据操作的粒度分，分为表锁和行锁\n\n\n## 表锁（偏读）\n表锁偏向MyISAM存储引擎，开销小，加锁快，无死锁，锁定粒度大，发生锁冲突的概率最高，并发度最低\n\n手动增加表锁\n``` linux\nlock table 表名称 read(write),表名称2 read(write);\n```\n\n查看表上加过的锁\n```\nshow open tables;\n```\n\n删除表锁\n```\nunlock tables;\n```\n\n### 读锁\n- 当前session和其他session都可以读该表\n- 当前session中插入或者更新锁定的表都会报错\n- 其他session插入或更新则会等待\n\n### 写锁\n- 当前session对该表的增删改查都没有问题\n- 其他session对该表的所有操作被阻塞\n\n### 小结\nMyISAM在执行查询语句(SELECT)前,会自动给涉及的所有表加读锁,在执行增删改操作前,会自动给涉及的表加写锁。\n\n1. 对MyISAM表的读操作(加读锁) ,不会阻寒其他进程对同一表的读请求,但会阻赛对同一表的写请求。只有当读锁释放后,才会执行其它进程的写操作。\n2. 对MylSAM表的写操作(加写锁) ,会阻塞其他进程对同一表的读和写操作,只有当写锁释放后,才会执行其它进程的读写操作\n\n简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。\n\n## 行锁（偏写）\n行锁偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB与MYISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。\n\nACID、和事务四种隔离级别，带来的三种问题就不写了。\n\n常看当前数据库的事务隔离级别:\n```\nshow variables like 'tx_isolation';\n```\n\n设置事务隔离级别：\n```\nset tx_isolation='REPEATABLE-READ';\n```\n\n可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。\n\nmysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。\n\n## 间隙锁\n```\nupdate table_name set id > start and id < end ;\n```\n这时如果其他的session执行insert或update id= start和end区间的数据，就会阻塞\n\n## 锁分析\n通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况\n```\nshow status like'innodb_row_lock%';\n```\n\n对各个状态量的说明如下：\n- Innodb_row_lock_current_waits: 当前正在等待锁定的数量\n- Innodb_row_lock_time: 从系统启动到现在锁定总时间长度\n- Innodb_row_lock_time_avg: 每次等待所花平均时间\n- Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间\n- Innodb_row_lock_waits:系统启动后到现在总共等待的次数\n\n对于这5个状态变量，比较重要的主要是：\n- Innodb_row_lock_time_avg （等待平均时长）\n- Innodb_row_lock_waits （等待总次数）\n- Innodb_row_lock_time（等待总时长）\n\n尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。\n\n## 死锁\n相互等待即会产生死锁 wait-for graph\n\n查看近期死锁日志信息\n```\nshow engine innodb status; \n```\n大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁\n\n## 关于锁的优化\n- 尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁\n- 合理设计索引，尽量缩小锁的范围\n- 尽可能减少检索条件，避免间隙锁\n- 尽量控制事务大小，减少锁定资源量和时间长度\n- 尽可能低级别事务隔离","slug":"mysql性能优化学习笔记","published":1,"updated":"2020-05-19T09:18:42.011Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl3y004iqotnkj19lj17","content":"<p>记录下学习MySQL存储结构以及相关性能优化的基础知识<br><a id=\"more\"></a></p>\n<h1 id=\"btree、b-tree区别\"><a href=\"#btree、b-tree区别\" class=\"headerlink\" title=\"btree、b+tree区别\"></a>btree、b+tree区别</h1><h2 id=\"btree\"><a href=\"#btree\" class=\"headerlink\" title=\"btree\"></a>btree</h2><p><img src=\"/image/mysql/btree.png\" alt=\"mysql01-photo\"></p>\n<h2 id=\"b-tree\"><a href=\"#b-tree\" class=\"headerlink\" title=\"b+tree\"></a>b+tree</h2><p><img src=\"/image/mysql/b+tree.png\" alt=\"mysql02-photo\"></p>\n<h1 id=\"InnoDB、MyISAM区别\"><a href=\"#InnoDB、MyISAM区别\" class=\"headerlink\" title=\"InnoDB、MyISAM区别\"></a>InnoDB、MyISAM区别</h1><h2 id=\"MyISAM\"><a href=\"#MyISAM\" class=\"headerlink\" title=\"MyISAM\"></a>MyISAM</h2><p><img src=\"/image/mysql/mysql_myISAM.png\" alt=\"mysql03-photo\"></p>\n<h2 id=\"InnoDB\"><a href=\"#InnoDB\" class=\"headerlink\" title=\"InnoDB\"></a>InnoDB</h2><p><img src=\"/image/mysql/mysql_InnoDB.png\" alt=\"mysql04-photo\"></p>\n<h2 id=\"对比表格\"><a href=\"#对比表格\" class=\"headerlink\" title=\"对比表格\"></a>对比表格</h2><table>\n<thead>\n<tr>\n<th>对比内容</th>\n<th>MyISAM</th>\n<th>Innodb</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>存储结构</td>\n<td>三个文件存储：firm（表定义文件）、myd（数据文件）、myi（索引文件）</td>\n<td>两个文件存储：firm（表定义文件）、idb（数据、索引文件）</td>\n</tr>\n<tr>\n<td>外键</td>\n<td>不支持</td>\n<td>支持</td>\n<td></td>\n</tr>\n<tr>\n<td>事务</td>\n<td>不支持</td>\n<td>支持</td>\n<td></td>\n</tr>\n<tr>\n<td>锁支持</td>\n<td>表级锁</td>\n<td>表、行级锁</td>\n<td></td>\n</tr>\n<tr>\n<td>哈希索引</td>\n<td>不支持</td>\n<td>支持</td>\n<td></td>\n</tr>\n<tr>\n<td>全文索引</td>\n<td>支持</td>\n<td>不支持</td>\n<td></td>\n</tr>\n<tr>\n<td>记录存储结构</td>\n<td>按记录插入顺序保存</td>\n<td>按主键有序保存</td>\n<td></td>\n</tr>\n<tr>\n<td>索引实现方式</td>\n<td>聚簇索引，堆表</td>\n<td>非聚簇索引，是索引组织表</td>\n<td></td>\n</tr>\n<tr>\n<td>叶子节点根保存内容</td>\n<td>行数据地址</td>\n<td>具体的行数据</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"explain\"><a href=\"#explain\" class=\"headerlink\" title=\"explain\"></a>explain</h1><h2 id=\"type\"><a href=\"#type\" class=\"headerlink\" title=\"type\"></a>type</h2><ul>\n<li>ALL 扫描全表数据</li>\n<li>index 遍历索引</li>\n<li>range 索引范围查找</li>\n<li>index_subquery 在子查询中使用 ref</li>\n<li>unique_subquery 在子查询中使用 eq_ref</li>\n<li>ref_or_null 对Null进行索引的优化的 ref</li>\n<li>fulltext 使用全文索引</li>\n<li>ref 使用非唯一索引查找数据</li>\n<li>eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。</li>\n</ul>\n<h2 id=\"extra部分重要解释\"><a href=\"#extra部分重要解释\" class=\"headerlink\" title=\"extra部分重要解释\"></a>extra部分重要解释</h2><ul>\n<li>Using index：查询的列被索引覆盖，并且where筛选条件是索引的前导列，是性能高的表现。一般是使用了覆盖索引(索引包含了所有查询的字段)。对于innodb来说，如果是辅助索引性能会有不少提高。</li>\n<li>Using where Using index：查询的列被索引覆盖，并且where筛选条件是索引列之一但是不是索引的前导列，意味着无法直接通过索引查找来查询到符合条件的数据</li>\n<li>Using index condition：与Using where类似，查询的列不完全被索引覆盖，where条件中是一个前导列的范围；</li>\n<li><p>Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。<br>  例如 distinct、group by、order by但列未创建索引等情况</p>\n</li>\n<li><p>Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。</p>\n</li>\n</ul>\n<h1 id=\"索引优化简单总结\"><a href=\"#索引优化简单总结\" class=\"headerlink\" title=\"索引优化简单总结\"></a>索引优化简单总结</h1><ol>\n<li>全值匹配</li>\n<li>最佳左前缀法则</li>\n<li>不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描</li>\n<li>存储引擎不能使用索引中范围条件右边的列</li>\n<li>尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少select *语句</li>\n<li>mysql在使用不等于（！=或者&lt;&gt;）的时候无法使用索引会导致全表扫描</li>\n<li>is null,is not null 也无法使用索引</li>\n<li><p>like以通配符开头（’$abc…’）mysql索引失效会变成全表扫描操作<br> 问题：解决like’%字符串%’索引不被使用的方法？</p>\n<ul>\n<li>使用覆盖索引，查询字段必须是建立覆盖索引字段</li>\n<li>当覆盖索引指向的字段是varchar(380)及380以上的字段时，覆盖索引会失效</li>\n</ul>\n</li>\n<li><p>字符串不加单引号索引失效</p>\n</li>\n<li>少用or或in,非主键索引会失效，主键索引有时会生效,用它连接时很多情况下索引会失效</li>\n</ol>\n<p><img src=\"/image/mysql/mysql_index.png\" alt=\"mysql05-photo\"></p>\n<h2 id=\"in和exists\"><a href=\"#in和exists\" class=\"headerlink\" title=\"in和exists\"></a>in和exists</h2><p>mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。</p>\n<ol>\n<li>如果查询的两个表大小相当，那么用in和exists差别不大。</li>\n<li>如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。</li>\n<li>not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</li>\n</ol>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li>MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。</li>\n<li>order by满足两种情况会使用Using index。<ul>\n<li>.order by语句使用索引最左前列。</li>\n<li>.使用where子句与order by子句条件列组合满足索引最左前列。</li>\n</ul>\n</li>\n<li>尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。</li>\n<li>如果order by的条件不在索引列上，就会产生Using filesort。</li>\n<li>group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最佳左前缀法则。注意where高于having，能写在where中的限定条件就不要去having限定了。</li>\n</ul>\n<h1 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h1><p>关闭自动提交模式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET AUTOCOMMIT=0;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>START TRANSACTION、BEGIN开启事务</li>\n<li>COMMIT提交当前事务</li>\n<li>ROLLBACK回滚当前事务</li>\n</ul>\n<h2 id=\"锁的分类\"><a href=\"#锁的分类\" class=\"headerlink\" title=\"锁的分类\"></a>锁的分类</h2><ul>\n<li>从性能上分为乐观锁(用版本对比来实现)和悲观锁</li>\n<li>从对数据库操作的类型，分为读锁和写锁(都属于悲观锁)<ul>\n<li>读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响</li>\n<li>写锁（排它锁）：当前写操作没有完成前，它会阻断其他写锁和读锁</li>\n</ul>\n</li>\n<li>从对数据操作的粒度分，分为表锁和行锁</li>\n</ul>\n<h2 id=\"表锁（偏读）\"><a href=\"#表锁（偏读）\" class=\"headerlink\" title=\"表锁（偏读）\"></a>表锁（偏读）</h2><p>表锁偏向MyISAM存储引擎，开销小，加锁快，无死锁，锁定粒度大，发生锁冲突的概率最高，并发度最低</p>\n<p>手动增加表锁<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lock table 表名称 read(write),表名称2 read(write);</span><br></pre></td></tr></table></figure></p>\n<p>查看表上加过的锁<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show open tables;</span><br></pre></td></tr></table></figure></p>\n<p>删除表锁<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">unlock tables;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"读锁\"><a href=\"#读锁\" class=\"headerlink\" title=\"读锁\"></a>读锁</h3><ul>\n<li>当前session和其他session都可以读该表</li>\n<li>当前session中插入或者更新锁定的表都会报错</li>\n<li>其他session插入或更新则会等待</li>\n</ul>\n<h3 id=\"写锁\"><a href=\"#写锁\" class=\"headerlink\" title=\"写锁\"></a>写锁</h3><ul>\n<li>当前session对该表的增删改查都没有问题</li>\n<li>其他session对该表的所有操作被阻塞</li>\n</ul>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>MyISAM在执行查询语句(SELECT)前,会自动给涉及的所有表加读锁,在执行增删改操作前,会自动给涉及的表加写锁。</p>\n<ol>\n<li>对MyISAM表的读操作(加读锁) ,不会阻寒其他进程对同一表的读请求,但会阻赛对同一表的写请求。只有当读锁释放后,才会执行其它进程的写操作。</li>\n<li>对MylSAM表的写操作(加写锁) ,会阻塞其他进程对同一表的读和写操作,只有当写锁释放后,才会执行其它进程的读写操作</li>\n</ol>\n<p>简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。</p>\n<h2 id=\"行锁（偏写）\"><a href=\"#行锁（偏写）\" class=\"headerlink\" title=\"行锁（偏写）\"></a>行锁（偏写）</h2><p>行锁偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB与MYISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。</p>\n<p>ACID、和事务四种隔离级别，带来的三种问题就不写了。</p>\n<p>常看当前数据库的事务隔离级别:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show variables like &apos;tx_isolation&apos;;</span><br></pre></td></tr></table></figure></p>\n<p>设置事务隔离级别：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set tx_isolation=&apos;REPEATABLE-READ&apos;;</span><br></pre></td></tr></table></figure></p>\n<p>可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。</p>\n<p>mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。</p>\n<h2 id=\"间隙锁\"><a href=\"#间隙锁\" class=\"headerlink\" title=\"间隙锁\"></a>间隙锁</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">update table_name set id &gt; start and id &lt; end ;</span><br></pre></td></tr></table></figure>\n<p>这时如果其他的session执行insert或update id= start和end区间的数据，就会阻塞</p>\n<h2 id=\"锁分析\"><a href=\"#锁分析\" class=\"headerlink\" title=\"锁分析\"></a>锁分析</h2><p>通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show status like&apos;innodb_row_lock%&apos;;</span><br></pre></td></tr></table></figure></p>\n<p>对各个状态量的说明如下：</p>\n<ul>\n<li>Innodb_row_lock_current_waits: 当前正在等待锁定的数量</li>\n<li>Innodb_row_lock_time: 从系统启动到现在锁定总时间长度</li>\n<li>Innodb_row_lock_time_avg: 每次等待所花平均时间</li>\n<li>Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间</li>\n<li>Innodb_row_lock_waits:系统启动后到现在总共等待的次数</li>\n</ul>\n<p>对于这5个状态变量，比较重要的主要是：</p>\n<ul>\n<li>Innodb_row_lock_time_avg （等待平均时长）</li>\n<li>Innodb_row_lock_waits （等待总次数）</li>\n<li>Innodb_row_lock_time（等待总时长）</li>\n</ul>\n<p>尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。</p>\n<h2 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h2><p>相互等待即会产生死锁 wait-for graph</p>\n<p>查看近期死锁日志信息<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show engine innodb status;</span><br></pre></td></tr></table></figure></p>\n<p>大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁</p>\n<h2 id=\"关于锁的优化\"><a href=\"#关于锁的优化\" class=\"headerlink\" title=\"关于锁的优化\"></a>关于锁的优化</h2><ul>\n<li>尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁</li>\n<li>合理设计索引，尽量缩小锁的范围</li>\n<li>尽可能减少检索条件，避免间隙锁</li>\n<li>尽量控制事务大小，减少锁定资源量和时间长度</li>\n<li>尽可能低级别事务隔离</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>记录下学习MySQL存储结构以及相关性能优化的基础知识<br>","more":"</p>\n<h1 id=\"btree、b-tree区别\"><a href=\"#btree、b-tree区别\" class=\"headerlink\" title=\"btree、b+tree区别\"></a>btree、b+tree区别</h1><h2 id=\"btree\"><a href=\"#btree\" class=\"headerlink\" title=\"btree\"></a>btree</h2><p><img src=\"/image/mysql/btree.png\" alt=\"mysql01-photo\"></p>\n<h2 id=\"b-tree\"><a href=\"#b-tree\" class=\"headerlink\" title=\"b+tree\"></a>b+tree</h2><p><img src=\"/image/mysql/b+tree.png\" alt=\"mysql02-photo\"></p>\n<h1 id=\"InnoDB、MyISAM区别\"><a href=\"#InnoDB、MyISAM区别\" class=\"headerlink\" title=\"InnoDB、MyISAM区别\"></a>InnoDB、MyISAM区别</h1><h2 id=\"MyISAM\"><a href=\"#MyISAM\" class=\"headerlink\" title=\"MyISAM\"></a>MyISAM</h2><p><img src=\"/image/mysql/mysql_myISAM.png\" alt=\"mysql03-photo\"></p>\n<h2 id=\"InnoDB\"><a href=\"#InnoDB\" class=\"headerlink\" title=\"InnoDB\"></a>InnoDB</h2><p><img src=\"/image/mysql/mysql_InnoDB.png\" alt=\"mysql04-photo\"></p>\n<h2 id=\"对比表格\"><a href=\"#对比表格\" class=\"headerlink\" title=\"对比表格\"></a>对比表格</h2><table>\n<thead>\n<tr>\n<th>对比内容</th>\n<th>MyISAM</th>\n<th>Innodb</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>存储结构</td>\n<td>三个文件存储：firm（表定义文件）、myd（数据文件）、myi（索引文件）</td>\n<td>两个文件存储：firm（表定义文件）、idb（数据、索引文件）</td>\n</tr>\n<tr>\n<td>外键</td>\n<td>不支持</td>\n<td>支持</td>\n<td></td>\n</tr>\n<tr>\n<td>事务</td>\n<td>不支持</td>\n<td>支持</td>\n<td></td>\n</tr>\n<tr>\n<td>锁支持</td>\n<td>表级锁</td>\n<td>表、行级锁</td>\n<td></td>\n</tr>\n<tr>\n<td>哈希索引</td>\n<td>不支持</td>\n<td>支持</td>\n<td></td>\n</tr>\n<tr>\n<td>全文索引</td>\n<td>支持</td>\n<td>不支持</td>\n<td></td>\n</tr>\n<tr>\n<td>记录存储结构</td>\n<td>按记录插入顺序保存</td>\n<td>按主键有序保存</td>\n<td></td>\n</tr>\n<tr>\n<td>索引实现方式</td>\n<td>聚簇索引，堆表</td>\n<td>非聚簇索引，是索引组织表</td>\n<td></td>\n</tr>\n<tr>\n<td>叶子节点根保存内容</td>\n<td>行数据地址</td>\n<td>具体的行数据</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h1 id=\"explain\"><a href=\"#explain\" class=\"headerlink\" title=\"explain\"></a>explain</h1><h2 id=\"type\"><a href=\"#type\" class=\"headerlink\" title=\"type\"></a>type</h2><ul>\n<li>ALL 扫描全表数据</li>\n<li>index 遍历索引</li>\n<li>range 索引范围查找</li>\n<li>index_subquery 在子查询中使用 ref</li>\n<li>unique_subquery 在子查询中使用 eq_ref</li>\n<li>ref_or_null 对Null进行索引的优化的 ref</li>\n<li>fulltext 使用全文索引</li>\n<li>ref 使用非唯一索引查找数据</li>\n<li>eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。</li>\n</ul>\n<h2 id=\"extra部分重要解释\"><a href=\"#extra部分重要解释\" class=\"headerlink\" title=\"extra部分重要解释\"></a>extra部分重要解释</h2><ul>\n<li>Using index：查询的列被索引覆盖，并且where筛选条件是索引的前导列，是性能高的表现。一般是使用了覆盖索引(索引包含了所有查询的字段)。对于innodb来说，如果是辅助索引性能会有不少提高。</li>\n<li>Using where Using index：查询的列被索引覆盖，并且where筛选条件是索引列之一但是不是索引的前导列，意味着无法直接通过索引查找来查询到符合条件的数据</li>\n<li>Using index condition：与Using where类似，查询的列不完全被索引覆盖，where条件中是一个前导列的范围；</li>\n<li><p>Using temporary：mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。<br>  例如 distinct、group by、order by但列未创建索引等情况</p>\n</li>\n<li><p>Using filesort：mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。这种情况下一般也是要考虑使用索引来优化的。</p>\n</li>\n</ul>\n<h1 id=\"索引优化简单总结\"><a href=\"#索引优化简单总结\" class=\"headerlink\" title=\"索引优化简单总结\"></a>索引优化简单总结</h1><ol>\n<li>全值匹配</li>\n<li>最佳左前缀法则</li>\n<li>不在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描</li>\n<li>存储引擎不能使用索引中范围条件右边的列</li>\n<li>尽量使用覆盖索引（只访问索引的查询（索引列包含查询列）），减少select *语句</li>\n<li>mysql在使用不等于（！=或者&lt;&gt;）的时候无法使用索引会导致全表扫描</li>\n<li>is null,is not null 也无法使用索引</li>\n<li><p>like以通配符开头（’$abc…’）mysql索引失效会变成全表扫描操作<br> 问题：解决like’%字符串%’索引不被使用的方法？</p>\n<ul>\n<li>使用覆盖索引，查询字段必须是建立覆盖索引字段</li>\n<li>当覆盖索引指向的字段是varchar(380)及380以上的字段时，覆盖索引会失效</li>\n</ul>\n</li>\n<li><p>字符串不加单引号索引失效</p>\n</li>\n<li>少用or或in,非主键索引会失效，主键索引有时会生效,用它连接时很多情况下索引会失效</li>\n</ol>\n<p><img src=\"/image/mysql/mysql_index.png\" alt=\"mysql05-photo\"></p>\n<h2 id=\"in和exists\"><a href=\"#in和exists\" class=\"headerlink\" title=\"in和exists\"></a>in和exists</h2><p>mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。</p>\n<ol>\n<li>如果查询的两个表大小相当，那么用in和exists差别不大。</li>\n<li>如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。</li>\n<li>not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</li>\n</ol>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li>MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。</li>\n<li>order by满足两种情况会使用Using index。<ul>\n<li>.order by语句使用索引最左前列。</li>\n<li>.使用where子句与order by子句条件列组合满足索引最左前列。</li>\n</ul>\n</li>\n<li>尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。</li>\n<li>如果order by的条件不在索引列上，就会产生Using filesort。</li>\n<li>group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最佳左前缀法则。注意where高于having，能写在where中的限定条件就不要去having限定了。</li>\n</ul>\n<h1 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h1><p>关闭自动提交模式<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SET AUTOCOMMIT=0;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>START TRANSACTION、BEGIN开启事务</li>\n<li>COMMIT提交当前事务</li>\n<li>ROLLBACK回滚当前事务</li>\n</ul>\n<h2 id=\"锁的分类\"><a href=\"#锁的分类\" class=\"headerlink\" title=\"锁的分类\"></a>锁的分类</h2><ul>\n<li>从性能上分为乐观锁(用版本对比来实现)和悲观锁</li>\n<li>从对数据库操作的类型，分为读锁和写锁(都属于悲观锁)<ul>\n<li>读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响</li>\n<li>写锁（排它锁）：当前写操作没有完成前，它会阻断其他写锁和读锁</li>\n</ul>\n</li>\n<li>从对数据操作的粒度分，分为表锁和行锁</li>\n</ul>\n<h2 id=\"表锁（偏读）\"><a href=\"#表锁（偏读）\" class=\"headerlink\" title=\"表锁（偏读）\"></a>表锁（偏读）</h2><p>表锁偏向MyISAM存储引擎，开销小，加锁快，无死锁，锁定粒度大，发生锁冲突的概率最高，并发度最低</p>\n<p>手动增加表锁<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lock table 表名称 read(write),表名称2 read(write);</span><br></pre></td></tr></table></figure></p>\n<p>查看表上加过的锁<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show open tables;</span><br></pre></td></tr></table></figure></p>\n<p>删除表锁<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">unlock tables;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"读锁\"><a href=\"#读锁\" class=\"headerlink\" title=\"读锁\"></a>读锁</h3><ul>\n<li>当前session和其他session都可以读该表</li>\n<li>当前session中插入或者更新锁定的表都会报错</li>\n<li>其他session插入或更新则会等待</li>\n</ul>\n<h3 id=\"写锁\"><a href=\"#写锁\" class=\"headerlink\" title=\"写锁\"></a>写锁</h3><ul>\n<li>当前session对该表的增删改查都没有问题</li>\n<li>其他session对该表的所有操作被阻塞</li>\n</ul>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><p>MyISAM在执行查询语句(SELECT)前,会自动给涉及的所有表加读锁,在执行增删改操作前,会自动给涉及的表加写锁。</p>\n<ol>\n<li>对MyISAM表的读操作(加读锁) ,不会阻寒其他进程对同一表的读请求,但会阻赛对同一表的写请求。只有当读锁释放后,才会执行其它进程的写操作。</li>\n<li>对MylSAM表的写操作(加写锁) ,会阻塞其他进程对同一表的读和写操作,只有当写锁释放后,才会执行其它进程的读写操作</li>\n</ol>\n<p>简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。</p>\n<h2 id=\"行锁（偏写）\"><a href=\"#行锁（偏写）\" class=\"headerlink\" title=\"行锁（偏写）\"></a>行锁（偏写）</h2><p>行锁偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB与MYISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。</p>\n<p>ACID、和事务四种隔离级别，带来的三种问题就不写了。</p>\n<p>常看当前数据库的事务隔离级别:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show variables like &apos;tx_isolation&apos;;</span><br></pre></td></tr></table></figure></p>\n<p>设置事务隔离级别：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">set tx_isolation=&apos;REPEATABLE-READ&apos;;</span><br></pre></td></tr></table></figure></p>\n<p>可重复读的隔离级别下使用了MVCC机制，select操作不会更新版本号，是快照读（历史版本）；insert、update和delete会更新版本号，是当前读（当前版本）。</p>\n<p>mysql中事务隔离级别为serializable时会锁表，因此不会出现幻读的情况，这种隔离级别并发性极低，开发中很少会用到。</p>\n<h2 id=\"间隙锁\"><a href=\"#间隙锁\" class=\"headerlink\" title=\"间隙锁\"></a>间隙锁</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">update table_name set id &gt; start and id &lt; end ;</span><br></pre></td></tr></table></figure>\n<p>这时如果其他的session执行insert或update id= start和end区间的数据，就会阻塞</p>\n<h2 id=\"锁分析\"><a href=\"#锁分析\" class=\"headerlink\" title=\"锁分析\"></a>锁分析</h2><p>通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show status like&apos;innodb_row_lock%&apos;;</span><br></pre></td></tr></table></figure></p>\n<p>对各个状态量的说明如下：</p>\n<ul>\n<li>Innodb_row_lock_current_waits: 当前正在等待锁定的数量</li>\n<li>Innodb_row_lock_time: 从系统启动到现在锁定总时间长度</li>\n<li>Innodb_row_lock_time_avg: 每次等待所花平均时间</li>\n<li>Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花时间</li>\n<li>Innodb_row_lock_waits:系统启动后到现在总共等待的次数</li>\n</ul>\n<p>对于这5个状态变量，比较重要的主要是：</p>\n<ul>\n<li>Innodb_row_lock_time_avg （等待平均时长）</li>\n<li>Innodb_row_lock_waits （等待总次数）</li>\n<li>Innodb_row_lock_time（等待总时长）</li>\n</ul>\n<p>尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。</p>\n<h2 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h2><p>相互等待即会产生死锁 wait-for graph</p>\n<p>查看近期死锁日志信息<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">show engine innodb status;</span><br></pre></td></tr></table></figure></p>\n<p>大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁</p>\n<h2 id=\"关于锁的优化\"><a href=\"#关于锁的优化\" class=\"headerlink\" title=\"关于锁的优化\"></a>关于锁的优化</h2><ul>\n<li>尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁</li>\n<li>合理设计索引，尽量缩小锁的范围</li>\n<li>尽可能减少检索条件，避免间隙锁</li>\n<li>尽量控制事务大小，减少锁定资源量和时间长度</li>\n<li>尽可能低级别事务隔离</li>\n</ul>"},{"title":"代理模式/JAVA动态代理","date":"2018-12-12T07:01:00.000Z","_content":"\n# 代理模式/JAVA动态代理\n\n> 在学习Spring AOP与RPC的实现时，总会与代理模式密不可分，而日常编码中代理模式也是常用的设计模式之一。学习代理模式与动态代理的实现与作用是非常有益于理解框架的源码实现，并且可以提高抽象思维。本文是个人在学习代理模式以及动态代理的一个小总结，没有过深的探讨。本文不会提及具体动态代理底层字节码框架的实现，之后有机会会补充Javassist和ASM字节码框架的文章。\n\n<!-- more -->\n\n## 概念\n\n_**计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决**_\n\n代理模式被定位为：为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。\n\n代理设计模式是二十三种着名的GOF设计模式之一 ，它描述了如何解决重复出现的设计问题，以设计灵活且可重用的面向对象软件，即更容易实现，更改的对象，测试和重用。在JAVA中可以实现静态代理、动态代理，而动态代理常用的有JDK Proxy和CGLIB两种方式实现动态代理。\n\n### 代理模式的核心作用\n* 通过代理控制对对象的访问，做为隔离客户端和委托类的中介。\n* 借助代理增加一些功能，而不需要修改原有代码。符合开闭原则。\n\n![Proxy_design_UML_photo](/image/W3sDesign_Proxy_Design_Pattern_UML.jpg)\n\n### 静态代理与动态代理\n静态代理一般指的显式指定的代理，由业务实现类、业务代理类两部分组成。业务实现类提供业务的主要实现，业务代理类负责对业务真正的实现进行调用，并且可以进行拦截、过滤、预处理。但静态代理对代码是有很大耦合性的，如果需要大量代理的使用，则需要动态代理。\n\n动态代理则是在程序运行时，根据需求动态的通过反射机制、字节码框架，动态生成代理类进行代理业务操作，极大程度的减少代理模式实现的编码量。\n\n## 如何实现动态代理\n\n### JDK Proxy实现动态代理\n\njava.lang.reflect包中有提供给我们实现动态代理的类库，Proxy和InvocationHandler，来帮助我们实现基于接口的动态代理。\n\n创建代理对象\n```java\n@CallerSensitive\npublic static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h) throws IllegalArgumentException\n```\n* ClassLoader loader：被代理类的ClassLoader\n* Class<?>[] interfaces：被代理类所实现的接口\n* InvocationHandler h：代理对象实例\n\n实现InvocationHandler接口，实现invoke方法，通过反射调用原方法。\n```java\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable;\n```\n* Object proxy：调用该方法的代理类的实例\n* Method method：代理方法\n* Object[] args：代理方法参数列表\n\n下面是一段非常简单的示例：\n```java\npublic interface IBusiness {\n    void doSomething();\n}\n\npublic class BusinessImpl implements IBusiness {\n    @Override\n    public void doSomething() {\n        System.out.println(\"do something ...\");\n    }\n}\n```\n\n```java\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\n\n/**\n * JDK proxy动态代理示例\n *\n * @Author: liu.bo\n * @CreateTime: 2018-12-05 10:36\n */\npublic class JDKProxyDemo01 {\n\n    public static void main(String[] args) {\n        BusinessImpl impl = new BusinessImpl();\n        BusinessProxy proxy = new BusinessProxy();\n        IBusiness iBusiness = (IBusiness) proxy.blind(impl);\n        iBusiness.doSomething();\n    }\n\n}\n\nclass BusinessProxy implements InvocationHandler {\n    private Object obj;\n\n    public Object blind(Object obj) {\n        this.obj = obj;\n        return Proxy.newProxyInstance(obj.getClass().getClassLoader(),\n                obj.getClass().getInterfaces(), this);\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        Object result = null;\n        System.out.println(\"before ...\");\n        result = method.invoke(obj, args);\n        System.out.println(\"after ...\");\n        return result;\n    }\n}\n```\n\n由示例可知，借助于JDK proxy实现动态代理的弊端，被代理类必须有接口，JDK动态代理其实也是基本接口实现的。因为通过接口指向实现类实例的多态方式，可以有效地将具体实现与调用解耦，便于后期的修改和维护。\n\nJDK动态代理是利用反射机制在运行时创建代理类的。核心是InvocationHandler。每一个代理的实例都会有一个关联的调用处理程序(InvocationHandler)。对待代理实例进行调用时，将对方法的调用进行编码并指派到它的调用处理器(InvocationHandler)的invoke方法。所以对代理对象实例方法的调用都是通过InvocationHandler中的invoke方法来完成的，而invoke方法会根据传入的代理对象、方法名称以及参数决定调用代理的哪个方法。\n\n关于JDK Proxy动态代理具体实现细节，可以参考[深入理解JDK动态代理机制](https://www.jianshu.com/p/471c80a7e831)，该篇文章很简洁的介绍了源码。\n\n## CGLIB实现动态代理\n\ncglib能够实现基于类的动态代理，生成业务类的子类，覆盖业务方法实现代理，因为采用的是继承，所以不能对final修饰的类进行代理。 \n\n### Enhancer\n\n实例Enhancer，通过该类对象创建代理实例。\n\n```java\npublic Enhancer() {\n    super(SOURCE);\n}\n\npublic void setSuperclass(Class superclass)\n\npublic void setCallback(final Callback callback)\n\npublic Object create()\n\npublic Object create(Class[] argumentTypes, Object[] arguments)\n```\n\n* setSuperclass：设置代理的父类\n* setCallback：设置代理回调\n    net.sf.cglib.proxy.Callback是一个用于标记的接口，net.sf.cglib.proxy.Enhancer使用的所有回调都会继承这个接口。\n* create：默认使用无参构造方法创建目标对象，如果需要调用有参构造方法应该使用net.sf.cglib.proxy.Enhancer.create(Class[], Object[])。该方法的第一个参数指明参数类型，第二个参数指明参数值。参数中的原子类型需要使用包装类。\n\n### CallBack\n\n![cglib_callback_photo](/image/cglib_callback.png)\n\n    net.sf.cglib.proxy.FixedValue：在强制一个特定方法返回固定值，在特定场景下非常有用且性能高。\n    net.sf.cglib.proxy.NoOp：它直接透传到父类的方法实现。\n    net.sf.cglib.proxy.LazyLoader：在被代理对象需要懒加载场景下非常有用，如果被代理对象加载完成，那么在以后的代理调用时会重复使用。\n    net.sf.cglib.proxy.Dispatcher：与net.sf.cglib.proxy.LazyLoader差不多，但每次调用代理方法时都会调用loadObject方法来加载被代理对象。\n    net.sf.cglib.proxy.ProxyRefDispatcher：与Dispatcher相同，但它的loadObject方法支持传入代理对象。\n    net.sf.cglib.proxy.MethodInterceptor：是最常用的回调类型，在基于代理的AOP实现中它经常被用来拦截方法调用。\n\n### 使用Enhancer创建代理对象\n\n先编写一个简单的代理示例：\n\n```java\npublic static void main(String[] args) {\n    Enhancer enhancer = new Enhancer();\n    enhancer.setSuperclass(BusinessImpl.class);\n    enhancer.setCallback(NoOp.INSTANCE);\n    BusinessImpl business = (BusinessImpl) enhancer.create();\n    business.doSomething();\n    System.out.println(business.getClass().getSuperclass());\n}\n```\n\n运行结果\n\n```\ndo something ...\nclass proxy.BusinessImpl\n```\n\n通过运行结果，最后生成的代理类的父类是我们的业务类，由此可以得出结论Enhancer生成的代理对象是设置的Superclass设置的子类。\n\n而我们使用的内置回调NoOp，实际上代理类没有做其他的代理操作，相当于直接调用了父业务类的方法。\n\n### 使用MethodInterceptor\n\n通过实现MethodInterceptor接口，可以将代理的所有方法调用都会被分派给net.sf.cglib.proxy.MethodInterceptor的intercept方法。intercept方法中可以调用底层对象。\n\n```java\npublic Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable\n```\n\n* obj：代理对象\n* method：被代理的方法\n* args：被代理方法的参数列表\n* methodProxy：代理方法\n\n```java\nimport net.sf.cglib.proxy.Enhancer;\nimport net.sf.cglib.proxy.MethodInterceptor;\nimport net.sf.cglib.proxy.MethodProxy;\nimport net.sf.cglib.proxy.NoOp;\n\nimport java.lang.reflect.Method;\n\n/**\n * @Description:\n * @Author: liu.bo\n * @CreateTime: 2018-12-05 09:40\n */\npublic class CglibProxyDemo01 {\n    public static void main(String[] args) {\n        BusinessImpl impl = new BusinessImpl();\n        Enhancer enhancer = new Enhancer();\n        enhancer.setSuperclass(impl.getClass());\n        enhancer.setCallback(new CglibProxy(impl));\n        BusinessImpl business = (BusinessImpl) enhancer.create();\n        business.doSomething();\n        System.out.println(business.getClass().getSuperclass());\n    }\n}\n\nclass CglibProxy implements MethodInterceptor {\n    private Object obj;\n\n    public CglibProxy(Object obj) {\n        this.obj = obj;\n    }\n\n    @Override\n    public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {\n        System.out.println(\"method:\" + method);\n        System.out.println(\"methodProxy:\" + methodProxy);\n        Object returnObj = null;\n        System.out.println(\"after...\");\n        returnObj = methodProxy.invoke(this.obj, args);\n        System.out.println(\"before...\");\n        return returnObj;\n    }\n}\n```\n运行结果\n```\nmethod:public void proxy.BusinessImpl.doSomething()\nmethodProxy:net.sf.cglib.proxy.MethodProxy@45ff54e6\nafter...\ndo something ...\nbefore...\nclass proxy.BusinessImpl\n```\n\n关于使用Method还是MethodProxy调用类方法，Method则是被代理类的方法，即通过反射调用。而MethodProxy则是cglib提供的被代理方法的代理。看了一些文章有讲到MethodProxy的执行效率更高，但具体没有研究过，有待验证。\n\n### CallbackFilter\n\nEnhancer还提供了CallbackFilter和多个Callbacks，通过下标的方式提供对于具体细化到方法粒度的回调。\n\n```java\npublic void setCallbacks(Callback[] callbacks)\n\npublic void setCallbackFilter(CallbackFilter filter)\n```\n\n因为设置CallbackFilter需要传入CallbackFilter接口实现类\n\n```java\n/**\n * Map methods of subclasses generated by {@link Enhancer} to a particular\n * callback. The type of the callbacks chosen for each method affects\n * the bytecode generated for that method in the subclass, and cannot\n * change for the life of the class.\n * <p>Note: {@link CallbackFilter} implementations are supposed to be\n * lightweight as cglib might keep {@link CallbackFilter} objects\n * alive to enable caching of generated classes. Prefer using {@code static}\n * classes for implementation of {@link CallbackFilter}.</p>\n */\npublic interface CallbackFilter {\n    /**\n     * Map a method to a callback.\n     * @param method the intercepted method\n     * @return the index into the array of callbacks (as specified by {@link Enhancer#setCallbacks}) to use for the method, \n     */\n    int accept(Method method);\n\n    /**\n     * The <code>CallbackFilter</code> in use affects which cached class\n     * the <code>Enhancer</code> will use, so this is a reminder that\n     * you should correctly implement <code>equals</code> and\n     * <code>hashCode</code> for custom <code>CallbackFilter</code>\n     * implementations in order to improve performance.\n    */\n    boolean equals(Object o);\n}\n```\n\n关于CallbackFilter，我们可以看下accept方法，主要作用为通过方法映射到不同的callback，方法的返回值是enhancer中设置的Callbacks的下标。\n\n举个栗子\n\n先增加两个方法，因为本身与接口无关，所以就直接在类中增加方法了。\n```java\npublic class BusinessImpl implements IBusiness {\n    @Override\n    public void doSomething() {\n        System.out.println(\"do something ...\");\n    }\n    public void doSomethingA() {\n        System.out.println(\"do something A ...\");\n    }\n    public void doSomethingB() {\n        System.out.println(\"do something B ...\");\n    }\n}\n```\n\n然后实现CallbackFilter，我们先设置方法A和方法B使用第二个Callback，默认使用第一个。\n```java\nclass DemoCallbackFilter implements net.sf.cglib.proxy.CallbackFilter {\n    @Override\n    public int accept(Method method) {\n        if(method.getName().equals(\"doSomethingA\") || method.getName().equals(\"doSomethingB\")){\n            return 1;\n        }\n        return 0;\n    }\n}\n```\n这里我们设置CallbackFilter，并且设置Callbacks，第一个设置为默认代理，第二个使用之前例子中的MethodInterceptor。\n\n```java\npublic static void main(String[] args) {\n    Enhancer enhancer = new Enhancer();\n    enhancer.setSuperclass(BusinessImpl.class);\n    Callback callBack_0 = NoOp.INSTANCE;\n    Callback callBack_1 = new CglibProxy(new BusinessImpl());\n    Callback[] callbacks = new Callback[]{callBack_0, callBack_1 };\n    enhancer.setCallbackFilter(new DemoCallbackFilter());\n    enhancer.setCallbacks(callbacks);\n    BusinessImpl business = (BusinessImpl) enhancer.create();\n    business.doSomething();\n    business.doSomethingA();\n    business.doSomethingB();\n}\n```\n\n运行结果如下\n```\ndo something ...\nmethodName:public void proxy.BusinessImpl.doSomethingA()\nmethodProxy:net.sf.cglib.proxy.MethodProxy@45283ce2\nafter...\ndo something A ...\nbefore...\nmethodName:public void proxy.BusinessImpl.doSomethingB()\nmethodProxy:net.sf.cglib.proxy.MethodProxy@3d71d552\nafter...\ndo something B ...\nbefore...\n```\n\n可以看出，通过CallbackFilter实现了对方法粒度的回调过滤。\n\n## 总结\n一般情况下都可以使用JDK动态代理方法来创建代理，对于没有接口的情况或者性能因素，CGLIB是一个很好的选择。而CGLIB是一个强大的高性能的代码生成库。作为JDK动态代理的互补，它对于那些没有实现接口的类提供了代理方案。在底层，它使用ASM字节码操纵框架。本质上来说，CGLIB通过产生子类覆盖非final方法来进行代理。它比使用Java反射的JDK动态代理方法更快。CGLIB不能代理一个final类或者final方法。\n\n## 参考资料\n* https://en.wikipedia.org/wiki/Proxy_pattern\n* https://www.jianshu.com/p/471c80a7e831\n* https://www.jianshu.com/p/9a61af393e41?from=timeline&isappinstalled=0\n* https://www.cnblogs.com/ygj0930/p/6542259.html\n* https://www.cnblogs.com/LCcnblogs/p/6823982.html\n* https://www.2cto.com/kf/201801/710319.html\n* https://www.cnblogs.com/xrq730/p/6661692.html\n* https://mp.weixin.qq.com/s/sS4QYvERlYFZh1EyXuDV3Q","source":"_posts/proxy_pattern.md","raw":"---\ntitle: 代理模式/JAVA动态代理\ndate: 2018-12-12 15:01:00\ntags: 设计模式\ncategories: 设计模式\n---\n\n# 代理模式/JAVA动态代理\n\n> 在学习Spring AOP与RPC的实现时，总会与代理模式密不可分，而日常编码中代理模式也是常用的设计模式之一。学习代理模式与动态代理的实现与作用是非常有益于理解框架的源码实现，并且可以提高抽象思维。本文是个人在学习代理模式以及动态代理的一个小总结，没有过深的探讨。本文不会提及具体动态代理底层字节码框架的实现，之后有机会会补充Javassist和ASM字节码框架的文章。\n\n<!-- more -->\n\n## 概念\n\n_**计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决**_\n\n代理模式被定位为：为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。\n\n代理设计模式是二十三种着名的GOF设计模式之一 ，它描述了如何解决重复出现的设计问题，以设计灵活且可重用的面向对象软件，即更容易实现，更改的对象，测试和重用。在JAVA中可以实现静态代理、动态代理，而动态代理常用的有JDK Proxy和CGLIB两种方式实现动态代理。\n\n### 代理模式的核心作用\n* 通过代理控制对对象的访问，做为隔离客户端和委托类的中介。\n* 借助代理增加一些功能，而不需要修改原有代码。符合开闭原则。\n\n![Proxy_design_UML_photo](/image/W3sDesign_Proxy_Design_Pattern_UML.jpg)\n\n### 静态代理与动态代理\n静态代理一般指的显式指定的代理，由业务实现类、业务代理类两部分组成。业务实现类提供业务的主要实现，业务代理类负责对业务真正的实现进行调用，并且可以进行拦截、过滤、预处理。但静态代理对代码是有很大耦合性的，如果需要大量代理的使用，则需要动态代理。\n\n动态代理则是在程序运行时，根据需求动态的通过反射机制、字节码框架，动态生成代理类进行代理业务操作，极大程度的减少代理模式实现的编码量。\n\n## 如何实现动态代理\n\n### JDK Proxy实现动态代理\n\njava.lang.reflect包中有提供给我们实现动态代理的类库，Proxy和InvocationHandler，来帮助我们实现基于接口的动态代理。\n\n创建代理对象\n```java\n@CallerSensitive\npublic static Object newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h) throws IllegalArgumentException\n```\n* ClassLoader loader：被代理类的ClassLoader\n* Class<?>[] interfaces：被代理类所实现的接口\n* InvocationHandler h：代理对象实例\n\n实现InvocationHandler接口，实现invoke方法，通过反射调用原方法。\n```java\npublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable;\n```\n* Object proxy：调用该方法的代理类的实例\n* Method method：代理方法\n* Object[] args：代理方法参数列表\n\n下面是一段非常简单的示例：\n```java\npublic interface IBusiness {\n    void doSomething();\n}\n\npublic class BusinessImpl implements IBusiness {\n    @Override\n    public void doSomething() {\n        System.out.println(\"do something ...\");\n    }\n}\n```\n\n```java\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\n\n/**\n * JDK proxy动态代理示例\n *\n * @Author: liu.bo\n * @CreateTime: 2018-12-05 10:36\n */\npublic class JDKProxyDemo01 {\n\n    public static void main(String[] args) {\n        BusinessImpl impl = new BusinessImpl();\n        BusinessProxy proxy = new BusinessProxy();\n        IBusiness iBusiness = (IBusiness) proxy.blind(impl);\n        iBusiness.doSomething();\n    }\n\n}\n\nclass BusinessProxy implements InvocationHandler {\n    private Object obj;\n\n    public Object blind(Object obj) {\n        this.obj = obj;\n        return Proxy.newProxyInstance(obj.getClass().getClassLoader(),\n                obj.getClass().getInterfaces(), this);\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        Object result = null;\n        System.out.println(\"before ...\");\n        result = method.invoke(obj, args);\n        System.out.println(\"after ...\");\n        return result;\n    }\n}\n```\n\n由示例可知，借助于JDK proxy实现动态代理的弊端，被代理类必须有接口，JDK动态代理其实也是基本接口实现的。因为通过接口指向实现类实例的多态方式，可以有效地将具体实现与调用解耦，便于后期的修改和维护。\n\nJDK动态代理是利用反射机制在运行时创建代理类的。核心是InvocationHandler。每一个代理的实例都会有一个关联的调用处理程序(InvocationHandler)。对待代理实例进行调用时，将对方法的调用进行编码并指派到它的调用处理器(InvocationHandler)的invoke方法。所以对代理对象实例方法的调用都是通过InvocationHandler中的invoke方法来完成的，而invoke方法会根据传入的代理对象、方法名称以及参数决定调用代理的哪个方法。\n\n关于JDK Proxy动态代理具体实现细节，可以参考[深入理解JDK动态代理机制](https://www.jianshu.com/p/471c80a7e831)，该篇文章很简洁的介绍了源码。\n\n## CGLIB实现动态代理\n\ncglib能够实现基于类的动态代理，生成业务类的子类，覆盖业务方法实现代理，因为采用的是继承，所以不能对final修饰的类进行代理。 \n\n### Enhancer\n\n实例Enhancer，通过该类对象创建代理实例。\n\n```java\npublic Enhancer() {\n    super(SOURCE);\n}\n\npublic void setSuperclass(Class superclass)\n\npublic void setCallback(final Callback callback)\n\npublic Object create()\n\npublic Object create(Class[] argumentTypes, Object[] arguments)\n```\n\n* setSuperclass：设置代理的父类\n* setCallback：设置代理回调\n    net.sf.cglib.proxy.Callback是一个用于标记的接口，net.sf.cglib.proxy.Enhancer使用的所有回调都会继承这个接口。\n* create：默认使用无参构造方法创建目标对象，如果需要调用有参构造方法应该使用net.sf.cglib.proxy.Enhancer.create(Class[], Object[])。该方法的第一个参数指明参数类型，第二个参数指明参数值。参数中的原子类型需要使用包装类。\n\n### CallBack\n\n![cglib_callback_photo](/image/cglib_callback.png)\n\n    net.sf.cglib.proxy.FixedValue：在强制一个特定方法返回固定值，在特定场景下非常有用且性能高。\n    net.sf.cglib.proxy.NoOp：它直接透传到父类的方法实现。\n    net.sf.cglib.proxy.LazyLoader：在被代理对象需要懒加载场景下非常有用，如果被代理对象加载完成，那么在以后的代理调用时会重复使用。\n    net.sf.cglib.proxy.Dispatcher：与net.sf.cglib.proxy.LazyLoader差不多，但每次调用代理方法时都会调用loadObject方法来加载被代理对象。\n    net.sf.cglib.proxy.ProxyRefDispatcher：与Dispatcher相同，但它的loadObject方法支持传入代理对象。\n    net.sf.cglib.proxy.MethodInterceptor：是最常用的回调类型，在基于代理的AOP实现中它经常被用来拦截方法调用。\n\n### 使用Enhancer创建代理对象\n\n先编写一个简单的代理示例：\n\n```java\npublic static void main(String[] args) {\n    Enhancer enhancer = new Enhancer();\n    enhancer.setSuperclass(BusinessImpl.class);\n    enhancer.setCallback(NoOp.INSTANCE);\n    BusinessImpl business = (BusinessImpl) enhancer.create();\n    business.doSomething();\n    System.out.println(business.getClass().getSuperclass());\n}\n```\n\n运行结果\n\n```\ndo something ...\nclass proxy.BusinessImpl\n```\n\n通过运行结果，最后生成的代理类的父类是我们的业务类，由此可以得出结论Enhancer生成的代理对象是设置的Superclass设置的子类。\n\n而我们使用的内置回调NoOp，实际上代理类没有做其他的代理操作，相当于直接调用了父业务类的方法。\n\n### 使用MethodInterceptor\n\n通过实现MethodInterceptor接口，可以将代理的所有方法调用都会被分派给net.sf.cglib.proxy.MethodInterceptor的intercept方法。intercept方法中可以调用底层对象。\n\n```java\npublic Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable\n```\n\n* obj：代理对象\n* method：被代理的方法\n* args：被代理方法的参数列表\n* methodProxy：代理方法\n\n```java\nimport net.sf.cglib.proxy.Enhancer;\nimport net.sf.cglib.proxy.MethodInterceptor;\nimport net.sf.cglib.proxy.MethodProxy;\nimport net.sf.cglib.proxy.NoOp;\n\nimport java.lang.reflect.Method;\n\n/**\n * @Description:\n * @Author: liu.bo\n * @CreateTime: 2018-12-05 09:40\n */\npublic class CglibProxyDemo01 {\n    public static void main(String[] args) {\n        BusinessImpl impl = new BusinessImpl();\n        Enhancer enhancer = new Enhancer();\n        enhancer.setSuperclass(impl.getClass());\n        enhancer.setCallback(new CglibProxy(impl));\n        BusinessImpl business = (BusinessImpl) enhancer.create();\n        business.doSomething();\n        System.out.println(business.getClass().getSuperclass());\n    }\n}\n\nclass CglibProxy implements MethodInterceptor {\n    private Object obj;\n\n    public CglibProxy(Object obj) {\n        this.obj = obj;\n    }\n\n    @Override\n    public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {\n        System.out.println(\"method:\" + method);\n        System.out.println(\"methodProxy:\" + methodProxy);\n        Object returnObj = null;\n        System.out.println(\"after...\");\n        returnObj = methodProxy.invoke(this.obj, args);\n        System.out.println(\"before...\");\n        return returnObj;\n    }\n}\n```\n运行结果\n```\nmethod:public void proxy.BusinessImpl.doSomething()\nmethodProxy:net.sf.cglib.proxy.MethodProxy@45ff54e6\nafter...\ndo something ...\nbefore...\nclass proxy.BusinessImpl\n```\n\n关于使用Method还是MethodProxy调用类方法，Method则是被代理类的方法，即通过反射调用。而MethodProxy则是cglib提供的被代理方法的代理。看了一些文章有讲到MethodProxy的执行效率更高，但具体没有研究过，有待验证。\n\n### CallbackFilter\n\nEnhancer还提供了CallbackFilter和多个Callbacks，通过下标的方式提供对于具体细化到方法粒度的回调。\n\n```java\npublic void setCallbacks(Callback[] callbacks)\n\npublic void setCallbackFilter(CallbackFilter filter)\n```\n\n因为设置CallbackFilter需要传入CallbackFilter接口实现类\n\n```java\n/**\n * Map methods of subclasses generated by {@link Enhancer} to a particular\n * callback. The type of the callbacks chosen for each method affects\n * the bytecode generated for that method in the subclass, and cannot\n * change for the life of the class.\n * <p>Note: {@link CallbackFilter} implementations are supposed to be\n * lightweight as cglib might keep {@link CallbackFilter} objects\n * alive to enable caching of generated classes. Prefer using {@code static}\n * classes for implementation of {@link CallbackFilter}.</p>\n */\npublic interface CallbackFilter {\n    /**\n     * Map a method to a callback.\n     * @param method the intercepted method\n     * @return the index into the array of callbacks (as specified by {@link Enhancer#setCallbacks}) to use for the method, \n     */\n    int accept(Method method);\n\n    /**\n     * The <code>CallbackFilter</code> in use affects which cached class\n     * the <code>Enhancer</code> will use, so this is a reminder that\n     * you should correctly implement <code>equals</code> and\n     * <code>hashCode</code> for custom <code>CallbackFilter</code>\n     * implementations in order to improve performance.\n    */\n    boolean equals(Object o);\n}\n```\n\n关于CallbackFilter，我们可以看下accept方法，主要作用为通过方法映射到不同的callback，方法的返回值是enhancer中设置的Callbacks的下标。\n\n举个栗子\n\n先增加两个方法，因为本身与接口无关，所以就直接在类中增加方法了。\n```java\npublic class BusinessImpl implements IBusiness {\n    @Override\n    public void doSomething() {\n        System.out.println(\"do something ...\");\n    }\n    public void doSomethingA() {\n        System.out.println(\"do something A ...\");\n    }\n    public void doSomethingB() {\n        System.out.println(\"do something B ...\");\n    }\n}\n```\n\n然后实现CallbackFilter，我们先设置方法A和方法B使用第二个Callback，默认使用第一个。\n```java\nclass DemoCallbackFilter implements net.sf.cglib.proxy.CallbackFilter {\n    @Override\n    public int accept(Method method) {\n        if(method.getName().equals(\"doSomethingA\") || method.getName().equals(\"doSomethingB\")){\n            return 1;\n        }\n        return 0;\n    }\n}\n```\n这里我们设置CallbackFilter，并且设置Callbacks，第一个设置为默认代理，第二个使用之前例子中的MethodInterceptor。\n\n```java\npublic static void main(String[] args) {\n    Enhancer enhancer = new Enhancer();\n    enhancer.setSuperclass(BusinessImpl.class);\n    Callback callBack_0 = NoOp.INSTANCE;\n    Callback callBack_1 = new CglibProxy(new BusinessImpl());\n    Callback[] callbacks = new Callback[]{callBack_0, callBack_1 };\n    enhancer.setCallbackFilter(new DemoCallbackFilter());\n    enhancer.setCallbacks(callbacks);\n    BusinessImpl business = (BusinessImpl) enhancer.create();\n    business.doSomething();\n    business.doSomethingA();\n    business.doSomethingB();\n}\n```\n\n运行结果如下\n```\ndo something ...\nmethodName:public void proxy.BusinessImpl.doSomethingA()\nmethodProxy:net.sf.cglib.proxy.MethodProxy@45283ce2\nafter...\ndo something A ...\nbefore...\nmethodName:public void proxy.BusinessImpl.doSomethingB()\nmethodProxy:net.sf.cglib.proxy.MethodProxy@3d71d552\nafter...\ndo something B ...\nbefore...\n```\n\n可以看出，通过CallbackFilter实现了对方法粒度的回调过滤。\n\n## 总结\n一般情况下都可以使用JDK动态代理方法来创建代理，对于没有接口的情况或者性能因素，CGLIB是一个很好的选择。而CGLIB是一个强大的高性能的代码生成库。作为JDK动态代理的互补，它对于那些没有实现接口的类提供了代理方案。在底层，它使用ASM字节码操纵框架。本质上来说，CGLIB通过产生子类覆盖非final方法来进行代理。它比使用Java反射的JDK动态代理方法更快。CGLIB不能代理一个final类或者final方法。\n\n## 参考资料\n* https://en.wikipedia.org/wiki/Proxy_pattern\n* https://www.jianshu.com/p/471c80a7e831\n* https://www.jianshu.com/p/9a61af393e41?from=timeline&isappinstalled=0\n* https://www.cnblogs.com/ygj0930/p/6542259.html\n* https://www.cnblogs.com/LCcnblogs/p/6823982.html\n* https://www.2cto.com/kf/201801/710319.html\n* https://www.cnblogs.com/xrq730/p/6661692.html\n* https://mp.weixin.qq.com/s/sS4QYvERlYFZh1EyXuDV3Q","slug":"proxy_pattern","published":1,"updated":"2019-08-26T07:53:01.213Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl40004lqotn98uugnh8","content":"<h1 id=\"代理模式-JAVA动态代理\"><a href=\"#代理模式-JAVA动态代理\" class=\"headerlink\" title=\"代理模式/JAVA动态代理\"></a>代理模式/JAVA动态代理</h1><blockquote>\n<p>在学习Spring AOP与RPC的实现时，总会与代理模式密不可分，而日常编码中代理模式也是常用的设计模式之一。学习代理模式与动态代理的实现与作用是非常有益于理解框架的源码实现，并且可以提高抽象思维。本文是个人在学习代理模式以及动态代理的一个小总结，没有过深的探讨。本文不会提及具体动态代理底层字节码框架的实现，之后有机会会补充Javassist和ASM字节码框架的文章。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><p><em><strong>计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决</strong></em></p>\n<p>代理模式被定位为：为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。</p>\n<p>代理设计模式是二十三种着名的GOF设计模式之一 ，它描述了如何解决重复出现的设计问题，以设计灵活且可重用的面向对象软件，即更容易实现，更改的对象，测试和重用。在JAVA中可以实现静态代理、动态代理，而动态代理常用的有JDK Proxy和CGLIB两种方式实现动态代理。</p>\n<h3 id=\"代理模式的核心作用\"><a href=\"#代理模式的核心作用\" class=\"headerlink\" title=\"代理模式的核心作用\"></a>代理模式的核心作用</h3><ul>\n<li>通过代理控制对对象的访问，做为隔离客户端和委托类的中介。</li>\n<li>借助代理增加一些功能，而不需要修改原有代码。符合开闭原则。</li>\n</ul>\n<p><img src=\"/image/W3sDesign_Proxy_Design_Pattern_UML.jpg\" alt=\"Proxy_design_UML_photo\"></p>\n<h3 id=\"静态代理与动态代理\"><a href=\"#静态代理与动态代理\" class=\"headerlink\" title=\"静态代理与动态代理\"></a>静态代理与动态代理</h3><p>静态代理一般指的显式指定的代理，由业务实现类、业务代理类两部分组成。业务实现类提供业务的主要实现，业务代理类负责对业务真正的实现进行调用，并且可以进行拦截、过滤、预处理。但静态代理对代码是有很大耦合性的，如果需要大量代理的使用，则需要动态代理。</p>\n<p>动态代理则是在程序运行时，根据需求动态的通过反射机制、字节码框架，动态生成代理类进行代理业务操作，极大程度的减少代理模式实现的编码量。</p>\n<h2 id=\"如何实现动态代理\"><a href=\"#如何实现动态代理\" class=\"headerlink\" title=\"如何实现动态代理\"></a>如何实现动态代理</h2><h3 id=\"JDK-Proxy实现动态代理\"><a href=\"#JDK-Proxy实现动态代理\" class=\"headerlink\" title=\"JDK Proxy实现动态代理\"></a>JDK Proxy实现动态代理</h3><p>java.lang.reflect包中有提供给我们实现动态代理的类库，Proxy和InvocationHandler，来帮助我们实现基于接口的动态代理。</p>\n<p>创建代理对象<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@CallerSensitive</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Object <span class=\"title\">newProxyInstance</span><span class=\"params\">(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h)</span> <span class=\"keyword\">throws</span> IllegalArgumentException</span></span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>ClassLoader loader：被代理类的ClassLoader</li>\n<li>Class&lt;?&gt;[] interfaces：被代理类所实现的接口</li>\n<li>InvocationHandler h：代理对象实例</li>\n</ul>\n<p>实现InvocationHandler接口，实现invoke方法，通过反射调用原方法。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">invoke</span><span class=\"params\">(Object proxy, Method method, Object[] args)</span> <span class=\"keyword\">throws</span> Throwable</span>;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>Object proxy：调用该方法的代理类的实例</li>\n<li>Method method：代理方法</li>\n<li>Object[] args：代理方法参数列表</li>\n</ul>\n<p>下面是一段非常简单的示例：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">IBusiness</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BusinessImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">IBusiness</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"do something ...\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.lang.reflect.InvocationHandler;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.lang.reflect.Method;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.lang.reflect.Proxy;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * JDK proxy动态代理示例</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Author</span>: liu.bo</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@CreateTime</span>: 2018-12-05 10:36</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JDKProxyDemo01</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        BusinessImpl impl = <span class=\"keyword\">new</span> BusinessImpl();</span><br><span class=\"line\">        BusinessProxy proxy = <span class=\"keyword\">new</span> BusinessProxy();</span><br><span class=\"line\">        IBusiness iBusiness = (IBusiness) proxy.blind(impl);</span><br><span class=\"line\">        iBusiness.doSomething();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BusinessProxy</span> <span class=\"keyword\">implements</span> <span class=\"title\">InvocationHandler</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> Object obj;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">blind</span><span class=\"params\">(Object obj)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.obj = obj;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Proxy.newProxyInstance(obj.getClass().getClassLoader(),</span><br><span class=\"line\">                obj.getClass().getInterfaces(), <span class=\"keyword\">this</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">invoke</span><span class=\"params\">(Object proxy, Method method, Object[] args)</span> <span class=\"keyword\">throws</span> Throwable </span>&#123;</span><br><span class=\"line\">        Object result = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"before ...\"</span>);</span><br><span class=\"line\">        result = method.invoke(obj, args);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"after ...\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由示例可知，借助于JDK proxy实现动态代理的弊端，被代理类必须有接口，JDK动态代理其实也是基本接口实现的。因为通过接口指向实现类实例的多态方式，可以有效地将具体实现与调用解耦，便于后期的修改和维护。</p>\n<p>JDK动态代理是利用反射机制在运行时创建代理类的。核心是InvocationHandler。每一个代理的实例都会有一个关联的调用处理程序(InvocationHandler)。对待代理实例进行调用时，将对方法的调用进行编码并指派到它的调用处理器(InvocationHandler)的invoke方法。所以对代理对象实例方法的调用都是通过InvocationHandler中的invoke方法来完成的，而invoke方法会根据传入的代理对象、方法名称以及参数决定调用代理的哪个方法。</p>\n<p>关于JDK Proxy动态代理具体实现细节，可以参考<a href=\"https://www.jianshu.com/p/471c80a7e831\" target=\"_blank\" rel=\"noopener\">深入理解JDK动态代理机制</a>，该篇文章很简洁的介绍了源码。</p>\n<h2 id=\"CGLIB实现动态代理\"><a href=\"#CGLIB实现动态代理\" class=\"headerlink\" title=\"CGLIB实现动态代理\"></a>CGLIB实现动态代理</h2><p>cglib能够实现基于类的动态代理，生成业务类的子类，覆盖业务方法实现代理，因为采用的是继承，所以不能对final修饰的类进行代理。 </p>\n<h3 id=\"Enhancer\"><a href=\"#Enhancer\" class=\"headerlink\" title=\"Enhancer\"></a>Enhancer</h3><p>实例Enhancer，通过该类对象创建代理实例。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Enhancer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">super</span>(SOURCE);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setSuperclass</span><span class=\"params\">(Class superclass)</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setCallback</span><span class=\"params\">(<span class=\"keyword\">final</span> Callback callback)</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">create</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">create</span><span class=\"params\">(Class[] argumentTypes, Object[] arguments)</span></span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>setSuperclass：设置代理的父类</li>\n<li>setCallback：设置代理回调<br>  net.sf.cglib.proxy.Callback是一个用于标记的接口，net.sf.cglib.proxy.Enhancer使用的所有回调都会继承这个接口。</li>\n<li>create：默认使用无参构造方法创建目标对象，如果需要调用有参构造方法应该使用net.sf.cglib.proxy.Enhancer.create(Class[], Object[])。该方法的第一个参数指明参数类型，第二个参数指明参数值。参数中的原子类型需要使用包装类。</li>\n</ul>\n<h3 id=\"CallBack\"><a href=\"#CallBack\" class=\"headerlink\" title=\"CallBack\"></a>CallBack</h3><p><img src=\"/image/cglib_callback.png\" alt=\"cglib_callback_photo\"></p>\n<pre><code>net.sf.cglib.proxy.FixedValue：在强制一个特定方法返回固定值，在特定场景下非常有用且性能高。\nnet.sf.cglib.proxy.NoOp：它直接透传到父类的方法实现。\nnet.sf.cglib.proxy.LazyLoader：在被代理对象需要懒加载场景下非常有用，如果被代理对象加载完成，那么在以后的代理调用时会重复使用。\nnet.sf.cglib.proxy.Dispatcher：与net.sf.cglib.proxy.LazyLoader差不多，但每次调用代理方法时都会调用loadObject方法来加载被代理对象。\nnet.sf.cglib.proxy.ProxyRefDispatcher：与Dispatcher相同，但它的loadObject方法支持传入代理对象。\nnet.sf.cglib.proxy.MethodInterceptor：是最常用的回调类型，在基于代理的AOP实现中它经常被用来拦截方法调用。\n</code></pre><h3 id=\"使用Enhancer创建代理对象\"><a href=\"#使用Enhancer创建代理对象\" class=\"headerlink\" title=\"使用Enhancer创建代理对象\"></a>使用Enhancer创建代理对象</h3><p>先编写一个简单的代理示例：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    Enhancer enhancer = <span class=\"keyword\">new</span> Enhancer();</span><br><span class=\"line\">    enhancer.setSuperclass(BusinessImpl.class);</span><br><span class=\"line\">    enhancer.setCallback(NoOp.INSTANCE);</span><br><span class=\"line\">    BusinessImpl business = (BusinessImpl) enhancer.create();</span><br><span class=\"line\">    business.doSomething();</span><br><span class=\"line\">    System.out.println(business.getClass().getSuperclass());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">do something ...</span><br><span class=\"line\">class proxy.BusinessImpl</span><br></pre></td></tr></table></figure>\n<p>通过运行结果，最后生成的代理类的父类是我们的业务类，由此可以得出结论Enhancer生成的代理对象是设置的Superclass设置的子类。</p>\n<p>而我们使用的内置回调NoOp，实际上代理类没有做其他的代理操作，相当于直接调用了父业务类的方法。</p>\n<h3 id=\"使用MethodInterceptor\"><a href=\"#使用MethodInterceptor\" class=\"headerlink\" title=\"使用MethodInterceptor\"></a>使用MethodInterceptor</h3><p>通过实现MethodInterceptor接口，可以将代理的所有方法调用都会被分派给net.sf.cglib.proxy.MethodInterceptor的intercept方法。intercept方法中可以调用底层对象。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">intercept</span><span class=\"params\">(Object obj, Method method, Object[] args, MethodProxy methodProxy)</span> <span class=\"keyword\">throws</span> Throwable</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>obj：代理对象</li>\n<li>method：被代理的方法</li>\n<li>args：被代理方法的参数列表</li>\n<li>methodProxy：代理方法</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> net.sf.cglib.proxy.Enhancer;</span><br><span class=\"line\"><span class=\"keyword\">import</span> net.sf.cglib.proxy.MethodInterceptor;</span><br><span class=\"line\"><span class=\"keyword\">import</span> net.sf.cglib.proxy.MethodProxy;</span><br><span class=\"line\"><span class=\"keyword\">import</span> net.sf.cglib.proxy.NoOp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.lang.reflect.Method;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Description</span>:</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Author</span>: liu.bo</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@CreateTime</span>: 2018-12-05 09:40</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CglibProxyDemo01</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        BusinessImpl impl = <span class=\"keyword\">new</span> BusinessImpl();</span><br><span class=\"line\">        Enhancer enhancer = <span class=\"keyword\">new</span> Enhancer();</span><br><span class=\"line\">        enhancer.setSuperclass(impl.getClass());</span><br><span class=\"line\">        enhancer.setCallback(<span class=\"keyword\">new</span> CglibProxy(impl));</span><br><span class=\"line\">        BusinessImpl business = (BusinessImpl) enhancer.create();</span><br><span class=\"line\">        business.doSomething();</span><br><span class=\"line\">        System.out.println(business.getClass().getSuperclass());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CglibProxy</span> <span class=\"keyword\">implements</span> <span class=\"title\">MethodInterceptor</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> Object obj;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">CglibProxy</span><span class=\"params\">(Object obj)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.obj = obj;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">intercept</span><span class=\"params\">(Object obj, Method method, Object[] args, MethodProxy methodProxy)</span> <span class=\"keyword\">throws</span> Throwable </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"method:\"</span> + method);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"methodProxy:\"</span> + methodProxy);</span><br><span class=\"line\">        Object returnObj = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"after...\"</span>);</span><br><span class=\"line\">        returnObj = methodProxy.invoke(<span class=\"keyword\">this</span>.obj, args);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"before...\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> returnObj;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行结果<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method:public void proxy.BusinessImpl.doSomething()</span><br><span class=\"line\">methodProxy:net.sf.cglib.proxy.MethodProxy@45ff54e6</span><br><span class=\"line\">after...</span><br><span class=\"line\">do something ...</span><br><span class=\"line\">before...</span><br><span class=\"line\">class proxy.BusinessImpl</span><br></pre></td></tr></table></figure></p>\n<p>关于使用Method还是MethodProxy调用类方法，Method则是被代理类的方法，即通过反射调用。而MethodProxy则是cglib提供的被代理方法的代理。看了一些文章有讲到MethodProxy的执行效率更高，但具体没有研究过，有待验证。</p>\n<h3 id=\"CallbackFilter\"><a href=\"#CallbackFilter\" class=\"headerlink\" title=\"CallbackFilter\"></a>CallbackFilter</h3><p>Enhancer还提供了CallbackFilter和多个Callbacks，通过下标的方式提供对于具体细化到方法粒度的回调。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setCallbacks</span><span class=\"params\">(Callback[] callbacks)</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setCallbackFilter</span><span class=\"params\">(CallbackFilter filter)</span></span></span><br></pre></td></tr></table></figure>\n<p>因为设置CallbackFilter需要传入CallbackFilter接口实现类</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Map methods of subclasses generated by &#123;<span class=\"doctag\">@link</span> Enhancer&#125; to a particular</span></span><br><span class=\"line\"><span class=\"comment\"> * callback. The type of the callbacks chosen for each method affects</span></span><br><span class=\"line\"><span class=\"comment\"> * the bytecode generated for that method in the subclass, and cannot</span></span><br><span class=\"line\"><span class=\"comment\"> * change for the life of the class.</span></span><br><span class=\"line\"><span class=\"comment\"> * &lt;p&gt;Note: &#123;<span class=\"doctag\">@link</span> CallbackFilter&#125; implementations are supposed to be</span></span><br><span class=\"line\"><span class=\"comment\"> * lightweight as cglib might keep &#123;<span class=\"doctag\">@link</span> CallbackFilter&#125; objects</span></span><br><span class=\"line\"><span class=\"comment\"> * alive to enable caching of generated classes. Prefer using &#123;<span class=\"doctag\">@code</span> static&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * classes for implementation of &#123;<span class=\"doctag\">@link</span> CallbackFilter&#125;.&lt;/p&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">CallbackFilter</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Map a method to a callback.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> method the intercepted method</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> the index into the array of callbacks (as specified by &#123;<span class=\"doctag\">@link</span> Enhancer#setCallbacks&#125;) to use for the method, </span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">accept</span><span class=\"params\">(Method method)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * The &lt;code&gt;CallbackFilter&lt;/code&gt; in use affects which cached class</span></span><br><span class=\"line\"><span class=\"comment\">     * the &lt;code&gt;Enhancer&lt;/code&gt; will use, so this is a reminder that</span></span><br><span class=\"line\"><span class=\"comment\">     * you should correctly implement &lt;code&gt;equals&lt;/code&gt; and</span></span><br><span class=\"line\"><span class=\"comment\">     * &lt;code&gt;hashCode&lt;/code&gt; for custom &lt;code&gt;CallbackFilter&lt;/code&gt;</span></span><br><span class=\"line\"><span class=\"comment\">     * implementations in order to improve performance.</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">boolean</span> <span class=\"title\">equals</span><span class=\"params\">(Object o)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>关于CallbackFilter，我们可以看下accept方法，主要作用为通过方法映射到不同的callback，方法的返回值是enhancer中设置的Callbacks的下标。</p>\n<p>举个栗子</p>\n<p>先增加两个方法，因为本身与接口无关，所以就直接在类中增加方法了。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BusinessImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">IBusiness</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"do something ...\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomethingA</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"do something A ...\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomethingB</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"do something B ...\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>然后实现CallbackFilter，我们先设置方法A和方法B使用第二个Callback，默认使用第一个。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DemoCallbackFilter</span> <span class=\"keyword\">implements</span> <span class=\"title\">net</span>.<span class=\"title\">sf</span>.<span class=\"title\">cglib</span>.<span class=\"title\">proxy</span>.<span class=\"title\">CallbackFilter</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">accept</span><span class=\"params\">(Method method)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(method.getName().equals(<span class=\"string\">\"doSomethingA\"</span>) || method.getName().equals(<span class=\"string\">\"doSomethingB\"</span>))&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>这里我们设置CallbackFilter，并且设置Callbacks，第一个设置为默认代理，第二个使用之前例子中的MethodInterceptor。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    Enhancer enhancer = <span class=\"keyword\">new</span> Enhancer();</span><br><span class=\"line\">    enhancer.setSuperclass(BusinessImpl.class);</span><br><span class=\"line\">    Callback callBack_0 = NoOp.INSTANCE;</span><br><span class=\"line\">    Callback callBack_1 = <span class=\"keyword\">new</span> CglibProxy(<span class=\"keyword\">new</span> BusinessImpl());</span><br><span class=\"line\">    Callback[] callbacks = <span class=\"keyword\">new</span> Callback[]&#123;callBack_0, callBack_1 &#125;;</span><br><span class=\"line\">    enhancer.setCallbackFilter(<span class=\"keyword\">new</span> DemoCallbackFilter());</span><br><span class=\"line\">    enhancer.setCallbacks(callbacks);</span><br><span class=\"line\">    BusinessImpl business = (BusinessImpl) enhancer.create();</span><br><span class=\"line\">    business.doSomething();</span><br><span class=\"line\">    business.doSomethingA();</span><br><span class=\"line\">    business.doSomethingB();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行结果如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">do something ...</span><br><span class=\"line\">methodName:public void proxy.BusinessImpl.doSomethingA()</span><br><span class=\"line\">methodProxy:net.sf.cglib.proxy.MethodProxy@45283ce2</span><br><span class=\"line\">after...</span><br><span class=\"line\">do something A ...</span><br><span class=\"line\">before...</span><br><span class=\"line\">methodName:public void proxy.BusinessImpl.doSomethingB()</span><br><span class=\"line\">methodProxy:net.sf.cglib.proxy.MethodProxy@3d71d552</span><br><span class=\"line\">after...</span><br><span class=\"line\">do something B ...</span><br><span class=\"line\">before...</span><br></pre></td></tr></table></figure></p>\n<p>可以看出，通过CallbackFilter实现了对方法粒度的回调过滤。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>一般情况下都可以使用JDK动态代理方法来创建代理，对于没有接口的情况或者性能因素，CGLIB是一个很好的选择。而CGLIB是一个强大的高性能的代码生成库。作为JDK动态代理的互补，它对于那些没有实现接口的类提供了代理方案。在底层，它使用ASM字节码操纵框架。本质上来说，CGLIB通过产生子类覆盖非final方法来进行代理。它比使用Java反射的JDK动态代理方法更快。CGLIB不能代理一个final类或者final方法。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Proxy_pattern\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Proxy_pattern</a></li>\n<li><a href=\"https://www.jianshu.com/p/471c80a7e831\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/471c80a7e831</a></li>\n<li><a href=\"https://www.jianshu.com/p/9a61af393e41?from=timeline&amp;isappinstalled=0\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/9a61af393e41?from=timeline&amp;isappinstalled=0</a></li>\n<li><a href=\"https://www.cnblogs.com/ygj0930/p/6542259.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/ygj0930/p/6542259.html</a></li>\n<li><a href=\"https://www.cnblogs.com/LCcnblogs/p/6823982.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/LCcnblogs/p/6823982.html</a></li>\n<li><a href=\"https://www.2cto.com/kf/201801/710319.html\" target=\"_blank\" rel=\"noopener\">https://www.2cto.com/kf/201801/710319.html</a></li>\n<li><a href=\"https://www.cnblogs.com/xrq730/p/6661692.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/xrq730/p/6661692.html</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/sS4QYvERlYFZh1EyXuDV3Q\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/sS4QYvERlYFZh1EyXuDV3Q</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"代理模式-JAVA动态代理\"><a href=\"#代理模式-JAVA动态代理\" class=\"headerlink\" title=\"代理模式/JAVA动态代理\"></a>代理模式/JAVA动态代理</h1><blockquote>\n<p>在学习Spring AOP与RPC的实现时，总会与代理模式密不可分，而日常编码中代理模式也是常用的设计模式之一。学习代理模式与动态代理的实现与作用是非常有益于理解框架的源码实现，并且可以提高抽象思维。本文是个人在学习代理模式以及动态代理的一个小总结，没有过深的探讨。本文不会提及具体动态代理底层字节码框架的实现，之后有机会会补充Javassist和ASM字节码框架的文章。</p>\n</blockquote>","more":"<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><p><em><strong>计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决</strong></em></p>\n<p>代理模式被定位为：为其他对象提供一种代理以控制对这个对象的访问。在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。</p>\n<p>代理设计模式是二十三种着名的GOF设计模式之一 ，它描述了如何解决重复出现的设计问题，以设计灵活且可重用的面向对象软件，即更容易实现，更改的对象，测试和重用。在JAVA中可以实现静态代理、动态代理，而动态代理常用的有JDK Proxy和CGLIB两种方式实现动态代理。</p>\n<h3 id=\"代理模式的核心作用\"><a href=\"#代理模式的核心作用\" class=\"headerlink\" title=\"代理模式的核心作用\"></a>代理模式的核心作用</h3><ul>\n<li>通过代理控制对对象的访问，做为隔离客户端和委托类的中介。</li>\n<li>借助代理增加一些功能，而不需要修改原有代码。符合开闭原则。</li>\n</ul>\n<p><img src=\"/image/W3sDesign_Proxy_Design_Pattern_UML.jpg\" alt=\"Proxy_design_UML_photo\"></p>\n<h3 id=\"静态代理与动态代理\"><a href=\"#静态代理与动态代理\" class=\"headerlink\" title=\"静态代理与动态代理\"></a>静态代理与动态代理</h3><p>静态代理一般指的显式指定的代理，由业务实现类、业务代理类两部分组成。业务实现类提供业务的主要实现，业务代理类负责对业务真正的实现进行调用，并且可以进行拦截、过滤、预处理。但静态代理对代码是有很大耦合性的，如果需要大量代理的使用，则需要动态代理。</p>\n<p>动态代理则是在程序运行时，根据需求动态的通过反射机制、字节码框架，动态生成代理类进行代理业务操作，极大程度的减少代理模式实现的编码量。</p>\n<h2 id=\"如何实现动态代理\"><a href=\"#如何实现动态代理\" class=\"headerlink\" title=\"如何实现动态代理\"></a>如何实现动态代理</h2><h3 id=\"JDK-Proxy实现动态代理\"><a href=\"#JDK-Proxy实现动态代理\" class=\"headerlink\" title=\"JDK Proxy实现动态代理\"></a>JDK Proxy实现动态代理</h3><p>java.lang.reflect包中有提供给我们实现动态代理的类库，Proxy和InvocationHandler，来帮助我们实现基于接口的动态代理。</p>\n<p>创建代理对象<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@CallerSensitive</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Object <span class=\"title\">newProxyInstance</span><span class=\"params\">(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h)</span> <span class=\"keyword\">throws</span> IllegalArgumentException</span></span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>ClassLoader loader：被代理类的ClassLoader</li>\n<li>Class&lt;?&gt;[] interfaces：被代理类所实现的接口</li>\n<li>InvocationHandler h：代理对象实例</li>\n</ul>\n<p>实现InvocationHandler接口，实现invoke方法，通过反射调用原方法。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">invoke</span><span class=\"params\">(Object proxy, Method method, Object[] args)</span> <span class=\"keyword\">throws</span> Throwable</span>;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>Object proxy：调用该方法的代理类的实例</li>\n<li>Method method：代理方法</li>\n<li>Object[] args：代理方法参数列表</li>\n</ul>\n<p>下面是一段非常简单的示例：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">IBusiness</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span></span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BusinessImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">IBusiness</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"do something ...\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.lang.reflect.InvocationHandler;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.lang.reflect.Method;</span><br><span class=\"line\"><span class=\"keyword\">import</span> java.lang.reflect.Proxy;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * JDK proxy动态代理示例</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Author</span>: liu.bo</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@CreateTime</span>: 2018-12-05 10:36</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JDKProxyDemo01</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        BusinessImpl impl = <span class=\"keyword\">new</span> BusinessImpl();</span><br><span class=\"line\">        BusinessProxy proxy = <span class=\"keyword\">new</span> BusinessProxy();</span><br><span class=\"line\">        IBusiness iBusiness = (IBusiness) proxy.blind(impl);</span><br><span class=\"line\">        iBusiness.doSomething();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BusinessProxy</span> <span class=\"keyword\">implements</span> <span class=\"title\">InvocationHandler</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> Object obj;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">blind</span><span class=\"params\">(Object obj)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.obj = obj;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> Proxy.newProxyInstance(obj.getClass().getClassLoader(),</span><br><span class=\"line\">                obj.getClass().getInterfaces(), <span class=\"keyword\">this</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">invoke</span><span class=\"params\">(Object proxy, Method method, Object[] args)</span> <span class=\"keyword\">throws</span> Throwable </span>&#123;</span><br><span class=\"line\">        Object result = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"before ...\"</span>);</span><br><span class=\"line\">        result = method.invoke(obj, args);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"after ...\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>由示例可知，借助于JDK proxy实现动态代理的弊端，被代理类必须有接口，JDK动态代理其实也是基本接口实现的。因为通过接口指向实现类实例的多态方式，可以有效地将具体实现与调用解耦，便于后期的修改和维护。</p>\n<p>JDK动态代理是利用反射机制在运行时创建代理类的。核心是InvocationHandler。每一个代理的实例都会有一个关联的调用处理程序(InvocationHandler)。对待代理实例进行调用时，将对方法的调用进行编码并指派到它的调用处理器(InvocationHandler)的invoke方法。所以对代理对象实例方法的调用都是通过InvocationHandler中的invoke方法来完成的，而invoke方法会根据传入的代理对象、方法名称以及参数决定调用代理的哪个方法。</p>\n<p>关于JDK Proxy动态代理具体实现细节，可以参考<a href=\"https://www.jianshu.com/p/471c80a7e831\" target=\"_blank\" rel=\"noopener\">深入理解JDK动态代理机制</a>，该篇文章很简洁的介绍了源码。</p>\n<h2 id=\"CGLIB实现动态代理\"><a href=\"#CGLIB实现动态代理\" class=\"headerlink\" title=\"CGLIB实现动态代理\"></a>CGLIB实现动态代理</h2><p>cglib能够实现基于类的动态代理，生成业务类的子类，覆盖业务方法实现代理，因为采用的是继承，所以不能对final修饰的类进行代理。 </p>\n<h3 id=\"Enhancer\"><a href=\"#Enhancer\" class=\"headerlink\" title=\"Enhancer\"></a>Enhancer</h3><p>实例Enhancer，通过该类对象创建代理实例。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Enhancer</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">super</span>(SOURCE);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setSuperclass</span><span class=\"params\">(Class superclass)</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setCallback</span><span class=\"params\">(<span class=\"keyword\">final</span> Callback callback)</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">create</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">create</span><span class=\"params\">(Class[] argumentTypes, Object[] arguments)</span></span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>setSuperclass：设置代理的父类</li>\n<li>setCallback：设置代理回调<br>  net.sf.cglib.proxy.Callback是一个用于标记的接口，net.sf.cglib.proxy.Enhancer使用的所有回调都会继承这个接口。</li>\n<li>create：默认使用无参构造方法创建目标对象，如果需要调用有参构造方法应该使用net.sf.cglib.proxy.Enhancer.create(Class[], Object[])。该方法的第一个参数指明参数类型，第二个参数指明参数值。参数中的原子类型需要使用包装类。</li>\n</ul>\n<h3 id=\"CallBack\"><a href=\"#CallBack\" class=\"headerlink\" title=\"CallBack\"></a>CallBack</h3><p><img src=\"/image/cglib_callback.png\" alt=\"cglib_callback_photo\"></p>\n<pre><code>net.sf.cglib.proxy.FixedValue：在强制一个特定方法返回固定值，在特定场景下非常有用且性能高。\nnet.sf.cglib.proxy.NoOp：它直接透传到父类的方法实现。\nnet.sf.cglib.proxy.LazyLoader：在被代理对象需要懒加载场景下非常有用，如果被代理对象加载完成，那么在以后的代理调用时会重复使用。\nnet.sf.cglib.proxy.Dispatcher：与net.sf.cglib.proxy.LazyLoader差不多，但每次调用代理方法时都会调用loadObject方法来加载被代理对象。\nnet.sf.cglib.proxy.ProxyRefDispatcher：与Dispatcher相同，但它的loadObject方法支持传入代理对象。\nnet.sf.cglib.proxy.MethodInterceptor：是最常用的回调类型，在基于代理的AOP实现中它经常被用来拦截方法调用。\n</code></pre><h3 id=\"使用Enhancer创建代理对象\"><a href=\"#使用Enhancer创建代理对象\" class=\"headerlink\" title=\"使用Enhancer创建代理对象\"></a>使用Enhancer创建代理对象</h3><p>先编写一个简单的代理示例：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    Enhancer enhancer = <span class=\"keyword\">new</span> Enhancer();</span><br><span class=\"line\">    enhancer.setSuperclass(BusinessImpl.class);</span><br><span class=\"line\">    enhancer.setCallback(NoOp.INSTANCE);</span><br><span class=\"line\">    BusinessImpl business = (BusinessImpl) enhancer.create();</span><br><span class=\"line\">    business.doSomething();</span><br><span class=\"line\">    System.out.println(business.getClass().getSuperclass());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">do something ...</span><br><span class=\"line\">class proxy.BusinessImpl</span><br></pre></td></tr></table></figure>\n<p>通过运行结果，最后生成的代理类的父类是我们的业务类，由此可以得出结论Enhancer生成的代理对象是设置的Superclass设置的子类。</p>\n<p>而我们使用的内置回调NoOp，实际上代理类没有做其他的代理操作，相当于直接调用了父业务类的方法。</p>\n<h3 id=\"使用MethodInterceptor\"><a href=\"#使用MethodInterceptor\" class=\"headerlink\" title=\"使用MethodInterceptor\"></a>使用MethodInterceptor</h3><p>通过实现MethodInterceptor接口，可以将代理的所有方法调用都会被分派给net.sf.cglib.proxy.MethodInterceptor的intercept方法。intercept方法中可以调用底层对象。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">intercept</span><span class=\"params\">(Object obj, Method method, Object[] args, MethodProxy methodProxy)</span> <span class=\"keyword\">throws</span> Throwable</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>obj：代理对象</li>\n<li>method：被代理的方法</li>\n<li>args：被代理方法的参数列表</li>\n<li>methodProxy：代理方法</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> net.sf.cglib.proxy.Enhancer;</span><br><span class=\"line\"><span class=\"keyword\">import</span> net.sf.cglib.proxy.MethodInterceptor;</span><br><span class=\"line\"><span class=\"keyword\">import</span> net.sf.cglib.proxy.MethodProxy;</span><br><span class=\"line\"><span class=\"keyword\">import</span> net.sf.cglib.proxy.NoOp;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.lang.reflect.Method;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Description</span>:</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@Author</span>: liu.bo</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@CreateTime</span>: 2018-12-05 09:40</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CglibProxyDemo01</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">        BusinessImpl impl = <span class=\"keyword\">new</span> BusinessImpl();</span><br><span class=\"line\">        Enhancer enhancer = <span class=\"keyword\">new</span> Enhancer();</span><br><span class=\"line\">        enhancer.setSuperclass(impl.getClass());</span><br><span class=\"line\">        enhancer.setCallback(<span class=\"keyword\">new</span> CglibProxy(impl));</span><br><span class=\"line\">        BusinessImpl business = (BusinessImpl) enhancer.create();</span><br><span class=\"line\">        business.doSomething();</span><br><span class=\"line\">        System.out.println(business.getClass().getSuperclass());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CglibProxy</span> <span class=\"keyword\">implements</span> <span class=\"title\">MethodInterceptor</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> Object obj;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">CglibProxy</span><span class=\"params\">(Object obj)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.obj = obj;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Object <span class=\"title\">intercept</span><span class=\"params\">(Object obj, Method method, Object[] args, MethodProxy methodProxy)</span> <span class=\"keyword\">throws</span> Throwable </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"method:\"</span> + method);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"methodProxy:\"</span> + methodProxy);</span><br><span class=\"line\">        Object returnObj = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"after...\"</span>);</span><br><span class=\"line\">        returnObj = methodProxy.invoke(<span class=\"keyword\">this</span>.obj, args);</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"before...\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> returnObj;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行结果<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">method:public void proxy.BusinessImpl.doSomething()</span><br><span class=\"line\">methodProxy:net.sf.cglib.proxy.MethodProxy@45ff54e6</span><br><span class=\"line\">after...</span><br><span class=\"line\">do something ...</span><br><span class=\"line\">before...</span><br><span class=\"line\">class proxy.BusinessImpl</span><br></pre></td></tr></table></figure></p>\n<p>关于使用Method还是MethodProxy调用类方法，Method则是被代理类的方法，即通过反射调用。而MethodProxy则是cglib提供的被代理方法的代理。看了一些文章有讲到MethodProxy的执行效率更高，但具体没有研究过，有待验证。</p>\n<h3 id=\"CallbackFilter\"><a href=\"#CallbackFilter\" class=\"headerlink\" title=\"CallbackFilter\"></a>CallbackFilter</h3><p>Enhancer还提供了CallbackFilter和多个Callbacks，通过下标的方式提供对于具体细化到方法粒度的回调。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setCallbacks</span><span class=\"params\">(Callback[] callbacks)</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setCallbackFilter</span><span class=\"params\">(CallbackFilter filter)</span></span></span><br></pre></td></tr></table></figure>\n<p>因为设置CallbackFilter需要传入CallbackFilter接口实现类</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Map methods of subclasses generated by &#123;<span class=\"doctag\">@link</span> Enhancer&#125; to a particular</span></span><br><span class=\"line\"><span class=\"comment\"> * callback. The type of the callbacks chosen for each method affects</span></span><br><span class=\"line\"><span class=\"comment\"> * the bytecode generated for that method in the subclass, and cannot</span></span><br><span class=\"line\"><span class=\"comment\"> * change for the life of the class.</span></span><br><span class=\"line\"><span class=\"comment\"> * &lt;p&gt;Note: &#123;<span class=\"doctag\">@link</span> CallbackFilter&#125; implementations are supposed to be</span></span><br><span class=\"line\"><span class=\"comment\"> * lightweight as cglib might keep &#123;<span class=\"doctag\">@link</span> CallbackFilter&#125; objects</span></span><br><span class=\"line\"><span class=\"comment\"> * alive to enable caching of generated classes. Prefer using &#123;<span class=\"doctag\">@code</span> static&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * classes for implementation of &#123;<span class=\"doctag\">@link</span> CallbackFilter&#125;.&lt;/p&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">interface</span> <span class=\"title\">CallbackFilter</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * Map a method to a callback.</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> method the intercepted method</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@return</span> the index into the array of callbacks (as specified by &#123;<span class=\"doctag\">@link</span> Enhancer#setCallbacks&#125;) to use for the method, </span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">accept</span><span class=\"params\">(Method method)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * The &lt;code&gt;CallbackFilter&lt;/code&gt; in use affects which cached class</span></span><br><span class=\"line\"><span class=\"comment\">     * the &lt;code&gt;Enhancer&lt;/code&gt; will use, so this is a reminder that</span></span><br><span class=\"line\"><span class=\"comment\">     * you should correctly implement &lt;code&gt;equals&lt;/code&gt; and</span></span><br><span class=\"line\"><span class=\"comment\">     * &lt;code&gt;hashCode&lt;/code&gt; for custom &lt;code&gt;CallbackFilter&lt;/code&gt;</span></span><br><span class=\"line\"><span class=\"comment\">     * implementations in order to improve performance.</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">boolean</span> <span class=\"title\">equals</span><span class=\"params\">(Object o)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>关于CallbackFilter，我们可以看下accept方法，主要作用为通过方法映射到不同的callback，方法的返回值是enhancer中设置的Callbacks的下标。</p>\n<p>举个栗子</p>\n<p>先增加两个方法，因为本身与接口无关，所以就直接在类中增加方法了。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">BusinessImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">IBusiness</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomething</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"do something ...\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomethingA</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"do something A ...\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">doSomethingB</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(<span class=\"string\">\"do something B ...\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>然后实现CallbackFilter，我们先设置方法A和方法B使用第二个Callback，默认使用第一个。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">DemoCallbackFilter</span> <span class=\"keyword\">implements</span> <span class=\"title\">net</span>.<span class=\"title\">sf</span>.<span class=\"title\">cglib</span>.<span class=\"title\">proxy</span>.<span class=\"title\">CallbackFilter</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">accept</span><span class=\"params\">(Method method)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(method.getName().equals(<span class=\"string\">\"doSomethingA\"</span>) || method.getName().equals(<span class=\"string\">\"doSomethingB\"</span>))&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>这里我们设置CallbackFilter，并且设置Callbacks，第一个设置为默认代理，第二个使用之前例子中的MethodInterceptor。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    Enhancer enhancer = <span class=\"keyword\">new</span> Enhancer();</span><br><span class=\"line\">    enhancer.setSuperclass(BusinessImpl.class);</span><br><span class=\"line\">    Callback callBack_0 = NoOp.INSTANCE;</span><br><span class=\"line\">    Callback callBack_1 = <span class=\"keyword\">new</span> CglibProxy(<span class=\"keyword\">new</span> BusinessImpl());</span><br><span class=\"line\">    Callback[] callbacks = <span class=\"keyword\">new</span> Callback[]&#123;callBack_0, callBack_1 &#125;;</span><br><span class=\"line\">    enhancer.setCallbackFilter(<span class=\"keyword\">new</span> DemoCallbackFilter());</span><br><span class=\"line\">    enhancer.setCallbacks(callbacks);</span><br><span class=\"line\">    BusinessImpl business = (BusinessImpl) enhancer.create();</span><br><span class=\"line\">    business.doSomething();</span><br><span class=\"line\">    business.doSomethingA();</span><br><span class=\"line\">    business.doSomethingB();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>运行结果如下<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">do something ...</span><br><span class=\"line\">methodName:public void proxy.BusinessImpl.doSomethingA()</span><br><span class=\"line\">methodProxy:net.sf.cglib.proxy.MethodProxy@45283ce2</span><br><span class=\"line\">after...</span><br><span class=\"line\">do something A ...</span><br><span class=\"line\">before...</span><br><span class=\"line\">methodName:public void proxy.BusinessImpl.doSomethingB()</span><br><span class=\"line\">methodProxy:net.sf.cglib.proxy.MethodProxy@3d71d552</span><br><span class=\"line\">after...</span><br><span class=\"line\">do something B ...</span><br><span class=\"line\">before...</span><br></pre></td></tr></table></figure></p>\n<p>可以看出，通过CallbackFilter实现了对方法粒度的回调过滤。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>一般情况下都可以使用JDK动态代理方法来创建代理，对于没有接口的情况或者性能因素，CGLIB是一个很好的选择。而CGLIB是一个强大的高性能的代码生成库。作为JDK动态代理的互补，它对于那些没有实现接口的类提供了代理方案。在底层，它使用ASM字节码操纵框架。本质上来说，CGLIB通过产生子类覆盖非final方法来进行代理。它比使用Java反射的JDK动态代理方法更快。CGLIB不能代理一个final类或者final方法。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Proxy_pattern\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Proxy_pattern</a></li>\n<li><a href=\"https://www.jianshu.com/p/471c80a7e831\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/471c80a7e831</a></li>\n<li><a href=\"https://www.jianshu.com/p/9a61af393e41?from=timeline&amp;isappinstalled=0\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/9a61af393e41?from=timeline&amp;isappinstalled=0</a></li>\n<li><a href=\"https://www.cnblogs.com/ygj0930/p/6542259.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/ygj0930/p/6542259.html</a></li>\n<li><a href=\"https://www.cnblogs.com/LCcnblogs/p/6823982.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/LCcnblogs/p/6823982.html</a></li>\n<li><a href=\"https://www.2cto.com/kf/201801/710319.html\" target=\"_blank\" rel=\"noopener\">https://www.2cto.com/kf/201801/710319.html</a></li>\n<li><a href=\"https://www.cnblogs.com/xrq730/p/6661692.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/xrq730/p/6661692.html</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/sS4QYvERlYFZh1EyXuDV3Q\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/sS4QYvERlYFZh1EyXuDV3Q</a></li>\n</ul>"},{"title":"设计模式六大原则","date":"2019-01-16T03:18:00.000Z","_content":"\n# 设计模式六大原则\n\n> 前段时间一直都在学习设计模式相关的知识，总结了下设计模式相关知识，其中设计模式的六大原则个人认为尤为重要，非常有助于理解设计模式。本文内容全部摘要自[刘伟技术博客](https://blog.csdn.net/LoveLion/article/category/738450/7 \"刘伟技术博客\")，总结了下相关的知识点进行了记录。\n\n<!-- more -->\n\n## 单一职责原则\n\n单一职责原则是最简单的面向对象设计原则，它用于控制类的粒度大小。单一职责原则定义如下：\n\n> 单一职责原则(Single Responsibility Principle, SRP)：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。\n\n单一职责原则告诉我们：一个类不能太“累”！在软件系统中，一个类（大到模块，小到方法）承担的职责越多，它被复用的可能性就越小，而且一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离，将不同的职责封装在不同的类中，即将不同的变化原因封装在不同的类中，如果多个职责总是同时发生改变则可将它们封装在同一类中。\n\n单一职责原则是实现高内聚、低耦合的指导方针，它是最简单但又最难运用的原则，需要设计人员发现类的不同职责并将其分离，而发现类的多重职责需要设计人员具有较强的分析设计能力和相关实践经验。\n\n## 开闭原则\n\n开闭原则是面向对象的可复用设计的第一块基石，它是最重要的面向对象设计原则。开闭原则由Bertrand  Meyer于1988年提出，其定义如下：\n\n> 开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。\n\n在开闭原则的定义中，软件实体可以指一个软件模块、一个由多个类组成的局部结构或一个独立的类。\n\n任何软件都需要面临一个很重要的问题，即它们的需求会随时间的推移而发生变化。当软件系统需要面对新的需求时，我们应该尽量保证系统的设计框架是稳定的。如果一个软件设计符合开闭原则，那么可以非常方便地对系统进行扩展，而且在扩展时无须修改现有代码，使得软件系统在拥有适应性和灵活性的同时具备较好的稳定性和延续性。随着软件规模越来越大，软件寿命越来越长，软件维护成本越来越高，设计满足开闭原则的软件系统也变得越来越重要。\n\n为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。在Java、C#等编程语言中，可以为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。在很多面向对象编程语言中都提供了接口、抽象类等机制，可以通过它们定义系统的抽象层，再通过具体类来进行扩展。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。\n\n## 里氏替换原则\n\n里氏代换原则由2008年图灵奖得主、美国第一位计算机科学女博士Barbara Liskov教授和卡内基·梅隆大学Jeannette Wing教授于1994年提出。其严格表述如下：如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1代换o2时，程序P的行为没有变化，那么类型S是类型T的子类型。这个定义比较拗口且难以理解，因此我们一般使用它的另一个通俗版定义：\n\n> 里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。\n\n里氏代换原则告诉我们，在软件中将一个基类对象替换成它的子类对象，程序将不会产生任何错误和异常，反过来则不成立，如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。例如：我喜欢动物，那我一定喜欢狗，因为狗是动物的子类；但是我喜欢狗，不能据此断定我喜欢动物，因为我并不喜欢老鼠，虽然它也是动物。\n\n例如有两个类，一个类为BaseClass，另一个是SubClass类，并且SubClass类是BaseClass类的子类，那么一个方法如果可以接受一个BaseClass类型的基类对象base的话，如：method1(base)，那么它必然可以接受一个BaseClass类型的子类对象sub，method1(sub)能够正常运行。反过来的代换不成立，如一个方法method2接受BaseClass类型的子类对象sub为参数：method2(sub)，那么一般而言不可以有method2(base)，除非是重载方法。\n\n里氏代换原则是实现开闭原则的重要方式之一，由于使用基类对象的地方都可以使用子类对象，因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。\n\n在使用里氏代换原则时需要注意如下几个问题：\n\n1. 子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。\n\n2. 我们在运用里氏代换原则时，尽量把父类设计为抽象类或者接口，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。\n\n3. Java语言中，在编译阶段，Java编译器会检查一个程序是否符合里氏代换原则，这是一个与实现无关的、纯语法意义上的检查，但Java编译器的检查是有局限的。\n\n里氏代换原则是实现开闭原则的重要方式之一。在本实例中，在传递参数时使用基类对象，除此以外，在定义成员变量、定义局部变量、确定方法返回类型时都可使用里氏代换原则。针对基类编程，在程序运行时再确定具体子类。\n\n## 依赖倒置原则\n\n如果说开闭原则是面向对象设计的目标的话，那么依赖倒转原则就是面向对象设计的主要实现机制之一，它是系统抽象化的具体实现。依赖倒转原则是Robert C. Martin在1996年为“C++Reporter”所写的专栏Engineering Notebook的第三篇，后来加入到他在2002年出版的经典著作“Agile Software Development, Principles, Patterns, and Practices”一书中。依赖倒转原则定义如下：\n\n> 依赖倒转原则(Dependency Inversion  Principle, DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。\n\n依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。\n\n在引入抽象层后，系统将具有很好的灵活性，在程序中尽量使用抽象层进行编程，而将具体类写在配置文件中，这样一来，如果系统行为发生变化，只需要对抽象层进行扩展，并修改配置文件，而无须修改原有系统的源代码，在不修改的情况下来扩展系统的功能，满足开闭原则的要求。\n\n在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和接口注入。构造注入是指通过构造函数来传入具体类的对象，设值注入是指通过Setter方法来传入具体类的对象，而接口注入是指通过在接口中声明的业务方法来传入具体类的对象。这些方法在定义时使用的是抽象类型，在运行时再传入具体类型的对象，由子类对象来覆盖父类对象。\n\n开闭原则、里氏代换原则和依赖倒转原则，在大多数情况下，这三个设计原则会同时出现，开闭原则是目标，里氏代换原则是基础，依赖倒转原则是手段，它们相辅相成，相互补充，目标一致，只是分析问题时所站角度不同而已。\n\n## 接口隔离原则\n\n> 接口隔离原则(Interface  Segregation Principle, ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。\n\n根据接口隔离原则，当一个接口太大时，我们需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。每一个接口应该承担一种相对独立的角色，不干不该干的事，该干的事都要干。这里的“接口”往往有两种不同的含义：一种是指一个类型所具有的方法特征的集合，仅仅是一种逻辑上的抽象；另外一种是指某种语言具体的“接口”定义，有严格的定义和结构，比如Java语言中的interface。对于这两种不同的含义，ISP的表达方式以及含义都有所不同：\n\n1. 当把“接口”理解成一个类型所提供的所有方法特征的集合的时候，这就是一种逻辑上的概念，接口的划分将直接带来类型的划分。可以把接口理解成角色，一个接口只能代表一个角色，每个角色都有它特定的一个接口，此时，这个原则可以叫做“角色隔离原则”。\n\n2. 如果把“接口”理解成狭义的特定语言的接口，那么ISP表达的意思是指接口仅仅提供客户端需要的行为，客户端不需要的行为则隐藏起来，应当为客户端提供尽可能小的单独的接口，而不要提供大的总接口。在面向对象编程语言中，实现一个接口就需要实现该接口中定义的所有方法，因此大的总接口使用起来不一定很方便，为了使接口的职责单一，需要将大接口中的方法根据其职责不同分别放在不同的小接口中，以确保每个接口使用起来都较为方便，并都承担某一单一角色。接口应该尽量细化，同时接口中的方法应该尽量少，每个接口中只包含一个客户端（如子模块或业务逻辑类）所需的方法即可，这种机制也称为“定制服务”，即为不同的客户端提供宽窄不同的接口。\n\n在使用接口隔离原则时，我们需要注意控制接口的粒度，接口不能太小，如果太小会导致系统中接口泛滥，不利于维护；接口也不能太大，太大的接口将违背接口隔离原则，灵活性较差，使用起来很不方便。一般而言，接口中仅包含为某一类用户定制的方法即可，不应该强迫客户依赖于那些它们不用的方法。\n\n## 迪米特法则\n\n迪米特法则来自于1987年美国东北大学(Northeastern University)一个名为“Demeter”的研究项目。迪米特法则又称为最少知识原则(LeastKnowledge Principle, LKP)，其定义如下：\n\n> 迪米特法则(Law of  Demeter, LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。\n\n如果一个系统符合迪米特法则，那么当其中某一个模块发生修改时，就会尽量少地影响其他模块，扩展会相对容易，这是对软件实体之间通信的限制，迪米特法则要求限制软件实体之间通信的宽度和深度。迪米特法则可降低系统的耦合度，使类与类之间保持松散的耦合关系。\n\n迪米特法则还有几种定义形式，包括：不要和“陌生人”说话、只与你的直接朋友通信等，在迪米特法则中，对于一个对象，其朋友包括以下几类：\n\n1. 当前对象本身(this)；\n2. 以参数形式传入到当前对象方法中的对象；\n3. 当前对象的成员对象；\n4. 如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友；\n5. 当前对象所创建的对象。\n\n任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”，否则就是“陌生人”。在应用迪米特法则时，一个对象只能与直接朋友发生交互，不要与“陌生人”发生直接交互，这样做可以降低系统的耦合度，一个对象的改变不会给太多其他对象带来影响。\n\n迪米特法则要求我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。\n\n将迪米特法则运用到系统设计中时，要注意下面的几点：在类的划分上，应当尽量创建松耦合的类，类之间的耦合度越低，就越有利于复用，一个处在松耦合中的类一旦被修改，不会对关联的类造成太大波及；在类的结构设计上，每一个类都应当尽量降低其成员变量和成员函数的访问权限；在类的设计上，只要有可能，一个类型应当设计成不变类；在对其他类的引用上，一个对象对其他对象的引用应当降到最低。\n\n# 参考资料\n* http://blog.csdn.net/zhengzhb/article/details/7281833\n* https://blog.csdn.net/LoveLion/article/category/738450/7\n* https://baijiahao.baidu.com/s?id=1591642387721949859&wfr=spider&for=pc","source":"_posts/pattern.md","raw":"---\ntitle: 设计模式六大原则\ndate: 2019-01-16 11:18:00\ntags: 设计模式\ncategories: 设计模式\n---\n\n# 设计模式六大原则\n\n> 前段时间一直都在学习设计模式相关的知识，总结了下设计模式相关知识，其中设计模式的六大原则个人认为尤为重要，非常有助于理解设计模式。本文内容全部摘要自[刘伟技术博客](https://blog.csdn.net/LoveLion/article/category/738450/7 \"刘伟技术博客\")，总结了下相关的知识点进行了记录。\n\n<!-- more -->\n\n## 单一职责原则\n\n单一职责原则是最简单的面向对象设计原则，它用于控制类的粒度大小。单一职责原则定义如下：\n\n> 单一职责原则(Single Responsibility Principle, SRP)：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。\n\n单一职责原则告诉我们：一个类不能太“累”！在软件系统中，一个类（大到模块，小到方法）承担的职责越多，它被复用的可能性就越小，而且一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离，将不同的职责封装在不同的类中，即将不同的变化原因封装在不同的类中，如果多个职责总是同时发生改变则可将它们封装在同一类中。\n\n单一职责原则是实现高内聚、低耦合的指导方针，它是最简单但又最难运用的原则，需要设计人员发现类的不同职责并将其分离，而发现类的多重职责需要设计人员具有较强的分析设计能力和相关实践经验。\n\n## 开闭原则\n\n开闭原则是面向对象的可复用设计的第一块基石，它是最重要的面向对象设计原则。开闭原则由Bertrand  Meyer于1988年提出，其定义如下：\n\n> 开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。\n\n在开闭原则的定义中，软件实体可以指一个软件模块、一个由多个类组成的局部结构或一个独立的类。\n\n任何软件都需要面临一个很重要的问题，即它们的需求会随时间的推移而发生变化。当软件系统需要面对新的需求时，我们应该尽量保证系统的设计框架是稳定的。如果一个软件设计符合开闭原则，那么可以非常方便地对系统进行扩展，而且在扩展时无须修改现有代码，使得软件系统在拥有适应性和灵活性的同时具备较好的稳定性和延续性。随着软件规模越来越大，软件寿命越来越长，软件维护成本越来越高，设计满足开闭原则的软件系统也变得越来越重要。\n\n为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。在Java、C#等编程语言中，可以为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。在很多面向对象编程语言中都提供了接口、抽象类等机制，可以通过它们定义系统的抽象层，再通过具体类来进行扩展。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。\n\n## 里氏替换原则\n\n里氏代换原则由2008年图灵奖得主、美国第一位计算机科学女博士Barbara Liskov教授和卡内基·梅隆大学Jeannette Wing教授于1994年提出。其严格表述如下：如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1代换o2时，程序P的行为没有变化，那么类型S是类型T的子类型。这个定义比较拗口且难以理解，因此我们一般使用它的另一个通俗版定义：\n\n> 里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。\n\n里氏代换原则告诉我们，在软件中将一个基类对象替换成它的子类对象，程序将不会产生任何错误和异常，反过来则不成立，如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。例如：我喜欢动物，那我一定喜欢狗，因为狗是动物的子类；但是我喜欢狗，不能据此断定我喜欢动物，因为我并不喜欢老鼠，虽然它也是动物。\n\n例如有两个类，一个类为BaseClass，另一个是SubClass类，并且SubClass类是BaseClass类的子类，那么一个方法如果可以接受一个BaseClass类型的基类对象base的话，如：method1(base)，那么它必然可以接受一个BaseClass类型的子类对象sub，method1(sub)能够正常运行。反过来的代换不成立，如一个方法method2接受BaseClass类型的子类对象sub为参数：method2(sub)，那么一般而言不可以有method2(base)，除非是重载方法。\n\n里氏代换原则是实现开闭原则的重要方式之一，由于使用基类对象的地方都可以使用子类对象，因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。\n\n在使用里氏代换原则时需要注意如下几个问题：\n\n1. 子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。\n\n2. 我们在运用里氏代换原则时，尽量把父类设计为抽象类或者接口，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。\n\n3. Java语言中，在编译阶段，Java编译器会检查一个程序是否符合里氏代换原则，这是一个与实现无关的、纯语法意义上的检查，但Java编译器的检查是有局限的。\n\n里氏代换原则是实现开闭原则的重要方式之一。在本实例中，在传递参数时使用基类对象，除此以外，在定义成员变量、定义局部变量、确定方法返回类型时都可使用里氏代换原则。针对基类编程，在程序运行时再确定具体子类。\n\n## 依赖倒置原则\n\n如果说开闭原则是面向对象设计的目标的话，那么依赖倒转原则就是面向对象设计的主要实现机制之一，它是系统抽象化的具体实现。依赖倒转原则是Robert C. Martin在1996年为“C++Reporter”所写的专栏Engineering Notebook的第三篇，后来加入到他在2002年出版的经典著作“Agile Software Development, Principles, Patterns, and Practices”一书中。依赖倒转原则定义如下：\n\n> 依赖倒转原则(Dependency Inversion  Principle, DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。\n\n依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。\n\n在引入抽象层后，系统将具有很好的灵活性，在程序中尽量使用抽象层进行编程，而将具体类写在配置文件中，这样一来，如果系统行为发生变化，只需要对抽象层进行扩展，并修改配置文件，而无须修改原有系统的源代码，在不修改的情况下来扩展系统的功能，满足开闭原则的要求。\n\n在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和接口注入。构造注入是指通过构造函数来传入具体类的对象，设值注入是指通过Setter方法来传入具体类的对象，而接口注入是指通过在接口中声明的业务方法来传入具体类的对象。这些方法在定义时使用的是抽象类型，在运行时再传入具体类型的对象，由子类对象来覆盖父类对象。\n\n开闭原则、里氏代换原则和依赖倒转原则，在大多数情况下，这三个设计原则会同时出现，开闭原则是目标，里氏代换原则是基础，依赖倒转原则是手段，它们相辅相成，相互补充，目标一致，只是分析问题时所站角度不同而已。\n\n## 接口隔离原则\n\n> 接口隔离原则(Interface  Segregation Principle, ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。\n\n根据接口隔离原则，当一个接口太大时，我们需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。每一个接口应该承担一种相对独立的角色，不干不该干的事，该干的事都要干。这里的“接口”往往有两种不同的含义：一种是指一个类型所具有的方法特征的集合，仅仅是一种逻辑上的抽象；另外一种是指某种语言具体的“接口”定义，有严格的定义和结构，比如Java语言中的interface。对于这两种不同的含义，ISP的表达方式以及含义都有所不同：\n\n1. 当把“接口”理解成一个类型所提供的所有方法特征的集合的时候，这就是一种逻辑上的概念，接口的划分将直接带来类型的划分。可以把接口理解成角色，一个接口只能代表一个角色，每个角色都有它特定的一个接口，此时，这个原则可以叫做“角色隔离原则”。\n\n2. 如果把“接口”理解成狭义的特定语言的接口，那么ISP表达的意思是指接口仅仅提供客户端需要的行为，客户端不需要的行为则隐藏起来，应当为客户端提供尽可能小的单独的接口，而不要提供大的总接口。在面向对象编程语言中，实现一个接口就需要实现该接口中定义的所有方法，因此大的总接口使用起来不一定很方便，为了使接口的职责单一，需要将大接口中的方法根据其职责不同分别放在不同的小接口中，以确保每个接口使用起来都较为方便，并都承担某一单一角色。接口应该尽量细化，同时接口中的方法应该尽量少，每个接口中只包含一个客户端（如子模块或业务逻辑类）所需的方法即可，这种机制也称为“定制服务”，即为不同的客户端提供宽窄不同的接口。\n\n在使用接口隔离原则时，我们需要注意控制接口的粒度，接口不能太小，如果太小会导致系统中接口泛滥，不利于维护；接口也不能太大，太大的接口将违背接口隔离原则，灵活性较差，使用起来很不方便。一般而言，接口中仅包含为某一类用户定制的方法即可，不应该强迫客户依赖于那些它们不用的方法。\n\n## 迪米特法则\n\n迪米特法则来自于1987年美国东北大学(Northeastern University)一个名为“Demeter”的研究项目。迪米特法则又称为最少知识原则(LeastKnowledge Principle, LKP)，其定义如下：\n\n> 迪米特法则(Law of  Demeter, LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。\n\n如果一个系统符合迪米特法则，那么当其中某一个模块发生修改时，就会尽量少地影响其他模块，扩展会相对容易，这是对软件实体之间通信的限制，迪米特法则要求限制软件实体之间通信的宽度和深度。迪米特法则可降低系统的耦合度，使类与类之间保持松散的耦合关系。\n\n迪米特法则还有几种定义形式，包括：不要和“陌生人”说话、只与你的直接朋友通信等，在迪米特法则中，对于一个对象，其朋友包括以下几类：\n\n1. 当前对象本身(this)；\n2. 以参数形式传入到当前对象方法中的对象；\n3. 当前对象的成员对象；\n4. 如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友；\n5. 当前对象所创建的对象。\n\n任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”，否则就是“陌生人”。在应用迪米特法则时，一个对象只能与直接朋友发生交互，不要与“陌生人”发生直接交互，这样做可以降低系统的耦合度，一个对象的改变不会给太多其他对象带来影响。\n\n迪米特法则要求我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。\n\n将迪米特法则运用到系统设计中时，要注意下面的几点：在类的划分上，应当尽量创建松耦合的类，类之间的耦合度越低，就越有利于复用，一个处在松耦合中的类一旦被修改，不会对关联的类造成太大波及；在类的结构设计上，每一个类都应当尽量降低其成员变量和成员函数的访问权限；在类的设计上，只要有可能，一个类型应当设计成不变类；在对其他类的引用上，一个对象对其他对象的引用应当降到最低。\n\n# 参考资料\n* http://blog.csdn.net/zhengzhb/article/details/7281833\n* https://blog.csdn.net/LoveLion/article/category/738450/7\n* https://baijiahao.baidu.com/s?id=1591642387721949859&wfr=spider&for=pc","slug":"pattern","published":1,"updated":"2019-08-26T07:52:55.252Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl41004nqotnw631xlyw","content":"<h1 id=\"设计模式六大原则\"><a href=\"#设计模式六大原则\" class=\"headerlink\" title=\"设计模式六大原则\"></a>设计模式六大原则</h1><blockquote>\n<p>前段时间一直都在学习设计模式相关的知识，总结了下设计模式相关知识，其中设计模式的六大原则个人认为尤为重要，非常有助于理解设计模式。本文内容全部摘要自<a href=\"https://blog.csdn.net/LoveLion/article/category/738450/7\" title=\"刘伟技术博客\" target=\"_blank\" rel=\"noopener\">刘伟技术博客</a>，总结了下相关的知识点进行了记录。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"单一职责原则\"><a href=\"#单一职责原则\" class=\"headerlink\" title=\"单一职责原则\"></a>单一职责原则</h2><p>单一职责原则是最简单的面向对象设计原则，它用于控制类的粒度大小。单一职责原则定义如下：</p>\n<blockquote>\n<p>单一职责原则(Single Responsibility Principle, SRP)：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。</p>\n</blockquote>\n<p>单一职责原则告诉我们：一个类不能太“累”！在软件系统中，一个类（大到模块，小到方法）承担的职责越多，它被复用的可能性就越小，而且一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离，将不同的职责封装在不同的类中，即将不同的变化原因封装在不同的类中，如果多个职责总是同时发生改变则可将它们封装在同一类中。</p>\n<p>单一职责原则是实现高内聚、低耦合的指导方针，它是最简单但又最难运用的原则，需要设计人员发现类的不同职责并将其分离，而发现类的多重职责需要设计人员具有较强的分析设计能力和相关实践经验。</p>\n<h2 id=\"开闭原则\"><a href=\"#开闭原则\" class=\"headerlink\" title=\"开闭原则\"></a>开闭原则</h2><p>开闭原则是面向对象的可复用设计的第一块基石，它是最重要的面向对象设计原则。开闭原则由Bertrand  Meyer于1988年提出，其定义如下：</p>\n<blockquote>\n<p>开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。</p>\n</blockquote>\n<p>在开闭原则的定义中，软件实体可以指一个软件模块、一个由多个类组成的局部结构或一个独立的类。</p>\n<p>任何软件都需要面临一个很重要的问题，即它们的需求会随时间的推移而发生变化。当软件系统需要面对新的需求时，我们应该尽量保证系统的设计框架是稳定的。如果一个软件设计符合开闭原则，那么可以非常方便地对系统进行扩展，而且在扩展时无须修改现有代码，使得软件系统在拥有适应性和灵活性的同时具备较好的稳定性和延续性。随着软件规模越来越大，软件寿命越来越长，软件维护成本越来越高，设计满足开闭原则的软件系统也变得越来越重要。</p>\n<p>为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。在Java、C#等编程语言中，可以为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。在很多面向对象编程语言中都提供了接口、抽象类等机制，可以通过它们定义系统的抽象层，再通过具体类来进行扩展。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。</p>\n<h2 id=\"里氏替换原则\"><a href=\"#里氏替换原则\" class=\"headerlink\" title=\"里氏替换原则\"></a>里氏替换原则</h2><p>里氏代换原则由2008年图灵奖得主、美国第一位计算机科学女博士Barbara Liskov教授和卡内基·梅隆大学Jeannette Wing教授于1994年提出。其严格表述如下：如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1代换o2时，程序P的行为没有变化，那么类型S是类型T的子类型。这个定义比较拗口且难以理解，因此我们一般使用它的另一个通俗版定义：</p>\n<blockquote>\n<p>里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。</p>\n</blockquote>\n<p>里氏代换原则告诉我们，在软件中将一个基类对象替换成它的子类对象，程序将不会产生任何错误和异常，反过来则不成立，如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。例如：我喜欢动物，那我一定喜欢狗，因为狗是动物的子类；但是我喜欢狗，不能据此断定我喜欢动物，因为我并不喜欢老鼠，虽然它也是动物。</p>\n<p>例如有两个类，一个类为BaseClass，另一个是SubClass类，并且SubClass类是BaseClass类的子类，那么一个方法如果可以接受一个BaseClass类型的基类对象base的话，如：method1(base)，那么它必然可以接受一个BaseClass类型的子类对象sub，method1(sub)能够正常运行。反过来的代换不成立，如一个方法method2接受BaseClass类型的子类对象sub为参数：method2(sub)，那么一般而言不可以有method2(base)，除非是重载方法。</p>\n<p>里氏代换原则是实现开闭原则的重要方式之一，由于使用基类对象的地方都可以使用子类对象，因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。</p>\n<p>在使用里氏代换原则时需要注意如下几个问题：</p>\n<ol>\n<li><p>子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。</p>\n</li>\n<li><p>我们在运用里氏代换原则时，尽量把父类设计为抽象类或者接口，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。</p>\n</li>\n<li><p>Java语言中，在编译阶段，Java编译器会检查一个程序是否符合里氏代换原则，这是一个与实现无关的、纯语法意义上的检查，但Java编译器的检查是有局限的。</p>\n</li>\n</ol>\n<p>里氏代换原则是实现开闭原则的重要方式之一。在本实例中，在传递参数时使用基类对象，除此以外，在定义成员变量、定义局部变量、确定方法返回类型时都可使用里氏代换原则。针对基类编程，在程序运行时再确定具体子类。</p>\n<h2 id=\"依赖倒置原则\"><a href=\"#依赖倒置原则\" class=\"headerlink\" title=\"依赖倒置原则\"></a>依赖倒置原则</h2><p>如果说开闭原则是面向对象设计的目标的话，那么依赖倒转原则就是面向对象设计的主要实现机制之一，它是系统抽象化的具体实现。依赖倒转原则是Robert C. Martin在1996年为“C++Reporter”所写的专栏Engineering Notebook的第三篇，后来加入到他在2002年出版的经典著作“Agile Software Development, Principles, Patterns, and Practices”一书中。依赖倒转原则定义如下：</p>\n<blockquote>\n<p>依赖倒转原则(Dependency Inversion  Principle, DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。</p>\n</blockquote>\n<p>依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。</p>\n<p>在引入抽象层后，系统将具有很好的灵活性，在程序中尽量使用抽象层进行编程，而将具体类写在配置文件中，这样一来，如果系统行为发生变化，只需要对抽象层进行扩展，并修改配置文件，而无须修改原有系统的源代码，在不修改的情况下来扩展系统的功能，满足开闭原则的要求。</p>\n<p>在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和接口注入。构造注入是指通过构造函数来传入具体类的对象，设值注入是指通过Setter方法来传入具体类的对象，而接口注入是指通过在接口中声明的业务方法来传入具体类的对象。这些方法在定义时使用的是抽象类型，在运行时再传入具体类型的对象，由子类对象来覆盖父类对象。</p>\n<p>开闭原则、里氏代换原则和依赖倒转原则，在大多数情况下，这三个设计原则会同时出现，开闭原则是目标，里氏代换原则是基础，依赖倒转原则是手段，它们相辅相成，相互补充，目标一致，只是分析问题时所站角度不同而已。</p>\n<h2 id=\"接口隔离原则\"><a href=\"#接口隔离原则\" class=\"headerlink\" title=\"接口隔离原则\"></a>接口隔离原则</h2><blockquote>\n<p>接口隔离原则(Interface  Segregation Principle, ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。</p>\n</blockquote>\n<p>根据接口隔离原则，当一个接口太大时，我们需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。每一个接口应该承担一种相对独立的角色，不干不该干的事，该干的事都要干。这里的“接口”往往有两种不同的含义：一种是指一个类型所具有的方法特征的集合，仅仅是一种逻辑上的抽象；另外一种是指某种语言具体的“接口”定义，有严格的定义和结构，比如Java语言中的interface。对于这两种不同的含义，ISP的表达方式以及含义都有所不同：</p>\n<ol>\n<li><p>当把“接口”理解成一个类型所提供的所有方法特征的集合的时候，这就是一种逻辑上的概念，接口的划分将直接带来类型的划分。可以把接口理解成角色，一个接口只能代表一个角色，每个角色都有它特定的一个接口，此时，这个原则可以叫做“角色隔离原则”。</p>\n</li>\n<li><p>如果把“接口”理解成狭义的特定语言的接口，那么ISP表达的意思是指接口仅仅提供客户端需要的行为，客户端不需要的行为则隐藏起来，应当为客户端提供尽可能小的单独的接口，而不要提供大的总接口。在面向对象编程语言中，实现一个接口就需要实现该接口中定义的所有方法，因此大的总接口使用起来不一定很方便，为了使接口的职责单一，需要将大接口中的方法根据其职责不同分别放在不同的小接口中，以确保每个接口使用起来都较为方便，并都承担某一单一角色。接口应该尽量细化，同时接口中的方法应该尽量少，每个接口中只包含一个客户端（如子模块或业务逻辑类）所需的方法即可，这种机制也称为“定制服务”，即为不同的客户端提供宽窄不同的接口。</p>\n</li>\n</ol>\n<p>在使用接口隔离原则时，我们需要注意控制接口的粒度，接口不能太小，如果太小会导致系统中接口泛滥，不利于维护；接口也不能太大，太大的接口将违背接口隔离原则，灵活性较差，使用起来很不方便。一般而言，接口中仅包含为某一类用户定制的方法即可，不应该强迫客户依赖于那些它们不用的方法。</p>\n<h2 id=\"迪米特法则\"><a href=\"#迪米特法则\" class=\"headerlink\" title=\"迪米特法则\"></a>迪米特法则</h2><p>迪米特法则来自于1987年美国东北大学(Northeastern University)一个名为“Demeter”的研究项目。迪米特法则又称为最少知识原则(LeastKnowledge Principle, LKP)，其定义如下：</p>\n<blockquote>\n<p>迪米特法则(Law of  Demeter, LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。</p>\n</blockquote>\n<p>如果一个系统符合迪米特法则，那么当其中某一个模块发生修改时，就会尽量少地影响其他模块，扩展会相对容易，这是对软件实体之间通信的限制，迪米特法则要求限制软件实体之间通信的宽度和深度。迪米特法则可降低系统的耦合度，使类与类之间保持松散的耦合关系。</p>\n<p>迪米特法则还有几种定义形式，包括：不要和“陌生人”说话、只与你的直接朋友通信等，在迪米特法则中，对于一个对象，其朋友包括以下几类：</p>\n<ol>\n<li>当前对象本身(this)；</li>\n<li>以参数形式传入到当前对象方法中的对象；</li>\n<li>当前对象的成员对象；</li>\n<li>如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友；</li>\n<li>当前对象所创建的对象。</li>\n</ol>\n<p>任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”，否则就是“陌生人”。在应用迪米特法则时，一个对象只能与直接朋友发生交互，不要与“陌生人”发生直接交互，这样做可以降低系统的耦合度，一个对象的改变不会给太多其他对象带来影响。</p>\n<p>迪米特法则要求我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。</p>\n<p>将迪米特法则运用到系统设计中时，要注意下面的几点：在类的划分上，应当尽量创建松耦合的类，类之间的耦合度越低，就越有利于复用，一个处在松耦合中的类一旦被修改，不会对关联的类造成太大波及；在类的结构设计上，每一个类都应当尽量降低其成员变量和成员函数的访问权限；在类的设计上，只要有可能，一个类型应当设计成不变类；在对其他类的引用上，一个对象对其他对象的引用应当降到最低。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"http://blog.csdn.net/zhengzhb/article/details/7281833\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/zhengzhb/article/details/7281833</a></li>\n<li><a href=\"https://blog.csdn.net/LoveLion/article/category/738450/7\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/LoveLion/article/category/738450/7</a></li>\n<li><a href=\"https://baijiahao.baidu.com/s?id=1591642387721949859&amp;wfr=spider&amp;for=pc\" target=\"_blank\" rel=\"noopener\">https://baijiahao.baidu.com/s?id=1591642387721949859&amp;wfr=spider&amp;for=pc</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"设计模式六大原则\"><a href=\"#设计模式六大原则\" class=\"headerlink\" title=\"设计模式六大原则\"></a>设计模式六大原则</h1><blockquote>\n<p>前段时间一直都在学习设计模式相关的知识，总结了下设计模式相关知识，其中设计模式的六大原则个人认为尤为重要，非常有助于理解设计模式。本文内容全部摘要自<a href=\"https://blog.csdn.net/LoveLion/article/category/738450/7\" title=\"刘伟技术博客\" target=\"_blank\" rel=\"noopener\">刘伟技术博客</a>，总结了下相关的知识点进行了记录。</p>\n</blockquote>","more":"<h2 id=\"单一职责原则\"><a href=\"#单一职责原则\" class=\"headerlink\" title=\"单一职责原则\"></a>单一职责原则</h2><p>单一职责原则是最简单的面向对象设计原则，它用于控制类的粒度大小。单一职责原则定义如下：</p>\n<blockquote>\n<p>单一职责原则(Single Responsibility Principle, SRP)：一个类只负责一个功能领域中的相应职责，或者可以定义为：就一个类而言，应该只有一个引起它变化的原因。</p>\n</blockquote>\n<p>单一职责原则告诉我们：一个类不能太“累”！在软件系统中，一个类（大到模块，小到方法）承担的职责越多，它被复用的可能性就越小，而且一个类承担的职责过多，就相当于将这些职责耦合在一起，当其中一个职责变化时，可能会影响其他职责的运作，因此要将这些职责进行分离，将不同的职责封装在不同的类中，即将不同的变化原因封装在不同的类中，如果多个职责总是同时发生改变则可将它们封装在同一类中。</p>\n<p>单一职责原则是实现高内聚、低耦合的指导方针，它是最简单但又最难运用的原则，需要设计人员发现类的不同职责并将其分离，而发现类的多重职责需要设计人员具有较强的分析设计能力和相关实践经验。</p>\n<h2 id=\"开闭原则\"><a href=\"#开闭原则\" class=\"headerlink\" title=\"开闭原则\"></a>开闭原则</h2><p>开闭原则是面向对象的可复用设计的第一块基石，它是最重要的面向对象设计原则。开闭原则由Bertrand  Meyer于1988年提出，其定义如下：</p>\n<blockquote>\n<p>开闭原则(Open-Closed Principle, OCP)：一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。</p>\n</blockquote>\n<p>在开闭原则的定义中，软件实体可以指一个软件模块、一个由多个类组成的局部结构或一个独立的类。</p>\n<p>任何软件都需要面临一个很重要的问题，即它们的需求会随时间的推移而发生变化。当软件系统需要面对新的需求时，我们应该尽量保证系统的设计框架是稳定的。如果一个软件设计符合开闭原则，那么可以非常方便地对系统进行扩展，而且在扩展时无须修改现有代码，使得软件系统在拥有适应性和灵活性的同时具备较好的稳定性和延续性。随着软件规模越来越大，软件寿命越来越长，软件维护成本越来越高，设计满足开闭原则的软件系统也变得越来越重要。</p>\n<p>为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。在Java、C#等编程语言中，可以为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。在很多面向对象编程语言中都提供了接口、抽象类等机制，可以通过它们定义系统的抽象层，再通过具体类来进行扩展。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。</p>\n<h2 id=\"里氏替换原则\"><a href=\"#里氏替换原则\" class=\"headerlink\" title=\"里氏替换原则\"></a>里氏替换原则</h2><p>里氏代换原则由2008年图灵奖得主、美国第一位计算机科学女博士Barbara Liskov教授和卡内基·梅隆大学Jeannette Wing教授于1994年提出。其严格表述如下：如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1代换o2时，程序P的行为没有变化，那么类型S是类型T的子类型。这个定义比较拗口且难以理解，因此我们一般使用它的另一个通俗版定义：</p>\n<blockquote>\n<p>里氏代换原则(Liskov Substitution Principle, LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。</p>\n</blockquote>\n<p>里氏代换原则告诉我们，在软件中将一个基类对象替换成它的子类对象，程序将不会产生任何错误和异常，反过来则不成立，如果一个软件实体使用的是一个子类对象的话，那么它不一定能够使用基类对象。例如：我喜欢动物，那我一定喜欢狗，因为狗是动物的子类；但是我喜欢狗，不能据此断定我喜欢动物，因为我并不喜欢老鼠，虽然它也是动物。</p>\n<p>例如有两个类，一个类为BaseClass，另一个是SubClass类，并且SubClass类是BaseClass类的子类，那么一个方法如果可以接受一个BaseClass类型的基类对象base的话，如：method1(base)，那么它必然可以接受一个BaseClass类型的子类对象sub，method1(sub)能够正常运行。反过来的代换不成立，如一个方法method2接受BaseClass类型的子类对象sub为参数：method2(sub)，那么一般而言不可以有method2(base)，除非是重载方法。</p>\n<p>里氏代换原则是实现开闭原则的重要方式之一，由于使用基类对象的地方都可以使用子类对象，因此在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。</p>\n<p>在使用里氏代换原则时需要注意如下几个问题：</p>\n<ol>\n<li><p>子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。</p>\n</li>\n<li><p>我们在运用里氏代换原则时，尽量把父类设计为抽象类或者接口，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。</p>\n</li>\n<li><p>Java语言中，在编译阶段，Java编译器会检查一个程序是否符合里氏代换原则，这是一个与实现无关的、纯语法意义上的检查，但Java编译器的检查是有局限的。</p>\n</li>\n</ol>\n<p>里氏代换原则是实现开闭原则的重要方式之一。在本实例中，在传递参数时使用基类对象，除此以外，在定义成员变量、定义局部变量、确定方法返回类型时都可使用里氏代换原则。针对基类编程，在程序运行时再确定具体子类。</p>\n<h2 id=\"依赖倒置原则\"><a href=\"#依赖倒置原则\" class=\"headerlink\" title=\"依赖倒置原则\"></a>依赖倒置原则</h2><p>如果说开闭原则是面向对象设计的目标的话，那么依赖倒转原则就是面向对象设计的主要实现机制之一，它是系统抽象化的具体实现。依赖倒转原则是Robert C. Martin在1996年为“C++Reporter”所写的专栏Engineering Notebook的第三篇，后来加入到他在2002年出版的经典著作“Agile Software Development, Principles, Patterns, and Practices”一书中。依赖倒转原则定义如下：</p>\n<blockquote>\n<p>依赖倒转原则(Dependency Inversion  Principle, DIP)：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。</p>\n</blockquote>\n<p>依赖倒转原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。为了确保该原则的应用，一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。</p>\n<p>在引入抽象层后，系统将具有很好的灵活性，在程序中尽量使用抽象层进行编程，而将具体类写在配置文件中，这样一来，如果系统行为发生变化，只需要对抽象层进行扩展，并修改配置文件，而无须修改原有系统的源代码，在不修改的情况下来扩展系统的功能，满足开闭原则的要求。</p>\n<p>在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：构造注入，设值注入（Setter注入）和接口注入。构造注入是指通过构造函数来传入具体类的对象，设值注入是指通过Setter方法来传入具体类的对象，而接口注入是指通过在接口中声明的业务方法来传入具体类的对象。这些方法在定义时使用的是抽象类型，在运行时再传入具体类型的对象，由子类对象来覆盖父类对象。</p>\n<p>开闭原则、里氏代换原则和依赖倒转原则，在大多数情况下，这三个设计原则会同时出现，开闭原则是目标，里氏代换原则是基础，依赖倒转原则是手段，它们相辅相成，相互补充，目标一致，只是分析问题时所站角度不同而已。</p>\n<h2 id=\"接口隔离原则\"><a href=\"#接口隔离原则\" class=\"headerlink\" title=\"接口隔离原则\"></a>接口隔离原则</h2><blockquote>\n<p>接口隔离原则(Interface  Segregation Principle, ISP)：使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。</p>\n</blockquote>\n<p>根据接口隔离原则，当一个接口太大时，我们需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。每一个接口应该承担一种相对独立的角色，不干不该干的事，该干的事都要干。这里的“接口”往往有两种不同的含义：一种是指一个类型所具有的方法特征的集合，仅仅是一种逻辑上的抽象；另外一种是指某种语言具体的“接口”定义，有严格的定义和结构，比如Java语言中的interface。对于这两种不同的含义，ISP的表达方式以及含义都有所不同：</p>\n<ol>\n<li><p>当把“接口”理解成一个类型所提供的所有方法特征的集合的时候，这就是一种逻辑上的概念，接口的划分将直接带来类型的划分。可以把接口理解成角色，一个接口只能代表一个角色，每个角色都有它特定的一个接口，此时，这个原则可以叫做“角色隔离原则”。</p>\n</li>\n<li><p>如果把“接口”理解成狭义的特定语言的接口，那么ISP表达的意思是指接口仅仅提供客户端需要的行为，客户端不需要的行为则隐藏起来，应当为客户端提供尽可能小的单独的接口，而不要提供大的总接口。在面向对象编程语言中，实现一个接口就需要实现该接口中定义的所有方法，因此大的总接口使用起来不一定很方便，为了使接口的职责单一，需要将大接口中的方法根据其职责不同分别放在不同的小接口中，以确保每个接口使用起来都较为方便，并都承担某一单一角色。接口应该尽量细化，同时接口中的方法应该尽量少，每个接口中只包含一个客户端（如子模块或业务逻辑类）所需的方法即可，这种机制也称为“定制服务”，即为不同的客户端提供宽窄不同的接口。</p>\n</li>\n</ol>\n<p>在使用接口隔离原则时，我们需要注意控制接口的粒度，接口不能太小，如果太小会导致系统中接口泛滥，不利于维护；接口也不能太大，太大的接口将违背接口隔离原则，灵活性较差，使用起来很不方便。一般而言，接口中仅包含为某一类用户定制的方法即可，不应该强迫客户依赖于那些它们不用的方法。</p>\n<h2 id=\"迪米特法则\"><a href=\"#迪米特法则\" class=\"headerlink\" title=\"迪米特法则\"></a>迪米特法则</h2><p>迪米特法则来自于1987年美国东北大学(Northeastern University)一个名为“Demeter”的研究项目。迪米特法则又称为最少知识原则(LeastKnowledge Principle, LKP)，其定义如下：</p>\n<blockquote>\n<p>迪米特法则(Law of  Demeter, LoD)：一个软件实体应当尽可能少地与其他实体发生相互作用。</p>\n</blockquote>\n<p>如果一个系统符合迪米特法则，那么当其中某一个模块发生修改时，就会尽量少地影响其他模块，扩展会相对容易，这是对软件实体之间通信的限制，迪米特法则要求限制软件实体之间通信的宽度和深度。迪米特法则可降低系统的耦合度，使类与类之间保持松散的耦合关系。</p>\n<p>迪米特法则还有几种定义形式，包括：不要和“陌生人”说话、只与你的直接朋友通信等，在迪米特法则中，对于一个对象，其朋友包括以下几类：</p>\n<ol>\n<li>当前对象本身(this)；</li>\n<li>以参数形式传入到当前对象方法中的对象；</li>\n<li>当前对象的成员对象；</li>\n<li>如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友；</li>\n<li>当前对象所创建的对象。</li>\n</ol>\n<p>任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”，否则就是“陌生人”。在应用迪米特法则时，一个对象只能与直接朋友发生交互，不要与“陌生人”发生直接交互，这样做可以降低系统的耦合度，一个对象的改变不会给太多其他对象带来影响。</p>\n<p>迪米特法则要求我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。</p>\n<p>将迪米特法则运用到系统设计中时，要注意下面的几点：在类的划分上，应当尽量创建松耦合的类，类之间的耦合度越低，就越有利于复用，一个处在松耦合中的类一旦被修改，不会对关联的类造成太大波及；在类的结构设计上，每一个类都应当尽量降低其成员变量和成员函数的访问权限；在类的设计上，只要有可能，一个类型应当设计成不变类；在对其他类的引用上，一个对象对其他对象的引用应当降到最低。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"http://blog.csdn.net/zhengzhb/article/details/7281833\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/zhengzhb/article/details/7281833</a></li>\n<li><a href=\"https://blog.csdn.net/LoveLion/article/category/738450/7\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/LoveLion/article/category/738450/7</a></li>\n<li><a href=\"https://baijiahao.baidu.com/s?id=1591642387721949859&amp;wfr=spider&amp;for=pc\" target=\"_blank\" rel=\"noopener\">https://baijiahao.baidu.com/s?id=1591642387721949859&amp;wfr=spider&amp;for=pc</a></li>\n</ul>"},{"title":"CAS","date":"2020-01-01T06:00:00.000Z","_content":"\n转眼间就2020年了，去年学习的东西甚少，今年要多看看书了。\n\n<!-- more -->\n\n# 概念\n> In computer science, compare-and-swap (CAS) is an atomic instruction used in multithreading to achieve synchronization. It compares the contents of a memory location with a given value and, only if they are the same, modifies the contents of that memory location to a new given value. This is done as a single atomic operation. The atomicity guarantees that the new value is calculated based on up-to-date information; if the value had been updated by another thread in the meantime, the write would fail. The result of the operation must indicate whether it performed the substitution; this can be done either with a simple boolean response (this variant is often called compare-and-set), or by returning the value read from the memory location (not the value written to it).\n\n在计算机科学中，比较和交换（Conmpare And Swap）是用于实现多线程同步的原子指令。 它将内存位置的内容与给定值进行比较，只有在相同的情况下，将该内存位置的内容修改为新的给定值。 这是作为单个原子操作完成的。 原子性保证新值基于最新信息计算; 如果该值在同一时间被另一个线程更新，则写入将失败。 操作结果必须说明是否进行替换; 这可以通过一个简单的布尔响应（这个变体通常称为比较和设置），或通过返回从内存位置读取的值来完成（摘自维基本科）\n\n## 举例解释\n字面意思“比较并交换”，一个CAS涉及到以下操作：\n> 我们假设内存中的元数据V，旧的预期值A，需要修改的新值B。\n> 1. 比较 A 与 V 是否相等。（比较）\n> 2. 如果比较相等，将 B 写入 V。（交换）\n> 3. 返回操作是否成功。\n\n# JAVA中CAS的实现\n## JDK工具类中的使用\n在JDK的源码中，可以在java.util.concurrent的atomic包和locks包下看到使用到CAS。以AtomicInteger举例\n``` java\n/**\n    * Atomically sets the value to the given updated value\n    * if the current value {@code ==} the expected value.\n    *\n    * @param expect the expected value\n    * @param update the new value\n    * @return {@code true} if successful. False return indicates that\n    * the actual value was not equal to the expected value.\n    */\npublic final boolean compareAndSet(int expect, int update) {\n    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);\n}\n```\n可以看到在compareAndSet中，通过unsafe对象调用了native修饰的compareAndSwapInt方法。\n``` java\nprivate static final Unsafe unsafe = Unsafe.getUnsafe();\n```\n``` java\npublic final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);\n```\n## JVM底层调用\n关于native修饰的底层调用本地方式实现的内容，我直接查看了一些文章。\n\n我们发现在 /jdk9u/hotspot/src/share/vm/unsafe.cpp中有这样的代码：\n```\n{CC \"compareAndSetInt\", CC \"(\" OBJ \"J\"\"I\"\"I\"\")Z\", FN_PTR(Unsafe_CompareAndSetInt)},\n```\n这个涉及到JNI的调用，感兴趣的同学可以自行学习。我们搜索Unsafe_CompareAndSetInt后发现:\n```\nUNSAFE_ENTRY(jboolean, Unsafe_CompareAndSetInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) {\n  oop p = JNIHandles::resolve(obj);\n  jint* addr = (jint *)index_oop_from_field_offset_long(p, offset);\n\n  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;\n} UNSAFE_END\n```\n最终我们终于看到了核心代码Atomic::cmpxchg。\n\n继续向底层探索，在文件java/jdk9u/hotspot/src/os_cpu/linux_x86/vm/atomic_linux_x86.hpp有这样的代码:\n```\ninline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value, cmpxchg_memory_order order) {\n  int mp = os::is_MP();\n  __asm__ volatile (LOCK_IF_MP(%4) \"cmpxchgl %1,(%3)\"\n                    : \"=a\" (exchange_value)\n                    : \"r\" (exchange_value), \"a\" (compare_value), \"r\" (dest), \"r\" (mp)\n                    : \"cc\", \"memory\");\n  return exchange_value;\n}\n```\n我们通过文件名可以知道，针对不同的操作系统,JVM 对于Atomic::cmpxchg应该有不同的实现。由于我们服务基本都是使用的是64位linux，所以我们就看看linux_x86的实现。\n我们继续看代码：\n\n- __asm__的意思是这个是一段内嵌汇编代码。也就是在C语言中使用汇编代码。\n- 这里的volatile和JAVA有一点类似，但不是为了内存的可见性，而是告诉编译器对访问该变量的代码就不再进行优化。\n- LOCK_IF_MP(%4)的意思就比较简单，就是如果操作系统是多核的，那就增加一个LOCK。\n- cmpxchgl就是汇编版的“比较并交换”。但是我们知道比较并交换，有三个步骤，不是原子的。所以在多核情况下加一个 LOCK，由CPU硬件保证他的原子性。\n- 我们再看看LOCK是怎么实现的呢？我们去Intel的官网上看看，可以知道LOCK在的早期实现是直接将cup的总线阻塞，这样的实现可见效率是很低下的。后来优化为X86 cpu 有锁定一个特定内存地址的能力，当这个特定内存地址被锁定后，它就可以阻止其他的系统总线读取或修改这个内存地址。\n\n关于CAS的底层探索我们就到此为止。我们总结一下JAVA的CAS是怎么实现的：\n1. java的cas利用的的是unsafe这个类提供的cas操作。\n2. unsafe的cas依赖了的是jvm针对不同的操作系统实现的 Atomic::cmpxchg\n3. Atomic::cmpxchg的实现使用了汇编的cas操作，并使用cpu硬件提供的lock信号保证其原子性\n\n# CAS带来的问题\n## ABA\n以下是维基百科定义：\n\nIn multithreaded computing, the ABA problem occurs during synchronization, when a location is read twice, has the same value for both reads, and \"value is the same\" is used to indicate \"nothing has changed\". However, another thread can execute between the two reads and change the value, do other work, then change the value back, thus fooling the first thread into thinking \"nothing has changed\" even though the second thread did work that violates that assumption.\n\nhe ABA problem occurs when multiple threads (or processes) accessing shared data interleave. Below is the sequence of events that will result in the ABA problem:\n\n1. Process P1 reads value A from shared memory,\n2. P1 is preempted, allowing process P2 to run,\n3. P2 modifies the shared memory value A to value B and back to A before preemption,\n4. P1 begins execution again, sees that the shared memory value has not changed and continues.\n\nAlthough P1 can continue executing, it is possible that the behavior will not be correct due to the \"hidden\" modification in shared memory.\n\nA common case of the ABA problem is encountered when implementing a lock-free data structure. If an item is removed from the list, deleted, and then a new item is allocated and added to the list, it is common for the allocated object to be at the same location as the deleted object due to optimization. A pointer to the new item is thus sometimes equal to a pointer to the old item which is an ABA problem.\n\n简而言之，当两个线程访问同一个地址时，将“值相同”用于表示“没有变化”。\n - 线程P1从内存中取出A\n - 线程P2也从内存中取出A\n - 线程P2进行操作并且将值修改为B，而后又修改为A。\n - 线程P1进行CAS操作时候发现值仍为A，便可以进行操作。\n\n其实在一般情况下，看似以最终结果来看可以认为是没有问题的，但是整个操作的过程是有问题的，比如：链表的头在变化了两次后恢复了原值，但并不代表链表没有发生过变化。\n### 解决思路\nTagged state reference 标记状态参考：使用某个标识来表示是否有过变更的版本信息。JDK中有提供AtomicStampedReference/AtomicMarkableReference用于解决ABA问题。\n\n还有两种不常用的解决方案：\n- Intermediate nodes 中间节点\n- Deferred reclamation\n\n# 参考资料\n* https://segmentfault.com/a/1190000013127775\n* https://en.wikipedia.org/wiki/Compare-and-swap\n* https://en.wikipedia.org/wiki/ABA_problem","source":"_posts/CAS.md","raw":"---\ntitle: CAS\ndate: 2020-01-01 14:00:00\ntags: Java\ncategories: Java\n---\n\n转眼间就2020年了，去年学习的东西甚少，今年要多看看书了。\n\n<!-- more -->\n\n# 概念\n> In computer science, compare-and-swap (CAS) is an atomic instruction used in multithreading to achieve synchronization. It compares the contents of a memory location with a given value and, only if they are the same, modifies the contents of that memory location to a new given value. This is done as a single atomic operation. The atomicity guarantees that the new value is calculated based on up-to-date information; if the value had been updated by another thread in the meantime, the write would fail. The result of the operation must indicate whether it performed the substitution; this can be done either with a simple boolean response (this variant is often called compare-and-set), or by returning the value read from the memory location (not the value written to it).\n\n在计算机科学中，比较和交换（Conmpare And Swap）是用于实现多线程同步的原子指令。 它将内存位置的内容与给定值进行比较，只有在相同的情况下，将该内存位置的内容修改为新的给定值。 这是作为单个原子操作完成的。 原子性保证新值基于最新信息计算; 如果该值在同一时间被另一个线程更新，则写入将失败。 操作结果必须说明是否进行替换; 这可以通过一个简单的布尔响应（这个变体通常称为比较和设置），或通过返回从内存位置读取的值来完成（摘自维基本科）\n\n## 举例解释\n字面意思“比较并交换”，一个CAS涉及到以下操作：\n> 我们假设内存中的元数据V，旧的预期值A，需要修改的新值B。\n> 1. 比较 A 与 V 是否相等。（比较）\n> 2. 如果比较相等，将 B 写入 V。（交换）\n> 3. 返回操作是否成功。\n\n# JAVA中CAS的实现\n## JDK工具类中的使用\n在JDK的源码中，可以在java.util.concurrent的atomic包和locks包下看到使用到CAS。以AtomicInteger举例\n``` java\n/**\n    * Atomically sets the value to the given updated value\n    * if the current value {@code ==} the expected value.\n    *\n    * @param expect the expected value\n    * @param update the new value\n    * @return {@code true} if successful. False return indicates that\n    * the actual value was not equal to the expected value.\n    */\npublic final boolean compareAndSet(int expect, int update) {\n    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);\n}\n```\n可以看到在compareAndSet中，通过unsafe对象调用了native修饰的compareAndSwapInt方法。\n``` java\nprivate static final Unsafe unsafe = Unsafe.getUnsafe();\n```\n``` java\npublic final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);\n```\n## JVM底层调用\n关于native修饰的底层调用本地方式实现的内容，我直接查看了一些文章。\n\n我们发现在 /jdk9u/hotspot/src/share/vm/unsafe.cpp中有这样的代码：\n```\n{CC \"compareAndSetInt\", CC \"(\" OBJ \"J\"\"I\"\"I\"\")Z\", FN_PTR(Unsafe_CompareAndSetInt)},\n```\n这个涉及到JNI的调用，感兴趣的同学可以自行学习。我们搜索Unsafe_CompareAndSetInt后发现:\n```\nUNSAFE_ENTRY(jboolean, Unsafe_CompareAndSetInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) {\n  oop p = JNIHandles::resolve(obj);\n  jint* addr = (jint *)index_oop_from_field_offset_long(p, offset);\n\n  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;\n} UNSAFE_END\n```\n最终我们终于看到了核心代码Atomic::cmpxchg。\n\n继续向底层探索，在文件java/jdk9u/hotspot/src/os_cpu/linux_x86/vm/atomic_linux_x86.hpp有这样的代码:\n```\ninline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value, cmpxchg_memory_order order) {\n  int mp = os::is_MP();\n  __asm__ volatile (LOCK_IF_MP(%4) \"cmpxchgl %1,(%3)\"\n                    : \"=a\" (exchange_value)\n                    : \"r\" (exchange_value), \"a\" (compare_value), \"r\" (dest), \"r\" (mp)\n                    : \"cc\", \"memory\");\n  return exchange_value;\n}\n```\n我们通过文件名可以知道，针对不同的操作系统,JVM 对于Atomic::cmpxchg应该有不同的实现。由于我们服务基本都是使用的是64位linux，所以我们就看看linux_x86的实现。\n我们继续看代码：\n\n- __asm__的意思是这个是一段内嵌汇编代码。也就是在C语言中使用汇编代码。\n- 这里的volatile和JAVA有一点类似，但不是为了内存的可见性，而是告诉编译器对访问该变量的代码就不再进行优化。\n- LOCK_IF_MP(%4)的意思就比较简单，就是如果操作系统是多核的，那就增加一个LOCK。\n- cmpxchgl就是汇编版的“比较并交换”。但是我们知道比较并交换，有三个步骤，不是原子的。所以在多核情况下加一个 LOCK，由CPU硬件保证他的原子性。\n- 我们再看看LOCK是怎么实现的呢？我们去Intel的官网上看看，可以知道LOCK在的早期实现是直接将cup的总线阻塞，这样的实现可见效率是很低下的。后来优化为X86 cpu 有锁定一个特定内存地址的能力，当这个特定内存地址被锁定后，它就可以阻止其他的系统总线读取或修改这个内存地址。\n\n关于CAS的底层探索我们就到此为止。我们总结一下JAVA的CAS是怎么实现的：\n1. java的cas利用的的是unsafe这个类提供的cas操作。\n2. unsafe的cas依赖了的是jvm针对不同的操作系统实现的 Atomic::cmpxchg\n3. Atomic::cmpxchg的实现使用了汇编的cas操作，并使用cpu硬件提供的lock信号保证其原子性\n\n# CAS带来的问题\n## ABA\n以下是维基百科定义：\n\nIn multithreaded computing, the ABA problem occurs during synchronization, when a location is read twice, has the same value for both reads, and \"value is the same\" is used to indicate \"nothing has changed\". However, another thread can execute between the two reads and change the value, do other work, then change the value back, thus fooling the first thread into thinking \"nothing has changed\" even though the second thread did work that violates that assumption.\n\nhe ABA problem occurs when multiple threads (or processes) accessing shared data interleave. Below is the sequence of events that will result in the ABA problem:\n\n1. Process P1 reads value A from shared memory,\n2. P1 is preempted, allowing process P2 to run,\n3. P2 modifies the shared memory value A to value B and back to A before preemption,\n4. P1 begins execution again, sees that the shared memory value has not changed and continues.\n\nAlthough P1 can continue executing, it is possible that the behavior will not be correct due to the \"hidden\" modification in shared memory.\n\nA common case of the ABA problem is encountered when implementing a lock-free data structure. If an item is removed from the list, deleted, and then a new item is allocated and added to the list, it is common for the allocated object to be at the same location as the deleted object due to optimization. A pointer to the new item is thus sometimes equal to a pointer to the old item which is an ABA problem.\n\n简而言之，当两个线程访问同一个地址时，将“值相同”用于表示“没有变化”。\n - 线程P1从内存中取出A\n - 线程P2也从内存中取出A\n - 线程P2进行操作并且将值修改为B，而后又修改为A。\n - 线程P1进行CAS操作时候发现值仍为A，便可以进行操作。\n\n其实在一般情况下，看似以最终结果来看可以认为是没有问题的，但是整个操作的过程是有问题的，比如：链表的头在变化了两次后恢复了原值，但并不代表链表没有发生过变化。\n### 解决思路\nTagged state reference 标记状态参考：使用某个标识来表示是否有过变更的版本信息。JDK中有提供AtomicStampedReference/AtomicMarkableReference用于解决ABA问题。\n\n还有两种不常用的解决方案：\n- Intermediate nodes 中间节点\n- Deferred reclamation\n\n# 参考资料\n* https://segmentfault.com/a/1190000013127775\n* https://en.wikipedia.org/wiki/Compare-and-swap\n* https://en.wikipedia.org/wiki/ABA_problem","slug":"CAS","published":1,"updated":"2020-02-17T08:28:55.070Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl43004sqotnsnlsr9ek","content":"<p>转眼间就2020年了，去年学习的东西甚少，今年要多看看书了。</p>\n<a id=\"more\"></a>\n<h1 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h1><blockquote>\n<p>In computer science, compare-and-swap (CAS) is an atomic instruction used in multithreading to achieve synchronization. It compares the contents of a memory location with a given value and, only if they are the same, modifies the contents of that memory location to a new given value. This is done as a single atomic operation. The atomicity guarantees that the new value is calculated based on up-to-date information; if the value had been updated by another thread in the meantime, the write would fail. The result of the operation must indicate whether it performed the substitution; this can be done either with a simple boolean response (this variant is often called compare-and-set), or by returning the value read from the memory location (not the value written to it).</p>\n</blockquote>\n<p>在计算机科学中，比较和交换（Conmpare And Swap）是用于实现多线程同步的原子指令。 它将内存位置的内容与给定值进行比较，只有在相同的情况下，将该内存位置的内容修改为新的给定值。 这是作为单个原子操作完成的。 原子性保证新值基于最新信息计算; 如果该值在同一时间被另一个线程更新，则写入将失败。 操作结果必须说明是否进行替换; 这可以通过一个简单的布尔响应（这个变体通常称为比较和设置），或通过返回从内存位置读取的值来完成（摘自维基本科）</p>\n<h2 id=\"举例解释\"><a href=\"#举例解释\" class=\"headerlink\" title=\"举例解释\"></a>举例解释</h2><p>字面意思“比较并交换”，一个CAS涉及到以下操作：</p>\n<blockquote>\n<p>我们假设内存中的元数据V，旧的预期值A，需要修改的新值B。</p>\n<ol>\n<li>比较 A 与 V 是否相等。（比较）</li>\n<li>如果比较相等，将 B 写入 V。（交换）</li>\n<li>返回操作是否成功。</li>\n</ol>\n</blockquote>\n<h1 id=\"JAVA中CAS的实现\"><a href=\"#JAVA中CAS的实现\" class=\"headerlink\" title=\"JAVA中CAS的实现\"></a>JAVA中CAS的实现</h1><h2 id=\"JDK工具类中的使用\"><a href=\"#JDK工具类中的使用\" class=\"headerlink\" title=\"JDK工具类中的使用\"></a>JDK工具类中的使用</h2><p>在JDK的源码中，可以在java.util.concurrent的atomic包和locks包下看到使用到CAS。以AtomicInteger举例<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">    * Atomically sets the value to the given updated value</span></span><br><span class=\"line\"><span class=\"comment\">    * if the current value &#123;<span class=\"doctag\">@code</span> ==&#125; the expected value.</span></span><br><span class=\"line\"><span class=\"comment\">    *</span></span><br><span class=\"line\"><span class=\"comment\">    * <span class=\"doctag\">@param</span> expect the expected value</span></span><br><span class=\"line\"><span class=\"comment\">    * <span class=\"doctag\">@param</span> update the new value</span></span><br><span class=\"line\"><span class=\"comment\">    * <span class=\"doctag\">@return</span> &#123;<span class=\"doctag\">@code</span> true&#125; if successful. False return indicates that</span></span><br><span class=\"line\"><span class=\"comment\">    * the actual value was not equal to the expected value.</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">boolean</span> <span class=\"title\">compareAndSet</span><span class=\"params\">(<span class=\"keyword\">int</span> expect, <span class=\"keyword\">int</span> update)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> unsafe.compareAndSwapInt(<span class=\"keyword\">this</span>, valueOffset, expect, update);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>可以看到在compareAndSet中，通过unsafe对象调用了native修饰的compareAndSwapInt方法。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">native</span> <span class=\"keyword\">boolean</span> <span class=\"title\">compareAndSwapInt</span><span class=\"params\">(Object var1, <span class=\"keyword\">long</span> var2, <span class=\"keyword\">int</span> var4, <span class=\"keyword\">int</span> var5)</span></span>;</span><br></pre></td></tr></table></figure>\n<h2 id=\"JVM底层调用\"><a href=\"#JVM底层调用\" class=\"headerlink\" title=\"JVM底层调用\"></a>JVM底层调用</h2><p>关于native修饰的底层调用本地方式实现的内容，我直接查看了一些文章。</p>\n<p>我们发现在 /jdk9u/hotspot/src/share/vm/unsafe.cpp中有这样的代码：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;CC &quot;compareAndSetInt&quot;, CC &quot;(&quot; OBJ &quot;J&quot;&quot;I&quot;&quot;I&quot;&quot;)Z&quot;, FN_PTR(Unsafe_CompareAndSetInt)&#125;,</span><br></pre></td></tr></table></figure></p>\n<p>这个涉及到JNI的调用，感兴趣的同学可以自行学习。我们搜索Unsafe_CompareAndSetInt后发现:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSetInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) &#123;</span><br><span class=\"line\">  oop p = JNIHandles::resolve(obj);</span><br><span class=\"line\">  jint* addr = (jint *)index_oop_from_field_offset_long(p, offset);</span><br><span class=\"line\"></span><br><span class=\"line\">  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;</span><br><span class=\"line\">&#125; UNSAFE_END</span><br></pre></td></tr></table></figure></p>\n<p>最终我们终于看到了核心代码Atomic::cmpxchg。</p>\n<p>继续向底层探索，在文件java/jdk9u/hotspot/src/os_cpu/linux_x86/vm/atomic_linux_x86.hpp有这样的代码:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value, cmpxchg_memory_order order) &#123;</span><br><span class=\"line\">  int mp = os::is_MP();</span><br><span class=\"line\">  __asm__ volatile (LOCK_IF_MP(%4) &quot;cmpxchgl %1,(%3)&quot;</span><br><span class=\"line\">                    : &quot;=a&quot; (exchange_value)</span><br><span class=\"line\">                    : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp)</span><br><span class=\"line\">                    : &quot;cc&quot;, &quot;memory&quot;);</span><br><span class=\"line\">  return exchange_value;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>我们通过文件名可以知道，针对不同的操作系统,JVM 对于Atomic::cmpxchg应该有不同的实现。由于我们服务基本都是使用的是64位linux，所以我们就看看linux_x86的实现。<br>我们继续看代码：</p>\n<ul>\n<li><strong>asm</strong>的意思是这个是一段内嵌汇编代码。也就是在C语言中使用汇编代码。</li>\n<li>这里的volatile和JAVA有一点类似，但不是为了内存的可见性，而是告诉编译器对访问该变量的代码就不再进行优化。</li>\n<li>LOCK_IF_MP(%4)的意思就比较简单，就是如果操作系统是多核的，那就增加一个LOCK。</li>\n<li>cmpxchgl就是汇编版的“比较并交换”。但是我们知道比较并交换，有三个步骤，不是原子的。所以在多核情况下加一个 LOCK，由CPU硬件保证他的原子性。</li>\n<li>我们再看看LOCK是怎么实现的呢？我们去Intel的官网上看看，可以知道LOCK在的早期实现是直接将cup的总线阻塞，这样的实现可见效率是很低下的。后来优化为X86 cpu 有锁定一个特定内存地址的能力，当这个特定内存地址被锁定后，它就可以阻止其他的系统总线读取或修改这个内存地址。</li>\n</ul>\n<p>关于CAS的底层探索我们就到此为止。我们总结一下JAVA的CAS是怎么实现的：</p>\n<ol>\n<li>java的cas利用的的是unsafe这个类提供的cas操作。</li>\n<li>unsafe的cas依赖了的是jvm针对不同的操作系统实现的 Atomic::cmpxchg</li>\n<li>Atomic::cmpxchg的实现使用了汇编的cas操作，并使用cpu硬件提供的lock信号保证其原子性</li>\n</ol>\n<h1 id=\"CAS带来的问题\"><a href=\"#CAS带来的问题\" class=\"headerlink\" title=\"CAS带来的问题\"></a>CAS带来的问题</h1><h2 id=\"ABA\"><a href=\"#ABA\" class=\"headerlink\" title=\"ABA\"></a>ABA</h2><p>以下是维基百科定义：</p>\n<p>In multithreaded computing, the ABA problem occurs during synchronization, when a location is read twice, has the same value for both reads, and “value is the same” is used to indicate “nothing has changed”. However, another thread can execute between the two reads and change the value, do other work, then change the value back, thus fooling the first thread into thinking “nothing has changed” even though the second thread did work that violates that assumption.</p>\n<p>he ABA problem occurs when multiple threads (or processes) accessing shared data interleave. Below is the sequence of events that will result in the ABA problem:</p>\n<ol>\n<li>Process P1 reads value A from shared memory,</li>\n<li>P1 is preempted, allowing process P2 to run,</li>\n<li>P2 modifies the shared memory value A to value B and back to A before preemption,</li>\n<li>P1 begins execution again, sees that the shared memory value has not changed and continues.</li>\n</ol>\n<p>Although P1 can continue executing, it is possible that the behavior will not be correct due to the “hidden” modification in shared memory.</p>\n<p>A common case of the ABA problem is encountered when implementing a lock-free data structure. If an item is removed from the list, deleted, and then a new item is allocated and added to the list, it is common for the allocated object to be at the same location as the deleted object due to optimization. A pointer to the new item is thus sometimes equal to a pointer to the old item which is an ABA problem.</p>\n<p>简而言之，当两个线程访问同一个地址时，将“值相同”用于表示“没有变化”。</p>\n<ul>\n<li>线程P1从内存中取出A</li>\n<li>线程P2也从内存中取出A</li>\n<li>线程P2进行操作并且将值修改为B，而后又修改为A。</li>\n<li>线程P1进行CAS操作时候发现值仍为A，便可以进行操作。</li>\n</ul>\n<p>其实在一般情况下，看似以最终结果来看可以认为是没有问题的，但是整个操作的过程是有问题的，比如：链表的头在变化了两次后恢复了原值，但并不代表链表没有发生过变化。</p>\n<h3 id=\"解决思路\"><a href=\"#解决思路\" class=\"headerlink\" title=\"解决思路\"></a>解决思路</h3><p>Tagged state reference 标记状态参考：使用某个标识来表示是否有过变更的版本信息。JDK中有提供AtomicStampedReference/AtomicMarkableReference用于解决ABA问题。</p>\n<p>还有两种不常用的解决方案：</p>\n<ul>\n<li>Intermediate nodes 中间节点</li>\n<li>Deferred reclamation</li>\n</ul>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://segmentfault.com/a/1190000013127775\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000013127775</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Compare-and-swap\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Compare-and-swap</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/ABA_problem\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/ABA_problem</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>转眼间就2020年了，去年学习的东西甚少，今年要多看看书了。</p>","more":"<h1 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h1><blockquote>\n<p>In computer science, compare-and-swap (CAS) is an atomic instruction used in multithreading to achieve synchronization. It compares the contents of a memory location with a given value and, only if they are the same, modifies the contents of that memory location to a new given value. This is done as a single atomic operation. The atomicity guarantees that the new value is calculated based on up-to-date information; if the value had been updated by another thread in the meantime, the write would fail. The result of the operation must indicate whether it performed the substitution; this can be done either with a simple boolean response (this variant is often called compare-and-set), or by returning the value read from the memory location (not the value written to it).</p>\n</blockquote>\n<p>在计算机科学中，比较和交换（Conmpare And Swap）是用于实现多线程同步的原子指令。 它将内存位置的内容与给定值进行比较，只有在相同的情况下，将该内存位置的内容修改为新的给定值。 这是作为单个原子操作完成的。 原子性保证新值基于最新信息计算; 如果该值在同一时间被另一个线程更新，则写入将失败。 操作结果必须说明是否进行替换; 这可以通过一个简单的布尔响应（这个变体通常称为比较和设置），或通过返回从内存位置读取的值来完成（摘自维基本科）</p>\n<h2 id=\"举例解释\"><a href=\"#举例解释\" class=\"headerlink\" title=\"举例解释\"></a>举例解释</h2><p>字面意思“比较并交换”，一个CAS涉及到以下操作：</p>\n<blockquote>\n<p>我们假设内存中的元数据V，旧的预期值A，需要修改的新值B。</p>\n<ol>\n<li>比较 A 与 V 是否相等。（比较）</li>\n<li>如果比较相等，将 B 写入 V。（交换）</li>\n<li>返回操作是否成功。</li>\n</ol>\n</blockquote>\n<h1 id=\"JAVA中CAS的实现\"><a href=\"#JAVA中CAS的实现\" class=\"headerlink\" title=\"JAVA中CAS的实现\"></a>JAVA中CAS的实现</h1><h2 id=\"JDK工具类中的使用\"><a href=\"#JDK工具类中的使用\" class=\"headerlink\" title=\"JDK工具类中的使用\"></a>JDK工具类中的使用</h2><p>在JDK的源码中，可以在java.util.concurrent的atomic包和locks包下看到使用到CAS。以AtomicInteger举例<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">    * Atomically sets the value to the given updated value</span></span><br><span class=\"line\"><span class=\"comment\">    * if the current value &#123;<span class=\"doctag\">@code</span> ==&#125; the expected value.</span></span><br><span class=\"line\"><span class=\"comment\">    *</span></span><br><span class=\"line\"><span class=\"comment\">    * <span class=\"doctag\">@param</span> expect the expected value</span></span><br><span class=\"line\"><span class=\"comment\">    * <span class=\"doctag\">@param</span> update the new value</span></span><br><span class=\"line\"><span class=\"comment\">    * <span class=\"doctag\">@return</span> &#123;<span class=\"doctag\">@code</span> true&#125; if successful. False return indicates that</span></span><br><span class=\"line\"><span class=\"comment\">    * the actual value was not equal to the expected value.</span></span><br><span class=\"line\"><span class=\"comment\">    */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">boolean</span> <span class=\"title\">compareAndSet</span><span class=\"params\">(<span class=\"keyword\">int</span> expect, <span class=\"keyword\">int</span> update)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> unsafe.compareAndSwapInt(<span class=\"keyword\">this</span>, valueOffset, expect, update);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>可以看到在compareAndSet中，通过unsafe对象调用了native修饰的compareAndSwapInt方法。<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> Unsafe unsafe = Unsafe.getUnsafe();</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">native</span> <span class=\"keyword\">boolean</span> <span class=\"title\">compareAndSwapInt</span><span class=\"params\">(Object var1, <span class=\"keyword\">long</span> var2, <span class=\"keyword\">int</span> var4, <span class=\"keyword\">int</span> var5)</span></span>;</span><br></pre></td></tr></table></figure>\n<h2 id=\"JVM底层调用\"><a href=\"#JVM底层调用\" class=\"headerlink\" title=\"JVM底层调用\"></a>JVM底层调用</h2><p>关于native修饰的底层调用本地方式实现的内容，我直接查看了一些文章。</p>\n<p>我们发现在 /jdk9u/hotspot/src/share/vm/unsafe.cpp中有这样的代码：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;CC &quot;compareAndSetInt&quot;, CC &quot;(&quot; OBJ &quot;J&quot;&quot;I&quot;&quot;I&quot;&quot;)Z&quot;, FN_PTR(Unsafe_CompareAndSetInt)&#125;,</span><br></pre></td></tr></table></figure></p>\n<p>这个涉及到JNI的调用，感兴趣的同学可以自行学习。我们搜索Unsafe_CompareAndSetInt后发现:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSetInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) &#123;</span><br><span class=\"line\">  oop p = JNIHandles::resolve(obj);</span><br><span class=\"line\">  jint* addr = (jint *)index_oop_from_field_offset_long(p, offset);</span><br><span class=\"line\"></span><br><span class=\"line\">  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;</span><br><span class=\"line\">&#125; UNSAFE_END</span><br></pre></td></tr></table></figure></p>\n<p>最终我们终于看到了核心代码Atomic::cmpxchg。</p>\n<p>继续向底层探索，在文件java/jdk9u/hotspot/src/os_cpu/linux_x86/vm/atomic_linux_x86.hpp有这样的代码:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">inline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value, cmpxchg_memory_order order) &#123;</span><br><span class=\"line\">  int mp = os::is_MP();</span><br><span class=\"line\">  __asm__ volatile (LOCK_IF_MP(%4) &quot;cmpxchgl %1,(%3)&quot;</span><br><span class=\"line\">                    : &quot;=a&quot; (exchange_value)</span><br><span class=\"line\">                    : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp)</span><br><span class=\"line\">                    : &quot;cc&quot;, &quot;memory&quot;);</span><br><span class=\"line\">  return exchange_value;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>我们通过文件名可以知道，针对不同的操作系统,JVM 对于Atomic::cmpxchg应该有不同的实现。由于我们服务基本都是使用的是64位linux，所以我们就看看linux_x86的实现。<br>我们继续看代码：</p>\n<ul>\n<li><strong>asm</strong>的意思是这个是一段内嵌汇编代码。也就是在C语言中使用汇编代码。</li>\n<li>这里的volatile和JAVA有一点类似，但不是为了内存的可见性，而是告诉编译器对访问该变量的代码就不再进行优化。</li>\n<li>LOCK_IF_MP(%4)的意思就比较简单，就是如果操作系统是多核的，那就增加一个LOCK。</li>\n<li>cmpxchgl就是汇编版的“比较并交换”。但是我们知道比较并交换，有三个步骤，不是原子的。所以在多核情况下加一个 LOCK，由CPU硬件保证他的原子性。</li>\n<li>我们再看看LOCK是怎么实现的呢？我们去Intel的官网上看看，可以知道LOCK在的早期实现是直接将cup的总线阻塞，这样的实现可见效率是很低下的。后来优化为X86 cpu 有锁定一个特定内存地址的能力，当这个特定内存地址被锁定后，它就可以阻止其他的系统总线读取或修改这个内存地址。</li>\n</ul>\n<p>关于CAS的底层探索我们就到此为止。我们总结一下JAVA的CAS是怎么实现的：</p>\n<ol>\n<li>java的cas利用的的是unsafe这个类提供的cas操作。</li>\n<li>unsafe的cas依赖了的是jvm针对不同的操作系统实现的 Atomic::cmpxchg</li>\n<li>Atomic::cmpxchg的实现使用了汇编的cas操作，并使用cpu硬件提供的lock信号保证其原子性</li>\n</ol>\n<h1 id=\"CAS带来的问题\"><a href=\"#CAS带来的问题\" class=\"headerlink\" title=\"CAS带来的问题\"></a>CAS带来的问题</h1><h2 id=\"ABA\"><a href=\"#ABA\" class=\"headerlink\" title=\"ABA\"></a>ABA</h2><p>以下是维基百科定义：</p>\n<p>In multithreaded computing, the ABA problem occurs during synchronization, when a location is read twice, has the same value for both reads, and “value is the same” is used to indicate “nothing has changed”. However, another thread can execute between the two reads and change the value, do other work, then change the value back, thus fooling the first thread into thinking “nothing has changed” even though the second thread did work that violates that assumption.</p>\n<p>he ABA problem occurs when multiple threads (or processes) accessing shared data interleave. Below is the sequence of events that will result in the ABA problem:</p>\n<ol>\n<li>Process P1 reads value A from shared memory,</li>\n<li>P1 is preempted, allowing process P2 to run,</li>\n<li>P2 modifies the shared memory value A to value B and back to A before preemption,</li>\n<li>P1 begins execution again, sees that the shared memory value has not changed and continues.</li>\n</ol>\n<p>Although P1 can continue executing, it is possible that the behavior will not be correct due to the “hidden” modification in shared memory.</p>\n<p>A common case of the ABA problem is encountered when implementing a lock-free data structure. If an item is removed from the list, deleted, and then a new item is allocated and added to the list, it is common for the allocated object to be at the same location as the deleted object due to optimization. A pointer to the new item is thus sometimes equal to a pointer to the old item which is an ABA problem.</p>\n<p>简而言之，当两个线程访问同一个地址时，将“值相同”用于表示“没有变化”。</p>\n<ul>\n<li>线程P1从内存中取出A</li>\n<li>线程P2也从内存中取出A</li>\n<li>线程P2进行操作并且将值修改为B，而后又修改为A。</li>\n<li>线程P1进行CAS操作时候发现值仍为A，便可以进行操作。</li>\n</ul>\n<p>其实在一般情况下，看似以最终结果来看可以认为是没有问题的，但是整个操作的过程是有问题的，比如：链表的头在变化了两次后恢复了原值，但并不代表链表没有发生过变化。</p>\n<h3 id=\"解决思路\"><a href=\"#解决思路\" class=\"headerlink\" title=\"解决思路\"></a>解决思路</h3><p>Tagged state reference 标记状态参考：使用某个标识来表示是否有过变更的版本信息。JDK中有提供AtomicStampedReference/AtomicMarkableReference用于解决ABA问题。</p>\n<p>还有两种不常用的解决方案：</p>\n<ul>\n<li>Intermediate nodes 中间节点</li>\n<li>Deferred reclamation</li>\n</ul>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"https://segmentfault.com/a/1190000013127775\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000013127775</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Compare-and-swap\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Compare-and-swap</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/ABA_problem\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/ABA_problem</a></li>\n</ul>"},{"title":"对象的创建及类的加载机制","date":"2018-11-28T06:20:10.000Z","_content":"\n> 本篇是最近在学习JVM相关知识时的随笔，虽然我们现在大都通过Spring容器进行对象的实例化，但本身应当了解对象的各类创建方式，以及最基本的Class文件如何通过何种方式加载到内存中生成对应的对象的。\n\n<!-- more -->\n\n## 类加载的各种几种方式和区别\n\n1. new\n2. clazz.newInstance\n3. constructor.newInstance\n4. clone\n5. 反序列化\n6. ClassLoader\n\n总结起来有对象的实例化方式分为：\n\nnew关键字进行实例化、反射机制进行实例化、克隆对象实例化、反序列化方式实例化，以及以上几种方式的最基本的类加载器加载对象。\n\n注：clazz.newInstance在JDK1.9之后变为了Deprecated，不推荐使用。\nclazz.getDeclearedConstructor().newInstance()，通过构造器类进行实例化。\n\n## ClassLoader\n\n> 我们都知道JAVA程序是运行在JVM中，我们编写的.java文件编译后生成.class文件，而该文件用于描述类的数据结构，以及通过CLASSPATH加载其他相关类的支持。而.class文件加载到JVM内存中这个过程，就是由ClassLoader完成的。\n\n类加载器主要分为两类，一类是JDK默认提供的，一类是用户自定义的。 \n\n* JDK1.8以前：\n\n    ![classloader01-photo](/image/classloader01.png)\n\n* JDK1.8之后：\n\n    ![classloader02-photo](/image/classloader02.jpg)\n\n### JDK 默认提供三种类加载器：\n\n* Bootstrap ClassLoader 启动类加载器\n\n    每次执行java命令时都会使用该加载器为虚拟机加载核心类。该加载器是由nativecode实现，而不是Java代码，加载类的路径为<JAVA_HOME>/jre/lib。特别的 <JAVA_HOME>/jre/lib/rt.jar中包含了sun.misc.Launcher 类， 而sun.misc.Launcher$ExtClassLoader和sun.misc.Launcher$AppClassLoader都是 sun.misc.Launcher的内部类，所以拓展类加载器和系统类加载器都是由启动类加载器加载的。\n\n* PlatformClassLoader，平台类加载器；（JDK1.8以前为Extension ClassLoader, 拓展类加载器）\n\n    JDK1.8之前：JDK目录下提供的ext目录，可以直接将需要执行的扩展jar包直接放入运行，但并不提倡使用，因为不安全，现在已经废除。用于加载拓展库中的类。拓展库路径为<JAVA_HOME>/jre/lib/ext/。实现类为sun.misc.Launcher$ExtClassLoader\n\n* System ClassLoader 系统类加载器：\n\n    用于加载CLASSPATH中的类。实现类为sun.misc.Launcher$AppClassLoader\n\n### 用户自定义的类加载器\n\n* Custom ClassLoader, 一般都是java.lang.ClassLoder的子类\n\n    正统的类加载机制是基于双亲委派的，也就是当调用类加载器加载类时，首先将加载任务委派给双亲，若双亲无法加载成功时，自己才进行类加载。\n\n    在实例化一个新的类加载器时，我们可以为其指定一个parent，即双亲，若未显式指定，则System ClassLoader就作为默认双亲。\n\n    具体的说，类加载任务是由ClassLoader的loadClass() 方法来执行的，他会按照以下顺序加载类：\n\n    通过findLoadedClass() 看该类是否已经被加载。该方法为nativecode 实现，若已加载则返回。\n    \n    若未加载则委派给双亲，parent.loadClass()，若成功则返回。\n    \n    若未成功，则调用 findClass() 方法加载类。java.lang.ClassLoader中该方法只是简单的抛出一个ClassNotFoundException所以，自定义的ClassLoader都需要 Override findClass() 方法。\n\n### ClassLoader的API\n\n#### java.lang.ClassLoader\n\n* ClassLoader 是一个抽象类。\n* 待加载的类必须用The Java™Language Specification 定义的全类名，全类名的定义请查阅The Form of a Binary。\n* 给定一个全类名，类加载器应该去定位该类所在的位置。通用的策略是将全类名转换为类文件路径，然后通过类文件路径在文件系统中定位。\n* 每一个加载到内存的类都由一个Class对象来表示，每一个Class对象都有一个指向加载该类的类加载器的引用。但是数组的Class对象是由Java运行时环境创建的，通过 Class.getClassLoader()方法返回的是数组元素的类加载器，若数组元素是基本类型，则返回null，若类是由Bootstrap ClassLoader加载的话也是返回null。\n* ClassLoader默认支持并行加载，但是其子类必须调用ClassLoader.registerAsParallelCapable()来启用并行加载\n* 一般来说,JVM从本地文件系统加载类的行为是与平台有关的。\n* defineClass() 方法可以将字节流转换成一个Class对象。然后调用Class.newInstance()来创建类的实例\n\n```java\npublic static void main(String[] args) {\n    // Object 类在 <java_home>/jre/lib/rt.jar 中，\n    // 由 Bootstrap ClassLoader 加载，由于该类加载器是由 native code 编写\n    // 所以输出为 null\n    Object[] objects = new Object[5];\n    System.out.println();\n    System.out.println(objects.getClass().getClassLoader());\n\n    // ZipFileAttributes 类在 <java_home>/jre/lib/ext/zipfs.jar 中，\n    // 由 Extension ClassLoader 加载，\n    // 输出为  sun.misc.Launcher$ExtClassLoader@4b67cf4d\n    ZipFileAttributes[] attributes = new ZipFileAttributes[5];\n    System.out.println();\n    System.out.println(attributes.getClass().getClassLoader());\n\n    // Main 类是自定义的类，\n    // 默认由 System ClassLoader 加载，\n    // 输出为 sun.misc.Launcher$AppClassLoader@18b4aac2\n    Main[] array = new Main[5];\n    array[0] = new Main();\n    System.out.println();\n    System.out.println(array.getClass().getClassLoader());\n}\n```\n\n#### java.security.SecureClassLoader\n增加了一层权限验证，因为关注点不在安全，所以暂不讨论。\n\n#### java.net.URLClassLoader\n该类加载器用来加载URL指定的JAR文件或目录中的类和资源，以/结尾的URL认为是目录，否则认为是JAR文件。\n\n```java\n// 尝试通过 URLClassLoader 来加载桌面下的 Test 类。\npublic static void main(String[] args) {\n    try {\n        URL[] urls = new URL[1];\n        URLStreamHandler streamHandler = null;\n        File classPath = new File(\"/home/chen/Desktop/\");\n        String repository = (new URL(\"file\", null,\n                classPath.getCanonicalPath() + File.separator))\n                .toString();\n        urls[0] = new URL(null, repository, streamHandler);\n\n        ClassLoader loader = new URLClassLoader(urls);\n\n        Class testClass = loader.loadClass(\"Test\");\n\n        // output:  java.net.URLClassLoader@7f31245a\n        System.out.println(testClass.getClassLoader());\n    } catch (MalformedURLException e) {\n        e.printStackTrace();\n    } catch (IOException e) {\n        e.printStackTrace();\n    } catch (ClassNotFoundException e) {\n        e.printStackTrace();\n    }\n}\n\n```\n\n## 破坏双亲委派机制\n可以看出双亲委派机制是一种至下而上的加载方式，那么SPI是如何打破这种关系？\n\n以JDBC加载驱动为例：\n在JDBC4.0之后支持SPI方式加载java.sql.Driver的实现类。SPI实现方式为，通过ServiceLoader.load(Driver.class)方法，去各自实现Driver接口的lib的META-INF/services/java.sql.Driver文件里找到实现类的名字，通过Thread.currentThread().getContextClassLoader()类加载器加载实现类并返回实例。\n\n先看下如果不用Thread.currentThread().getContextClassLoader()加载器加载，整个流程会怎么样。\n\n- 从META-INF/services/java.sql.Driver文件得到实现类名字DriverA\n- Class.forName(\"xx.xx.DriverA\")来加载实现类\n- Class.forName()方法默认使用当前类的ClassLoader，JDBC是在DriverManager类里调用Driver的，当前类也就是DriverManager，它的加载器是BootstrapClassLoader。\n\n用BootstrapClassLoader去加载非rt.jar包里的类xx.xx.DriverA，就会找不到。要加载xx.xx.DriverA需要用到AppClassLoader或其他自定义ClassLoader\n\n最终矛盾出现在，要在BootstrapClassLoader加载的类里，调用AppClassLoader去加载实现类。这样就出现了一个问题：如何在父加载器加载的类中，去调用子加载器去加载类？\n\njdk提供了两种方式，\n- Thread.currentThread().getContextClassLoader()\n- ClassLoader.getSystemClassLoader()\n一般都指向AppClassLoader，他们能加载classpath中的类\n\nSPI则用Thread.currentThread().getContextClassLoader()来加载实现类，实现在核心包里的基础类调用用户代码\n\n## 参考资料\n* https://github.com/c-rainstorm/blog/blob/master/java\n* https://mp.weixin.qq.com/s/HIiy7Q5UoPySFn3ge8Y-Ow\n* https://docs.oracle.com/javase/tutorial/ext/basics/load.html\n* https://en.wikipedia.org/wiki/Java_Classloader\n* https://www.jianshu.com/p/9cf306550b0a","source":"_posts/对象创建及类的加载机制.md","raw":"---\ntitle: 对象的创建及类的加载机制\ndate: 2018-11-28 14:20:10\ntags: Java\ncategories: Java\n---\n\n> 本篇是最近在学习JVM相关知识时的随笔，虽然我们现在大都通过Spring容器进行对象的实例化，但本身应当了解对象的各类创建方式，以及最基本的Class文件如何通过何种方式加载到内存中生成对应的对象的。\n\n<!-- more -->\n\n## 类加载的各种几种方式和区别\n\n1. new\n2. clazz.newInstance\n3. constructor.newInstance\n4. clone\n5. 反序列化\n6. ClassLoader\n\n总结起来有对象的实例化方式分为：\n\nnew关键字进行实例化、反射机制进行实例化、克隆对象实例化、反序列化方式实例化，以及以上几种方式的最基本的类加载器加载对象。\n\n注：clazz.newInstance在JDK1.9之后变为了Deprecated，不推荐使用。\nclazz.getDeclearedConstructor().newInstance()，通过构造器类进行实例化。\n\n## ClassLoader\n\n> 我们都知道JAVA程序是运行在JVM中，我们编写的.java文件编译后生成.class文件，而该文件用于描述类的数据结构，以及通过CLASSPATH加载其他相关类的支持。而.class文件加载到JVM内存中这个过程，就是由ClassLoader完成的。\n\n类加载器主要分为两类，一类是JDK默认提供的，一类是用户自定义的。 \n\n* JDK1.8以前：\n\n    ![classloader01-photo](/image/classloader01.png)\n\n* JDK1.8之后：\n\n    ![classloader02-photo](/image/classloader02.jpg)\n\n### JDK 默认提供三种类加载器：\n\n* Bootstrap ClassLoader 启动类加载器\n\n    每次执行java命令时都会使用该加载器为虚拟机加载核心类。该加载器是由nativecode实现，而不是Java代码，加载类的路径为<JAVA_HOME>/jre/lib。特别的 <JAVA_HOME>/jre/lib/rt.jar中包含了sun.misc.Launcher 类， 而sun.misc.Launcher$ExtClassLoader和sun.misc.Launcher$AppClassLoader都是 sun.misc.Launcher的内部类，所以拓展类加载器和系统类加载器都是由启动类加载器加载的。\n\n* PlatformClassLoader，平台类加载器；（JDK1.8以前为Extension ClassLoader, 拓展类加载器）\n\n    JDK1.8之前：JDK目录下提供的ext目录，可以直接将需要执行的扩展jar包直接放入运行，但并不提倡使用，因为不安全，现在已经废除。用于加载拓展库中的类。拓展库路径为<JAVA_HOME>/jre/lib/ext/。实现类为sun.misc.Launcher$ExtClassLoader\n\n* System ClassLoader 系统类加载器：\n\n    用于加载CLASSPATH中的类。实现类为sun.misc.Launcher$AppClassLoader\n\n### 用户自定义的类加载器\n\n* Custom ClassLoader, 一般都是java.lang.ClassLoder的子类\n\n    正统的类加载机制是基于双亲委派的，也就是当调用类加载器加载类时，首先将加载任务委派给双亲，若双亲无法加载成功时，自己才进行类加载。\n\n    在实例化一个新的类加载器时，我们可以为其指定一个parent，即双亲，若未显式指定，则System ClassLoader就作为默认双亲。\n\n    具体的说，类加载任务是由ClassLoader的loadClass() 方法来执行的，他会按照以下顺序加载类：\n\n    通过findLoadedClass() 看该类是否已经被加载。该方法为nativecode 实现，若已加载则返回。\n    \n    若未加载则委派给双亲，parent.loadClass()，若成功则返回。\n    \n    若未成功，则调用 findClass() 方法加载类。java.lang.ClassLoader中该方法只是简单的抛出一个ClassNotFoundException所以，自定义的ClassLoader都需要 Override findClass() 方法。\n\n### ClassLoader的API\n\n#### java.lang.ClassLoader\n\n* ClassLoader 是一个抽象类。\n* 待加载的类必须用The Java™Language Specification 定义的全类名，全类名的定义请查阅The Form of a Binary。\n* 给定一个全类名，类加载器应该去定位该类所在的位置。通用的策略是将全类名转换为类文件路径，然后通过类文件路径在文件系统中定位。\n* 每一个加载到内存的类都由一个Class对象来表示，每一个Class对象都有一个指向加载该类的类加载器的引用。但是数组的Class对象是由Java运行时环境创建的，通过 Class.getClassLoader()方法返回的是数组元素的类加载器，若数组元素是基本类型，则返回null，若类是由Bootstrap ClassLoader加载的话也是返回null。\n* ClassLoader默认支持并行加载，但是其子类必须调用ClassLoader.registerAsParallelCapable()来启用并行加载\n* 一般来说,JVM从本地文件系统加载类的行为是与平台有关的。\n* defineClass() 方法可以将字节流转换成一个Class对象。然后调用Class.newInstance()来创建类的实例\n\n```java\npublic static void main(String[] args) {\n    // Object 类在 <java_home>/jre/lib/rt.jar 中，\n    // 由 Bootstrap ClassLoader 加载，由于该类加载器是由 native code 编写\n    // 所以输出为 null\n    Object[] objects = new Object[5];\n    System.out.println();\n    System.out.println(objects.getClass().getClassLoader());\n\n    // ZipFileAttributes 类在 <java_home>/jre/lib/ext/zipfs.jar 中，\n    // 由 Extension ClassLoader 加载，\n    // 输出为  sun.misc.Launcher$ExtClassLoader@4b67cf4d\n    ZipFileAttributes[] attributes = new ZipFileAttributes[5];\n    System.out.println();\n    System.out.println(attributes.getClass().getClassLoader());\n\n    // Main 类是自定义的类，\n    // 默认由 System ClassLoader 加载，\n    // 输出为 sun.misc.Launcher$AppClassLoader@18b4aac2\n    Main[] array = new Main[5];\n    array[0] = new Main();\n    System.out.println();\n    System.out.println(array.getClass().getClassLoader());\n}\n```\n\n#### java.security.SecureClassLoader\n增加了一层权限验证，因为关注点不在安全，所以暂不讨论。\n\n#### java.net.URLClassLoader\n该类加载器用来加载URL指定的JAR文件或目录中的类和资源，以/结尾的URL认为是目录，否则认为是JAR文件。\n\n```java\n// 尝试通过 URLClassLoader 来加载桌面下的 Test 类。\npublic static void main(String[] args) {\n    try {\n        URL[] urls = new URL[1];\n        URLStreamHandler streamHandler = null;\n        File classPath = new File(\"/home/chen/Desktop/\");\n        String repository = (new URL(\"file\", null,\n                classPath.getCanonicalPath() + File.separator))\n                .toString();\n        urls[0] = new URL(null, repository, streamHandler);\n\n        ClassLoader loader = new URLClassLoader(urls);\n\n        Class testClass = loader.loadClass(\"Test\");\n\n        // output:  java.net.URLClassLoader@7f31245a\n        System.out.println(testClass.getClassLoader());\n    } catch (MalformedURLException e) {\n        e.printStackTrace();\n    } catch (IOException e) {\n        e.printStackTrace();\n    } catch (ClassNotFoundException e) {\n        e.printStackTrace();\n    }\n}\n\n```\n\n## 破坏双亲委派机制\n可以看出双亲委派机制是一种至下而上的加载方式，那么SPI是如何打破这种关系？\n\n以JDBC加载驱动为例：\n在JDBC4.0之后支持SPI方式加载java.sql.Driver的实现类。SPI实现方式为，通过ServiceLoader.load(Driver.class)方法，去各自实现Driver接口的lib的META-INF/services/java.sql.Driver文件里找到实现类的名字，通过Thread.currentThread().getContextClassLoader()类加载器加载实现类并返回实例。\n\n先看下如果不用Thread.currentThread().getContextClassLoader()加载器加载，整个流程会怎么样。\n\n- 从META-INF/services/java.sql.Driver文件得到实现类名字DriverA\n- Class.forName(\"xx.xx.DriverA\")来加载实现类\n- Class.forName()方法默认使用当前类的ClassLoader，JDBC是在DriverManager类里调用Driver的，当前类也就是DriverManager，它的加载器是BootstrapClassLoader。\n\n用BootstrapClassLoader去加载非rt.jar包里的类xx.xx.DriverA，就会找不到。要加载xx.xx.DriverA需要用到AppClassLoader或其他自定义ClassLoader\n\n最终矛盾出现在，要在BootstrapClassLoader加载的类里，调用AppClassLoader去加载实现类。这样就出现了一个问题：如何在父加载器加载的类中，去调用子加载器去加载类？\n\njdk提供了两种方式，\n- Thread.currentThread().getContextClassLoader()\n- ClassLoader.getSystemClassLoader()\n一般都指向AppClassLoader，他们能加载classpath中的类\n\nSPI则用Thread.currentThread().getContextClassLoader()来加载实现类，实现在核心包里的基础类调用用户代码\n\n## 参考资料\n* https://github.com/c-rainstorm/blog/blob/master/java\n* https://mp.weixin.qq.com/s/HIiy7Q5UoPySFn3ge8Y-Ow\n* https://docs.oracle.com/javase/tutorial/ext/basics/load.html\n* https://en.wikipedia.org/wiki/Java_Classloader\n* https://www.jianshu.com/p/9cf306550b0a","slug":"对象创建及类的加载机制","published":1,"updated":"2020-05-20T03:05:38.588Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl46004uqotnq6vlpplq","content":"<blockquote>\n<p>本篇是最近在学习JVM相关知识时的随笔，虽然我们现在大都通过Spring容器进行对象的实例化，但本身应当了解对象的各类创建方式，以及最基本的Class文件如何通过何种方式加载到内存中生成对应的对象的。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"类加载的各种几种方式和区别\"><a href=\"#类加载的各种几种方式和区别\" class=\"headerlink\" title=\"类加载的各种几种方式和区别\"></a>类加载的各种几种方式和区别</h2><ol>\n<li>new</li>\n<li>clazz.newInstance</li>\n<li>constructor.newInstance</li>\n<li>clone</li>\n<li>反序列化</li>\n<li>ClassLoader</li>\n</ol>\n<p>总结起来有对象的实例化方式分为：</p>\n<p>new关键字进行实例化、反射机制进行实例化、克隆对象实例化、反序列化方式实例化，以及以上几种方式的最基本的类加载器加载对象。</p>\n<p>注：clazz.newInstance在JDK1.9之后变为了Deprecated，不推荐使用。<br>clazz.getDeclearedConstructor().newInstance()，通过构造器类进行实例化。</p>\n<h2 id=\"ClassLoader\"><a href=\"#ClassLoader\" class=\"headerlink\" title=\"ClassLoader\"></a>ClassLoader</h2><blockquote>\n<p>我们都知道JAVA程序是运行在JVM中，我们编写的.java文件编译后生成.class文件，而该文件用于描述类的数据结构，以及通过CLASSPATH加载其他相关类的支持。而.class文件加载到JVM内存中这个过程，就是由ClassLoader完成的。</p>\n</blockquote>\n<p>类加载器主要分为两类，一类是JDK默认提供的，一类是用户自定义的。 </p>\n<ul>\n<li><p>JDK1.8以前：</p>\n<p>  <img src=\"/image/classloader01.png\" alt=\"classloader01-photo\"></p>\n</li>\n<li><p>JDK1.8之后：</p>\n<p>  <img src=\"/image/classloader02.jpg\" alt=\"classloader02-photo\"></p>\n</li>\n</ul>\n<h3 id=\"JDK-默认提供三种类加载器：\"><a href=\"#JDK-默认提供三种类加载器：\" class=\"headerlink\" title=\"JDK 默认提供三种类加载器：\"></a>JDK 默认提供三种类加载器：</h3><ul>\n<li><p>Bootstrap ClassLoader 启动类加载器</p>\n<p>  每次执行java命令时都会使用该加载器为虚拟机加载核心类。该加载器是由nativecode实现，而不是Java代码，加载类的路径为&lt;JAVA_HOME&gt;/jre/lib。特别的 &lt;JAVA_HOME&gt;/jre/lib/rt.jar中包含了sun.misc.Launcher 类， 而sun.misc.Launcher$ExtClassLoader和sun.misc.Launcher$AppClassLoader都是 sun.misc.Launcher的内部类，所以拓展类加载器和系统类加载器都是由启动类加载器加载的。</p>\n</li>\n<li><p>PlatformClassLoader，平台类加载器；（JDK1.8以前为Extension ClassLoader, 拓展类加载器）</p>\n<p>  JDK1.8之前：JDK目录下提供的ext目录，可以直接将需要执行的扩展jar包直接放入运行，但并不提倡使用，因为不安全，现在已经废除。用于加载拓展库中的类。拓展库路径为&lt;JAVA_HOME&gt;/jre/lib/ext/。实现类为sun.misc.Launcher$ExtClassLoader</p>\n</li>\n<li><p>System ClassLoader 系统类加载器：</p>\n<p>  用于加载CLASSPATH中的类。实现类为sun.misc.Launcher$AppClassLoader</p>\n</li>\n</ul>\n<h3 id=\"用户自定义的类加载器\"><a href=\"#用户自定义的类加载器\" class=\"headerlink\" title=\"用户自定义的类加载器\"></a>用户自定义的类加载器</h3><ul>\n<li><p>Custom ClassLoader, 一般都是java.lang.ClassLoder的子类</p>\n<p>  正统的类加载机制是基于双亲委派的，也就是当调用类加载器加载类时，首先将加载任务委派给双亲，若双亲无法加载成功时，自己才进行类加载。</p>\n<p>  在实例化一个新的类加载器时，我们可以为其指定一个parent，即双亲，若未显式指定，则System ClassLoader就作为默认双亲。</p>\n<p>  具体的说，类加载任务是由ClassLoader的loadClass() 方法来执行的，他会按照以下顺序加载类：</p>\n<p>  通过findLoadedClass() 看该类是否已经被加载。该方法为nativecode 实现，若已加载则返回。</p>\n<p>  若未加载则委派给双亲，parent.loadClass()，若成功则返回。</p>\n<p>  若未成功，则调用 findClass() 方法加载类。java.lang.ClassLoader中该方法只是简单的抛出一个ClassNotFoundException所以，自定义的ClassLoader都需要 Override findClass() 方法。</p>\n</li>\n</ul>\n<h3 id=\"ClassLoader的API\"><a href=\"#ClassLoader的API\" class=\"headerlink\" title=\"ClassLoader的API\"></a>ClassLoader的API</h3><h4 id=\"java-lang-ClassLoader\"><a href=\"#java-lang-ClassLoader\" class=\"headerlink\" title=\"java.lang.ClassLoader\"></a>java.lang.ClassLoader</h4><ul>\n<li>ClassLoader 是一个抽象类。</li>\n<li>待加载的类必须用The Java™Language Specification 定义的全类名，全类名的定义请查阅The Form of a Binary。</li>\n<li>给定一个全类名，类加载器应该去定位该类所在的位置。通用的策略是将全类名转换为类文件路径，然后通过类文件路径在文件系统中定位。</li>\n<li>每一个加载到内存的类都由一个Class对象来表示，每一个Class对象都有一个指向加载该类的类加载器的引用。但是数组的Class对象是由Java运行时环境创建的，通过 Class.getClassLoader()方法返回的是数组元素的类加载器，若数组元素是基本类型，则返回null，若类是由Bootstrap ClassLoader加载的话也是返回null。</li>\n<li>ClassLoader默认支持并行加载，但是其子类必须调用ClassLoader.registerAsParallelCapable()来启用并行加载</li>\n<li>一般来说,JVM从本地文件系统加载类的行为是与平台有关的。</li>\n<li>defineClass() 方法可以将字节流转换成一个Class对象。然后调用Class.newInstance()来创建类的实例</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Object 类在 &lt;java_home&gt;/jre/lib/rt.jar 中，</span></span><br><span class=\"line\">    <span class=\"comment\">// 由 Bootstrap ClassLoader 加载，由于该类加载器是由 native code 编写</span></span><br><span class=\"line\">    <span class=\"comment\">// 所以输出为 null</span></span><br><span class=\"line\">    Object[] objects = <span class=\"keyword\">new</span> Object[<span class=\"number\">5</span>];</span><br><span class=\"line\">    System.out.println();</span><br><span class=\"line\">    System.out.println(objects.getClass().getClassLoader());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ZipFileAttributes 类在 &lt;java_home&gt;/jre/lib/ext/zipfs.jar 中，</span></span><br><span class=\"line\">    <span class=\"comment\">// 由 Extension ClassLoader 加载，</span></span><br><span class=\"line\">    <span class=\"comment\">// 输出为  sun.misc.Launcher$ExtClassLoader@4b67cf4d</span></span><br><span class=\"line\">    ZipFileAttributes[] attributes = <span class=\"keyword\">new</span> ZipFileAttributes[<span class=\"number\">5</span>];</span><br><span class=\"line\">    System.out.println();</span><br><span class=\"line\">    System.out.println(attributes.getClass().getClassLoader());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// Main 类是自定义的类，</span></span><br><span class=\"line\">    <span class=\"comment\">// 默认由 System ClassLoader 加载，</span></span><br><span class=\"line\">    <span class=\"comment\">// 输出为 sun.misc.Launcher$AppClassLoader@18b4aac2</span></span><br><span class=\"line\">    Main[] array = <span class=\"keyword\">new</span> Main[<span class=\"number\">5</span>];</span><br><span class=\"line\">    array[<span class=\"number\">0</span>] = <span class=\"keyword\">new</span> Main();</span><br><span class=\"line\">    System.out.println();</span><br><span class=\"line\">    System.out.println(array.getClass().getClassLoader());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"java-security-SecureClassLoader\"><a href=\"#java-security-SecureClassLoader\" class=\"headerlink\" title=\"java.security.SecureClassLoader\"></a>java.security.SecureClassLoader</h4><p>增加了一层权限验证，因为关注点不在安全，所以暂不讨论。</p>\n<h4 id=\"java-net-URLClassLoader\"><a href=\"#java-net-URLClassLoader\" class=\"headerlink\" title=\"java.net.URLClassLoader\"></a>java.net.URLClassLoader</h4><p>该类加载器用来加载URL指定的JAR文件或目录中的类和资源，以/结尾的URL认为是目录，否则认为是JAR文件。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 尝试通过 URLClassLoader 来加载桌面下的 Test 类。</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        URL[] urls = <span class=\"keyword\">new</span> URL[<span class=\"number\">1</span>];</span><br><span class=\"line\">        URLStreamHandler streamHandler = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        File classPath = <span class=\"keyword\">new</span> File(<span class=\"string\">\"/home/chen/Desktop/\"</span>);</span><br><span class=\"line\">        String repository = (<span class=\"keyword\">new</span> URL(<span class=\"string\">\"file\"</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                classPath.getCanonicalPath() + File.separator))</span><br><span class=\"line\">                .toString();</span><br><span class=\"line\">        urls[<span class=\"number\">0</span>] = <span class=\"keyword\">new</span> URL(<span class=\"keyword\">null</span>, repository, streamHandler);</span><br><span class=\"line\"></span><br><span class=\"line\">        ClassLoader loader = <span class=\"keyword\">new</span> URLClassLoader(urls);</span><br><span class=\"line\"></span><br><span class=\"line\">        Class testClass = loader.loadClass(<span class=\"string\">\"Test\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// output:  java.net.URLClassLoader@7f31245a</span></span><br><span class=\"line\">        System.out.println(testClass.getClassLoader());</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (MalformedURLException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (ClassNotFoundException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"破坏双亲委派机制\"><a href=\"#破坏双亲委派机制\" class=\"headerlink\" title=\"破坏双亲委派机制\"></a>破坏双亲委派机制</h2><p>可以看出双亲委派机制是一种至下而上的加载方式，那么SPI是如何打破这种关系？</p>\n<p>以JDBC加载驱动为例：<br>在JDBC4.0之后支持SPI方式加载java.sql.Driver的实现类。SPI实现方式为，通过ServiceLoader.load(Driver.class)方法，去各自实现Driver接口的lib的META-INF/services/java.sql.Driver文件里找到实现类的名字，通过Thread.currentThread().getContextClassLoader()类加载器加载实现类并返回实例。</p>\n<p>先看下如果不用Thread.currentThread().getContextClassLoader()加载器加载，整个流程会怎么样。</p>\n<ul>\n<li>从META-INF/services/java.sql.Driver文件得到实现类名字DriverA</li>\n<li>Class.forName(“xx.xx.DriverA”)来加载实现类</li>\n<li>Class.forName()方法默认使用当前类的ClassLoader，JDBC是在DriverManager类里调用Driver的，当前类也就是DriverManager，它的加载器是BootstrapClassLoader。</li>\n</ul>\n<p>用BootstrapClassLoader去加载非rt.jar包里的类xx.xx.DriverA，就会找不到。要加载xx.xx.DriverA需要用到AppClassLoader或其他自定义ClassLoader</p>\n<p>最终矛盾出现在，要在BootstrapClassLoader加载的类里，调用AppClassLoader去加载实现类。这样就出现了一个问题：如何在父加载器加载的类中，去调用子加载器去加载类？</p>\n<p>jdk提供了两种方式，</p>\n<ul>\n<li>Thread.currentThread().getContextClassLoader()</li>\n<li>ClassLoader.getSystemClassLoader()<br>一般都指向AppClassLoader，他们能加载classpath中的类</li>\n</ul>\n<p>SPI则用Thread.currentThread().getContextClassLoader()来加载实现类，实现在核心包里的基础类调用用户代码</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://github.com/c-rainstorm/blog/blob/master/java\" target=\"_blank\" rel=\"noopener\">https://github.com/c-rainstorm/blog/blob/master/java</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/HIiy7Q5UoPySFn3ge8Y-Ow\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/HIiy7Q5UoPySFn3ge8Y-Ow</a></li>\n<li><a href=\"https://docs.oracle.com/javase/tutorial/ext/basics/load.html\" target=\"_blank\" rel=\"noopener\">https://docs.oracle.com/javase/tutorial/ext/basics/load.html</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Java_Classloader\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Java_Classloader</a></li>\n<li><a href=\"https://www.jianshu.com/p/9cf306550b0a\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/9cf306550b0a</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本篇是最近在学习JVM相关知识时的随笔，虽然我们现在大都通过Spring容器进行对象的实例化，但本身应当了解对象的各类创建方式，以及最基本的Class文件如何通过何种方式加载到内存中生成对应的对象的。</p>\n</blockquote>","more":"<h2 id=\"类加载的各种几种方式和区别\"><a href=\"#类加载的各种几种方式和区别\" class=\"headerlink\" title=\"类加载的各种几种方式和区别\"></a>类加载的各种几种方式和区别</h2><ol>\n<li>new</li>\n<li>clazz.newInstance</li>\n<li>constructor.newInstance</li>\n<li>clone</li>\n<li>反序列化</li>\n<li>ClassLoader</li>\n</ol>\n<p>总结起来有对象的实例化方式分为：</p>\n<p>new关键字进行实例化、反射机制进行实例化、克隆对象实例化、反序列化方式实例化，以及以上几种方式的最基本的类加载器加载对象。</p>\n<p>注：clazz.newInstance在JDK1.9之后变为了Deprecated，不推荐使用。<br>clazz.getDeclearedConstructor().newInstance()，通过构造器类进行实例化。</p>\n<h2 id=\"ClassLoader\"><a href=\"#ClassLoader\" class=\"headerlink\" title=\"ClassLoader\"></a>ClassLoader</h2><blockquote>\n<p>我们都知道JAVA程序是运行在JVM中，我们编写的.java文件编译后生成.class文件，而该文件用于描述类的数据结构，以及通过CLASSPATH加载其他相关类的支持。而.class文件加载到JVM内存中这个过程，就是由ClassLoader完成的。</p>\n</blockquote>\n<p>类加载器主要分为两类，一类是JDK默认提供的，一类是用户自定义的。 </p>\n<ul>\n<li><p>JDK1.8以前：</p>\n<p>  <img src=\"/image/classloader01.png\" alt=\"classloader01-photo\"></p>\n</li>\n<li><p>JDK1.8之后：</p>\n<p>  <img src=\"/image/classloader02.jpg\" alt=\"classloader02-photo\"></p>\n</li>\n</ul>\n<h3 id=\"JDK-默认提供三种类加载器：\"><a href=\"#JDK-默认提供三种类加载器：\" class=\"headerlink\" title=\"JDK 默认提供三种类加载器：\"></a>JDK 默认提供三种类加载器：</h3><ul>\n<li><p>Bootstrap ClassLoader 启动类加载器</p>\n<p>  每次执行java命令时都会使用该加载器为虚拟机加载核心类。该加载器是由nativecode实现，而不是Java代码，加载类的路径为&lt;JAVA_HOME&gt;/jre/lib。特别的 &lt;JAVA_HOME&gt;/jre/lib/rt.jar中包含了sun.misc.Launcher 类， 而sun.misc.Launcher$ExtClassLoader和sun.misc.Launcher$AppClassLoader都是 sun.misc.Launcher的内部类，所以拓展类加载器和系统类加载器都是由启动类加载器加载的。</p>\n</li>\n<li><p>PlatformClassLoader，平台类加载器；（JDK1.8以前为Extension ClassLoader, 拓展类加载器）</p>\n<p>  JDK1.8之前：JDK目录下提供的ext目录，可以直接将需要执行的扩展jar包直接放入运行，但并不提倡使用，因为不安全，现在已经废除。用于加载拓展库中的类。拓展库路径为&lt;JAVA_HOME&gt;/jre/lib/ext/。实现类为sun.misc.Launcher$ExtClassLoader</p>\n</li>\n<li><p>System ClassLoader 系统类加载器：</p>\n<p>  用于加载CLASSPATH中的类。实现类为sun.misc.Launcher$AppClassLoader</p>\n</li>\n</ul>\n<h3 id=\"用户自定义的类加载器\"><a href=\"#用户自定义的类加载器\" class=\"headerlink\" title=\"用户自定义的类加载器\"></a>用户自定义的类加载器</h3><ul>\n<li><p>Custom ClassLoader, 一般都是java.lang.ClassLoder的子类</p>\n<p>  正统的类加载机制是基于双亲委派的，也就是当调用类加载器加载类时，首先将加载任务委派给双亲，若双亲无法加载成功时，自己才进行类加载。</p>\n<p>  在实例化一个新的类加载器时，我们可以为其指定一个parent，即双亲，若未显式指定，则System ClassLoader就作为默认双亲。</p>\n<p>  具体的说，类加载任务是由ClassLoader的loadClass() 方法来执行的，他会按照以下顺序加载类：</p>\n<p>  通过findLoadedClass() 看该类是否已经被加载。该方法为nativecode 实现，若已加载则返回。</p>\n<p>  若未加载则委派给双亲，parent.loadClass()，若成功则返回。</p>\n<p>  若未成功，则调用 findClass() 方法加载类。java.lang.ClassLoader中该方法只是简单的抛出一个ClassNotFoundException所以，自定义的ClassLoader都需要 Override findClass() 方法。</p>\n</li>\n</ul>\n<h3 id=\"ClassLoader的API\"><a href=\"#ClassLoader的API\" class=\"headerlink\" title=\"ClassLoader的API\"></a>ClassLoader的API</h3><h4 id=\"java-lang-ClassLoader\"><a href=\"#java-lang-ClassLoader\" class=\"headerlink\" title=\"java.lang.ClassLoader\"></a>java.lang.ClassLoader</h4><ul>\n<li>ClassLoader 是一个抽象类。</li>\n<li>待加载的类必须用The Java™Language Specification 定义的全类名，全类名的定义请查阅The Form of a Binary。</li>\n<li>给定一个全类名，类加载器应该去定位该类所在的位置。通用的策略是将全类名转换为类文件路径，然后通过类文件路径在文件系统中定位。</li>\n<li>每一个加载到内存的类都由一个Class对象来表示，每一个Class对象都有一个指向加载该类的类加载器的引用。但是数组的Class对象是由Java运行时环境创建的，通过 Class.getClassLoader()方法返回的是数组元素的类加载器，若数组元素是基本类型，则返回null，若类是由Bootstrap ClassLoader加载的话也是返回null。</li>\n<li>ClassLoader默认支持并行加载，但是其子类必须调用ClassLoader.registerAsParallelCapable()来启用并行加载</li>\n<li>一般来说,JVM从本地文件系统加载类的行为是与平台有关的。</li>\n<li>defineClass() 方法可以将字节流转换成一个Class对象。然后调用Class.newInstance()来创建类的实例</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Object 类在 &lt;java_home&gt;/jre/lib/rt.jar 中，</span></span><br><span class=\"line\">    <span class=\"comment\">// 由 Bootstrap ClassLoader 加载，由于该类加载器是由 native code 编写</span></span><br><span class=\"line\">    <span class=\"comment\">// 所以输出为 null</span></span><br><span class=\"line\">    Object[] objects = <span class=\"keyword\">new</span> Object[<span class=\"number\">5</span>];</span><br><span class=\"line\">    System.out.println();</span><br><span class=\"line\">    System.out.println(objects.getClass().getClassLoader());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ZipFileAttributes 类在 &lt;java_home&gt;/jre/lib/ext/zipfs.jar 中，</span></span><br><span class=\"line\">    <span class=\"comment\">// 由 Extension ClassLoader 加载，</span></span><br><span class=\"line\">    <span class=\"comment\">// 输出为  sun.misc.Launcher$ExtClassLoader@4b67cf4d</span></span><br><span class=\"line\">    ZipFileAttributes[] attributes = <span class=\"keyword\">new</span> ZipFileAttributes[<span class=\"number\">5</span>];</span><br><span class=\"line\">    System.out.println();</span><br><span class=\"line\">    System.out.println(attributes.getClass().getClassLoader());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// Main 类是自定义的类，</span></span><br><span class=\"line\">    <span class=\"comment\">// 默认由 System ClassLoader 加载，</span></span><br><span class=\"line\">    <span class=\"comment\">// 输出为 sun.misc.Launcher$AppClassLoader@18b4aac2</span></span><br><span class=\"line\">    Main[] array = <span class=\"keyword\">new</span> Main[<span class=\"number\">5</span>];</span><br><span class=\"line\">    array[<span class=\"number\">0</span>] = <span class=\"keyword\">new</span> Main();</span><br><span class=\"line\">    System.out.println();</span><br><span class=\"line\">    System.out.println(array.getClass().getClassLoader());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"java-security-SecureClassLoader\"><a href=\"#java-security-SecureClassLoader\" class=\"headerlink\" title=\"java.security.SecureClassLoader\"></a>java.security.SecureClassLoader</h4><p>增加了一层权限验证，因为关注点不在安全，所以暂不讨论。</p>\n<h4 id=\"java-net-URLClassLoader\"><a href=\"#java-net-URLClassLoader\" class=\"headerlink\" title=\"java.net.URLClassLoader\"></a>java.net.URLClassLoader</h4><p>该类加载器用来加载URL指定的JAR文件或目录中的类和资源，以/结尾的URL认为是目录，否则认为是JAR文件。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 尝试通过 URLClassLoader 来加载桌面下的 Test 类。</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">main</span><span class=\"params\">(String[] args)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        URL[] urls = <span class=\"keyword\">new</span> URL[<span class=\"number\">1</span>];</span><br><span class=\"line\">        URLStreamHandler streamHandler = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        File classPath = <span class=\"keyword\">new</span> File(<span class=\"string\">\"/home/chen/Desktop/\"</span>);</span><br><span class=\"line\">        String repository = (<span class=\"keyword\">new</span> URL(<span class=\"string\">\"file\"</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                classPath.getCanonicalPath() + File.separator))</span><br><span class=\"line\">                .toString();</span><br><span class=\"line\">        urls[<span class=\"number\">0</span>] = <span class=\"keyword\">new</span> URL(<span class=\"keyword\">null</span>, repository, streamHandler);</span><br><span class=\"line\"></span><br><span class=\"line\">        ClassLoader loader = <span class=\"keyword\">new</span> URLClassLoader(urls);</span><br><span class=\"line\"></span><br><span class=\"line\">        Class testClass = loader.loadClass(<span class=\"string\">\"Test\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// output:  java.net.URLClassLoader@7f31245a</span></span><br><span class=\"line\">        System.out.println(testClass.getClassLoader());</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (MalformedURLException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (ClassNotFoundException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"破坏双亲委派机制\"><a href=\"#破坏双亲委派机制\" class=\"headerlink\" title=\"破坏双亲委派机制\"></a>破坏双亲委派机制</h2><p>可以看出双亲委派机制是一种至下而上的加载方式，那么SPI是如何打破这种关系？</p>\n<p>以JDBC加载驱动为例：<br>在JDBC4.0之后支持SPI方式加载java.sql.Driver的实现类。SPI实现方式为，通过ServiceLoader.load(Driver.class)方法，去各自实现Driver接口的lib的META-INF/services/java.sql.Driver文件里找到实现类的名字，通过Thread.currentThread().getContextClassLoader()类加载器加载实现类并返回实例。</p>\n<p>先看下如果不用Thread.currentThread().getContextClassLoader()加载器加载，整个流程会怎么样。</p>\n<ul>\n<li>从META-INF/services/java.sql.Driver文件得到实现类名字DriverA</li>\n<li>Class.forName(“xx.xx.DriverA”)来加载实现类</li>\n<li>Class.forName()方法默认使用当前类的ClassLoader，JDBC是在DriverManager类里调用Driver的，当前类也就是DriverManager，它的加载器是BootstrapClassLoader。</li>\n</ul>\n<p>用BootstrapClassLoader去加载非rt.jar包里的类xx.xx.DriverA，就会找不到。要加载xx.xx.DriverA需要用到AppClassLoader或其他自定义ClassLoader</p>\n<p>最终矛盾出现在，要在BootstrapClassLoader加载的类里，调用AppClassLoader去加载实现类。这样就出现了一个问题：如何在父加载器加载的类中，去调用子加载器去加载类？</p>\n<p>jdk提供了两种方式，</p>\n<ul>\n<li>Thread.currentThread().getContextClassLoader()</li>\n<li>ClassLoader.getSystemClassLoader()<br>一般都指向AppClassLoader，他们能加载classpath中的类</li>\n</ul>\n<p>SPI则用Thread.currentThread().getContextClassLoader()来加载实现类，实现在核心包里的基础类调用用户代码</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://github.com/c-rainstorm/blog/blob/master/java\" target=\"_blank\" rel=\"noopener\">https://github.com/c-rainstorm/blog/blob/master/java</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/HIiy7Q5UoPySFn3ge8Y-Ow\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/HIiy7Q5UoPySFn3ge8Y-Ow</a></li>\n<li><a href=\"https://docs.oracle.com/javase/tutorial/ext/basics/load.html\" target=\"_blank\" rel=\"noopener\">https://docs.oracle.com/javase/tutorial/ext/basics/load.html</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Java_Classloader\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Java_Classloader</a></li>\n<li><a href=\"https://www.jianshu.com/p/9cf306550b0a\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/9cf306550b0a</a></li>\n</ul>"},{"title":"集合容器框架源码学习笔记","date":"2019-02-01T06:48:00.000Z","_content":"\n> 本文为近期学习JDK源码中集合类相关记录的笔记，因为是学习过程中的随笔，没有很仔细整理过。<br/>\n虽然在日常使用中只需要关注这些类的api如何使用即可，但是对于进阶的提升，可以在源码中更加熟悉各类的使用方式，以及学习到更多好的设计和处理问题的思路。<br/>\nps：公司内网已经不能访问github等开源网站，代码一直提不上去github，写了一些笔记都不能及时更新。\n\n<!-- more -->\n\n# HashMap\n## jdk1.7\nHashMap 里面是一个数组，然后数组中每个元素是一个单向链表。\n* capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。\n* loadFactor：负载因子，默认为 0.75。\n* threshold：扩容的阈值，等于 capacity * loadFactor\nHashMap扩容是长度的2倍，且长度永远是2的次幂，存储下标：index = h&(length-1)\n\n### put过程\n1. 判断当前数组是否需要初始化\n2. 如果key为null则put一个null进去\n3. 根据key计算出hashcode\n4. 根据hashcode得出table的下标所在位置的桶\n5. 如果桶是链表则遍历里面每个对象的hashcode、key和传入的key是否相当，相等则覆盖\n6. 如果桶是空新增一个entry写入到当前位置（addEntry）\n7. addEntry：判断是否需要扩容，计算公式如上，\n需要扩容则两倍扩容，并且将当前key重新hash定位,扩容后的位置要么是再原下标的位置，另一种是在下标为 <原下标+原容量> 的位置。\n8. createEntry：当前位置的桶传入到新建的桶中，如果当位置有桶则生成链表\n\n### get过程\n1. 根据key计算出heshcode，然后得到对应的下标\n2. 判断是否为链表，不是链表就根据key的hashcode进行比较，是则返回值；如果是链表则遍历链表同上进行比较。\n3. 没获取到返回null\n\n## jdk1.7的缺点\n当Hash冲突严重时，在Node上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为O(N)。jdk1.8主要优化的就是这个。\n\n## jdk1.8\n数据结构修改，数组+链表/红黑树\n当链表长度超过8之后，会转换为红黑树，如果低于6会转换回链表\n7中用entry标识每一个数据节点，8中修改为Node\n\n### put过程\n1. 判断当前table是否为空，空则进行初始化（resize中会判断是否进行初始化）\n2. 根据key得到hashcode定位到具体桶的位置，为空则没有hash冲突创建一个新的node。\n3. 如果有hash冲突，则比较entry的hashcode与当前位置的key的hashcode是否相等，相等则进行赋值。\n4. 如果当前桶为红黑树则按照红黑树的写入方式进行写入，如果是链表则在当前entry下创建形成链表。\n5. 判断当前链表大小是否超过预设阈值（TREEIFY_THRESHOLD）8，超过则转换为红黑树。\n6. 最后判断是否扩容\n\n### get\n1. 根据key得到hashcode定位到桶的位置，为空直接返回null。\n2. 遍历table的每一个entry，比较key是否相等，相等则返回value。\n3. 如果是红黑树则按照红黑树的方法进行查找，如果是链表则遍历进行查找。\n\n## HashMap在多线程并发时的问题是什么，哪里线程不安全\n在HashMap扩容的时候会调用resize()方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key时，计算出的index正好是环形链表的下标就会出现死循环。\n\n# ConcurrentHashMap\n## jdk1.7\n由segment组成，每一个segment继承自reentrantlock（重入锁），所以每次加锁是对于每一个段进行加锁，从而保证全局的线程安全。\n* concurrencyLevel：并行并发数、segment数，默认是16，是控制ConcurrentHashMap的segment的数量，不可扩容。\n* initialCapacity：初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。\n* loadFactor：负载因子，因为Segment 数组不可以扩容，所以这个负载因子是给每个Segment 内部使用的。\n\nHashEntry、value都是由volatile修饰的。\n\n### put过程\n1. 尝试获取自旋获取锁\n2. 如果重试次数达到了MAX_SCAN_RETRIES则改为阻塞锁获取，保证能获取成功\n3. 根据key得到hashcode定位到segments中HashEntry的下标\n4. 遍历HashEntry（链表）不为空则判断传入的key是否相等，相等则覆盖value\n5. 为空则新建HashEntry并加入到segments中，同时会先判断是否需要进行扩容\n6. 最后解除获取的锁\n\n### get过程\n1. 根据key得到hashcode并且计算得到segments中的下标，获取到HashEntry\n2. 遍历HashEntry中key，相等则获取value\n由于HashEntry的value是用volatile修饰的，保证了其可见性，所以每次获取都是最新的值\n\n## jdk1.8\nCocurrentHashMap抛弃了原有的Segment分段锁，采用了CAS + synchronized关键字来保证并发安全性。与HashMap1.7的问题一样，链表过长后查询效率低的问题。\n\nHashEntry修改为Node，其中的val,next都用了volatile修饰，保证了可见性\n\n对sizeCtl的控制都是用 CAS 来实现的:\n```java\n/**\n * Table initialization and resizing control.  When negative, the\n * table is being initialized or resized: -1 for initialization,\n * else -(1 + the number of active resizing threads).  Otherwise,\n * when table is null, holds the initial table size to use upon\n * creation, or 0 for default. After initialization, holds the\n * next element count value upon which to resize the table.\n */\nprivate transient volatile int sizeCtl;\n```\n下面是翻译：\n\n-1代表table正在初始化，N表示有 -N-1 个线程正在进行扩容操作。\n\n如果table未初始化，表示table需要初始化的大小。\n\n如果table初始化完成，表示table的容量，默认是table大小的0.75倍，用这个公式算 0.75（n – (n >>> 2)）。\n\nCAS 会出现的问题：ABA\n\n解决：对变量增加一个版本号，每次修改，版本号加1，比较的时候比较版本号。\n\nput过程：\n1. 根据key的hashcode计算得处table的下标\n2. 判断是否需要进行初始化\n3. 获取table对应下标的Node，如果为空表示当前位置可以写入数据，利用CAS 尝试写入，失败则自旋保证成功\n5. 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容\n6. 如果都不满足，则利用synchronized锁写入数据（此处锁的对象是Node）\n7. 如果数量大于TREEIFY_THRESHOLD则要转换为红黑树\n\nget过程：\n1. 根据key的hashcode计算得到table的下标，得到Node\n2. 如果是红黑树则按照树的方式获取值\n3. 如果不是则按照链表的方式遍历获取值\n\n# ArrayList\n默认容量10\n\nint newCapacity = oldCapacity + (oldCapacity >> 1)\n\n其中oldCapacity是原来的容量大小，oldCapacity >> 1为位运算的右移操作，右移一位相当于除以2，所以这句代码就等于\n\nint newCapacity = oldCapacity + oldCapacity / 2；\n\n即容量扩大为原来的1.5倍，获取newCapacity后再对newCapacity的大小进行判断，如果仍然小于minCapacity，则直接让newCapacity 等于minCapacity，而不再计算1.5倍的扩容。然后还要再进行一步判断，即判断当前新容量是否超过最大的容量 \n\nif (newCapacity - MAX_ARRAY_SIZE > 0)\n\n如果超过，则调用hugeCapacity方法，传进去的是minCapacity，即新增元素后需要的最小容量：\n如果minCapacity大于MAX_ARRAY_SIZE，则返回Integer的最大值。否则返回MAX_ARRAY_SIZE。\n\n调用Arrays.copyof方法，即复制原数组内容到一个新容量的大数组里。这里Arrays.copyof方法实际是调用System.arraycopy方法。\n\n# 相关问题\n## 追问1：ArrayList和LinkedList有什么区别？\n## 追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？\n## 追问3: HashMap和Hashtable有什么区别?\n## 追问4: HashMap的put和get方法是怎么实现的?\n## jdk1.7-.jdk1.8 HashMap的变化？\n## HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？\n对修改Hashtable内部共享数据的方法添加了synchronized，保证线程安全。\n包括put、get、remove、clear、size等方法都有同步。\n总的来说就是所有对Hashtable的所有数据操作的行为都进行了同步。\n\n## 追问5: 线程安全的集合类包括哪些，它们是怎么实现线程安全的?\n## 追问6: Hashtable和ConcurrentHashMap的区别？\n\n# 涉及其他知识点\n## 红黑树，平衡二叉树\n## hash算法，下标计算如何计算\n直接看下HashMap中的hash方法：\n```java\n/**\n * Computes key.hashCode() and spreads (XORs) higher bits of hash\n * to lower.  Because the table uses power-of-two masking, sets of\n * hashes that vary only in bits above the current mask will\n * always collide. (Among known examples are sets of Float keys\n * holding consecutive whole numbers in small tables.)  So we\n * apply a transform that spreads the impact of higher bits\n * downward. There is a tradeoff between speed, utility, and\n * quality of bit-spreading. Because many common sets of hashes\n * are already reasonably distributed (so don't benefit from\n * spreading), and because we use trees to handle large sets of\n * collisions in bins, we just XOR some shifted bits in the\n * cheapest possible way to reduce systematic lossage, as well as\n * to incorporate impact of the highest bits that would otherwise\n * never be used in index calculations because of table bounds.\n */\nstatic final int hash(Object key) {\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n```\n\n* key==null直接返回0;\n* hash为(h = key.hashCode()) ^ (h >>> 16);\n\n以下为put方法的片段代码：\n```java\nNode<K,V>[] tab; Node<K,V> p; int n, i;\nif ((tab = table) == null || (n = tab.length) == 0)\n    n = (tab = resize()).length;\nif ((p = tab[i = (n - 1) & hash]) == null)\n    tab[i] = newNode(hash, key, value, null);\nelse {\n...\n}\n```\n* n为table扩容后的长度\n* p为当前节点\n* 得到table下标位置(n - 1) & hash ;\n\n## 扩容细节 \n默认容量：DEFAULT_INITIAL_CAPACITY 1<<4 = 16;\n\n## CAS\n借助Unsafe来实现native code。CAS有3个操作数，内存值V、旧的预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。Unsafe借助CPU指令cmpxchg来实现。","source":"_posts/集合容器框架笔记.md","raw":"---\ntitle: 集合容器框架源码学习笔记\ndate: 2019-02-01 14:48:00\ntags: Java\ncategories: Java\n---\n\n> 本文为近期学习JDK源码中集合类相关记录的笔记，因为是学习过程中的随笔，没有很仔细整理过。<br/>\n虽然在日常使用中只需要关注这些类的api如何使用即可，但是对于进阶的提升，可以在源码中更加熟悉各类的使用方式，以及学习到更多好的设计和处理问题的思路。<br/>\nps：公司内网已经不能访问github等开源网站，代码一直提不上去github，写了一些笔记都不能及时更新。\n\n<!-- more -->\n\n# HashMap\n## jdk1.7\nHashMap 里面是一个数组，然后数组中每个元素是一个单向链表。\n* capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。\n* loadFactor：负载因子，默认为 0.75。\n* threshold：扩容的阈值，等于 capacity * loadFactor\nHashMap扩容是长度的2倍，且长度永远是2的次幂，存储下标：index = h&(length-1)\n\n### put过程\n1. 判断当前数组是否需要初始化\n2. 如果key为null则put一个null进去\n3. 根据key计算出hashcode\n4. 根据hashcode得出table的下标所在位置的桶\n5. 如果桶是链表则遍历里面每个对象的hashcode、key和传入的key是否相当，相等则覆盖\n6. 如果桶是空新增一个entry写入到当前位置（addEntry）\n7. addEntry：判断是否需要扩容，计算公式如上，\n需要扩容则两倍扩容，并且将当前key重新hash定位,扩容后的位置要么是再原下标的位置，另一种是在下标为 <原下标+原容量> 的位置。\n8. createEntry：当前位置的桶传入到新建的桶中，如果当位置有桶则生成链表\n\n### get过程\n1. 根据key计算出heshcode，然后得到对应的下标\n2. 判断是否为链表，不是链表就根据key的hashcode进行比较，是则返回值；如果是链表则遍历链表同上进行比较。\n3. 没获取到返回null\n\n## jdk1.7的缺点\n当Hash冲突严重时，在Node上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为O(N)。jdk1.8主要优化的就是这个。\n\n## jdk1.8\n数据结构修改，数组+链表/红黑树\n当链表长度超过8之后，会转换为红黑树，如果低于6会转换回链表\n7中用entry标识每一个数据节点，8中修改为Node\n\n### put过程\n1. 判断当前table是否为空，空则进行初始化（resize中会判断是否进行初始化）\n2. 根据key得到hashcode定位到具体桶的位置，为空则没有hash冲突创建一个新的node。\n3. 如果有hash冲突，则比较entry的hashcode与当前位置的key的hashcode是否相等，相等则进行赋值。\n4. 如果当前桶为红黑树则按照红黑树的写入方式进行写入，如果是链表则在当前entry下创建形成链表。\n5. 判断当前链表大小是否超过预设阈值（TREEIFY_THRESHOLD）8，超过则转换为红黑树。\n6. 最后判断是否扩容\n\n### get\n1. 根据key得到hashcode定位到桶的位置，为空直接返回null。\n2. 遍历table的每一个entry，比较key是否相等，相等则返回value。\n3. 如果是红黑树则按照红黑树的方法进行查找，如果是链表则遍历进行查找。\n\n## HashMap在多线程并发时的问题是什么，哪里线程不安全\n在HashMap扩容的时候会调用resize()方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key时，计算出的index正好是环形链表的下标就会出现死循环。\n\n# ConcurrentHashMap\n## jdk1.7\n由segment组成，每一个segment继承自reentrantlock（重入锁），所以每次加锁是对于每一个段进行加锁，从而保证全局的线程安全。\n* concurrencyLevel：并行并发数、segment数，默认是16，是控制ConcurrentHashMap的segment的数量，不可扩容。\n* initialCapacity：初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。\n* loadFactor：负载因子，因为Segment 数组不可以扩容，所以这个负载因子是给每个Segment 内部使用的。\n\nHashEntry、value都是由volatile修饰的。\n\n### put过程\n1. 尝试获取自旋获取锁\n2. 如果重试次数达到了MAX_SCAN_RETRIES则改为阻塞锁获取，保证能获取成功\n3. 根据key得到hashcode定位到segments中HashEntry的下标\n4. 遍历HashEntry（链表）不为空则判断传入的key是否相等，相等则覆盖value\n5. 为空则新建HashEntry并加入到segments中，同时会先判断是否需要进行扩容\n6. 最后解除获取的锁\n\n### get过程\n1. 根据key得到hashcode并且计算得到segments中的下标，获取到HashEntry\n2. 遍历HashEntry中key，相等则获取value\n由于HashEntry的value是用volatile修饰的，保证了其可见性，所以每次获取都是最新的值\n\n## jdk1.8\nCocurrentHashMap抛弃了原有的Segment分段锁，采用了CAS + synchronized关键字来保证并发安全性。与HashMap1.7的问题一样，链表过长后查询效率低的问题。\n\nHashEntry修改为Node，其中的val,next都用了volatile修饰，保证了可见性\n\n对sizeCtl的控制都是用 CAS 来实现的:\n```java\n/**\n * Table initialization and resizing control.  When negative, the\n * table is being initialized or resized: -1 for initialization,\n * else -(1 + the number of active resizing threads).  Otherwise,\n * when table is null, holds the initial table size to use upon\n * creation, or 0 for default. After initialization, holds the\n * next element count value upon which to resize the table.\n */\nprivate transient volatile int sizeCtl;\n```\n下面是翻译：\n\n-1代表table正在初始化，N表示有 -N-1 个线程正在进行扩容操作。\n\n如果table未初始化，表示table需要初始化的大小。\n\n如果table初始化完成，表示table的容量，默认是table大小的0.75倍，用这个公式算 0.75（n – (n >>> 2)）。\n\nCAS 会出现的问题：ABA\n\n解决：对变量增加一个版本号，每次修改，版本号加1，比较的时候比较版本号。\n\nput过程：\n1. 根据key的hashcode计算得处table的下标\n2. 判断是否需要进行初始化\n3. 获取table对应下标的Node，如果为空表示当前位置可以写入数据，利用CAS 尝试写入，失败则自旋保证成功\n5. 如果当前位置的 hashcode == MOVED == -1,则需要进行扩容\n6. 如果都不满足，则利用synchronized锁写入数据（此处锁的对象是Node）\n7. 如果数量大于TREEIFY_THRESHOLD则要转换为红黑树\n\nget过程：\n1. 根据key的hashcode计算得到table的下标，得到Node\n2. 如果是红黑树则按照树的方式获取值\n3. 如果不是则按照链表的方式遍历获取值\n\n# ArrayList\n默认容量10\n\nint newCapacity = oldCapacity + (oldCapacity >> 1)\n\n其中oldCapacity是原来的容量大小，oldCapacity >> 1为位运算的右移操作，右移一位相当于除以2，所以这句代码就等于\n\nint newCapacity = oldCapacity + oldCapacity / 2；\n\n即容量扩大为原来的1.5倍，获取newCapacity后再对newCapacity的大小进行判断，如果仍然小于minCapacity，则直接让newCapacity 等于minCapacity，而不再计算1.5倍的扩容。然后还要再进行一步判断，即判断当前新容量是否超过最大的容量 \n\nif (newCapacity - MAX_ARRAY_SIZE > 0)\n\n如果超过，则调用hugeCapacity方法，传进去的是minCapacity，即新增元素后需要的最小容量：\n如果minCapacity大于MAX_ARRAY_SIZE，则返回Integer的最大值。否则返回MAX_ARRAY_SIZE。\n\n调用Arrays.copyof方法，即复制原数组内容到一个新容量的大数组里。这里Arrays.copyof方法实际是调用System.arraycopy方法。\n\n# 相关问题\n## 追问1：ArrayList和LinkedList有什么区别？\n## 追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？\n## 追问3: HashMap和Hashtable有什么区别?\n## 追问4: HashMap的put和get方法是怎么实现的?\n## jdk1.7-.jdk1.8 HashMap的变化？\n## HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？\n对修改Hashtable内部共享数据的方法添加了synchronized，保证线程安全。\n包括put、get、remove、clear、size等方法都有同步。\n总的来说就是所有对Hashtable的所有数据操作的行为都进行了同步。\n\n## 追问5: 线程安全的集合类包括哪些，它们是怎么实现线程安全的?\n## 追问6: Hashtable和ConcurrentHashMap的区别？\n\n# 涉及其他知识点\n## 红黑树，平衡二叉树\n## hash算法，下标计算如何计算\n直接看下HashMap中的hash方法：\n```java\n/**\n * Computes key.hashCode() and spreads (XORs) higher bits of hash\n * to lower.  Because the table uses power-of-two masking, sets of\n * hashes that vary only in bits above the current mask will\n * always collide. (Among known examples are sets of Float keys\n * holding consecutive whole numbers in small tables.)  So we\n * apply a transform that spreads the impact of higher bits\n * downward. There is a tradeoff between speed, utility, and\n * quality of bit-spreading. Because many common sets of hashes\n * are already reasonably distributed (so don't benefit from\n * spreading), and because we use trees to handle large sets of\n * collisions in bins, we just XOR some shifted bits in the\n * cheapest possible way to reduce systematic lossage, as well as\n * to incorporate impact of the highest bits that would otherwise\n * never be used in index calculations because of table bounds.\n */\nstatic final int hash(Object key) {\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n```\n\n* key==null直接返回0;\n* hash为(h = key.hashCode()) ^ (h >>> 16);\n\n以下为put方法的片段代码：\n```java\nNode<K,V>[] tab; Node<K,V> p; int n, i;\nif ((tab = table) == null || (n = tab.length) == 0)\n    n = (tab = resize()).length;\nif ((p = tab[i = (n - 1) & hash]) == null)\n    tab[i] = newNode(hash, key, value, null);\nelse {\n...\n}\n```\n* n为table扩容后的长度\n* p为当前节点\n* 得到table下标位置(n - 1) & hash ;\n\n## 扩容细节 \n默认容量：DEFAULT_INITIAL_CAPACITY 1<<4 = 16;\n\n## CAS\n借助Unsafe来实现native code。CAS有3个操作数，内存值V、旧的预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。Unsafe借助CPU指令cmpxchg来实现。","slug":"集合容器框架笔记","published":1,"updated":"2019-08-26T07:53:49.141Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl48004xqotnjbknqk8v","content":"<blockquote>\n<p>本文为近期学习JDK源码中集合类相关记录的笔记，因为是学习过程中的随笔，没有很仔细整理过。<br><br>虽然在日常使用中只需要关注这些类的api如何使用即可，但是对于进阶的提升，可以在源码中更加熟悉各类的使用方式，以及学习到更多好的设计和处理问题的思路。<br><br>ps：公司内网已经不能访问github等开源网站，代码一直提不上去github，写了一些笔记都不能及时更新。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h1><h2 id=\"jdk1-7\"><a href=\"#jdk1-7\" class=\"headerlink\" title=\"jdk1.7\"></a>jdk1.7</h2><p>HashMap 里面是一个数组，然后数组中每个元素是一个单向链表。</p>\n<ul>\n<li>capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。</li>\n<li>loadFactor：负载因子，默认为 0.75。</li>\n<li>threshold：扩容的阈值，等于 capacity * loadFactor<br>HashMap扩容是长度的2倍，且长度永远是2的次幂，存储下标：index = h&amp;(length-1)</li>\n</ul>\n<h3 id=\"put过程\"><a href=\"#put过程\" class=\"headerlink\" title=\"put过程\"></a>put过程</h3><ol>\n<li>判断当前数组是否需要初始化</li>\n<li>如果key为null则put一个null进去</li>\n<li>根据key计算出hashcode</li>\n<li>根据hashcode得出table的下标所在位置的桶</li>\n<li>如果桶是链表则遍历里面每个对象的hashcode、key和传入的key是否相当，相等则覆盖</li>\n<li>如果桶是空新增一个entry写入到当前位置（addEntry）</li>\n<li>addEntry：判断是否需要扩容，计算公式如上，<br>需要扩容则两倍扩容，并且将当前key重新hash定位,扩容后的位置要么是再原下标的位置，另一种是在下标为 &lt;原下标+原容量&gt; 的位置。</li>\n<li>createEntry：当前位置的桶传入到新建的桶中，如果当位置有桶则生成链表</li>\n</ol>\n<h3 id=\"get过程\"><a href=\"#get过程\" class=\"headerlink\" title=\"get过程\"></a>get过程</h3><ol>\n<li>根据key计算出heshcode，然后得到对应的下标</li>\n<li>判断是否为链表，不是链表就根据key的hashcode进行比较，是则返回值；如果是链表则遍历链表同上进行比较。</li>\n<li>没获取到返回null</li>\n</ol>\n<h2 id=\"jdk1-7的缺点\"><a href=\"#jdk1-7的缺点\" class=\"headerlink\" title=\"jdk1.7的缺点\"></a>jdk1.7的缺点</h2><p>当Hash冲突严重时，在Node上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为O(N)。jdk1.8主要优化的就是这个。</p>\n<h2 id=\"jdk1-8\"><a href=\"#jdk1-8\" class=\"headerlink\" title=\"jdk1.8\"></a>jdk1.8</h2><p>数据结构修改，数组+链表/红黑树<br>当链表长度超过8之后，会转换为红黑树，如果低于6会转换回链表<br>7中用entry标识每一个数据节点，8中修改为Node</p>\n<h3 id=\"put过程-1\"><a href=\"#put过程-1\" class=\"headerlink\" title=\"put过程\"></a>put过程</h3><ol>\n<li>判断当前table是否为空，空则进行初始化（resize中会判断是否进行初始化）</li>\n<li>根据key得到hashcode定位到具体桶的位置，为空则没有hash冲突创建一个新的node。</li>\n<li>如果有hash冲突，则比较entry的hashcode与当前位置的key的hashcode是否相等，相等则进行赋值。</li>\n<li>如果当前桶为红黑树则按照红黑树的写入方式进行写入，如果是链表则在当前entry下创建形成链表。</li>\n<li>判断当前链表大小是否超过预设阈值（TREEIFY_THRESHOLD）8，超过则转换为红黑树。</li>\n<li>最后判断是否扩容</li>\n</ol>\n<h3 id=\"get\"><a href=\"#get\" class=\"headerlink\" title=\"get\"></a>get</h3><ol>\n<li>根据key得到hashcode定位到桶的位置，为空直接返回null。</li>\n<li>遍历table的每一个entry，比较key是否相等，相等则返回value。</li>\n<li>如果是红黑树则按照红黑树的方法进行查找，如果是链表则遍历进行查找。</li>\n</ol>\n<h2 id=\"HashMap在多线程并发时的问题是什么，哪里线程不安全\"><a href=\"#HashMap在多线程并发时的问题是什么，哪里线程不安全\" class=\"headerlink\" title=\"HashMap在多线程并发时的问题是什么，哪里线程不安全\"></a>HashMap在多线程并发时的问题是什么，哪里线程不安全</h2><p>在HashMap扩容的时候会调用resize()方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key时，计算出的index正好是环形链表的下标就会出现死循环。</p>\n<h1 id=\"ConcurrentHashMap\"><a href=\"#ConcurrentHashMap\" class=\"headerlink\" title=\"ConcurrentHashMap\"></a>ConcurrentHashMap</h1><h2 id=\"jdk1-7-1\"><a href=\"#jdk1-7-1\" class=\"headerlink\" title=\"jdk1.7\"></a>jdk1.7</h2><p>由segment组成，每一个segment继承自reentrantlock（重入锁），所以每次加锁是对于每一个段进行加锁，从而保证全局的线程安全。</p>\n<ul>\n<li>concurrencyLevel：并行并发数、segment数，默认是16，是控制ConcurrentHashMap的segment的数量，不可扩容。</li>\n<li>initialCapacity：初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。</li>\n<li>loadFactor：负载因子，因为Segment 数组不可以扩容，所以这个负载因子是给每个Segment 内部使用的。</li>\n</ul>\n<p>HashEntry、value都是由volatile修饰的。</p>\n<h3 id=\"put过程-2\"><a href=\"#put过程-2\" class=\"headerlink\" title=\"put过程\"></a>put过程</h3><ol>\n<li>尝试获取自旋获取锁</li>\n<li>如果重试次数达到了MAX_SCAN_RETRIES则改为阻塞锁获取，保证能获取成功</li>\n<li>根据key得到hashcode定位到segments中HashEntry的下标</li>\n<li>遍历HashEntry（链表）不为空则判断传入的key是否相等，相等则覆盖value</li>\n<li>为空则新建HashEntry并加入到segments中，同时会先判断是否需要进行扩容</li>\n<li>最后解除获取的锁</li>\n</ol>\n<h3 id=\"get过程-1\"><a href=\"#get过程-1\" class=\"headerlink\" title=\"get过程\"></a>get过程</h3><ol>\n<li>根据key得到hashcode并且计算得到segments中的下标，获取到HashEntry</li>\n<li>遍历HashEntry中key，相等则获取value<br>由于HashEntry的value是用volatile修饰的，保证了其可见性，所以每次获取都是最新的值</li>\n</ol>\n<h2 id=\"jdk1-8-1\"><a href=\"#jdk1-8-1\" class=\"headerlink\" title=\"jdk1.8\"></a>jdk1.8</h2><p>CocurrentHashMap抛弃了原有的Segment分段锁，采用了CAS + synchronized关键字来保证并发安全性。与HashMap1.7的问题一样，链表过长后查询效率低的问题。</p>\n<p>HashEntry修改为Node，其中的val,next都用了volatile修饰，保证了可见性</p>\n<p>对sizeCtl的控制都是用 CAS 来实现的:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Table initialization and resizing control.  When negative, the</span></span><br><span class=\"line\"><span class=\"comment\"> * table is being initialized or resized: -1 for initialization,</span></span><br><span class=\"line\"><span class=\"comment\"> * else -(1 + the number of active resizing threads).  Otherwise,</span></span><br><span class=\"line\"><span class=\"comment\"> * when table is null, holds the initial table size to use upon</span></span><br><span class=\"line\"><span class=\"comment\"> * creation, or 0 for default. After initialization, holds the</span></span><br><span class=\"line\"><span class=\"comment\"> * next element count value upon which to resize the table.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">transient</span> <span class=\"keyword\">volatile</span> <span class=\"keyword\">int</span> sizeCtl;</span><br></pre></td></tr></table></figure></p>\n<p>下面是翻译：</p>\n<p>-1代表table正在初始化，N表示有 -N-1 个线程正在进行扩容操作。</p>\n<p>如果table未初始化，表示table需要初始化的大小。</p>\n<p>如果table初始化完成，表示table的容量，默认是table大小的0.75倍，用这个公式算 0.75（n – (n &gt;&gt;&gt; 2)）。</p>\n<p>CAS 会出现的问题：ABA</p>\n<p>解决：对变量增加一个版本号，每次修改，版本号加1，比较的时候比较版本号。</p>\n<p>put过程：</p>\n<ol>\n<li>根据key的hashcode计算得处table的下标</li>\n<li>判断是否需要进行初始化</li>\n<li>获取table对应下标的Node，如果为空表示当前位置可以写入数据，利用CAS 尝试写入，失败则自旋保证成功</li>\n<li>如果当前位置的 hashcode == MOVED == -1,则需要进行扩容</li>\n<li>如果都不满足，则利用synchronized锁写入数据（此处锁的对象是Node）</li>\n<li>如果数量大于TREEIFY_THRESHOLD则要转换为红黑树</li>\n</ol>\n<p>get过程：</p>\n<ol>\n<li>根据key的hashcode计算得到table的下标，得到Node</li>\n<li>如果是红黑树则按照树的方式获取值</li>\n<li>如果不是则按照链表的方式遍历获取值</li>\n</ol>\n<h1 id=\"ArrayList\"><a href=\"#ArrayList\" class=\"headerlink\" title=\"ArrayList\"></a>ArrayList</h1><p>默认容量10</p>\n<p>int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1)</p>\n<p>其中oldCapacity是原来的容量大小，oldCapacity &gt;&gt; 1为位运算的右移操作，右移一位相当于除以2，所以这句代码就等于</p>\n<p>int newCapacity = oldCapacity + oldCapacity / 2；</p>\n<p>即容量扩大为原来的1.5倍，获取newCapacity后再对newCapacity的大小进行判断，如果仍然小于minCapacity，则直接让newCapacity 等于minCapacity，而不再计算1.5倍的扩容。然后还要再进行一步判断，即判断当前新容量是否超过最大的容量 </p>\n<p>if (newCapacity - MAX_ARRAY_SIZE &gt; 0)</p>\n<p>如果超过，则调用hugeCapacity方法，传进去的是minCapacity，即新增元素后需要的最小容量：<br>如果minCapacity大于MAX_ARRAY_SIZE，则返回Integer的最大值。否则返回MAX_ARRAY_SIZE。</p>\n<p>调用Arrays.copyof方法，即复制原数组内容到一个新容量的大数组里。这里Arrays.copyof方法实际是调用System.arraycopy方法。</p>\n<h1 id=\"相关问题\"><a href=\"#相关问题\" class=\"headerlink\" title=\"相关问题\"></a>相关问题</h1><h2 id=\"追问1：ArrayList和LinkedList有什么区别？\"><a href=\"#追问1：ArrayList和LinkedList有什么区别？\" class=\"headerlink\" title=\"追问1：ArrayList和LinkedList有什么区别？\"></a>追问1：ArrayList和LinkedList有什么区别？</h2><h2 id=\"追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？\"><a href=\"#追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？\" class=\"headerlink\" title=\"追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？\"></a>追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？</h2><h2 id=\"追问3-HashMap和Hashtable有什么区别\"><a href=\"#追问3-HashMap和Hashtable有什么区别\" class=\"headerlink\" title=\"追问3: HashMap和Hashtable有什么区别?\"></a>追问3: HashMap和Hashtable有什么区别?</h2><h2 id=\"追问4-HashMap的put和get方法是怎么实现的\"><a href=\"#追问4-HashMap的put和get方法是怎么实现的\" class=\"headerlink\" title=\"追问4: HashMap的put和get方法是怎么实现的?\"></a>追问4: HashMap的put和get方法是怎么实现的?</h2><h2 id=\"jdk1-7-jdk1-8-HashMap的变化？\"><a href=\"#jdk1-7-jdk1-8-HashMap的变化？\" class=\"headerlink\" title=\"jdk1.7-.jdk1.8 HashMap的变化？\"></a>jdk1.7-.jdk1.8 HashMap的变化？</h2><h2 id=\"HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？\"><a href=\"#HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？\" class=\"headerlink\" title=\"HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？\"></a>HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？</h2><p>对修改Hashtable内部共享数据的方法添加了synchronized，保证线程安全。<br>包括put、get、remove、clear、size等方法都有同步。<br>总的来说就是所有对Hashtable的所有数据操作的行为都进行了同步。</p>\n<h2 id=\"追问5-线程安全的集合类包括哪些，它们是怎么实现线程安全的\"><a href=\"#追问5-线程安全的集合类包括哪些，它们是怎么实现线程安全的\" class=\"headerlink\" title=\"追问5: 线程安全的集合类包括哪些，它们是怎么实现线程安全的?\"></a>追问5: 线程安全的集合类包括哪些，它们是怎么实现线程安全的?</h2><h2 id=\"追问6-Hashtable和ConcurrentHashMap的区别？\"><a href=\"#追问6-Hashtable和ConcurrentHashMap的区别？\" class=\"headerlink\" title=\"追问6: Hashtable和ConcurrentHashMap的区别？\"></a>追问6: Hashtable和ConcurrentHashMap的区别？</h2><h1 id=\"涉及其他知识点\"><a href=\"#涉及其他知识点\" class=\"headerlink\" title=\"涉及其他知识点\"></a>涉及其他知识点</h1><h2 id=\"红黑树，平衡二叉树\"><a href=\"#红黑树，平衡二叉树\" class=\"headerlink\" title=\"红黑树，平衡二叉树\"></a>红黑树，平衡二叉树</h2><h2 id=\"hash算法，下标计算如何计算\"><a href=\"#hash算法，下标计算如何计算\" class=\"headerlink\" title=\"hash算法，下标计算如何计算\"></a>hash算法，下标计算如何计算</h2><p>直接看下HashMap中的hash方法：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Computes key.hashCode() and spreads (XORs) higher bits of hash</span></span><br><span class=\"line\"><span class=\"comment\"> * to lower.  Because the table uses power-of-two masking, sets of</span></span><br><span class=\"line\"><span class=\"comment\"> * hashes that vary only in bits above the current mask will</span></span><br><span class=\"line\"><span class=\"comment\"> * always collide. (Among known examples are sets of Float keys</span></span><br><span class=\"line\"><span class=\"comment\"> * holding consecutive whole numbers in small tables.)  So we</span></span><br><span class=\"line\"><span class=\"comment\"> * apply a transform that spreads the impact of higher bits</span></span><br><span class=\"line\"><span class=\"comment\"> * downward. There is a tradeoff between speed, utility, and</span></span><br><span class=\"line\"><span class=\"comment\"> * quality of bit-spreading. Because many common sets of hashes</span></span><br><span class=\"line\"><span class=\"comment\"> * are already reasonably distributed (so don't benefit from</span></span><br><span class=\"line\"><span class=\"comment\"> * spreading), and because we use trees to handle large sets of</span></span><br><span class=\"line\"><span class=\"comment\"> * collisions in bins, we just XOR some shifted bits in the</span></span><br><span class=\"line\"><span class=\"comment\"> * cheapest possible way to reduce systematic lossage, as well as</span></span><br><span class=\"line\"><span class=\"comment\"> * to incorporate impact of the highest bits that would otherwise</span></span><br><span class=\"line\"><span class=\"comment\"> * never be used in index calculations because of table bounds.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> <span class=\"title\">hash</span><span class=\"params\">(Object key)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> h;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (key == <span class=\"keyword\">null</span>) ? <span class=\"number\">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class=\"number\">16</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>key==null直接返回0;</li>\n<li>hash为(h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</li>\n</ul>\n<p>以下为put方法的片段代码：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class=\"keyword\">int</span> n, i;</span><br><span class=\"line\"><span class=\"keyword\">if</span> ((tab = table) == <span class=\"keyword\">null</span> || (n = tab.length) == <span class=\"number\">0</span>)</span><br><span class=\"line\">    n = (tab = resize()).length;</span><br><span class=\"line\"><span class=\"keyword\">if</span> ((p = tab[i = (n - <span class=\"number\">1</span>) &amp; hash]) == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">    tab[i] = newNode(hash, key, value, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"><span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>n为table扩容后的长度</li>\n<li>p为当前节点</li>\n<li>得到table下标位置(n - 1) &amp; hash ;</li>\n</ul>\n<h2 id=\"扩容细节\"><a href=\"#扩容细节\" class=\"headerlink\" title=\"扩容细节\"></a>扩容细节</h2><p>默认容量：DEFAULT_INITIAL_CAPACITY 1&lt;&lt;4 = 16;</p>\n<h2 id=\"CAS\"><a href=\"#CAS\" class=\"headerlink\" title=\"CAS\"></a>CAS</h2><p>借助Unsafe来实现native code。CAS有3个操作数，内存值V、旧的预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。Unsafe借助CPU指令cmpxchg来实现。</p>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>本文为近期学习JDK源码中集合类相关记录的笔记，因为是学习过程中的随笔，没有很仔细整理过。<br><br>虽然在日常使用中只需要关注这些类的api如何使用即可，但是对于进阶的提升，可以在源码中更加熟悉各类的使用方式，以及学习到更多好的设计和处理问题的思路。<br><br>ps：公司内网已经不能访问github等开源网站，代码一直提不上去github，写了一些笔记都不能及时更新。</p>\n</blockquote>","more":"<h1 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h1><h2 id=\"jdk1-7\"><a href=\"#jdk1-7\" class=\"headerlink\" title=\"jdk1.7\"></a>jdk1.7</h2><p>HashMap 里面是一个数组，然后数组中每个元素是一个单向链表。</p>\n<ul>\n<li>capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。</li>\n<li>loadFactor：负载因子，默认为 0.75。</li>\n<li>threshold：扩容的阈值，等于 capacity * loadFactor<br>HashMap扩容是长度的2倍，且长度永远是2的次幂，存储下标：index = h&amp;(length-1)</li>\n</ul>\n<h3 id=\"put过程\"><a href=\"#put过程\" class=\"headerlink\" title=\"put过程\"></a>put过程</h3><ol>\n<li>判断当前数组是否需要初始化</li>\n<li>如果key为null则put一个null进去</li>\n<li>根据key计算出hashcode</li>\n<li>根据hashcode得出table的下标所在位置的桶</li>\n<li>如果桶是链表则遍历里面每个对象的hashcode、key和传入的key是否相当，相等则覆盖</li>\n<li>如果桶是空新增一个entry写入到当前位置（addEntry）</li>\n<li>addEntry：判断是否需要扩容，计算公式如上，<br>需要扩容则两倍扩容，并且将当前key重新hash定位,扩容后的位置要么是再原下标的位置，另一种是在下标为 &lt;原下标+原容量&gt; 的位置。</li>\n<li>createEntry：当前位置的桶传入到新建的桶中，如果当位置有桶则生成链表</li>\n</ol>\n<h3 id=\"get过程\"><a href=\"#get过程\" class=\"headerlink\" title=\"get过程\"></a>get过程</h3><ol>\n<li>根据key计算出heshcode，然后得到对应的下标</li>\n<li>判断是否为链表，不是链表就根据key的hashcode进行比较，是则返回值；如果是链表则遍历链表同上进行比较。</li>\n<li>没获取到返回null</li>\n</ol>\n<h2 id=\"jdk1-7的缺点\"><a href=\"#jdk1-7的缺点\" class=\"headerlink\" title=\"jdk1.7的缺点\"></a>jdk1.7的缺点</h2><p>当Hash冲突严重时，在Node上形成的链表会变的越来越长，这样在查询时的效率就会越来越低；时间复杂度为O(N)。jdk1.8主要优化的就是这个。</p>\n<h2 id=\"jdk1-8\"><a href=\"#jdk1-8\" class=\"headerlink\" title=\"jdk1.8\"></a>jdk1.8</h2><p>数据结构修改，数组+链表/红黑树<br>当链表长度超过8之后，会转换为红黑树，如果低于6会转换回链表<br>7中用entry标识每一个数据节点，8中修改为Node</p>\n<h3 id=\"put过程-1\"><a href=\"#put过程-1\" class=\"headerlink\" title=\"put过程\"></a>put过程</h3><ol>\n<li>判断当前table是否为空，空则进行初始化（resize中会判断是否进行初始化）</li>\n<li>根据key得到hashcode定位到具体桶的位置，为空则没有hash冲突创建一个新的node。</li>\n<li>如果有hash冲突，则比较entry的hashcode与当前位置的key的hashcode是否相等，相等则进行赋值。</li>\n<li>如果当前桶为红黑树则按照红黑树的写入方式进行写入，如果是链表则在当前entry下创建形成链表。</li>\n<li>判断当前链表大小是否超过预设阈值（TREEIFY_THRESHOLD）8，超过则转换为红黑树。</li>\n<li>最后判断是否扩容</li>\n</ol>\n<h3 id=\"get\"><a href=\"#get\" class=\"headerlink\" title=\"get\"></a>get</h3><ol>\n<li>根据key得到hashcode定位到桶的位置，为空直接返回null。</li>\n<li>遍历table的每一个entry，比较key是否相等，相等则返回value。</li>\n<li>如果是红黑树则按照红黑树的方法进行查找，如果是链表则遍历进行查找。</li>\n</ol>\n<h2 id=\"HashMap在多线程并发时的问题是什么，哪里线程不安全\"><a href=\"#HashMap在多线程并发时的问题是什么，哪里线程不安全\" class=\"headerlink\" title=\"HashMap在多线程并发时的问题是什么，哪里线程不安全\"></a>HashMap在多线程并发时的问题是什么，哪里线程不安全</h2><p>在HashMap扩容的时候会调用resize()方法，就是这里的并发操作容易在一个桶上形成环形链表；这样当获取一个不存在的 key时，计算出的index正好是环形链表的下标就会出现死循环。</p>\n<h1 id=\"ConcurrentHashMap\"><a href=\"#ConcurrentHashMap\" class=\"headerlink\" title=\"ConcurrentHashMap\"></a>ConcurrentHashMap</h1><h2 id=\"jdk1-7-1\"><a href=\"#jdk1-7-1\" class=\"headerlink\" title=\"jdk1.7\"></a>jdk1.7</h2><p>由segment组成，每一个segment继承自reentrantlock（重入锁），所以每次加锁是对于每一个段进行加锁，从而保证全局的线程安全。</p>\n<ul>\n<li>concurrencyLevel：并行并发数、segment数，默认是16，是控制ConcurrentHashMap的segment的数量，不可扩容。</li>\n<li>initialCapacity：初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。</li>\n<li>loadFactor：负载因子，因为Segment 数组不可以扩容，所以这个负载因子是给每个Segment 内部使用的。</li>\n</ul>\n<p>HashEntry、value都是由volatile修饰的。</p>\n<h3 id=\"put过程-2\"><a href=\"#put过程-2\" class=\"headerlink\" title=\"put过程\"></a>put过程</h3><ol>\n<li>尝试获取自旋获取锁</li>\n<li>如果重试次数达到了MAX_SCAN_RETRIES则改为阻塞锁获取，保证能获取成功</li>\n<li>根据key得到hashcode定位到segments中HashEntry的下标</li>\n<li>遍历HashEntry（链表）不为空则判断传入的key是否相等，相等则覆盖value</li>\n<li>为空则新建HashEntry并加入到segments中，同时会先判断是否需要进行扩容</li>\n<li>最后解除获取的锁</li>\n</ol>\n<h3 id=\"get过程-1\"><a href=\"#get过程-1\" class=\"headerlink\" title=\"get过程\"></a>get过程</h3><ol>\n<li>根据key得到hashcode并且计算得到segments中的下标，获取到HashEntry</li>\n<li>遍历HashEntry中key，相等则获取value<br>由于HashEntry的value是用volatile修饰的，保证了其可见性，所以每次获取都是最新的值</li>\n</ol>\n<h2 id=\"jdk1-8-1\"><a href=\"#jdk1-8-1\" class=\"headerlink\" title=\"jdk1.8\"></a>jdk1.8</h2><p>CocurrentHashMap抛弃了原有的Segment分段锁，采用了CAS + synchronized关键字来保证并发安全性。与HashMap1.7的问题一样，链表过长后查询效率低的问题。</p>\n<p>HashEntry修改为Node，其中的val,next都用了volatile修饰，保证了可见性</p>\n<p>对sizeCtl的控制都是用 CAS 来实现的:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Table initialization and resizing control.  When negative, the</span></span><br><span class=\"line\"><span class=\"comment\"> * table is being initialized or resized: -1 for initialization,</span></span><br><span class=\"line\"><span class=\"comment\"> * else -(1 + the number of active resizing threads).  Otherwise,</span></span><br><span class=\"line\"><span class=\"comment\"> * when table is null, holds the initial table size to use upon</span></span><br><span class=\"line\"><span class=\"comment\"> * creation, or 0 for default. After initialization, holds the</span></span><br><span class=\"line\"><span class=\"comment\"> * next element count value upon which to resize the table.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"keyword\">transient</span> <span class=\"keyword\">volatile</span> <span class=\"keyword\">int</span> sizeCtl;</span><br></pre></td></tr></table></figure></p>\n<p>下面是翻译：</p>\n<p>-1代表table正在初始化，N表示有 -N-1 个线程正在进行扩容操作。</p>\n<p>如果table未初始化，表示table需要初始化的大小。</p>\n<p>如果table初始化完成，表示table的容量，默认是table大小的0.75倍，用这个公式算 0.75（n – (n &gt;&gt;&gt; 2)）。</p>\n<p>CAS 会出现的问题：ABA</p>\n<p>解决：对变量增加一个版本号，每次修改，版本号加1，比较的时候比较版本号。</p>\n<p>put过程：</p>\n<ol>\n<li>根据key的hashcode计算得处table的下标</li>\n<li>判断是否需要进行初始化</li>\n<li>获取table对应下标的Node，如果为空表示当前位置可以写入数据，利用CAS 尝试写入，失败则自旋保证成功</li>\n<li>如果当前位置的 hashcode == MOVED == -1,则需要进行扩容</li>\n<li>如果都不满足，则利用synchronized锁写入数据（此处锁的对象是Node）</li>\n<li>如果数量大于TREEIFY_THRESHOLD则要转换为红黑树</li>\n</ol>\n<p>get过程：</p>\n<ol>\n<li>根据key的hashcode计算得到table的下标，得到Node</li>\n<li>如果是红黑树则按照树的方式获取值</li>\n<li>如果不是则按照链表的方式遍历获取值</li>\n</ol>\n<h1 id=\"ArrayList\"><a href=\"#ArrayList\" class=\"headerlink\" title=\"ArrayList\"></a>ArrayList</h1><p>默认容量10</p>\n<p>int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1)</p>\n<p>其中oldCapacity是原来的容量大小，oldCapacity &gt;&gt; 1为位运算的右移操作，右移一位相当于除以2，所以这句代码就等于</p>\n<p>int newCapacity = oldCapacity + oldCapacity / 2；</p>\n<p>即容量扩大为原来的1.5倍，获取newCapacity后再对newCapacity的大小进行判断，如果仍然小于minCapacity，则直接让newCapacity 等于minCapacity，而不再计算1.5倍的扩容。然后还要再进行一步判断，即判断当前新容量是否超过最大的容量 </p>\n<p>if (newCapacity - MAX_ARRAY_SIZE &gt; 0)</p>\n<p>如果超过，则调用hugeCapacity方法，传进去的是minCapacity，即新增元素后需要的最小容量：<br>如果minCapacity大于MAX_ARRAY_SIZE，则返回Integer的最大值。否则返回MAX_ARRAY_SIZE。</p>\n<p>调用Arrays.copyof方法，即复制原数组内容到一个新容量的大数组里。这里Arrays.copyof方法实际是调用System.arraycopy方法。</p>\n<h1 id=\"相关问题\"><a href=\"#相关问题\" class=\"headerlink\" title=\"相关问题\"></a>相关问题</h1><h2 id=\"追问1：ArrayList和LinkedList有什么区别？\"><a href=\"#追问1：ArrayList和LinkedList有什么区别？\" class=\"headerlink\" title=\"追问1：ArrayList和LinkedList有什么区别？\"></a>追问1：ArrayList和LinkedList有什么区别？</h2><h2 id=\"追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？\"><a href=\"#追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？\" class=\"headerlink\" title=\"追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？\"></a>追问2：ArrayList底层使用一个数组，它是怎么进行扩容的？</h2><h2 id=\"追问3-HashMap和Hashtable有什么区别\"><a href=\"#追问3-HashMap和Hashtable有什么区别\" class=\"headerlink\" title=\"追问3: HashMap和Hashtable有什么区别?\"></a>追问3: HashMap和Hashtable有什么区别?</h2><h2 id=\"追问4-HashMap的put和get方法是怎么实现的\"><a href=\"#追问4-HashMap的put和get方法是怎么实现的\" class=\"headerlink\" title=\"追问4: HashMap的put和get方法是怎么实现的?\"></a>追问4: HashMap的put和get方法是怎么实现的?</h2><h2 id=\"jdk1-7-jdk1-8-HashMap的变化？\"><a href=\"#jdk1-7-jdk1-8-HashMap的变化？\" class=\"headerlink\" title=\"jdk1.7-.jdk1.8 HashMap的变化？\"></a>jdk1.7-.jdk1.8 HashMap的变化？</h2><h2 id=\"HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？\"><a href=\"#HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？\" class=\"headerlink\" title=\"HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？\"></a>HashTable是通过synchronized实现线程安全，那么具体同步了哪些资源？</h2><p>对修改Hashtable内部共享数据的方法添加了synchronized，保证线程安全。<br>包括put、get、remove、clear、size等方法都有同步。<br>总的来说就是所有对Hashtable的所有数据操作的行为都进行了同步。</p>\n<h2 id=\"追问5-线程安全的集合类包括哪些，它们是怎么实现线程安全的\"><a href=\"#追问5-线程安全的集合类包括哪些，它们是怎么实现线程安全的\" class=\"headerlink\" title=\"追问5: 线程安全的集合类包括哪些，它们是怎么实现线程安全的?\"></a>追问5: 线程安全的集合类包括哪些，它们是怎么实现线程安全的?</h2><h2 id=\"追问6-Hashtable和ConcurrentHashMap的区别？\"><a href=\"#追问6-Hashtable和ConcurrentHashMap的区别？\" class=\"headerlink\" title=\"追问6: Hashtable和ConcurrentHashMap的区别？\"></a>追问6: Hashtable和ConcurrentHashMap的区别？</h2><h1 id=\"涉及其他知识点\"><a href=\"#涉及其他知识点\" class=\"headerlink\" title=\"涉及其他知识点\"></a>涉及其他知识点</h1><h2 id=\"红黑树，平衡二叉树\"><a href=\"#红黑树，平衡二叉树\" class=\"headerlink\" title=\"红黑树，平衡二叉树\"></a>红黑树，平衡二叉树</h2><h2 id=\"hash算法，下标计算如何计算\"><a href=\"#hash算法，下标计算如何计算\" class=\"headerlink\" title=\"hash算法，下标计算如何计算\"></a>hash算法，下标计算如何计算</h2><p>直接看下HashMap中的hash方法：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Computes key.hashCode() and spreads (XORs) higher bits of hash</span></span><br><span class=\"line\"><span class=\"comment\"> * to lower.  Because the table uses power-of-two masking, sets of</span></span><br><span class=\"line\"><span class=\"comment\"> * hashes that vary only in bits above the current mask will</span></span><br><span class=\"line\"><span class=\"comment\"> * always collide. (Among known examples are sets of Float keys</span></span><br><span class=\"line\"><span class=\"comment\"> * holding consecutive whole numbers in small tables.)  So we</span></span><br><span class=\"line\"><span class=\"comment\"> * apply a transform that spreads the impact of higher bits</span></span><br><span class=\"line\"><span class=\"comment\"> * downward. There is a tradeoff between speed, utility, and</span></span><br><span class=\"line\"><span class=\"comment\"> * quality of bit-spreading. Because many common sets of hashes</span></span><br><span class=\"line\"><span class=\"comment\"> * are already reasonably distributed (so don't benefit from</span></span><br><span class=\"line\"><span class=\"comment\"> * spreading), and because we use trees to handle large sets of</span></span><br><span class=\"line\"><span class=\"comment\"> * collisions in bins, we just XOR some shifted bits in the</span></span><br><span class=\"line\"><span class=\"comment\"> * cheapest possible way to reduce systematic lossage, as well as</span></span><br><span class=\"line\"><span class=\"comment\"> * to incorporate impact of the highest bits that would otherwise</span></span><br><span class=\"line\"><span class=\"comment\"> * never be used in index calculations because of table bounds.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> <span class=\"title\">hash</span><span class=\"params\">(Object key)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> h;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (key == <span class=\"keyword\">null</span>) ? <span class=\"number\">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class=\"number\">16</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>key==null直接返回0;</li>\n<li>hash为(h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</li>\n</ul>\n<p>以下为put方法的片段代码：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class=\"keyword\">int</span> n, i;</span><br><span class=\"line\"><span class=\"keyword\">if</span> ((tab = table) == <span class=\"keyword\">null</span> || (n = tab.length) == <span class=\"number\">0</span>)</span><br><span class=\"line\">    n = (tab = resize()).length;</span><br><span class=\"line\"><span class=\"keyword\">if</span> ((p = tab[i = (n - <span class=\"number\">1</span>) &amp; hash]) == <span class=\"keyword\">null</span>)</span><br><span class=\"line\">    tab[i] = newNode(hash, key, value, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"><span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>n为table扩容后的长度</li>\n<li>p为当前节点</li>\n<li>得到table下标位置(n - 1) &amp; hash ;</li>\n</ul>\n<h2 id=\"扩容细节\"><a href=\"#扩容细节\" class=\"headerlink\" title=\"扩容细节\"></a>扩容细节</h2><p>默认容量：DEFAULT_INITIAL_CAPACITY 1&lt;&lt;4 = 16;</p>\n<h2 id=\"CAS\"><a href=\"#CAS\" class=\"headerlink\" title=\"CAS\"></a>CAS</h2><p>借助Unsafe来实现native code。CAS有3个操作数，内存值V、旧的预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。Unsafe借助CPU指令cmpxchg来实现。</p>"},{"title":"redis客户端源码","date":"2020-03-13T02:00:00.000Z","_content":"\n学习一下Redis客户端Jedis源码，简单的API经常用已经很熟了，稍微学习一下底层的原理和设计。\n<!-- more -->\n\n- 创建Client->BinaryJedis-Connection，创建了一个DefaultJedisSocketFactory\n- checkIsInMultiOrPipeline，进行无事务检查，使用事务要用jedis.Transaction\n- 向RedisOutputStream写入字节数据\n- 使用sendCommand发送指令，get、set、其他的指令最终都是使用该方法进行发送的。\n\n``` java\n  public void sendCommand(final ProtocolCommand cmd, final byte[]... args) {\n    try {\n      connect();\n      Protocol.sendCommand(outputStream, cmd, args);\n    } catch (JedisConnectionException ex) {\n      /*\n       * When client send request which formed by invalid protocol, Redis send back error message\n       * before close connection. We try to read it to provide reason of failure.\n       */\n      try {\n        String errorMessage = Protocol.readErrorLineIfPossible(inputStream);\n        if (errorMessage != null && errorMessage.length() > 0) {\n          ex = new JedisConnectionException(errorMessage, ex.getCause());\n        }\n      } catch (Exception e) {\n        /*\n         * Catch any IOException or JedisConnectionException occurred from InputStream#read and just\n         * ignore. This approach is safe because reading error message is optional and connection\n         * will eventually be closed.\n         */\n      }\n      // Any other exceptions related to connection?\n      broken = true;\n      throw ex;\n    }\n  }\n```\n\n# RESP protocol redis序列化协议\n进行一次set操作，key是'test'，value是'abc'，本地创建Jedis Client后通过socket.accept获取写出的信息为\n```\n*3\n$3\nSET\n$4\ntest\n$3\nabc\n```\n\n大致看上去好像和appendOnly.aof文件中保存的东西类似，其实AOF文件中其实保存的就是操作指令转化为该协议的内容。对于词内容是什么，其实redis官方文档中就有这方面的解释 https://redis.io/topics/protocol\n\nThe RESP protocol was introduced in Redis 1.2, but it became the standard way for talking with the Redis server in Redis 2.0. This is the protocol you should implement in your Redis client.\n\nRESP is actually a serialization protocol that supports the following data types: Simple Strings, Errors, Integers, Bulk Strings and Arrays.\n\nThe way RESP is used in Redis as a request-response protocol is the following:\n\n- Clients send commands to a Redis server as a RESP Array of Bulk Strings.\n- The server replies with one of the RESP types according to the command implementation.\n\nIn RESP, the type of some data depends on the first byte:\n- For Simple Strings the first byte of the reply is \"+\"\n- For Errors the first byte of the reply is \"-\"\n- For Integers the first byte of the reply is \":\"\n- For Bulk Strings the first byte of the reply is \"$\"\n- For Arrays the first byte of the reply is \"*\"\nAdditionally RESP is able to represent a Null value using a special variation of Bulk Strings or Array as specified later.\n\nIn RESP different parts of the protocol are always terminated with \"\\r\\n\" (CRLF).\n\ngoogle翻译了下，有点奇怪，但是也能理解，其实就是分别对String、error、整形、字符串、数组设置对应的标识\n- 对于简单字符串，答复的第一个字节为“ +”\n- 对于错误，回复的第一个字节为“-”\n- 对于整数，答复的第一个字节为“：”\n- 对于批量字符串，答复的第一个字节为“ $”\n- 对于数组，回复的第一个字节为“ *”\n\n由此解析出：\n```\n*3 传入数组长度为3 \n$3 字符串长度3\nSET 字符串内容\n$4 字符串长度4\ntest 字符串内容\n$3 字符串长度3\nabc 字符串内容\n```\n\n## 响应信息获取\nredis.clients.jedis.Connection#getBulkReply\n- redis.clients.jedis.Connection#flush\n- redis.clients.jedis.Connection#readProtocolWithCheckingBroken\n- 读入RedisInputStream中响应写入的信息，而后进行Protocol.read()\n\n``` java\n  private static Object process(final RedisInputStream is) {\n    final byte b = is.readByte();\n    switch (b) {\n    case PLUS_BYTE:\n      return processStatusCodeReply(is);\n    case DOLLAR_BYTE:\n      return processBulkReply(is);\n    case ASTERISK_BYTE:\n      return processMultiBulkReply(is);\n    case COLON_BYTE:\n      return processInteger(is);\n    case MINUS_BYTE:\n      processError(is);\n      return null;\n    default:\n      throw new JedisConnectionException(\"Unknown reply: \" + (char) b);\n    }\n  }\n```\n读第一个字节判断返回的数据是某种RESP协议数据类型。然后以对应的方式进行解析。\n\n# redis.clients.jedis.JedisMonitor\n实现JedisMonitor，监控Redis Client的指令动作，但会大幅降低性能。","source":"_posts/redis_03_客户端源码.md","raw":"---\ntitle: redis客户端源码\ndate: 2020-03-13 10:00:00\ntags: redis\ncategories: 中间件\n---\n\n学习一下Redis客户端Jedis源码，简单的API经常用已经很熟了，稍微学习一下底层的原理和设计。\n<!-- more -->\n\n- 创建Client->BinaryJedis-Connection，创建了一个DefaultJedisSocketFactory\n- checkIsInMultiOrPipeline，进行无事务检查，使用事务要用jedis.Transaction\n- 向RedisOutputStream写入字节数据\n- 使用sendCommand发送指令，get、set、其他的指令最终都是使用该方法进行发送的。\n\n``` java\n  public void sendCommand(final ProtocolCommand cmd, final byte[]... args) {\n    try {\n      connect();\n      Protocol.sendCommand(outputStream, cmd, args);\n    } catch (JedisConnectionException ex) {\n      /*\n       * When client send request which formed by invalid protocol, Redis send back error message\n       * before close connection. We try to read it to provide reason of failure.\n       */\n      try {\n        String errorMessage = Protocol.readErrorLineIfPossible(inputStream);\n        if (errorMessage != null && errorMessage.length() > 0) {\n          ex = new JedisConnectionException(errorMessage, ex.getCause());\n        }\n      } catch (Exception e) {\n        /*\n         * Catch any IOException or JedisConnectionException occurred from InputStream#read and just\n         * ignore. This approach is safe because reading error message is optional and connection\n         * will eventually be closed.\n         */\n      }\n      // Any other exceptions related to connection?\n      broken = true;\n      throw ex;\n    }\n  }\n```\n\n# RESP protocol redis序列化协议\n进行一次set操作，key是'test'，value是'abc'，本地创建Jedis Client后通过socket.accept获取写出的信息为\n```\n*3\n$3\nSET\n$4\ntest\n$3\nabc\n```\n\n大致看上去好像和appendOnly.aof文件中保存的东西类似，其实AOF文件中其实保存的就是操作指令转化为该协议的内容。对于词内容是什么，其实redis官方文档中就有这方面的解释 https://redis.io/topics/protocol\n\nThe RESP protocol was introduced in Redis 1.2, but it became the standard way for talking with the Redis server in Redis 2.0. This is the protocol you should implement in your Redis client.\n\nRESP is actually a serialization protocol that supports the following data types: Simple Strings, Errors, Integers, Bulk Strings and Arrays.\n\nThe way RESP is used in Redis as a request-response protocol is the following:\n\n- Clients send commands to a Redis server as a RESP Array of Bulk Strings.\n- The server replies with one of the RESP types according to the command implementation.\n\nIn RESP, the type of some data depends on the first byte:\n- For Simple Strings the first byte of the reply is \"+\"\n- For Errors the first byte of the reply is \"-\"\n- For Integers the first byte of the reply is \":\"\n- For Bulk Strings the first byte of the reply is \"$\"\n- For Arrays the first byte of the reply is \"*\"\nAdditionally RESP is able to represent a Null value using a special variation of Bulk Strings or Array as specified later.\n\nIn RESP different parts of the protocol are always terminated with \"\\r\\n\" (CRLF).\n\ngoogle翻译了下，有点奇怪，但是也能理解，其实就是分别对String、error、整形、字符串、数组设置对应的标识\n- 对于简单字符串，答复的第一个字节为“ +”\n- 对于错误，回复的第一个字节为“-”\n- 对于整数，答复的第一个字节为“：”\n- 对于批量字符串，答复的第一个字节为“ $”\n- 对于数组，回复的第一个字节为“ *”\n\n由此解析出：\n```\n*3 传入数组长度为3 \n$3 字符串长度3\nSET 字符串内容\n$4 字符串长度4\ntest 字符串内容\n$3 字符串长度3\nabc 字符串内容\n```\n\n## 响应信息获取\nredis.clients.jedis.Connection#getBulkReply\n- redis.clients.jedis.Connection#flush\n- redis.clients.jedis.Connection#readProtocolWithCheckingBroken\n- 读入RedisInputStream中响应写入的信息，而后进行Protocol.read()\n\n``` java\n  private static Object process(final RedisInputStream is) {\n    final byte b = is.readByte();\n    switch (b) {\n    case PLUS_BYTE:\n      return processStatusCodeReply(is);\n    case DOLLAR_BYTE:\n      return processBulkReply(is);\n    case ASTERISK_BYTE:\n      return processMultiBulkReply(is);\n    case COLON_BYTE:\n      return processInteger(is);\n    case MINUS_BYTE:\n      processError(is);\n      return null;\n    default:\n      throw new JedisConnectionException(\"Unknown reply: \" + (char) b);\n    }\n  }\n```\n读第一个字节判断返回的数据是某种RESP协议数据类型。然后以对应的方式进行解析。\n\n# redis.clients.jedis.JedisMonitor\n实现JedisMonitor，监控Redis Client的指令动作，但会大幅降低性能。","slug":"redis_03_客户端源码","published":1,"updated":"2020-05-12T22:32:46.594Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl4a0050qotncyutw693","content":"<p>学习一下Redis客户端Jedis源码，简单的API经常用已经很熟了，稍微学习一下底层的原理和设计。<br><a id=\"more\"></a></p>\n<ul>\n<li>创建Client-&gt;BinaryJedis-Connection，创建了一个DefaultJedisSocketFactory</li>\n<li>checkIsInMultiOrPipeline，进行无事务检查，使用事务要用jedis.Transaction</li>\n<li>向RedisOutputStream写入字节数据</li>\n<li>使用sendCommand发送指令，get、set、其他的指令最终都是使用该方法进行发送的。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">sendCommand</span><span class=\"params\">(<span class=\"keyword\">final</span> ProtocolCommand cmd, <span class=\"keyword\">final</span> <span class=\"keyword\">byte</span>[]... args)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    connect();</span><br><span class=\"line\">    Protocol.sendCommand(outputStream, cmd, args);</span><br><span class=\"line\">  &#125; <span class=\"keyword\">catch</span> (JedisConnectionException ex) &#123;</span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">     * When client send request which formed by invalid protocol, Redis send back error message</span></span><br><span class=\"line\"><span class=\"comment\">     * before close connection. We try to read it to provide reason of failure.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">      String errorMessage = Protocol.readErrorLineIfPossible(inputStream);</span><br><span class=\"line\">      <span class=\"keyword\">if</span> (errorMessage != <span class=\"keyword\">null</span> &amp;&amp; errorMessage.length() &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        ex = <span class=\"keyword\">new</span> JedisConnectionException(errorMessage, ex.getCause());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">      <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">       * Catch any IOException or JedisConnectionException occurred from InputStream#read and just</span></span><br><span class=\"line\"><span class=\"comment\">       * ignore. This approach is safe because reading error message is optional and connection</span></span><br><span class=\"line\"><span class=\"comment\">       * will eventually be closed.</span></span><br><span class=\"line\"><span class=\"comment\">       */</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// Any other exceptions related to connection?</span></span><br><span class=\"line\">    broken = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    <span class=\"keyword\">throw</span> ex;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"RESP-protocol-redis序列化协议\"><a href=\"#RESP-protocol-redis序列化协议\" class=\"headerlink\" title=\"RESP protocol redis序列化协议\"></a>RESP protocol redis序列化协议</h1><p>进行一次set操作，key是’test’，value是’abc’，本地创建Jedis Client后通过socket.accept获取写出的信息为<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*3</span><br><span class=\"line\">$3</span><br><span class=\"line\">SET</span><br><span class=\"line\">$4</span><br><span class=\"line\">test</span><br><span class=\"line\">$3</span><br><span class=\"line\">abc</span><br></pre></td></tr></table></figure></p>\n<p>大致看上去好像和appendOnly.aof文件中保存的东西类似，其实AOF文件中其实保存的就是操作指令转化为该协议的内容。对于词内容是什么，其实redis官方文档中就有这方面的解释 <a href=\"https://redis.io/topics/protocol\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/protocol</a></p>\n<p>The RESP protocol was introduced in Redis 1.2, but it became the standard way for talking with the Redis server in Redis 2.0. This is the protocol you should implement in your Redis client.</p>\n<p>RESP is actually a serialization protocol that supports the following data types: Simple Strings, Errors, Integers, Bulk Strings and Arrays.</p>\n<p>The way RESP is used in Redis as a request-response protocol is the following:</p>\n<ul>\n<li>Clients send commands to a Redis server as a RESP Array of Bulk Strings.</li>\n<li>The server replies with one of the RESP types according to the command implementation.</li>\n</ul>\n<p>In RESP, the type of some data depends on the first byte:</p>\n<ul>\n<li>For Simple Strings the first byte of the reply is “+”</li>\n<li>For Errors the first byte of the reply is “-“</li>\n<li>For Integers the first byte of the reply is “:”</li>\n<li>For Bulk Strings the first byte of the reply is “$”</li>\n<li>For Arrays the first byte of the reply is “*”<br>Additionally RESP is able to represent a Null value using a special variation of Bulk Strings or Array as specified later.</li>\n</ul>\n<p>In RESP different parts of the protocol are always terminated with “\\r\\n” (CRLF).</p>\n<p>google翻译了下，有点奇怪，但是也能理解，其实就是分别对String、error、整形、字符串、数组设置对应的标识</p>\n<ul>\n<li>对于简单字符串，答复的第一个字节为“ +”</li>\n<li>对于错误，回复的第一个字节为“-”</li>\n<li>对于整数，答复的第一个字节为“：”</li>\n<li>对于批量字符串，答复的第一个字节为“ $”</li>\n<li>对于数组，回复的第一个字节为“ *”</li>\n</ul>\n<p>由此解析出：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*3 传入数组长度为3 </span><br><span class=\"line\">$3 字符串长度3</span><br><span class=\"line\">SET 字符串内容</span><br><span class=\"line\">$4 字符串长度4</span><br><span class=\"line\">test 字符串内容</span><br><span class=\"line\">$3 字符串长度3</span><br><span class=\"line\">abc 字符串内容</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"响应信息获取\"><a href=\"#响应信息获取\" class=\"headerlink\" title=\"响应信息获取\"></a>响应信息获取</h2><p>redis.clients.jedis.Connection#getBulkReply</p>\n<ul>\n<li>redis.clients.jedis.Connection#flush</li>\n<li>redis.clients.jedis.Connection#readProtocolWithCheckingBroken</li>\n<li>读入RedisInputStream中响应写入的信息，而后进行Protocol.read()</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Object <span class=\"title\">process</span><span class=\"params\">(<span class=\"keyword\">final</span> RedisInputStream is)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">final</span> <span class=\"keyword\">byte</span> b = is.readByte();</span><br><span class=\"line\">  <span class=\"keyword\">switch</span> (b) &#123;</span><br><span class=\"line\">  <span class=\"keyword\">case</span> PLUS_BYTE:</span><br><span class=\"line\">    <span class=\"keyword\">return</span> processStatusCodeReply(is);</span><br><span class=\"line\">  <span class=\"keyword\">case</span> DOLLAR_BYTE:</span><br><span class=\"line\">    <span class=\"keyword\">return</span> processBulkReply(is);</span><br><span class=\"line\">  <span class=\"keyword\">case</span> ASTERISK_BYTE:</span><br><span class=\"line\">    <span class=\"keyword\">return</span> processMultiBulkReply(is);</span><br><span class=\"line\">  <span class=\"keyword\">case</span> COLON_BYTE:</span><br><span class=\"line\">    <span class=\"keyword\">return</span> processInteger(is);</span><br><span class=\"line\">  <span class=\"keyword\">case</span> MINUS_BYTE:</span><br><span class=\"line\">    processError(is);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">  <span class=\"keyword\">default</span>:</span><br><span class=\"line\">    <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> JedisConnectionException(<span class=\"string\">\"Unknown reply: \"</span> + (<span class=\"keyword\">char</span>) b);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>读第一个字节判断返回的数据是某种RESP协议数据类型。然后以对应的方式进行解析。</p>\n<h1 id=\"redis-clients-jedis-JedisMonitor\"><a href=\"#redis-clients-jedis-JedisMonitor\" class=\"headerlink\" title=\"redis.clients.jedis.JedisMonitor\"></a>redis.clients.jedis.JedisMonitor</h1><p>实现JedisMonitor，监控Redis Client的指令动作，但会大幅降低性能。</p>\n","site":{"data":{}},"excerpt":"<p>学习一下Redis客户端Jedis源码，简单的API经常用已经很熟了，稍微学习一下底层的原理和设计。<br>","more":"</p>\n<ul>\n<li>创建Client-&gt;BinaryJedis-Connection，创建了一个DefaultJedisSocketFactory</li>\n<li>checkIsInMultiOrPipeline，进行无事务检查，使用事务要用jedis.Transaction</li>\n<li>向RedisOutputStream写入字节数据</li>\n<li>使用sendCommand发送指令，get、set、其他的指令最终都是使用该方法进行发送的。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">sendCommand</span><span class=\"params\">(<span class=\"keyword\">final</span> ProtocolCommand cmd, <span class=\"keyword\">final</span> <span class=\"keyword\">byte</span>[]... args)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    connect();</span><br><span class=\"line\">    Protocol.sendCommand(outputStream, cmd, args);</span><br><span class=\"line\">  &#125; <span class=\"keyword\">catch</span> (JedisConnectionException ex) &#123;</span><br><span class=\"line\">    <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">     * When client send request which formed by invalid protocol, Redis send back error message</span></span><br><span class=\"line\"><span class=\"comment\">     * before close connection. We try to read it to provide reason of failure.</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">      String errorMessage = Protocol.readErrorLineIfPossible(inputStream);</span><br><span class=\"line\">      <span class=\"keyword\">if</span> (errorMessage != <span class=\"keyword\">null</span> &amp;&amp; errorMessage.length() &gt; <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        ex = <span class=\"keyword\">new</span> JedisConnectionException(errorMessage, ex.getCause());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">      <span class=\"comment\">/*</span></span><br><span class=\"line\"><span class=\"comment\">       * Catch any IOException or JedisConnectionException occurred from InputStream#read and just</span></span><br><span class=\"line\"><span class=\"comment\">       * ignore. This approach is safe because reading error message is optional and connection</span></span><br><span class=\"line\"><span class=\"comment\">       * will eventually be closed.</span></span><br><span class=\"line\"><span class=\"comment\">       */</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">// Any other exceptions related to connection?</span></span><br><span class=\"line\">    broken = <span class=\"keyword\">true</span>;</span><br><span class=\"line\">    <span class=\"keyword\">throw</span> ex;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"RESP-protocol-redis序列化协议\"><a href=\"#RESP-protocol-redis序列化协议\" class=\"headerlink\" title=\"RESP protocol redis序列化协议\"></a>RESP protocol redis序列化协议</h1><p>进行一次set操作，key是’test’，value是’abc’，本地创建Jedis Client后通过socket.accept获取写出的信息为<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*3</span><br><span class=\"line\">$3</span><br><span class=\"line\">SET</span><br><span class=\"line\">$4</span><br><span class=\"line\">test</span><br><span class=\"line\">$3</span><br><span class=\"line\">abc</span><br></pre></td></tr></table></figure></p>\n<p>大致看上去好像和appendOnly.aof文件中保存的东西类似，其实AOF文件中其实保存的就是操作指令转化为该协议的内容。对于词内容是什么，其实redis官方文档中就有这方面的解释 <a href=\"https://redis.io/topics/protocol\" target=\"_blank\" rel=\"noopener\">https://redis.io/topics/protocol</a></p>\n<p>The RESP protocol was introduced in Redis 1.2, but it became the standard way for talking with the Redis server in Redis 2.0. This is the protocol you should implement in your Redis client.</p>\n<p>RESP is actually a serialization protocol that supports the following data types: Simple Strings, Errors, Integers, Bulk Strings and Arrays.</p>\n<p>The way RESP is used in Redis as a request-response protocol is the following:</p>\n<ul>\n<li>Clients send commands to a Redis server as a RESP Array of Bulk Strings.</li>\n<li>The server replies with one of the RESP types according to the command implementation.</li>\n</ul>\n<p>In RESP, the type of some data depends on the first byte:</p>\n<ul>\n<li>For Simple Strings the first byte of the reply is “+”</li>\n<li>For Errors the first byte of the reply is “-“</li>\n<li>For Integers the first byte of the reply is “:”</li>\n<li>For Bulk Strings the first byte of the reply is “$”</li>\n<li>For Arrays the first byte of the reply is “*”<br>Additionally RESP is able to represent a Null value using a special variation of Bulk Strings or Array as specified later.</li>\n</ul>\n<p>In RESP different parts of the protocol are always terminated with “\\r\\n” (CRLF).</p>\n<p>google翻译了下，有点奇怪，但是也能理解，其实就是分别对String、error、整形、字符串、数组设置对应的标识</p>\n<ul>\n<li>对于简单字符串，答复的第一个字节为“ +”</li>\n<li>对于错误，回复的第一个字节为“-”</li>\n<li>对于整数，答复的第一个字节为“：”</li>\n<li>对于批量字符串，答复的第一个字节为“ $”</li>\n<li>对于数组，回复的第一个字节为“ *”</li>\n</ul>\n<p>由此解析出：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">*3 传入数组长度为3 </span><br><span class=\"line\">$3 字符串长度3</span><br><span class=\"line\">SET 字符串内容</span><br><span class=\"line\">$4 字符串长度4</span><br><span class=\"line\">test 字符串内容</span><br><span class=\"line\">$3 字符串长度3</span><br><span class=\"line\">abc 字符串内容</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"响应信息获取\"><a href=\"#响应信息获取\" class=\"headerlink\" title=\"响应信息获取\"></a>响应信息获取</h2><p>redis.clients.jedis.Connection#getBulkReply</p>\n<ul>\n<li>redis.clients.jedis.Connection#flush</li>\n<li>redis.clients.jedis.Connection#readProtocolWithCheckingBroken</li>\n<li>读入RedisInputStream中响应写入的信息，而后进行Protocol.read()</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">static</span> Object <span class=\"title\">process</span><span class=\"params\">(<span class=\"keyword\">final</span> RedisInputStream is)</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">final</span> <span class=\"keyword\">byte</span> b = is.readByte();</span><br><span class=\"line\">  <span class=\"keyword\">switch</span> (b) &#123;</span><br><span class=\"line\">  <span class=\"keyword\">case</span> PLUS_BYTE:</span><br><span class=\"line\">    <span class=\"keyword\">return</span> processStatusCodeReply(is);</span><br><span class=\"line\">  <span class=\"keyword\">case</span> DOLLAR_BYTE:</span><br><span class=\"line\">    <span class=\"keyword\">return</span> processBulkReply(is);</span><br><span class=\"line\">  <span class=\"keyword\">case</span> ASTERISK_BYTE:</span><br><span class=\"line\">    <span class=\"keyword\">return</span> processMultiBulkReply(is);</span><br><span class=\"line\">  <span class=\"keyword\">case</span> COLON_BYTE:</span><br><span class=\"line\">    <span class=\"keyword\">return</span> processInteger(is);</span><br><span class=\"line\">  <span class=\"keyword\">case</span> MINUS_BYTE:</span><br><span class=\"line\">    processError(is);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"keyword\">null</span>;</span><br><span class=\"line\">  <span class=\"keyword\">default</span>:</span><br><span class=\"line\">    <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> JedisConnectionException(<span class=\"string\">\"Unknown reply: \"</span> + (<span class=\"keyword\">char</span>) b);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>读第一个字节判断返回的数据是某种RESP协议数据类型。然后以对应的方式进行解析。</p>\n<h1 id=\"redis-clients-jedis-JedisMonitor\"><a href=\"#redis-clients-jedis-JedisMonitor\" class=\"headerlink\" title=\"redis.clients.jedis.JedisMonitor\"></a>redis.clients.jedis.JedisMonitor</h1><p>实现JedisMonitor，监控Redis Client的指令动作，但会大幅降低性能。</p>"},{"title":"GC收集器与算法","date":"2020-05-02T02:00:00.000Z","_content":"\n记录下学习GC的各个收集器以及算法\n\n<!-- more -->\n\n# 如何判断对象可以被回收\n堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。\n\n## 引用计数法\n给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。\n\n这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。\n\n## 可达性分析算法\n这个算法的基本思想就是通过一系列的称为GC Roots的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连的话，则证明此对象是不可用的。\n\n- GC Roots根节点: 类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量等等\n\n![photo-1](/image/jvm/GC/GC_01.jpg)\n\n## finalize()\n即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。\n\n标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。\n\n### 第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。\n当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。\n\n### 第二次标记\n如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象finalize()方法中执行缓慢，或者发生死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。\n\nfinalize()方法是对象脱逃死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象要在finalize()中成功拯救自己----只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。\n\n## 废弃常量\n假如在常量池中存在字符串 \"abc\"，如果当前没有任何String对象引用该字符串常量的话，就说明常量 \"abc\" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\"abc\" 就会被系统清理出常量池。\n\n## 无用的类\n判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是 “无用的类” : \n- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。\n- 加载该类的 ClassLoader 已经被回收。\n- 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。\n\n***\n\n# 垃圾收集算法\n\n![photo-2](/image/jvm/GC/GC_02.jpg)\n\n## 标记-清除算法\n算法分为“标记”和“清除”阶段: 首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。\n\n它是最基础的收集算法，效率也很高，但是会带来两个明显的问题: \n1. 效率问题\n2. 空间问题（标记清除后会产生大量不连续的碎片）\n\n![photo-3](/image/jvm/GC/GC_03.jpg)\n\n## 复制算法\n为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。\n\n![photo-4](/image/jvm/GC/GC_04.jpg)\n\n## 标记-整理算法\n根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一段移动，然后直接清理掉端边界以外的内存。\n\n![photo-5](/image/jvm/GC/GC_05.jpg)\n\n## 分代收集算法\n当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。\n\n比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。\n\n***\n\n# 垃圾收集器\n\n![photo-6](/image/jvm/GC/GC_06.jpg)\n\n## Serial收集器\nSerial（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（\"Stop The World\"），直到它收集结束。\n\n**新生代采用复制算法，老年代采用标记-整理算法。**\n\n![photo-7](/image/jvm/GC/GC_07.jpg)\n\n虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。\n\n但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。\n\n## ParNew收集器\nParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。\n\n**新生代采用复制算法，老年代采用标记-整理算法。**\n\n![photo-8](/image/jvm/GC/GC_08.jpg)\n\n它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。\n\n### 并行和并发概念补充\n- 并行（Parallel） : 指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互场景。\n- 并发（Concurrent）: 指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。适合Web应用。\n\n## Parallel Scavenge收集器\nParallel Scavenge 收集器类似于ParNew 收集器，是Server 模式（内存大于2G，2个cpu）下的默认收集器\n\nParallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。\n\n**新生代采用复制算法，老年代采用标记-整理算法。**\n\n![photo-9](/image/jvm/GC/GC_09.jpg)\n\n## Serial Old收集器\n**Serial收集器的老年代版本**，它同样是一个单线程收集器。它主要有两大用途: 一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。\n\n## Parallel Old收集器\n**Parallel Scavenge收集器的老年代版本**。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。\n\n## CMS收集器\n> CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。\n\n### 执行步骤\n从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤: \n- 初始标记:  暂停所有的其他线程(STW)，并记录下直接与root相连的对象，速度很快 ；\n- 并发标记:  同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。\n- 重新标记:  重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短\n- 并发清除:  开启用户线程，同时GC线程开始对未标记的区域做清扫。\n\n![photo-10](/image/jvm/GC/GC_10.jpg)\n\n### 优点\n并发收集、低停顿\n\n### 缺点\n- 对CPU资源敏感（会和服务抢资源）；\n- 无法处理浮动垃圾(在java业务程序线程与垃圾收集线程并发执行过程中又产生的垃圾，这种浮动垃圾只能等到下一次gc再清理了)；\n- 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。\n\n### 相关参数\n- -XX:+UseConcMarkSweepGC 启用cms \n- -XX:ConcGCThreads:并发的GC线程数（并非STW时间，而是和服务一起执行的线程数）\n- -XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩（减少碎片）\n- -XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次（因压缩非常的消耗时间，所以不能每次FullGC都做）\n- -XX:CMSInitiatingOccupancyFraction:触发FulGC条件（默认是92）\n- -XX:+UseCMSInitiatingOccupancyOnly:是否动态调节\n- -XX:+CMSScavengeBeforeRemark:FullGC之前先做YGC（一般这个参数是打开的）\n- -XX:+CMSClassUnloadingEnabled:启用回收Perm区（jdk1.7及以前）\n\n## G1收集器\n> G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。\n\n![photo-11](/image/jvm/GC/GC_11.jpg)\n\n![photo-12](/image/jvm/GC/GC_12.jpg)\n\n### Region\nG1将Java堆划分为多个大小相等的独立区域（Region），虽保留新生代和老年代的概念，但不再是物理隔阂了，它们都是（可以不连续）Region的集合。\n\n### Humongous\n分配大对象（直接进Humongous区，专门存放短期巨型对象，不用直接进老年代，避免Full GC的大量开销）不会因为无法找到连续空间而提前触发下一次GC。\n\n### 特点\n- 并行与并发: G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。\n- 分代收集: 虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。\n- 空间整合: 与CMS的“标记--清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。\n- 可预测的停顿: 这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内完成垃圾收集。\n\n### 执行步骤\n- 初始标记（initial mark，STW）: 在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。\n- 并发标记（Concurrent Marking）: G1 GC 在整个堆中查找可访问的（存活的）对象。\n- 最终标记（Remark，STW）: 该阶段是 STW 回收，帮助完成标记周期。\n- 筛选回收（Cleanup，STW）: 筛选回收阶段首先对各个Region的回收价值和成本进行排序，**根据用户所期望的GC停顿时间来制定回收计划**，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。\n\n![photo-13](/image/jvm/GC/GC_13.jpg)\n\nG1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率。\n\n### Young GC\n- 新对象进入Eden区\n- 存活对象拷贝到Survivor区\n- 存活时间达到年龄阈值时，对象晋升到Old区\n\n### MixedGC\n- 不是FullGC，回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序)\n- global concurrent marking （全局并发标记）\n    - Initial marking phase: 标记GC Root，STW\n    - Root region scanning phase: 标记存活Region\n    - Concurrent marking phase: 标记存活的对象\n    - Remark phase: 重新标记,STW\n    - Cleanup phase: 部分STW\n\n### 相关参数\n- G1MixedGCLiveThresholdPercent: Old区的region被回收的时候的存活对象占比\n- G1MixedGCCountTarget: 一次global concurrent marking之后，最多执行Mixed GC的次数\n- G1OldCSetRegionThresholdPercent: 一次Mixed GC中能被选入CSet的最多old区的region数量\n\n#### 触发的时机\n- InitiatingHeapOccupancyPercent: 堆占有率达到这个值则触发global concurrent marking，默认45%\n- G1HeapWastePercent: 在global concurrent marking结束之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到了此参数，只有达到了，下次才会发生Mixed GC\n\n***\n\n# 如何选择垃圾收集器\n- 优先调整堆的大小让服务器自己来选择\n- 如果内存小于100M，使用串行收集器\n- 如果是单核，并且没有停顿时间的要求，串行或JVM自己选择\n- 如果允许停顿时间超过1秒，选择并行或者JVM自己选\n- 如果响应时间最重要，并且不能超过1秒，使用并发收集器\n\n下图有连线的可以搭配使用，官方推荐使用G1，因为性能高\n\n![photo-14](/image/jvm/GC/GC_14.jpg)","source":"_posts/GC收集器与算法.md","raw":"---\ntitle: GC收集器与算法\ndate: 2020-05-02 10:00:00\ntags: JVM\ncategories: Java\n---\n\n记录下学习GC的各个收集器以及算法\n\n<!-- more -->\n\n# 如何判断对象可以被回收\n堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。\n\n## 引用计数法\n给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。\n\n这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。\n\n## 可达性分析算法\n这个算法的基本思想就是通过一系列的称为GC Roots的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连的话，则证明此对象是不可用的。\n\n- GC Roots根节点: 类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量等等\n\n![photo-1](/image/jvm/GC/GC_01.jpg)\n\n## finalize()\n即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。\n\n标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。\n\n### 第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。\n当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。\n\n### 第二次标记\n如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象finalize()方法中执行缓慢，或者发生死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。\n\nfinalize()方法是对象脱逃死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象要在finalize()中成功拯救自己----只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。\n\n## 废弃常量\n假如在常量池中存在字符串 \"abc\"，如果当前没有任何String对象引用该字符串常量的话，就说明常量 \"abc\" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，\"abc\" 就会被系统清理出常量池。\n\n## 无用的类\n判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是 “无用的类” : \n- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。\n- 加载该类的 ClassLoader 已经被回收。\n- 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。\n\n***\n\n# 垃圾收集算法\n\n![photo-2](/image/jvm/GC/GC_02.jpg)\n\n## 标记-清除算法\n算法分为“标记”和“清除”阶段: 首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。\n\n它是最基础的收集算法，效率也很高，但是会带来两个明显的问题: \n1. 效率问题\n2. 空间问题（标记清除后会产生大量不连续的碎片）\n\n![photo-3](/image/jvm/GC/GC_03.jpg)\n\n## 复制算法\n为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。\n\n![photo-4](/image/jvm/GC/GC_04.jpg)\n\n## 标记-整理算法\n根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一段移动，然后直接清理掉端边界以外的内存。\n\n![photo-5](/image/jvm/GC/GC_05.jpg)\n\n## 分代收集算法\n当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。\n\n比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。\n\n***\n\n# 垃圾收集器\n\n![photo-6](/image/jvm/GC/GC_06.jpg)\n\n## Serial收集器\nSerial（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（\"Stop The World\"），直到它收集结束。\n\n**新生代采用复制算法，老年代采用标记-整理算法。**\n\n![photo-7](/image/jvm/GC/GC_07.jpg)\n\n虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。\n\n但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。\n\n## ParNew收集器\nParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。\n\n**新生代采用复制算法，老年代采用标记-整理算法。**\n\n![photo-8](/image/jvm/GC/GC_08.jpg)\n\n它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。\n\n### 并行和并发概念补充\n- 并行（Parallel） : 指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互场景。\n- 并发（Concurrent）: 指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。适合Web应用。\n\n## Parallel Scavenge收集器\nParallel Scavenge 收集器类似于ParNew 收集器，是Server 模式（内存大于2G，2个cpu）下的默认收集器\n\nParallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。\n\n**新生代采用复制算法，老年代采用标记-整理算法。**\n\n![photo-9](/image/jvm/GC/GC_09.jpg)\n\n## Serial Old收集器\n**Serial收集器的老年代版本**，它同样是一个单线程收集器。它主要有两大用途: 一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。\n\n## Parallel Old收集器\n**Parallel Scavenge收集器的老年代版本**。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。\n\n## CMS收集器\n> CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。\n\n### 执行步骤\n从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤: \n- 初始标记:  暂停所有的其他线程(STW)，并记录下直接与root相连的对象，速度很快 ；\n- 并发标记:  同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。\n- 重新标记:  重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短\n- 并发清除:  开启用户线程，同时GC线程开始对未标记的区域做清扫。\n\n![photo-10](/image/jvm/GC/GC_10.jpg)\n\n### 优点\n并发收集、低停顿\n\n### 缺点\n- 对CPU资源敏感（会和服务抢资源）；\n- 无法处理浮动垃圾(在java业务程序线程与垃圾收集线程并发执行过程中又产生的垃圾，这种浮动垃圾只能等到下一次gc再清理了)；\n- 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。\n\n### 相关参数\n- -XX:+UseConcMarkSweepGC 启用cms \n- -XX:ConcGCThreads:并发的GC线程数（并非STW时间，而是和服务一起执行的线程数）\n- -XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩（减少碎片）\n- -XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次（因压缩非常的消耗时间，所以不能每次FullGC都做）\n- -XX:CMSInitiatingOccupancyFraction:触发FulGC条件（默认是92）\n- -XX:+UseCMSInitiatingOccupancyOnly:是否动态调节\n- -XX:+CMSScavengeBeforeRemark:FullGC之前先做YGC（一般这个参数是打开的）\n- -XX:+CMSClassUnloadingEnabled:启用回收Perm区（jdk1.7及以前）\n\n## G1收集器\n> G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。\n\n![photo-11](/image/jvm/GC/GC_11.jpg)\n\n![photo-12](/image/jvm/GC/GC_12.jpg)\n\n### Region\nG1将Java堆划分为多个大小相等的独立区域（Region），虽保留新生代和老年代的概念，但不再是物理隔阂了，它们都是（可以不连续）Region的集合。\n\n### Humongous\n分配大对象（直接进Humongous区，专门存放短期巨型对象，不用直接进老年代，避免Full GC的大量开销）不会因为无法找到连续空间而提前触发下一次GC。\n\n### 特点\n- 并行与并发: G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。\n- 分代收集: 虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。\n- 空间整合: 与CMS的“标记--清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。\n- 可预测的停顿: 这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内完成垃圾收集。\n\n### 执行步骤\n- 初始标记（initial mark，STW）: 在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。\n- 并发标记（Concurrent Marking）: G1 GC 在整个堆中查找可访问的（存活的）对象。\n- 最终标记（Remark，STW）: 该阶段是 STW 回收，帮助完成标记周期。\n- 筛选回收（Cleanup，STW）: 筛选回收阶段首先对各个Region的回收价值和成本进行排序，**根据用户所期望的GC停顿时间来制定回收计划**，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。\n\n![photo-13](/image/jvm/GC/GC_13.jpg)\n\nG1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率。\n\n### Young GC\n- 新对象进入Eden区\n- 存活对象拷贝到Survivor区\n- 存活时间达到年龄阈值时，对象晋升到Old区\n\n### MixedGC\n- 不是FullGC，回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序)\n- global concurrent marking （全局并发标记）\n    - Initial marking phase: 标记GC Root，STW\n    - Root region scanning phase: 标记存活Region\n    - Concurrent marking phase: 标记存活的对象\n    - Remark phase: 重新标记,STW\n    - Cleanup phase: 部分STW\n\n### 相关参数\n- G1MixedGCLiveThresholdPercent: Old区的region被回收的时候的存活对象占比\n- G1MixedGCCountTarget: 一次global concurrent marking之后，最多执行Mixed GC的次数\n- G1OldCSetRegionThresholdPercent: 一次Mixed GC中能被选入CSet的最多old区的region数量\n\n#### 触发的时机\n- InitiatingHeapOccupancyPercent: 堆占有率达到这个值则触发global concurrent marking，默认45%\n- G1HeapWastePercent: 在global concurrent marking结束之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到了此参数，只有达到了，下次才会发生Mixed GC\n\n***\n\n# 如何选择垃圾收集器\n- 优先调整堆的大小让服务器自己来选择\n- 如果内存小于100M，使用串行收集器\n- 如果是单核，并且没有停顿时间的要求，串行或JVM自己选择\n- 如果允许停顿时间超过1秒，选择并行或者JVM自己选\n- 如果响应时间最重要，并且不能超过1秒，使用并发收集器\n\n下图有连线的可以搭配使用，官方推荐使用G1，因为性能高\n\n![photo-14](/image/jvm/GC/GC_14.jpg)","slug":"GC收集器与算法","published":1,"updated":"2020-05-20T16:04:57.505Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl6o005dqotnmu1746tw","content":"<p>记录下学习GC的各个收集器以及算法</p>\n<a id=\"more\"></a>\n<h1 id=\"如何判断对象可以被回收\"><a href=\"#如何判断对象可以被回收\" class=\"headerlink\" title=\"如何判断对象可以被回收\"></a>如何判断对象可以被回收</h1><p>堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。</p>\n<h2 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a>引用计数法</h2><p>给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。</p>\n<p>这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。</p>\n<h2 id=\"可达性分析算法\"><a href=\"#可达性分析算法\" class=\"headerlink\" title=\"可达性分析算法\"></a>可达性分析算法</h2><p>这个算法的基本思想就是通过一系列的称为GC Roots的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连的话，则证明此对象是不可用的。</p>\n<ul>\n<li>GC Roots根节点: 类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量等等</li>\n</ul>\n<p><img src=\"/image/jvm/GC/GC_01.jpg\" alt=\"photo-1\"></p>\n<h2 id=\"finalize\"><a href=\"#finalize\" class=\"headerlink\" title=\"finalize()\"></a>finalize()</h2><p>即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。</p>\n<p>标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。</p>\n<h3 id=\"第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize-方法。\"><a href=\"#第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize-方法。\" class=\"headerlink\" title=\"第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。\"></a>第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。</h3><p>当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。</p>\n<h3 id=\"第二次标记\"><a href=\"#第二次标记\" class=\"headerlink\" title=\"第二次标记\"></a>第二次标记</h3><p>如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象finalize()方法中执行缓慢，或者发生死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。</p>\n<p>finalize()方法是对象脱逃死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象要在finalize()中成功拯救自己—-只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。</p>\n<h2 id=\"废弃常量\"><a href=\"#废弃常量\" class=\"headerlink\" title=\"废弃常量\"></a>废弃常量</h2><p>假如在常量池中存在字符串 “abc”，如果当前没有任何String对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池。</p>\n<h2 id=\"无用的类\"><a href=\"#无用的类\" class=\"headerlink\" title=\"无用的类\"></a>无用的类</h2><p>判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是 “无用的类” : </p>\n<ul>\n<li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li>\n<li>加载该类的 ClassLoader 已经被回收。</li>\n<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li>\n</ul>\n<p>虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。</p>\n<hr>\n<h1 id=\"垃圾收集算法\"><a href=\"#垃圾收集算法\" class=\"headerlink\" title=\"垃圾收集算法\"></a>垃圾收集算法</h1><p><img src=\"/image/jvm/GC/GC_02.jpg\" alt=\"photo-2\"></p>\n<h2 id=\"标记-清除算法\"><a href=\"#标记-清除算法\" class=\"headerlink\" title=\"标记-清除算法\"></a>标记-清除算法</h2><p>算法分为“标记”和“清除”阶段: 首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。</p>\n<p>它是最基础的收集算法，效率也很高，但是会带来两个明显的问题: </p>\n<ol>\n<li>效率问题</li>\n<li>空间问题（标记清除后会产生大量不连续的碎片）</li>\n</ol>\n<p><img src=\"/image/jvm/GC/GC_03.jpg\" alt=\"photo-3\"></p>\n<h2 id=\"复制算法\"><a href=\"#复制算法\" class=\"headerlink\" title=\"复制算法\"></a>复制算法</h2><p>为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。</p>\n<p><img src=\"/image/jvm/GC/GC_04.jpg\" alt=\"photo-4\"></p>\n<h2 id=\"标记-整理算法\"><a href=\"#标记-整理算法\" class=\"headerlink\" title=\"标记-整理算法\"></a>标记-整理算法</h2><p>根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一段移动，然后直接清理掉端边界以外的内存。</p>\n<p><img src=\"/image/jvm/GC/GC_05.jpg\" alt=\"photo-5\"></p>\n<h2 id=\"分代收集算法\"><a href=\"#分代收集算法\" class=\"headerlink\" title=\"分代收集算法\"></a>分代收集算法</h2><p>当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。</p>\n<p>比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。</p>\n<hr>\n<h1 id=\"垃圾收集器\"><a href=\"#垃圾收集器\" class=\"headerlink\" title=\"垃圾收集器\"></a>垃圾收集器</h1><p><img src=\"/image/jvm/GC/GC_06.jpg\" alt=\"photo-6\"></p>\n<h2 id=\"Serial收集器\"><a href=\"#Serial收集器\" class=\"headerlink\" title=\"Serial收集器\"></a>Serial收集器</h2><p>Serial（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（”Stop The World”），直到它收集结束。</p>\n<p><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"/image/jvm/GC/GC_07.jpg\" alt=\"photo-7\"></p>\n<p>虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。</p>\n<p>但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。</p>\n<h2 id=\"ParNew收集器\"><a href=\"#ParNew收集器\" class=\"headerlink\" title=\"ParNew收集器\"></a>ParNew收集器</h2><p>ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。</p>\n<p><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"/image/jvm/GC/GC_08.jpg\" alt=\"photo-8\"></p>\n<p>它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。</p>\n<h3 id=\"并行和并发概念补充\"><a href=\"#并行和并发概念补充\" class=\"headerlink\" title=\"并行和并发概念补充\"></a>并行和并发概念补充</h3><ul>\n<li>并行（Parallel） : 指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互场景。</li>\n<li>并发（Concurrent）: 指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。适合Web应用。</li>\n</ul>\n<h2 id=\"Parallel-Scavenge收集器\"><a href=\"#Parallel-Scavenge收集器\" class=\"headerlink\" title=\"Parallel Scavenge收集器\"></a>Parallel Scavenge收集器</h2><p>Parallel Scavenge 收集器类似于ParNew 收集器，是Server 模式（内存大于2G，2个cpu）下的默认收集器</p>\n<p>Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。</p>\n<p><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"/image/jvm/GC/GC_09.jpg\" alt=\"photo-9\"></p>\n<h2 id=\"Serial-Old收集器\"><a href=\"#Serial-Old收集器\" class=\"headerlink\" title=\"Serial Old收集器\"></a>Serial Old收集器</h2><p><strong>Serial收集器的老年代版本</strong>，它同样是一个单线程收集器。它主要有两大用途: 一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。</p>\n<h2 id=\"Parallel-Old收集器\"><a href=\"#Parallel-Old收集器\" class=\"headerlink\" title=\"Parallel Old收集器\"></a>Parallel Old收集器</h2><p><strong>Parallel Scavenge收集器的老年代版本</strong>。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。</p>\n<h2 id=\"CMS收集器\"><a href=\"#CMS收集器\" class=\"headerlink\" title=\"CMS收集器\"></a>CMS收集器</h2><blockquote>\n<p>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。</p>\n</blockquote>\n<h3 id=\"执行步骤\"><a href=\"#执行步骤\" class=\"headerlink\" title=\"执行步骤\"></a>执行步骤</h3><p>从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤: </p>\n<ul>\n<li>初始标记:  暂停所有的其他线程(STW)，并记录下直接与root相连的对象，速度很快 ；</li>\n<li>并发标记:  同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。</li>\n<li>重新标记:  重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短</li>\n<li>并发清除:  开启用户线程，同时GC线程开始对未标记的区域做清扫。</li>\n</ul>\n<p><img src=\"/image/jvm/GC/GC_10.jpg\" alt=\"photo-10\"></p>\n<h3 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h3><p>并发收集、低停顿</p>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><ul>\n<li>对CPU资源敏感（会和服务抢资源）；</li>\n<li>无法处理浮动垃圾(在java业务程序线程与垃圾收集线程并发执行过程中又产生的垃圾，这种浮动垃圾只能等到下一次gc再清理了)；</li>\n<li>它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。</li>\n</ul>\n<h3 id=\"相关参数\"><a href=\"#相关参数\" class=\"headerlink\" title=\"相关参数\"></a>相关参数</h3><ul>\n<li>-XX:+UseConcMarkSweepGC 启用cms </li>\n<li>-XX:ConcGCThreads:并发的GC线程数（并非STW时间，而是和服务一起执行的线程数）</li>\n<li>-XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩（减少碎片）</li>\n<li>-XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次（因压缩非常的消耗时间，所以不能每次FullGC都做）</li>\n<li>-XX:CMSInitiatingOccupancyFraction:触发FulGC条件（默认是92）</li>\n<li>-XX:+UseCMSInitiatingOccupancyOnly:是否动态调节</li>\n<li>-XX:+CMSScavengeBeforeRemark:FullGC之前先做YGC（一般这个参数是打开的）</li>\n<li>-XX:+CMSClassUnloadingEnabled:启用回收Perm区（jdk1.7及以前）</li>\n</ul>\n<h2 id=\"G1收集器\"><a href=\"#G1收集器\" class=\"headerlink\" title=\"G1收集器\"></a>G1收集器</h2><blockquote>\n<p>G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。</p>\n</blockquote>\n<p><img src=\"/image/jvm/GC/GC_11.jpg\" alt=\"photo-11\"></p>\n<p><img src=\"/image/jvm/GC/GC_12.jpg\" alt=\"photo-12\"></p>\n<h3 id=\"Region\"><a href=\"#Region\" class=\"headerlink\" title=\"Region\"></a>Region</h3><p>G1将Java堆划分为多个大小相等的独立区域（Region），虽保留新生代和老年代的概念，但不再是物理隔阂了，它们都是（可以不连续）Region的集合。</p>\n<h3 id=\"Humongous\"><a href=\"#Humongous\" class=\"headerlink\" title=\"Humongous\"></a>Humongous</h3><p>分配大对象（直接进Humongous区，专门存放短期巨型对象，不用直接进老年代，避免Full GC的大量开销）不会因为无法找到连续空间而提前触发下一次GC。</p>\n<h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>并行与并发: G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。</li>\n<li>分代收集: 虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。</li>\n<li>空间整合: 与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。</li>\n<li>可预测的停顿: 这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内完成垃圾收集。</li>\n</ul>\n<h3 id=\"执行步骤-1\"><a href=\"#执行步骤-1\" class=\"headerlink\" title=\"执行步骤\"></a>执行步骤</h3><ul>\n<li>初始标记（initial mark，STW）: 在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。</li>\n<li>并发标记（Concurrent Marking）: G1 GC 在整个堆中查找可访问的（存活的）对象。</li>\n<li>最终标记（Remark，STW）: 该阶段是 STW 回收，帮助完成标记周期。</li>\n<li>筛选回收（Cleanup，STW）: 筛选回收阶段首先对各个Region的回收价值和成本进行排序，<strong>根据用户所期望的GC停顿时间来制定回收计划</strong>，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。</li>\n</ul>\n<p><img src=\"/image/jvm/GC/GC_13.jpg\" alt=\"photo-13\"></p>\n<p>G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率。</p>\n<h3 id=\"Young-GC\"><a href=\"#Young-GC\" class=\"headerlink\" title=\"Young GC\"></a>Young GC</h3><ul>\n<li>新对象进入Eden区</li>\n<li>存活对象拷贝到Survivor区</li>\n<li>存活时间达到年龄阈值时，对象晋升到Old区</li>\n</ul>\n<h3 id=\"MixedGC\"><a href=\"#MixedGC\" class=\"headerlink\" title=\"MixedGC\"></a>MixedGC</h3><ul>\n<li>不是FullGC，回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序)</li>\n<li>global concurrent marking （全局并发标记）<ul>\n<li>Initial marking phase: 标记GC Root，STW</li>\n<li>Root region scanning phase: 标记存活Region</li>\n<li>Concurrent marking phase: 标记存活的对象</li>\n<li>Remark phase: 重新标记,STW</li>\n<li>Cleanup phase: 部分STW</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"相关参数-1\"><a href=\"#相关参数-1\" class=\"headerlink\" title=\"相关参数\"></a>相关参数</h3><ul>\n<li>G1MixedGCLiveThresholdPercent: Old区的region被回收的时候的存活对象占比</li>\n<li>G1MixedGCCountTarget: 一次global concurrent marking之后，最多执行Mixed GC的次数</li>\n<li>G1OldCSetRegionThresholdPercent: 一次Mixed GC中能被选入CSet的最多old区的region数量</li>\n</ul>\n<h4 id=\"触发的时机\"><a href=\"#触发的时机\" class=\"headerlink\" title=\"触发的时机\"></a>触发的时机</h4><ul>\n<li>InitiatingHeapOccupancyPercent: 堆占有率达到这个值则触发global concurrent marking，默认45%</li>\n<li>G1HeapWastePercent: 在global concurrent marking结束之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到了此参数，只有达到了，下次才会发生Mixed GC</li>\n</ul>\n<hr>\n<h1 id=\"如何选择垃圾收集器\"><a href=\"#如何选择垃圾收集器\" class=\"headerlink\" title=\"如何选择垃圾收集器\"></a>如何选择垃圾收集器</h1><ul>\n<li>优先调整堆的大小让服务器自己来选择</li>\n<li>如果内存小于100M，使用串行收集器</li>\n<li>如果是单核，并且没有停顿时间的要求，串行或JVM自己选择</li>\n<li>如果允许停顿时间超过1秒，选择并行或者JVM自己选</li>\n<li>如果响应时间最重要，并且不能超过1秒，使用并发收集器</li>\n</ul>\n<p>下图有连线的可以搭配使用，官方推荐使用G1，因为性能高</p>\n<p><img src=\"/image/jvm/GC/GC_14.jpg\" alt=\"photo-14\"></p>\n","site":{"data":{}},"excerpt":"<p>记录下学习GC的各个收集器以及算法</p>","more":"<h1 id=\"如何判断对象可以被回收\"><a href=\"#如何判断对象可以被回收\" class=\"headerlink\" title=\"如何判断对象可以被回收\"></a>如何判断对象可以被回收</h1><p>堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象）。</p>\n<h2 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a>引用计数法</h2><p>给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。</p>\n<p>这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算法无法通知 GC 回收器回收他们。</p>\n<h2 id=\"可达性分析算法\"><a href=\"#可达性分析算法\" class=\"headerlink\" title=\"可达性分析算法\"></a>可达性分析算法</h2><p>这个算法的基本思想就是通过一系列的称为GC Roots的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连的话，则证明此对象是不可用的。</p>\n<ul>\n<li>GC Roots根节点: 类加载器、Thread、虚拟机栈的本地变量表、static成员、常量引用、本地方法栈的变量等等</li>\n</ul>\n<p><img src=\"/image/jvm/GC/GC_01.jpg\" alt=\"photo-1\"></p>\n<h2 id=\"finalize\"><a href=\"#finalize\" class=\"headerlink\" title=\"finalize()\"></a>finalize()</h2><p>即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。</p>\n<p>标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。</p>\n<h3 id=\"第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize-方法。\"><a href=\"#第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize-方法。\" class=\"headerlink\" title=\"第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。\"></a>第一次标记并进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。</h3><p>当对象没有覆盖finalize方法，或者finzlize方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”，对象被回收。</p>\n<h3 id=\"第二次标记\"><a href=\"#第二次标记\" class=\"headerlink\" title=\"第二次标记\"></a>第二次标记</h3><p>如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会被放置在一个名为F-Queue的队列之中，并在稍后由一条虚拟机自动建立的、低优先级的Finalizer线程去执行。这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束。这样做的原因是，如果一个对象finalize()方法中执行缓慢，或者发生死循环（更极端的情况），将很可能会导致F-Queue队列中的其他对象永久处于等待状态，甚至导致整个内存回收系统崩溃。</p>\n<p>finalize()方法是对象脱逃死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象要在finalize()中成功拯救自己—-只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。</p>\n<h2 id=\"废弃常量\"><a href=\"#废弃常量\" class=\"headerlink\" title=\"废弃常量\"></a>废弃常量</h2><p>假如在常量池中存在字符串 “abc”，如果当前没有任何String对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池。</p>\n<h2 id=\"无用的类\"><a href=\"#无用的类\" class=\"headerlink\" title=\"无用的类\"></a>无用的类</h2><p>判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是 “无用的类” : </p>\n<ul>\n<li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li>\n<li>加载该类的 ClassLoader 已经被回收。</li>\n<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li>\n</ul>\n<p>虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。</p>\n<hr>\n<h1 id=\"垃圾收集算法\"><a href=\"#垃圾收集算法\" class=\"headerlink\" title=\"垃圾收集算法\"></a>垃圾收集算法</h1><p><img src=\"/image/jvm/GC/GC_02.jpg\" alt=\"photo-2\"></p>\n<h2 id=\"标记-清除算法\"><a href=\"#标记-清除算法\" class=\"headerlink\" title=\"标记-清除算法\"></a>标记-清除算法</h2><p>算法分为“标记”和“清除”阶段: 首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。</p>\n<p>它是最基础的收集算法，效率也很高，但是会带来两个明显的问题: </p>\n<ol>\n<li>效率问题</li>\n<li>空间问题（标记清除后会产生大量不连续的碎片）</li>\n</ol>\n<p><img src=\"/image/jvm/GC/GC_03.jpg\" alt=\"photo-3\"></p>\n<h2 id=\"复制算法\"><a href=\"#复制算法\" class=\"headerlink\" title=\"复制算法\"></a>复制算法</h2><p>为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。</p>\n<p><img src=\"/image/jvm/GC/GC_04.jpg\" alt=\"photo-4\"></p>\n<h2 id=\"标记-整理算法\"><a href=\"#标记-整理算法\" class=\"headerlink\" title=\"标记-整理算法\"></a>标记-整理算法</h2><p>根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一段移动，然后直接清理掉端边界以外的内存。</p>\n<p><img src=\"/image/jvm/GC/GC_05.jpg\" alt=\"photo-5\"></p>\n<h2 id=\"分代收集算法\"><a href=\"#分代收集算法\" class=\"headerlink\" title=\"分代收集算法\"></a>分代收集算法</h2><p>当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。</p>\n<p>比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。</p>\n<hr>\n<h1 id=\"垃圾收集器\"><a href=\"#垃圾收集器\" class=\"headerlink\" title=\"垃圾收集器\"></a>垃圾收集器</h1><p><img src=\"/image/jvm/GC/GC_06.jpg\" alt=\"photo-6\"></p>\n<h2 id=\"Serial收集器\"><a href=\"#Serial收集器\" class=\"headerlink\" title=\"Serial收集器\"></a>Serial收集器</h2><p>Serial（串行）收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（”Stop The World”），直到它收集结束。</p>\n<p><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"/image/jvm/GC/GC_07.jpg\" alt=\"photo-7\"></p>\n<p>虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续）。</p>\n<p>但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。</p>\n<h2 id=\"ParNew收集器\"><a href=\"#ParNew收集器\" class=\"headerlink\" title=\"ParNew收集器\"></a>ParNew收集器</h2><p>ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。</p>\n<p><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"/image/jvm/GC/GC_08.jpg\" alt=\"photo-8\"></p>\n<p>它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作。</p>\n<h3 id=\"并行和并发概念补充\"><a href=\"#并行和并发概念补充\" class=\"headerlink\" title=\"并行和并发概念补充\"></a>并行和并发概念补充</h3><ul>\n<li>并行（Parallel） : 指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。适合科学计算、后台处理等弱交互场景。</li>\n<li>并发（Concurrent）: 指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。适合Web应用。</li>\n</ul>\n<h2 id=\"Parallel-Scavenge收集器\"><a href=\"#Parallel-Scavenge收集器\" class=\"headerlink\" title=\"Parallel Scavenge收集器\"></a>Parallel Scavenge收集器</h2><p>Parallel Scavenge 收集器类似于ParNew 收集器，是Server 模式（内存大于2G，2个cpu）下的默认收集器</p>\n<p>Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。</p>\n<p><strong>新生代采用复制算法，老年代采用标记-整理算法。</strong></p>\n<p><img src=\"/image/jvm/GC/GC_09.jpg\" alt=\"photo-9\"></p>\n<h2 id=\"Serial-Old收集器\"><a href=\"#Serial-Old收集器\" class=\"headerlink\" title=\"Serial Old收集器\"></a>Serial Old收集器</h2><p><strong>Serial收集器的老年代版本</strong>，它同样是一个单线程收集器。它主要有两大用途: 一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。</p>\n<h2 id=\"Parallel-Old收集器\"><a href=\"#Parallel-Old收集器\" class=\"headerlink\" title=\"Parallel Old收集器\"></a>Parallel Old收集器</h2><p><strong>Parallel Scavenge收集器的老年代版本</strong>。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器。</p>\n<h2 id=\"CMS收集器\"><a href=\"#CMS收集器\" class=\"headerlink\" title=\"CMS收集器\"></a>CMS收集器</h2><blockquote>\n<p>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它而非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。</p>\n</blockquote>\n<h3 id=\"执行步骤\"><a href=\"#执行步骤\" class=\"headerlink\" title=\"执行步骤\"></a>执行步骤</h3><p>从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤: </p>\n<ul>\n<li>初始标记:  暂停所有的其他线程(STW)，并记录下直接与root相连的对象，速度很快 ；</li>\n<li>并发标记:  同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。</li>\n<li>重新标记:  重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短</li>\n<li>并发清除:  开启用户线程，同时GC线程开始对未标记的区域做清扫。</li>\n</ul>\n<p><img src=\"/image/jvm/GC/GC_10.jpg\" alt=\"photo-10\"></p>\n<h3 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h3><p>并发收集、低停顿</p>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><ul>\n<li>对CPU资源敏感（会和服务抢资源）；</li>\n<li>无法处理浮动垃圾(在java业务程序线程与垃圾收集线程并发执行过程中又产生的垃圾，这种浮动垃圾只能等到下一次gc再清理了)；</li>\n<li>它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。</li>\n</ul>\n<h3 id=\"相关参数\"><a href=\"#相关参数\" class=\"headerlink\" title=\"相关参数\"></a>相关参数</h3><ul>\n<li>-XX:+UseConcMarkSweepGC 启用cms </li>\n<li>-XX:ConcGCThreads:并发的GC线程数（并非STW时间，而是和服务一起执行的线程数）</li>\n<li>-XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩（减少碎片）</li>\n<li>-XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次（因压缩非常的消耗时间，所以不能每次FullGC都做）</li>\n<li>-XX:CMSInitiatingOccupancyFraction:触发FulGC条件（默认是92）</li>\n<li>-XX:+UseCMSInitiatingOccupancyOnly:是否动态调节</li>\n<li>-XX:+CMSScavengeBeforeRemark:FullGC之前先做YGC（一般这个参数是打开的）</li>\n<li>-XX:+CMSClassUnloadingEnabled:启用回收Perm区（jdk1.7及以前）</li>\n</ul>\n<h2 id=\"G1收集器\"><a href=\"#G1收集器\" class=\"headerlink\" title=\"G1收集器\"></a>G1收集器</h2><blockquote>\n<p>G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。</p>\n</blockquote>\n<p><img src=\"/image/jvm/GC/GC_11.jpg\" alt=\"photo-11\"></p>\n<p><img src=\"/image/jvm/GC/GC_12.jpg\" alt=\"photo-12\"></p>\n<h3 id=\"Region\"><a href=\"#Region\" class=\"headerlink\" title=\"Region\"></a>Region</h3><p>G1将Java堆划分为多个大小相等的独立区域（Region），虽保留新生代和老年代的概念，但不再是物理隔阂了，它们都是（可以不连续）Region的集合。</p>\n<h3 id=\"Humongous\"><a href=\"#Humongous\" class=\"headerlink\" title=\"Humongous\"></a>Humongous</h3><p>分配大对象（直接进Humongous区，专门存放短期巨型对象，不用直接进老年代，避免Full GC的大量开销）不会因为无法找到连续空间而提前触发下一次GC。</p>\n<h3 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h3><ul>\n<li>并行与并发: G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。</li>\n<li>分代收集: 虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。</li>\n<li>空间整合: 与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。</li>\n<li>可预测的停顿: 这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS 共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内完成垃圾收集。</li>\n</ul>\n<h3 id=\"执行步骤-1\"><a href=\"#执行步骤-1\" class=\"headerlink\" title=\"执行步骤\"></a>执行步骤</h3><ul>\n<li>初始标记（initial mark，STW）: 在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。</li>\n<li>并发标记（Concurrent Marking）: G1 GC 在整个堆中查找可访问的（存活的）对象。</li>\n<li>最终标记（Remark，STW）: 该阶段是 STW 回收，帮助完成标记周期。</li>\n<li>筛选回收（Cleanup，STW）: 筛选回收阶段首先对各个Region的回收价值和成本进行排序，<strong>根据用户所期望的GC停顿时间来制定回收计划</strong>，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。</li>\n</ul>\n<p><img src=\"/image/jvm/GC/GC_13.jpg\" alt=\"photo-13\"></p>\n<p>G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了GF收集器在有限时间内可以尽可能高的收集效率。</p>\n<h3 id=\"Young-GC\"><a href=\"#Young-GC\" class=\"headerlink\" title=\"Young GC\"></a>Young GC</h3><ul>\n<li>新对象进入Eden区</li>\n<li>存活对象拷贝到Survivor区</li>\n<li>存活时间达到年龄阈值时，对象晋升到Old区</li>\n</ul>\n<h3 id=\"MixedGC\"><a href=\"#MixedGC\" class=\"headerlink\" title=\"MixedGC\"></a>MixedGC</h3><ul>\n<li>不是FullGC，回收所有的Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序)</li>\n<li>global concurrent marking （全局并发标记）<ul>\n<li>Initial marking phase: 标记GC Root，STW</li>\n<li>Root region scanning phase: 标记存活Region</li>\n<li>Concurrent marking phase: 标记存活的对象</li>\n<li>Remark phase: 重新标记,STW</li>\n<li>Cleanup phase: 部分STW</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"相关参数-1\"><a href=\"#相关参数-1\" class=\"headerlink\" title=\"相关参数\"></a>相关参数</h3><ul>\n<li>G1MixedGCLiveThresholdPercent: Old区的region被回收的时候的存活对象占比</li>\n<li>G1MixedGCCountTarget: 一次global concurrent marking之后，最多执行Mixed GC的次数</li>\n<li>G1OldCSetRegionThresholdPercent: 一次Mixed GC中能被选入CSet的最多old区的region数量</li>\n</ul>\n<h4 id=\"触发的时机\"><a href=\"#触发的时机\" class=\"headerlink\" title=\"触发的时机\"></a>触发的时机</h4><ul>\n<li>InitiatingHeapOccupancyPercent: 堆占有率达到这个值则触发global concurrent marking，默认45%</li>\n<li>G1HeapWastePercent: 在global concurrent marking结束之后，可以知道区有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到了此参数，只有达到了，下次才会发生Mixed GC</li>\n</ul>\n<hr>\n<h1 id=\"如何选择垃圾收集器\"><a href=\"#如何选择垃圾收集器\" class=\"headerlink\" title=\"如何选择垃圾收集器\"></a>如何选择垃圾收集器</h1><ul>\n<li>优先调整堆的大小让服务器自己来选择</li>\n<li>如果内存小于100M，使用串行收集器</li>\n<li>如果是单核，并且没有停顿时间的要求，串行或JVM自己选择</li>\n<li>如果允许停顿时间超过1秒，选择并行或者JVM自己选</li>\n<li>如果响应时间最重要，并且不能超过1秒，使用并发收集器</li>\n</ul>\n<p>下图有连线的可以搭配使用，官方推荐使用G1，因为性能高</p>\n<p><img src=\"/image/jvm/GC/GC_14.jpg\" alt=\"photo-14\"></p>"},{"title":"rabbitMQ知识点整理","date":"2020-02-08T02:00:00.000Z","_content":"\n重新温习了AMQP协议以及rabbitMQ的知识点，做下记录。基础的东西就不记了，就记录一些关键的知识点。\n<!-- more -->\n\n# channel(信道)的两种模式\n## confirm模式\nchannel设置成confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。\n\nconfirm模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。\n\n在channel被设置成confirm模式之后，所有被publish的后续消息都将被confirm（即ack）或者被nack一次。但是没有对消息被confirm的快慢做任何保证，并且同一条消息不会同时被confirm和nack 。\n\n### 如何开启confirm模式\n调用channel的confirmSelect方法将channel设置为confirm模式，如果没有设置no-wait标志的话，broker会返回confirm.select-ok表示同意发送者将当前channel信道设置为confirm模式(从目前RabbitMQ最新版本3.6来看，如果调用了channel.confirmSelect方法，默认情况下是直接将no-wait设置成false的，也就是默认情况下broker是必须回传confirm.select-ok的)。\n\n### 异步confirm模式\nChannel对象提供的ConfirmListener()回调方法只包含deliveryTag（当前Chanel发出的消息序号），我们需要自己为每一个Channel维护一个unconfirm的消息序号集合，每publish一条数据，集合中元素加1，每回调一次handleAck方法，unconfirm集合删掉相应的一条（multiple=false）或多条（multiple=true）记录。从程序运行效率上看，这个unconfirm集合最好采用有序集合SortedSet存储结构。实际上，SDK中的waitForConfirms()方法也是通过SortedSet维护消息序号的。\n\n## transaction模式\n提供的三个方法\n- txSelect() 打开事务\n- tCommit() 提交事务\n- txRollback() 回滚事务\n\n通过txSelect开启事务之后，便可以发布消息给broker代理服务器了，如果txCommit提交成功，则消息一定到达了broker，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务。\n\n采用事务机制实现会降低RabbitMQ的消息吞吐量，且不符合消息中间件异步解耦的特性。\n\n\n# Message Acknowledgement(ACK)\n用于保证消息从队列中可靠的发送给订阅者，即消息回执。\n\nrabbitMQ在声明消费者的时候可以设置autoAck。\n- true: 接收到消息后会自动ack，适用于对于消息吞吐量以及可靠性要求低的场景\n- false: 接收到消息后，需要手动进行ack，适用于对消息可靠性要求较高的场景\n``` java\n/**\n  * Start a non-nolocal, non-exclusive consumer, with\n  * a server-generated consumerTag.\n  * @param queue the name of the queue\n  * @param autoAck true if the server should consider messages\n  * acknowledged once delivered; false if the server should expect\n  * explicit acknowledgements\n  * @param callback an interface to the consumer object\n  * @return the consumerTag generated by the server\n  * @throws java.io.IOException if an error is encountered\n  * @see com.rabbitmq.client.AMQP.Basic.Consume\n  * @see com.rabbitmq.client.AMQP.Basic.ConsumeOk\n  * @see #basicConsume(String, boolean, String, boolean, boolean, Map, Consumer)\n  */\nString basicConsume(String queue, boolean autoAck, Consumer callback) throws IOException;\n```\n\nrabbitMQ提供了以下几个方法\n``` java\n/**\n  * Acknowledge one or several received\n  * messages. Supply the deliveryTag from the {@link com.rabbitmq.client.AMQP.Basic.GetOk}\n  * or {@link com.rabbitmq.client.AMQP.Basic.Deliver} method\n  * containing the received message being acknowledged.\n  * @see com.rabbitmq.client.AMQP.Basic.Ack\n  * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver}\n  * @param multiple true to acknowledge all messages up to and\n  * including the supplied delivery tag; false to acknowledge just\n  * the supplied delivery tag.\n  * @throws java.io.IOException if an error is encountered\n  */\nvoid basicAck(long deliveryTag, boolean multiple) throws IOException;\n\n/**\n  * Reject one or several received messages.\n  *\n  * Supply the <code>deliveryTag</code> from the {@link com.rabbitmq.client.AMQP.Basic.GetOk}\n  * or {@link com.rabbitmq.client.AMQP.Basic.GetOk} method containing the message to be rejected.\n  * @see com.rabbitmq.client.AMQP.Basic.Nack\n  * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver}\n  * @param multiple true to reject all messages up to and including\n  * the supplied delivery tag; false to reject just the supplied\n  * delivery tag.\n  * @param requeue true if the rejected message(s) should be requeued rather\n  * than discarded/dead-lettered\n  * @throws java.io.IOException if an error is encountered\n  */\nvoid basicNack(long deliveryTag, boolean multiple, boolean requeue) throws IOException;\n\n/**\n  * @throws java.io.IOException if an error is encountered\n  * Reject a message. Supply the deliveryTag from the {@link com.rabbitmq.client.AMQP.Basic.GetOk}\n  * or {@link com.rabbitmq.client.AMQP.Basic.Deliver} method\n  * containing the received message being rejected.\n  * @see com.rabbitmq.client.AMQP.Basic.Reject\n  * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver}\n  * @param requeue true if the rejected message should be requeued rather than discarded/dead-lettered\n  */\nvoid basicReject(long deliveryTag, boolean requeue) throws IOException;\n```\n\n# 关于重试\n重试只能是宏观的从组件层面解决问题，如网络问题等，而真正的业务失败应当从业务层面去解决，所以即便是重试也无法解决。\n\n## show me code\n设置autoAck为false，手动实现消息的ack和reject。通过basicNack设置requeue重入队列。，如果失败次数过多则直接reject该消息（默认业务上已经无法处理该消息）。\n\n``` java\npublic void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException {\n    MessageResponse result = MessageResponse.ERROR;\n\n    try {\n        result = this.processor.process(SerializeCode.deSerialize(body, this.processor.getMsgType()));\n    } catch (Exception e) {\n        logger.error(\"\", e);\n    }\n\n    if (null != result && !\"error\".equals(result.getResultMsg())) {\n        logger.info(\"消息 {} 处理成功\", envelope.getDeliveryTag());\n        this.channel.basicAck(envelope.getDeliveryTag(), false);\n        this.retryCount = 0;\n    } else {\n        logger.info(\"消息 {} 处理失败\", envelope.getDeliveryTag());\n        this.dealMessageAck(envelope);\n    }\n\n}\n\nprivate void dealMessageAck(final Envelope envelope) throws IOException {\n    ++this.retryCount;\n    if (this.retryCount < 10) {\n        logger.info(\"消费消息 {} 失败.第{}次 重新放入队列\", envelope.getDeliveryTag(), this.retryCount);\n        this.channel.basicNack(envelope.getDeliveryTag(), false, true);\n    } else {\n        logger.info(\"消费消息 {} 处理失败已经超过10次. 拒绝该消息\", envelope.getDeliveryTag(), this.retryCount);\n        this.channel.basicReject(envelope.getDeliveryTag(), false);\n    }\n\n}\n```\n\n# 持久化\n## exchange和queue的持久化\n``` java\n/**\n  * Actively declare a non-autodelete exchange with no extra arguments\n  * @see com.rabbitmq.client.AMQP.Exchange.Declare\n  * @see com.rabbitmq.client.AMQP.Exchange.DeclareOk\n  * @param exchange the name of the exchange\n  * @param type the exchange type\n  * @param durable true if we are declaring a durable exchange (the exchange will survive a server restart)\n  * @throws java.io.IOException if an error is encountered\n  * @return a declaration-confirm method to indicate the exchange was successfully declared\n  */\nExchange.DeclareOk exchangeDeclare(String exchange, String type, boolean durable) throws IOException;\n\n/**\n  * Declare a queue\n  * @see com.rabbitmq.client.AMQP.Queue.Declare\n  * @see com.rabbitmq.client.AMQP.Queue.DeclareOk\n  * @param queue the name of the queue\n  * @param durable true if we are declaring a durable queue (the queue will survive a server restart)\n  * @param exclusive true if we are declaring an exclusive queue (restricted to this connection)\n  * @param autoDelete true if we are declaring an autodelete queue (server will delete it when no longer in use)\n  * @param arguments other properties (construction arguments) for the queue\n  * @return a declaration-confirm method to indicate the queue was successfully declared\n  * @throws java.io.IOException if an error is encountered\n  */\nQueue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map<String, Object> arguments) throws IOException;\n```\n> @param durable\n- true if we are declaring a durable exchange (the exchange will survive a server restart)\n- true if we are declaring a durable queue (the queue will survive a server restart)\n\n声明exchange和queue的时候就可以设置durable为true进行持久化。\n\n## 消息的持久化\n``` java\n/**\n * Publish a message.\n *\n * Publishing to a non-existent exchange will result in a channel-level\n * protocol exception, which closes the channel.\n *\n * Invocations of <code>Channel#basicPublish</code> will eventually block if a\n * <a href=\"http://www.rabbitmq.com/alarms.html\">resource-driven alarm</a> is in effect.\n *\n * @see com.rabbitmq.client.AMQP.Basic.Publish\n * @see <a href=\"http://www.rabbitmq.com/alarms.html\">Resource-driven alarms</a>\n * @param exchange the exchange to publish the message to\n * @param routingKey the routing key\n * @param props other properties for the message - routing headers etc\n * @param body the message body\n * @throws java.io.IOException if an error is encountered\n */\nvoid basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body) throws IOException;\n```\n\n直接看BasicProperties，有很多属性，但是都没有注释，其实这个有定义一个常量类，com.rabbitmq.client.MessageProperties。\n\n``` java\n// Copyright (c) 2007-Present Pivotal Software, Inc.  All rights reserved.\n//\n// This software, the RabbitMQ Java client library, is triple-licensed under the\n// Mozilla Public License 1.1 (\"MPL\"), the GNU General Public License version 2\n// (\"GPL\") and the Apache License version 2 (\"ASL\"). For the MPL, please see\n// LICENSE-MPL-RabbitMQ. For the GPL, please see LICENSE-GPL2.  For the ASL,\n// please see LICENSE-APACHE2.\n//\n// This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTY OF ANY KIND,\n// either express or implied. See the LICENSE file for specific language governing\n// rights and limitations of this software.\n//\n// If you have any questions regarding licensing, please contact us at\n// info@rabbitmq.com.\n\npackage com.rabbitmq.client;\n\nimport com.rabbitmq.client.AMQP.BasicProperties;\nimport com.rabbitmq.client.impl.AMQContentHeader;\n\n/**\n * Constant holder class with useful static instances of {@link AMQContentHeader}.\n * These are intended for use with {@link Channel#basicPublish} and other Channel methods.\n */\npublic class MessageProperties {\n\n    /** Empty basic properties, with no fields set */\n    public static final BasicProperties MINIMAL_BASIC =\n        new BasicProperties(null, null, null, null,\n                            null, null, null, null,\n                            null, null, null, null,\n                            null, null);\n    /** Empty basic properties, with only deliveryMode set to 2 (persistent) */\n    public static final BasicProperties MINIMAL_PERSISTENT_BASIC =\n        new BasicProperties(null, null, null, 2,\n                            null, null, null, null,\n                            null, null, null, null,\n                            null, null);\n\n    /** Content-type \"application/octet-stream\", deliveryMode 1 (nonpersistent), priority zero */\n    public static final BasicProperties BASIC =\n        new BasicProperties(\"application/octet-stream\",\n                            null,\n                            null,\n                            1,\n                            0, null, null, null,\n                            null, null, null, null,\n                            null, null);\n\n    /** Content-type \"application/octet-stream\", deliveryMode 2 (persistent), priority zero */\n    public static final BasicProperties PERSISTENT_BASIC =\n        new BasicProperties(\"application/octet-stream\",\n                            null,\n                            null,\n                            2,\n                            0, null, null, null,\n                            null, null, null, null,\n                            null, null);\n\n    /** Content-type \"text/plain\", deliveryMode 1 (nonpersistent), priority zero */\n    public static final BasicProperties TEXT_PLAIN =\n        new BasicProperties(\"text/plain\",\n                            null,\n                            null,\n                            1,\n                            0, null, null, null,\n                            null, null, null, null,\n                            null, null);\n\n    /** Content-type \"text/plain\", deliveryMode 2 (persistent), priority zero */\n    public static final BasicProperties PERSISTENT_TEXT_PLAIN =\n        new BasicProperties(\"text/plain\",\n                            null,\n                            null,\n                            2,\n                            0, null, null, null,\n                            null, null, null, null,\n                            null, null);\n}\n```\n- deliveryMode 1 (nonpersistent)\n- deliveryMode 2 (persistent)\n这里就写的，deliveryMode 2就是持久化，所以在需要持久化的时候，这里根据消息的类型使用这个常量就可以，一般是用BasicProperties.PERSISTENT_TEXT_PLAIN。\n\n# 参考资料\n* http://rabbitmq.mr-ping.com/ \n* https://blog.csdn.net/jiao_fuyou/article/details/21594205\n* https://blog.csdn.net/weixin_37641832/article/details/83270778\n* https://honeypps.com/mq/rabbitmq-analysis-of-message-durable/","source":"_posts/rabbitMQ知识点整理.md","raw":"---\ntitle: rabbitMQ知识点整理\ndate: 2020-02-08 10:00:00\ntags: rabbitMQ\ncategories: 中间件\n---\n\n重新温习了AMQP协议以及rabbitMQ的知识点，做下记录。基础的东西就不记了，就记录一些关键的知识点。\n<!-- more -->\n\n# channel(信道)的两种模式\n## confirm模式\nchannel设置成confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。\n\nconfirm模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。\n\n在channel被设置成confirm模式之后，所有被publish的后续消息都将被confirm（即ack）或者被nack一次。但是没有对消息被confirm的快慢做任何保证，并且同一条消息不会同时被confirm和nack 。\n\n### 如何开启confirm模式\n调用channel的confirmSelect方法将channel设置为confirm模式，如果没有设置no-wait标志的话，broker会返回confirm.select-ok表示同意发送者将当前channel信道设置为confirm模式(从目前RabbitMQ最新版本3.6来看，如果调用了channel.confirmSelect方法，默认情况下是直接将no-wait设置成false的，也就是默认情况下broker是必须回传confirm.select-ok的)。\n\n### 异步confirm模式\nChannel对象提供的ConfirmListener()回调方法只包含deliveryTag（当前Chanel发出的消息序号），我们需要自己为每一个Channel维护一个unconfirm的消息序号集合，每publish一条数据，集合中元素加1，每回调一次handleAck方法，unconfirm集合删掉相应的一条（multiple=false）或多条（multiple=true）记录。从程序运行效率上看，这个unconfirm集合最好采用有序集合SortedSet存储结构。实际上，SDK中的waitForConfirms()方法也是通过SortedSet维护消息序号的。\n\n## transaction模式\n提供的三个方法\n- txSelect() 打开事务\n- tCommit() 提交事务\n- txRollback() 回滚事务\n\n通过txSelect开启事务之后，便可以发布消息给broker代理服务器了，如果txCommit提交成功，则消息一定到达了broker，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务。\n\n采用事务机制实现会降低RabbitMQ的消息吞吐量，且不符合消息中间件异步解耦的特性。\n\n\n# Message Acknowledgement(ACK)\n用于保证消息从队列中可靠的发送给订阅者，即消息回执。\n\nrabbitMQ在声明消费者的时候可以设置autoAck。\n- true: 接收到消息后会自动ack，适用于对于消息吞吐量以及可靠性要求低的场景\n- false: 接收到消息后，需要手动进行ack，适用于对消息可靠性要求较高的场景\n``` java\n/**\n  * Start a non-nolocal, non-exclusive consumer, with\n  * a server-generated consumerTag.\n  * @param queue the name of the queue\n  * @param autoAck true if the server should consider messages\n  * acknowledged once delivered; false if the server should expect\n  * explicit acknowledgements\n  * @param callback an interface to the consumer object\n  * @return the consumerTag generated by the server\n  * @throws java.io.IOException if an error is encountered\n  * @see com.rabbitmq.client.AMQP.Basic.Consume\n  * @see com.rabbitmq.client.AMQP.Basic.ConsumeOk\n  * @see #basicConsume(String, boolean, String, boolean, boolean, Map, Consumer)\n  */\nString basicConsume(String queue, boolean autoAck, Consumer callback) throws IOException;\n```\n\nrabbitMQ提供了以下几个方法\n``` java\n/**\n  * Acknowledge one or several received\n  * messages. Supply the deliveryTag from the {@link com.rabbitmq.client.AMQP.Basic.GetOk}\n  * or {@link com.rabbitmq.client.AMQP.Basic.Deliver} method\n  * containing the received message being acknowledged.\n  * @see com.rabbitmq.client.AMQP.Basic.Ack\n  * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver}\n  * @param multiple true to acknowledge all messages up to and\n  * including the supplied delivery tag; false to acknowledge just\n  * the supplied delivery tag.\n  * @throws java.io.IOException if an error is encountered\n  */\nvoid basicAck(long deliveryTag, boolean multiple) throws IOException;\n\n/**\n  * Reject one or several received messages.\n  *\n  * Supply the <code>deliveryTag</code> from the {@link com.rabbitmq.client.AMQP.Basic.GetOk}\n  * or {@link com.rabbitmq.client.AMQP.Basic.GetOk} method containing the message to be rejected.\n  * @see com.rabbitmq.client.AMQP.Basic.Nack\n  * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver}\n  * @param multiple true to reject all messages up to and including\n  * the supplied delivery tag; false to reject just the supplied\n  * delivery tag.\n  * @param requeue true if the rejected message(s) should be requeued rather\n  * than discarded/dead-lettered\n  * @throws java.io.IOException if an error is encountered\n  */\nvoid basicNack(long deliveryTag, boolean multiple, boolean requeue) throws IOException;\n\n/**\n  * @throws java.io.IOException if an error is encountered\n  * Reject a message. Supply the deliveryTag from the {@link com.rabbitmq.client.AMQP.Basic.GetOk}\n  * or {@link com.rabbitmq.client.AMQP.Basic.Deliver} method\n  * containing the received message being rejected.\n  * @see com.rabbitmq.client.AMQP.Basic.Reject\n  * @param deliveryTag the tag from the received {@link com.rabbitmq.client.AMQP.Basic.GetOk} or {@link com.rabbitmq.client.AMQP.Basic.Deliver}\n  * @param requeue true if the rejected message should be requeued rather than discarded/dead-lettered\n  */\nvoid basicReject(long deliveryTag, boolean requeue) throws IOException;\n```\n\n# 关于重试\n重试只能是宏观的从组件层面解决问题，如网络问题等，而真正的业务失败应当从业务层面去解决，所以即便是重试也无法解决。\n\n## show me code\n设置autoAck为false，手动实现消息的ack和reject。通过basicNack设置requeue重入队列。，如果失败次数过多则直接reject该消息（默认业务上已经无法处理该消息）。\n\n``` java\npublic void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException {\n    MessageResponse result = MessageResponse.ERROR;\n\n    try {\n        result = this.processor.process(SerializeCode.deSerialize(body, this.processor.getMsgType()));\n    } catch (Exception e) {\n        logger.error(\"\", e);\n    }\n\n    if (null != result && !\"error\".equals(result.getResultMsg())) {\n        logger.info(\"消息 {} 处理成功\", envelope.getDeliveryTag());\n        this.channel.basicAck(envelope.getDeliveryTag(), false);\n        this.retryCount = 0;\n    } else {\n        logger.info(\"消息 {} 处理失败\", envelope.getDeliveryTag());\n        this.dealMessageAck(envelope);\n    }\n\n}\n\nprivate void dealMessageAck(final Envelope envelope) throws IOException {\n    ++this.retryCount;\n    if (this.retryCount < 10) {\n        logger.info(\"消费消息 {} 失败.第{}次 重新放入队列\", envelope.getDeliveryTag(), this.retryCount);\n        this.channel.basicNack(envelope.getDeliveryTag(), false, true);\n    } else {\n        logger.info(\"消费消息 {} 处理失败已经超过10次. 拒绝该消息\", envelope.getDeliveryTag(), this.retryCount);\n        this.channel.basicReject(envelope.getDeliveryTag(), false);\n    }\n\n}\n```\n\n# 持久化\n## exchange和queue的持久化\n``` java\n/**\n  * Actively declare a non-autodelete exchange with no extra arguments\n  * @see com.rabbitmq.client.AMQP.Exchange.Declare\n  * @see com.rabbitmq.client.AMQP.Exchange.DeclareOk\n  * @param exchange the name of the exchange\n  * @param type the exchange type\n  * @param durable true if we are declaring a durable exchange (the exchange will survive a server restart)\n  * @throws java.io.IOException if an error is encountered\n  * @return a declaration-confirm method to indicate the exchange was successfully declared\n  */\nExchange.DeclareOk exchangeDeclare(String exchange, String type, boolean durable) throws IOException;\n\n/**\n  * Declare a queue\n  * @see com.rabbitmq.client.AMQP.Queue.Declare\n  * @see com.rabbitmq.client.AMQP.Queue.DeclareOk\n  * @param queue the name of the queue\n  * @param durable true if we are declaring a durable queue (the queue will survive a server restart)\n  * @param exclusive true if we are declaring an exclusive queue (restricted to this connection)\n  * @param autoDelete true if we are declaring an autodelete queue (server will delete it when no longer in use)\n  * @param arguments other properties (construction arguments) for the queue\n  * @return a declaration-confirm method to indicate the queue was successfully declared\n  * @throws java.io.IOException if an error is encountered\n  */\nQueue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map<String, Object> arguments) throws IOException;\n```\n> @param durable\n- true if we are declaring a durable exchange (the exchange will survive a server restart)\n- true if we are declaring a durable queue (the queue will survive a server restart)\n\n声明exchange和queue的时候就可以设置durable为true进行持久化。\n\n## 消息的持久化\n``` java\n/**\n * Publish a message.\n *\n * Publishing to a non-existent exchange will result in a channel-level\n * protocol exception, which closes the channel.\n *\n * Invocations of <code>Channel#basicPublish</code> will eventually block if a\n * <a href=\"http://www.rabbitmq.com/alarms.html\">resource-driven alarm</a> is in effect.\n *\n * @see com.rabbitmq.client.AMQP.Basic.Publish\n * @see <a href=\"http://www.rabbitmq.com/alarms.html\">Resource-driven alarms</a>\n * @param exchange the exchange to publish the message to\n * @param routingKey the routing key\n * @param props other properties for the message - routing headers etc\n * @param body the message body\n * @throws java.io.IOException if an error is encountered\n */\nvoid basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body) throws IOException;\n```\n\n直接看BasicProperties，有很多属性，但是都没有注释，其实这个有定义一个常量类，com.rabbitmq.client.MessageProperties。\n\n``` java\n// Copyright (c) 2007-Present Pivotal Software, Inc.  All rights reserved.\n//\n// This software, the RabbitMQ Java client library, is triple-licensed under the\n// Mozilla Public License 1.1 (\"MPL\"), the GNU General Public License version 2\n// (\"GPL\") and the Apache License version 2 (\"ASL\"). For the MPL, please see\n// LICENSE-MPL-RabbitMQ. For the GPL, please see LICENSE-GPL2.  For the ASL,\n// please see LICENSE-APACHE2.\n//\n// This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTY OF ANY KIND,\n// either express or implied. See the LICENSE file for specific language governing\n// rights and limitations of this software.\n//\n// If you have any questions regarding licensing, please contact us at\n// info@rabbitmq.com.\n\npackage com.rabbitmq.client;\n\nimport com.rabbitmq.client.AMQP.BasicProperties;\nimport com.rabbitmq.client.impl.AMQContentHeader;\n\n/**\n * Constant holder class with useful static instances of {@link AMQContentHeader}.\n * These are intended for use with {@link Channel#basicPublish} and other Channel methods.\n */\npublic class MessageProperties {\n\n    /** Empty basic properties, with no fields set */\n    public static final BasicProperties MINIMAL_BASIC =\n        new BasicProperties(null, null, null, null,\n                            null, null, null, null,\n                            null, null, null, null,\n                            null, null);\n    /** Empty basic properties, with only deliveryMode set to 2 (persistent) */\n    public static final BasicProperties MINIMAL_PERSISTENT_BASIC =\n        new BasicProperties(null, null, null, 2,\n                            null, null, null, null,\n                            null, null, null, null,\n                            null, null);\n\n    /** Content-type \"application/octet-stream\", deliveryMode 1 (nonpersistent), priority zero */\n    public static final BasicProperties BASIC =\n        new BasicProperties(\"application/octet-stream\",\n                            null,\n                            null,\n                            1,\n                            0, null, null, null,\n                            null, null, null, null,\n                            null, null);\n\n    /** Content-type \"application/octet-stream\", deliveryMode 2 (persistent), priority zero */\n    public static final BasicProperties PERSISTENT_BASIC =\n        new BasicProperties(\"application/octet-stream\",\n                            null,\n                            null,\n                            2,\n                            0, null, null, null,\n                            null, null, null, null,\n                            null, null);\n\n    /** Content-type \"text/plain\", deliveryMode 1 (nonpersistent), priority zero */\n    public static final BasicProperties TEXT_PLAIN =\n        new BasicProperties(\"text/plain\",\n                            null,\n                            null,\n                            1,\n                            0, null, null, null,\n                            null, null, null, null,\n                            null, null);\n\n    /** Content-type \"text/plain\", deliveryMode 2 (persistent), priority zero */\n    public static final BasicProperties PERSISTENT_TEXT_PLAIN =\n        new BasicProperties(\"text/plain\",\n                            null,\n                            null,\n                            2,\n                            0, null, null, null,\n                            null, null, null, null,\n                            null, null);\n}\n```\n- deliveryMode 1 (nonpersistent)\n- deliveryMode 2 (persistent)\n这里就写的，deliveryMode 2就是持久化，所以在需要持久化的时候，这里根据消息的类型使用这个常量就可以，一般是用BasicProperties.PERSISTENT_TEXT_PLAIN。\n\n# 参考资料\n* http://rabbitmq.mr-ping.com/ \n* https://blog.csdn.net/jiao_fuyou/article/details/21594205\n* https://blog.csdn.net/weixin_37641832/article/details/83270778\n* https://honeypps.com/mq/rabbitmq-analysis-of-message-durable/","slug":"rabbitMQ知识点整理","published":1,"updated":"2020-05-07T09:53:25.786Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl6p005eqotnx3t8nm4t","content":"<p>重新温习了AMQP协议以及rabbitMQ的知识点，做下记录。基础的东西就不记了，就记录一些关键的知识点。<br><a id=\"more\"></a></p>\n<h1 id=\"channel-信道-的两种模式\"><a href=\"#channel-信道-的两种模式\" class=\"headerlink\" title=\"channel(信道)的两种模式\"></a>channel(信道)的两种模式</h1><h2 id=\"confirm模式\"><a href=\"#confirm模式\" class=\"headerlink\" title=\"confirm模式\"></a>confirm模式</h2><p>channel设置成confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。</p>\n<p>confirm模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。</p>\n<p>在channel被设置成confirm模式之后，所有被publish的后续消息都将被confirm（即ack）或者被nack一次。但是没有对消息被confirm的快慢做任何保证，并且同一条消息不会同时被confirm和nack 。</p>\n<h3 id=\"如何开启confirm模式\"><a href=\"#如何开启confirm模式\" class=\"headerlink\" title=\"如何开启confirm模式\"></a>如何开启confirm模式</h3><p>调用channel的confirmSelect方法将channel设置为confirm模式，如果没有设置no-wait标志的话，broker会返回confirm.select-ok表示同意发送者将当前channel信道设置为confirm模式(从目前RabbitMQ最新版本3.6来看，如果调用了channel.confirmSelect方法，默认情况下是直接将no-wait设置成false的，也就是默认情况下broker是必须回传confirm.select-ok的)。</p>\n<h3 id=\"异步confirm模式\"><a href=\"#异步confirm模式\" class=\"headerlink\" title=\"异步confirm模式\"></a>异步confirm模式</h3><p>Channel对象提供的ConfirmListener()回调方法只包含deliveryTag（当前Chanel发出的消息序号），我们需要自己为每一个Channel维护一个unconfirm的消息序号集合，每publish一条数据，集合中元素加1，每回调一次handleAck方法，unconfirm集合删掉相应的一条（multiple=false）或多条（multiple=true）记录。从程序运行效率上看，这个unconfirm集合最好采用有序集合SortedSet存储结构。实际上，SDK中的waitForConfirms()方法也是通过SortedSet维护消息序号的。</p>\n<h2 id=\"transaction模式\"><a href=\"#transaction模式\" class=\"headerlink\" title=\"transaction模式\"></a>transaction模式</h2><p>提供的三个方法</p>\n<ul>\n<li>txSelect() 打开事务</li>\n<li>tCommit() 提交事务</li>\n<li>txRollback() 回滚事务</li>\n</ul>\n<p>通过txSelect开启事务之后，便可以发布消息给broker代理服务器了，如果txCommit提交成功，则消息一定到达了broker，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务。</p>\n<p>采用事务机制实现会降低RabbitMQ的消息吞吐量，且不符合消息中间件异步解耦的特性。</p>\n<h1 id=\"Message-Acknowledgement-ACK\"><a href=\"#Message-Acknowledgement-ACK\" class=\"headerlink\" title=\"Message Acknowledgement(ACK)\"></a>Message Acknowledgement(ACK)</h1><p>用于保证消息从队列中可靠的发送给订阅者，即消息回执。</p>\n<p>rabbitMQ在声明消费者的时候可以设置autoAck。</p>\n<ul>\n<li>true: 接收到消息后会自动ack，适用于对于消息吞吐量以及可靠性要求低的场景</li>\n<li>false: 接收到消息后，需要手动进行ack，适用于对消息可靠性要求较高的场景<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Start a non-nolocal, non-exclusive consumer, with</span></span><br><span class=\"line\"><span class=\"comment\">  * a server-generated consumerTag.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> queue the name of the queue</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> autoAck true if the server should consider messages</span></span><br><span class=\"line\"><span class=\"comment\">  * acknowledged once delivered; false if the server should expect</span></span><br><span class=\"line\"><span class=\"comment\">  * explicit acknowledgements</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> callback an interface to the consumer object</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@return</span> the consumerTag generated by the server</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Consume</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.ConsumeOk</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> #basicConsume(String, boolean, String, boolean, boolean, Map, Consumer)</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"><span class=\"function\">String <span class=\"title\">basicConsume</span><span class=\"params\">(String queue, <span class=\"keyword\">boolean</span> autoAck, Consumer callback)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>rabbitMQ提供了以下几个方法<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Acknowledge one or several received</span></span><br><span class=\"line\"><span class=\"comment\">  * messages. Supply the deliveryTag from the &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125; method</span></span><br><span class=\"line\"><span class=\"comment\">  * containing the received message being acknowledged.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Ack</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> deliveryTag the tag from the received &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125; or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> multiple true to acknowledge all messages up to and</span></span><br><span class=\"line\"><span class=\"comment\">  * including the supplied delivery tag; false to acknowledge just</span></span><br><span class=\"line\"><span class=\"comment\">  * the supplied delivery tag.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">basicAck</span><span class=\"params\">(<span class=\"keyword\">long</span> deliveryTag, <span class=\"keyword\">boolean</span> multiple)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Reject one or several received messages.</span></span><br><span class=\"line\"><span class=\"comment\">  *</span></span><br><span class=\"line\"><span class=\"comment\">  * Supply the &lt;code&gt;deliveryTag&lt;/code&gt; from the &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125; method containing the message to be rejected.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Nack</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> deliveryTag the tag from the received &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125; or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> multiple true to reject all messages up to and including</span></span><br><span class=\"line\"><span class=\"comment\">  * the supplied delivery tag; false to reject just the supplied</span></span><br><span class=\"line\"><span class=\"comment\">  * delivery tag.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> requeue true if the rejected message(s) should be requeued rather</span></span><br><span class=\"line\"><span class=\"comment\">  * than discarded/dead-lettered</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">basicNack</span><span class=\"params\">(<span class=\"keyword\">long</span> deliveryTag, <span class=\"keyword\">boolean</span> multiple, <span class=\"keyword\">boolean</span> requeue)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  * Reject a message. Supply the deliveryTag from the &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125; method</span></span><br><span class=\"line\"><span class=\"comment\">  * containing the received message being rejected.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Reject</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> deliveryTag the tag from the received &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125; or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> requeue true if the rejected message should be requeued rather than discarded/dead-lettered</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">basicReject</span><span class=\"params\">(<span class=\"keyword\">long</span> deliveryTag, <span class=\"keyword\">boolean</span> requeue)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"关于重试\"><a href=\"#关于重试\" class=\"headerlink\" title=\"关于重试\"></a>关于重试</h1><p>重试只能是宏观的从组件层面解决问题，如网络问题等，而真正的业务失败应当从业务层面去解决，所以即便是重试也无法解决。</p>\n<h2 id=\"show-me-code\"><a href=\"#show-me-code\" class=\"headerlink\" title=\"show me code\"></a>show me code</h2><p>设置autoAck为false，手动实现消息的ack和reject。通过basicNack设置requeue重入队列。，如果失败次数过多则直接reject该消息（默认业务上已经无法处理该消息）。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">handleDelivery</span><span class=\"params\">(String consumerTag, Envelope envelope, BasicProperties properties, <span class=\"keyword\">byte</span>[] body)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">    MessageResponse result = MessageResponse.ERROR;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        result = <span class=\"keyword\">this</span>.processor.process(SerializeCode.deSerialize(body, <span class=\"keyword\">this</span>.processor.getMsgType()));</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">        logger.error(<span class=\"string\">\"\"</span>, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"keyword\">null</span> != result &amp;&amp; !<span class=\"string\">\"error\"</span>.equals(result.getResultMsg())) &#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"消息 &#123;&#125; 处理成功\"</span>, envelope.getDeliveryTag());</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.channel.basicAck(envelope.getDeliveryTag(), <span class=\"keyword\">false</span>);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.retryCount = <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"消息 &#123;&#125; 处理失败\"</span>, envelope.getDeliveryTag());</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.dealMessageAck(envelope);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">dealMessageAck</span><span class=\"params\">(<span class=\"keyword\">final</span> Envelope envelope)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">    ++<span class=\"keyword\">this</span>.retryCount;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>.retryCount &lt; <span class=\"number\">10</span>) &#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"消费消息 &#123;&#125; 失败.第&#123;&#125;次 重新放入队列\"</span>, envelope.getDeliveryTag(), <span class=\"keyword\">this</span>.retryCount);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.channel.basicNack(envelope.getDeliveryTag(), <span class=\"keyword\">false</span>, <span class=\"keyword\">true</span>);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"消费消息 &#123;&#125; 处理失败已经超过10次. 拒绝该消息\"</span>, envelope.getDeliveryTag(), <span class=\"keyword\">this</span>.retryCount);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.channel.basicReject(envelope.getDeliveryTag(), <span class=\"keyword\">false</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h1><h2 id=\"exchange和queue的持久化\"><a href=\"#exchange和queue的持久化\" class=\"headerlink\" title=\"exchange和queue的持久化\"></a>exchange和queue的持久化</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Actively declare a non-autodelete exchange with no extra arguments</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Exchange.Declare</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Exchange.DeclareOk</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> exchange the name of the exchange</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> type the exchange type</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> durable true if we are declaring a durable exchange (the exchange will survive a server restart)</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@return</span> a declaration-confirm method to indicate the exchange was successfully declared</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\">Exchange.<span class=\"function\">DeclareOk <span class=\"title\">exchangeDeclare</span><span class=\"params\">(String exchange, String type, <span class=\"keyword\">boolean</span> durable)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Declare a queue</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Queue.Declare</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Queue.DeclareOk</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> queue the name of the queue</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> durable true if we are declaring a durable queue (the queue will survive a server restart)</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> exclusive true if we are declaring an exclusive queue (restricted to this connection)</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> autoDelete true if we are declaring an autodelete queue (server will delete it when no longer in use)</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> arguments other properties (construction arguments) for the queue</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@return</span> a declaration-confirm method to indicate the queue was successfully declared</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\">Queue.<span class=\"function\">DeclareOk <span class=\"title\">queueDeclare</span><span class=\"params\">(String queue, <span class=\"keyword\">boolean</span> durable, <span class=\"keyword\">boolean</span> exclusive, <span class=\"keyword\">boolean</span> autoDelete, Map&lt;String, Object&gt; arguments)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>@param durable</p>\n<ul>\n<li>true if we are declaring a durable exchange (the exchange will survive a server restart)</li>\n<li>true if we are declaring a durable queue (the queue will survive a server restart)</li>\n</ul>\n</blockquote>\n<p>声明exchange和queue的时候就可以设置durable为true进行持久化。</p>\n<h2 id=\"消息的持久化\"><a href=\"#消息的持久化\" class=\"headerlink\" title=\"消息的持久化\"></a>消息的持久化</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Publish a message.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * Publishing to a non-existent exchange will result in a channel-level</span></span><br><span class=\"line\"><span class=\"comment\"> * protocol exception, which closes the channel.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * Invocations of &lt;code&gt;Channel#basicPublish&lt;/code&gt; will eventually block if a</span></span><br><span class=\"line\"><span class=\"comment\"> * &lt;a href=\"http://www.rabbitmq.com/alarms.html\"&gt;resource-driven alarm&lt;/a&gt; is in effect.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Publish</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@see</span> &lt;a href=\"http://www.rabbitmq.com/alarms.html\"&gt;Resource-driven alarms&lt;/a&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> exchange the exchange to publish the message to</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> routingKey the routing key</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> props other properties for the message - routing headers etc</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> body the message body</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">basicPublish</span><span class=\"params\">(String exchange, String routingKey, BasicProperties props, <span class=\"keyword\">byte</span>[] body)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure>\n<p>直接看BasicProperties，有很多属性，但是都没有注释，其实这个有定义一个常量类，com.rabbitmq.client.MessageProperties。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Copyright (c) 2007-Present Pivotal Software, Inc.  All rights reserved.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// This software, the RabbitMQ Java client library, is triple-licensed under the</span></span><br><span class=\"line\"><span class=\"comment\">// Mozilla Public License 1.1 (\"MPL\"), the GNU General Public License version 2</span></span><br><span class=\"line\"><span class=\"comment\">// (\"GPL\") and the Apache License version 2 (\"ASL\"). For the MPL, please see</span></span><br><span class=\"line\"><span class=\"comment\">// LICENSE-MPL-RabbitMQ. For the GPL, please see LICENSE-GPL2.  For the ASL,</span></span><br><span class=\"line\"><span class=\"comment\">// please see LICENSE-APACHE2.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTY OF ANY KIND,</span></span><br><span class=\"line\"><span class=\"comment\">// either express or implied. See the LICENSE file for specific language governing</span></span><br><span class=\"line\"><span class=\"comment\">// rights and limitations of this software.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// If you have any questions regarding licensing, please contact us at</span></span><br><span class=\"line\"><span class=\"comment\">// info@rabbitmq.com.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">package</span> com.rabbitmq.client;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.rabbitmq.client.AMQP.BasicProperties;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.rabbitmq.client.impl.AMQContentHeader;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Constant holder class with useful static instances of &#123;<span class=\"doctag\">@link</span> AMQContentHeader&#125;.</span></span><br><span class=\"line\"><span class=\"comment\"> * These are intended for use with &#123;<span class=\"doctag\">@link</span> Channel#basicPublish&#125; and other Channel methods.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MessageProperties</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Empty basic properties, with no fields set */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties MINIMAL_BASIC =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">    <span class=\"comment\">/** Empty basic properties, with only deliveryMode set to 2 (persistent) */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties MINIMAL_PERSISTENT_BASIC =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"number\">2</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Content-type \"application/octet-stream\", deliveryMode 1 (nonpersistent), priority zero */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties BASIC =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"string\">\"application/octet-stream\"</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"number\">1</span>,</span><br><span class=\"line\">                            <span class=\"number\">0</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Content-type \"application/octet-stream\", deliveryMode 2 (persistent), priority zero */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties PERSISTENT_BASIC =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"string\">\"application/octet-stream\"</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"number\">2</span>,</span><br><span class=\"line\">                            <span class=\"number\">0</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Content-type \"text/plain\", deliveryMode 1 (nonpersistent), priority zero */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties TEXT_PLAIN =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"string\">\"text/plain\"</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"number\">1</span>,</span><br><span class=\"line\">                            <span class=\"number\">0</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Content-type \"text/plain\", deliveryMode 2 (persistent), priority zero */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties PERSISTENT_TEXT_PLAIN =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"string\">\"text/plain\"</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"number\">2</span>,</span><br><span class=\"line\">                            <span class=\"number\">0</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>deliveryMode 1 (nonpersistent)</li>\n<li>deliveryMode 2 (persistent)<br>这里就写的，deliveryMode 2就是持久化，所以在需要持久化的时候，这里根据消息的类型使用这个常量就可以，一般是用BasicProperties.PERSISTENT_TEXT_PLAIN。</li>\n</ul>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"http://rabbitmq.mr-ping.com/\" target=\"_blank\" rel=\"noopener\">http://rabbitmq.mr-ping.com/</a> </li>\n<li><a href=\"https://blog.csdn.net/jiao_fuyou/article/details/21594205\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jiao_fuyou/article/details/21594205</a></li>\n<li><a href=\"https://blog.csdn.net/weixin_37641832/article/details/83270778\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_37641832/article/details/83270778</a></li>\n<li><a href=\"https://honeypps.com/mq/rabbitmq-analysis-of-message-durable/\" target=\"_blank\" rel=\"noopener\">https://honeypps.com/mq/rabbitmq-analysis-of-message-durable/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>重新温习了AMQP协议以及rabbitMQ的知识点，做下记录。基础的东西就不记了，就记录一些关键的知识点。<br>","more":"</p>\n<h1 id=\"channel-信道-的两种模式\"><a href=\"#channel-信道-的两种模式\" class=\"headerlink\" title=\"channel(信道)的两种模式\"></a>channel(信道)的两种模式</h1><h2 id=\"confirm模式\"><a href=\"#confirm模式\" class=\"headerlink\" title=\"confirm模式\"></a>confirm模式</h2><p>channel设置成confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。</p>\n<p>confirm模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。</p>\n<p>在channel被设置成confirm模式之后，所有被publish的后续消息都将被confirm（即ack）或者被nack一次。但是没有对消息被confirm的快慢做任何保证，并且同一条消息不会同时被confirm和nack 。</p>\n<h3 id=\"如何开启confirm模式\"><a href=\"#如何开启confirm模式\" class=\"headerlink\" title=\"如何开启confirm模式\"></a>如何开启confirm模式</h3><p>调用channel的confirmSelect方法将channel设置为confirm模式，如果没有设置no-wait标志的话，broker会返回confirm.select-ok表示同意发送者将当前channel信道设置为confirm模式(从目前RabbitMQ最新版本3.6来看，如果调用了channel.confirmSelect方法，默认情况下是直接将no-wait设置成false的，也就是默认情况下broker是必须回传confirm.select-ok的)。</p>\n<h3 id=\"异步confirm模式\"><a href=\"#异步confirm模式\" class=\"headerlink\" title=\"异步confirm模式\"></a>异步confirm模式</h3><p>Channel对象提供的ConfirmListener()回调方法只包含deliveryTag（当前Chanel发出的消息序号），我们需要自己为每一个Channel维护一个unconfirm的消息序号集合，每publish一条数据，集合中元素加1，每回调一次handleAck方法，unconfirm集合删掉相应的一条（multiple=false）或多条（multiple=true）记录。从程序运行效率上看，这个unconfirm集合最好采用有序集合SortedSet存储结构。实际上，SDK中的waitForConfirms()方法也是通过SortedSet维护消息序号的。</p>\n<h2 id=\"transaction模式\"><a href=\"#transaction模式\" class=\"headerlink\" title=\"transaction模式\"></a>transaction模式</h2><p>提供的三个方法</p>\n<ul>\n<li>txSelect() 打开事务</li>\n<li>tCommit() 提交事务</li>\n<li>txRollback() 回滚事务</li>\n</ul>\n<p>通过txSelect开启事务之后，便可以发布消息给broker代理服务器了，如果txCommit提交成功，则消息一定到达了broker，如果在txCommit执行之前broker异常崩溃或者由于其他原因抛出异常，这个时候我们便可以捕获异常通过txRollback回滚事务。</p>\n<p>采用事务机制实现会降低RabbitMQ的消息吞吐量，且不符合消息中间件异步解耦的特性。</p>\n<h1 id=\"Message-Acknowledgement-ACK\"><a href=\"#Message-Acknowledgement-ACK\" class=\"headerlink\" title=\"Message Acknowledgement(ACK)\"></a>Message Acknowledgement(ACK)</h1><p>用于保证消息从队列中可靠的发送给订阅者，即消息回执。</p>\n<p>rabbitMQ在声明消费者的时候可以设置autoAck。</p>\n<ul>\n<li>true: 接收到消息后会自动ack，适用于对于消息吞吐量以及可靠性要求低的场景</li>\n<li>false: 接收到消息后，需要手动进行ack，适用于对消息可靠性要求较高的场景<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Start a non-nolocal, non-exclusive consumer, with</span></span><br><span class=\"line\"><span class=\"comment\">  * a server-generated consumerTag.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> queue the name of the queue</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> autoAck true if the server should consider messages</span></span><br><span class=\"line\"><span class=\"comment\">  * acknowledged once delivered; false if the server should expect</span></span><br><span class=\"line\"><span class=\"comment\">  * explicit acknowledgements</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> callback an interface to the consumer object</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@return</span> the consumerTag generated by the server</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Consume</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.ConsumeOk</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> #basicConsume(String, boolean, String, boolean, boolean, Map, Consumer)</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"><span class=\"function\">String <span class=\"title\">basicConsume</span><span class=\"params\">(String queue, <span class=\"keyword\">boolean</span> autoAck, Consumer callback)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>rabbitMQ提供了以下几个方法<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Acknowledge one or several received</span></span><br><span class=\"line\"><span class=\"comment\">  * messages. Supply the deliveryTag from the &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125; method</span></span><br><span class=\"line\"><span class=\"comment\">  * containing the received message being acknowledged.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Ack</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> deliveryTag the tag from the received &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125; or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> multiple true to acknowledge all messages up to and</span></span><br><span class=\"line\"><span class=\"comment\">  * including the supplied delivery tag; false to acknowledge just</span></span><br><span class=\"line\"><span class=\"comment\">  * the supplied delivery tag.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">basicAck</span><span class=\"params\">(<span class=\"keyword\">long</span> deliveryTag, <span class=\"keyword\">boolean</span> multiple)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Reject one or several received messages.</span></span><br><span class=\"line\"><span class=\"comment\">  *</span></span><br><span class=\"line\"><span class=\"comment\">  * Supply the &lt;code&gt;deliveryTag&lt;/code&gt; from the &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125; method containing the message to be rejected.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Nack</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> deliveryTag the tag from the received &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125; or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> multiple true to reject all messages up to and including</span></span><br><span class=\"line\"><span class=\"comment\">  * the supplied delivery tag; false to reject just the supplied</span></span><br><span class=\"line\"><span class=\"comment\">  * delivery tag.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> requeue true if the rejected message(s) should be requeued rather</span></span><br><span class=\"line\"><span class=\"comment\">  * than discarded/dead-lettered</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">basicNack</span><span class=\"params\">(<span class=\"keyword\">long</span> deliveryTag, <span class=\"keyword\">boolean</span> multiple, <span class=\"keyword\">boolean</span> requeue)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  * Reject a message. Supply the deliveryTag from the &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125; method</span></span><br><span class=\"line\"><span class=\"comment\">  * containing the received message being rejected.</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Reject</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> deliveryTag the tag from the received &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.GetOk&#125; or &#123;<span class=\"doctag\">@link</span> com.rabbitmq.client.AMQP.Basic.Deliver&#125;</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> requeue true if the rejected message should be requeued rather than discarded/dead-lettered</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">basicReject</span><span class=\"params\">(<span class=\"keyword\">long</span> deliveryTag, <span class=\"keyword\">boolean</span> requeue)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"关于重试\"><a href=\"#关于重试\" class=\"headerlink\" title=\"关于重试\"></a>关于重试</h1><p>重试只能是宏观的从组件层面解决问题，如网络问题等，而真正的业务失败应当从业务层面去解决，所以即便是重试也无法解决。</p>\n<h2 id=\"show-me-code\"><a href=\"#show-me-code\" class=\"headerlink\" title=\"show me code\"></a>show me code</h2><p>设置autoAck为false，手动实现消息的ack和reject。通过basicNack设置requeue重入队列。，如果失败次数过多则直接reject该消息（默认业务上已经无法处理该消息）。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">handleDelivery</span><span class=\"params\">(String consumerTag, Envelope envelope, BasicProperties properties, <span class=\"keyword\">byte</span>[] body)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">    MessageResponse result = MessageResponse.ERROR;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        result = <span class=\"keyword\">this</span>.processor.process(SerializeCode.deSerialize(body, <span class=\"keyword\">this</span>.processor.getMsgType()));</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">        logger.error(<span class=\"string\">\"\"</span>, e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"keyword\">null</span> != result &amp;&amp; !<span class=\"string\">\"error\"</span>.equals(result.getResultMsg())) &#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"消息 &#123;&#125; 处理成功\"</span>, envelope.getDeliveryTag());</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.channel.basicAck(envelope.getDeliveryTag(), <span class=\"keyword\">false</span>);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.retryCount = <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"消息 &#123;&#125; 处理失败\"</span>, envelope.getDeliveryTag());</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.dealMessageAck(envelope);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">private</span> <span class=\"keyword\">void</span> <span class=\"title\">dealMessageAck</span><span class=\"params\">(<span class=\"keyword\">final</span> Envelope envelope)</span> <span class=\"keyword\">throws</span> IOException </span>&#123;</span><br><span class=\"line\">    ++<span class=\"keyword\">this</span>.retryCount;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (<span class=\"keyword\">this</span>.retryCount &lt; <span class=\"number\">10</span>) &#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"消费消息 &#123;&#125; 失败.第&#123;&#125;次 重新放入队列\"</span>, envelope.getDeliveryTag(), <span class=\"keyword\">this</span>.retryCount);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.channel.basicNack(envelope.getDeliveryTag(), <span class=\"keyword\">false</span>, <span class=\"keyword\">true</span>);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        logger.info(<span class=\"string\">\"消费消息 &#123;&#125; 处理失败已经超过10次. 拒绝该消息\"</span>, envelope.getDeliveryTag(), <span class=\"keyword\">this</span>.retryCount);</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.channel.basicReject(envelope.getDeliveryTag(), <span class=\"keyword\">false</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h1 id=\"持久化\"><a href=\"#持久化\" class=\"headerlink\" title=\"持久化\"></a>持久化</h1><h2 id=\"exchange和queue的持久化\"><a href=\"#exchange和queue的持久化\" class=\"headerlink\" title=\"exchange和queue的持久化\"></a>exchange和queue的持久化</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Actively declare a non-autodelete exchange with no extra arguments</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Exchange.Declare</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Exchange.DeclareOk</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> exchange the name of the exchange</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> type the exchange type</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> durable true if we are declaring a durable exchange (the exchange will survive a server restart)</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@return</span> a declaration-confirm method to indicate the exchange was successfully declared</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\">Exchange.<span class=\"function\">DeclareOk <span class=\"title\">exchangeDeclare</span><span class=\"params\">(String exchange, String type, <span class=\"keyword\">boolean</span> durable)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">  * Declare a queue</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Queue.Declare</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Queue.DeclareOk</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> queue the name of the queue</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> durable true if we are declaring a durable queue (the queue will survive a server restart)</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> exclusive true if we are declaring an exclusive queue (restricted to this connection)</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> autoDelete true if we are declaring an autodelete queue (server will delete it when no longer in use)</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@param</span> arguments other properties (construction arguments) for the queue</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@return</span> a declaration-confirm method to indicate the queue was successfully declared</span></span><br><span class=\"line\"><span class=\"comment\">  * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\">  */</span></span><br><span class=\"line\">Queue.<span class=\"function\">DeclareOk <span class=\"title\">queueDeclare</span><span class=\"params\">(String queue, <span class=\"keyword\">boolean</span> durable, <span class=\"keyword\">boolean</span> exclusive, <span class=\"keyword\">boolean</span> autoDelete, Map&lt;String, Object&gt; arguments)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>@param durable</p>\n<ul>\n<li>true if we are declaring a durable exchange (the exchange will survive a server restart)</li>\n<li>true if we are declaring a durable queue (the queue will survive a server restart)</li>\n</ul>\n</blockquote>\n<p>声明exchange和queue的时候就可以设置durable为true进行持久化。</p>\n<h2 id=\"消息的持久化\"><a href=\"#消息的持久化\" class=\"headerlink\" title=\"消息的持久化\"></a>消息的持久化</h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Publish a message.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * Publishing to a non-existent exchange will result in a channel-level</span></span><br><span class=\"line\"><span class=\"comment\"> * protocol exception, which closes the channel.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * Invocations of &lt;code&gt;Channel#basicPublish&lt;/code&gt; will eventually block if a</span></span><br><span class=\"line\"><span class=\"comment\"> * &lt;a href=\"http://www.rabbitmq.com/alarms.html\"&gt;resource-driven alarm&lt;/a&gt; is in effect.</span></span><br><span class=\"line\"><span class=\"comment\"> *</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@see</span> com.rabbitmq.client.AMQP.Basic.Publish</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@see</span> &lt;a href=\"http://www.rabbitmq.com/alarms.html\"&gt;Resource-driven alarms&lt;/a&gt;</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> exchange the exchange to publish the message to</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> routingKey the routing key</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> props other properties for the message - routing headers etc</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@param</span> body the message body</span></span><br><span class=\"line\"><span class=\"comment\"> * <span class=\"doctag\">@throws</span> java.io.IOException if an error is encountered</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">basicPublish</span><span class=\"params\">(String exchange, String routingKey, BasicProperties props, <span class=\"keyword\">byte</span>[] body)</span> <span class=\"keyword\">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure>\n<p>直接看BasicProperties，有很多属性，但是都没有注释，其实这个有定义一个常量类，com.rabbitmq.client.MessageProperties。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Copyright (c) 2007-Present Pivotal Software, Inc.  All rights reserved.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// This software, the RabbitMQ Java client library, is triple-licensed under the</span></span><br><span class=\"line\"><span class=\"comment\">// Mozilla Public License 1.1 (\"MPL\"), the GNU General Public License version 2</span></span><br><span class=\"line\"><span class=\"comment\">// (\"GPL\") and the Apache License version 2 (\"ASL\"). For the MPL, please see</span></span><br><span class=\"line\"><span class=\"comment\">// LICENSE-MPL-RabbitMQ. For the GPL, please see LICENSE-GPL2.  For the ASL,</span></span><br><span class=\"line\"><span class=\"comment\">// please see LICENSE-APACHE2.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// This software is distributed on an \"AS IS\" basis, WITHOUT WARRANTY OF ANY KIND,</span></span><br><span class=\"line\"><span class=\"comment\">// either express or implied. See the LICENSE file for specific language governing</span></span><br><span class=\"line\"><span class=\"comment\">// rights and limitations of this software.</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">// If you have any questions regarding licensing, please contact us at</span></span><br><span class=\"line\"><span class=\"comment\">// info@rabbitmq.com.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">package</span> com.rabbitmq.client;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> com.rabbitmq.client.AMQP.BasicProperties;</span><br><span class=\"line\"><span class=\"keyword\">import</span> com.rabbitmq.client.impl.AMQContentHeader;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Constant holder class with useful static instances of &#123;<span class=\"doctag\">@link</span> AMQContentHeader&#125;.</span></span><br><span class=\"line\"><span class=\"comment\"> * These are intended for use with &#123;<span class=\"doctag\">@link</span> Channel#basicPublish&#125; and other Channel methods.</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MessageProperties</span> </span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Empty basic properties, with no fields set */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties MINIMAL_BASIC =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">    <span class=\"comment\">/** Empty basic properties, with only deliveryMode set to 2 (persistent) */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties MINIMAL_PERSISTENT_BASIC =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"number\">2</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Content-type \"application/octet-stream\", deliveryMode 1 (nonpersistent), priority zero */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties BASIC =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"string\">\"application/octet-stream\"</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"number\">1</span>,</span><br><span class=\"line\">                            <span class=\"number\">0</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Content-type \"application/octet-stream\", deliveryMode 2 (persistent), priority zero */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties PERSISTENT_BASIC =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"string\">\"application/octet-stream\"</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"number\">2</span>,</span><br><span class=\"line\">                            <span class=\"number\">0</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Content-type \"text/plain\", deliveryMode 1 (nonpersistent), priority zero */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties TEXT_PLAIN =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"string\">\"text/plain\"</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"number\">1</span>,</span><br><span class=\"line\">                            <span class=\"number\">0</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/** Content-type \"text/plain\", deliveryMode 2 (persistent), priority zero */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> BasicProperties PERSISTENT_TEXT_PLAIN =</span><br><span class=\"line\">        <span class=\"keyword\">new</span> BasicProperties(<span class=\"string\">\"text/plain\"</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"number\">2</span>,</span><br><span class=\"line\">                            <span class=\"number\">0</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>,</span><br><span class=\"line\">                            <span class=\"keyword\">null</span>, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>deliveryMode 1 (nonpersistent)</li>\n<li>deliveryMode 2 (persistent)<br>这里就写的，deliveryMode 2就是持久化，所以在需要持久化的时候，这里根据消息的类型使用这个常量就可以，一般是用BasicProperties.PERSISTENT_TEXT_PLAIN。</li>\n</ul>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"http://rabbitmq.mr-ping.com/\" target=\"_blank\" rel=\"noopener\">http://rabbitmq.mr-ping.com/</a> </li>\n<li><a href=\"https://blog.csdn.net/jiao_fuyou/article/details/21594205\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jiao_fuyou/article/details/21594205</a></li>\n<li><a href=\"https://blog.csdn.net/weixin_37641832/article/details/83270778\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_37641832/article/details/83270778</a></li>\n<li><a href=\"https://honeypps.com/mq/rabbitmq-analysis-of-message-durable/\" target=\"_blank\" rel=\"noopener\">https://honeypps.com/mq/rabbitmq-analysis-of-message-durable/</a></li>\n</ul>"},{"title":"压测性能调优总结","date":"2019-04-25T02:00:00.000Z","_content":"\n> 来自公司同事压测性能调优的分享\n\n<!-- more -->\n\n\n## 前情提要\n完美中国项目进入压测环节，就是业务都做完啦，通过压测优化让系统性能达到设计标准，通过客户验收即可交付。这边有几个平衡点\n* 总体预算大体不变的框架下进行资源分配优化\n* 大体需求不变的前提下做功能效率优化\n\n> 基于这两点，盲目说~~性能不够加机器~~，~~砍功能说无法实现~~都是不可以的，压测的目的就是要攻克难关。\n\n## 优化场景\n\n### 数据同步效率优化\n#### 从问题出发\n> - mysql数据为什么要同步到es？\n\n#### 设计\n![压测性能调优_01](/image/压测性能调优_01.png)\n\n可能的瓶颈点\n（红字处\n\n#### 优化手段\n\n* 对数据进行多线程分片执行，对数据集进行分片，每个分片由单独线程执行，充分利用多核CPU的优势。\n\n++原先一个大表（2000w+数据）全量同步需要20+h，优化后在1h内同步完成++\n\n> 示例代码(非可执行代码)\n\n```\npublic class IndexExecutor<K, T>{\n    private static final int MAX_SAHRD_NUM = 32;\n    /**\n     * 最多32个线程\n     */\n    private static ExecutorService executor = Executors.newFixedThreadPool(MAX_SAHRD_NUM);\n\n    public IndexExecutor() {\n    }\n\n    private IndexExecutor(Params params) {\n        Assert.isTrue(params.shard < MAX_SAHRD_NUM, \"must small than MAX_SAHRD_NUM(32)\");\n        this.mapper = params.mapper;\n        this.mapping = params.mapping;\n        this.params = params;\n        super.setApplicationContext(context);\n        super.setMapping(this.mapping);\n        super.setMapper(this.mapper);\n    }\n\n    private Params params;\n    private BaseMapper mapper;\n    private TableToIndexMappingDto mapping;\n\n    public void build() {\n        // 非空校验\n        Objects.requireNonNull(params.mapper);\n        Objects.requireNonNull(params.mapping);\n        List<String> tableNames = this.findTableNames();\n\n        // 不阻塞调用请求\n        new Thread(() -> {\n            String indexAliasesName = this.mapping.getIndicesAliasesName();\n            String newIndexName = this.createIndexNewName(indexAliasesName);\n            this.createIndexAndMapping(newIndexName);\n            int shard = params.shard;\n            long begin = 0;\n            long[] counts = null;\n\n            // 遍历每个tableName\n            for (String tableName : tableNames) {\n                Long count = 0L;\n                begin = System.currentTimeMillis();\n                if (tableNames.size() > 1) {\n                    PartitionFeatureMapper partitionFeatureMapper = (PartitionFeatureMapper) mapper;\n                    count = partitionFeatureMapper.countAllByTableName(tableName);\n                } else {\n                    count = mapper.countAll();\n                }\n\n                counts = splitShard(shard, count);\n                CountDownLatch cd = new CountDownLatch(counts.length - 1);\n                for (int i = 0; i < counts.length; i++) {\n                    long segmentCount = counts[i];\n                    long lastCount = i == 0 ? 0L : counts[i - 1];\n                    logger.info(\"分片序号：{} 位置 {}-{} 开始\", i, lastCount, segmentCount);\n                    executor.execute(() -> {\n                        this.runShard(tableName, lastCount, segmentCount, newIndexName);\n                        cd.countDown();\n                        logger.info(\"{} 等待其他分片执行完毕，剩余分片数量 ：{}\", tableName, cd.getCount());\n                    });\n                    // 错开数据库io峰\n                    try {\n                        TimeUnit.SECONDS.sleep(1);\n                    } catch (InterruptedException e) {\n                        logger.error(\"\", e);\n                    }\n                }\n                try {\n                    cd.await();\n                } catch (InterruptedException e) {\n                    logger.error(\"{} 表，全量更新索引失败,{} \", tableName, newIndexName, e);\n                }\n            }\n            this.addOrUpdateIndexWithAliasesRef(indexAliasesName, newIndexName);\n            logger.info(\"迁移索引别名到新索引成功，alies {} index {}，耗时：{}ms\", indexAliasesName, newIndexName, System.currentTimeMillis() - begin);\n        }).start();\n    }\n\n    /**\n     * 如果是表名是着正则就按正则查出所有表名，\n     * 否则直接返回表名\n     *\n     * @return\n     */\n    public List<String> findTableNames() {\n        List<String> tableNames = null;\n        String tableName = this.mapping.getTableName();\n        if (this.mapper instanceof PartitionFeatureMapper) {\n            Connection connection = null;\n            String schema = null;\n            try {\n                // 这坨代码为了取库名\n                String jdbcUrl = this.params.dataSourceVo.getJdbcUrl();\n                String jdbcUserName = this.params.dataSourceVo.getJdbcUserName();\n                String jdbcUserPassword = this.params.dataSourceVo.getJdbcUserPassword();\n                connection = DriverManager.getConnection(jdbcUrl, jdbcUserName, jdbcUserPassword);\n                Field dbName = connection.getClass().getDeclaredField(\"dbName\");\n                dbName.setAccessible(true);\n                schema = String.valueOf(dbName.get(connection));\n            } catch (Throwable e) {\n                logger.error(\"\", e);\n            } finally {\n                if (connection != null) {\n                    try {\n                        connection.close();\n                    } catch (Throwable e) {\n                        logger.error(\"\", e);\n                    }\n                }\n            }\n            PartitionFeatureMapper partitionFeatureMapper = (PartitionFeatureMapper) this.mapper;\n            // 从该schema 查询所有表名\n            String tableRegex = tableName;\n            tableNames = partitionFeatureMapper.findTablesByRegex(schema, tableRegex);\n        } else if (this.mapper instanceof ExectuorMapper) {\n            tableNames = Lists.newArrayList(tableName);\n        }\n        return tableNames;\n    }\n\n    /**\n     * 每个分片的任务\n     *\n     * @param beginPos\n     * @param endPos\n     * @param indexName\n     */\n    private void runShard(String tableName, long beginPos, long endPos, String indexName) {\n        Map<String, String> map = null;\n        long count = endPos - beginPos;\n        if (this.mapper instanceof PartitionFeatureMapper) {\n            PartitionFeatureMapper mapper = (PartitionFeatureMapper) this.getMapper();\n            map = mapper.findMaxAndMinIdPartion(tableName, beginPos, count);\n        } else if (this.mapper instanceof ExectuorMapper) {\n            ExectuorMapper mapper = (ExectuorMapper) this.getMapper();\n            map = mapper.findMaxAndMinIdLimit(beginPos, count);\n        }\n        if (map == null || map.isEmpty()) {\n            logger.warn(\"beginPos{},count{},indexName{} map empty\", beginPos, endPos, indexName);\n            return;\n        }\n        String minId = String.valueOf(map.get(\"minId\"));\n        String actualMaxId = null;\n        long scanedCount = 0L;\n        long actualCount = 0L;\n        int batch = (int) (endPos > 1000 ? 1000 : endPos);\n        int runtime = 0;\n        List list = null;\n        do {\n            if (this.mapper instanceof PartitionFeatureMapper) {\n                PartitionFeatureMapper mapper = (PartitionFeatureMapper) this.getMapper();\n                actualMaxId = String.valueOf(mapper.findMaxIdPartition(tableName, minId, batch));\n\n                list = mapper.findByMaxAndMinIdPartition(tableName, minId, actualMaxId);\n\n            } else if (this.mapper instanceof ExectuorMapper) {\n                actualMaxId = String.valueOf(this.getMapper().findMaxId(minId, batch));\n                //mapper用dto接收\n                list = this.getMapper().findByMaxAndMinId(minId, actualMaxId);\n            }\n            if (logger.isDebugEnabled()) {\n                logger.info(\"segment[{}-{}] load from db success,minId:{}  maxId:{}\", beginPos, endPos, minId, actualMaxId);\n            }\n            if (list.isEmpty()) {\n                break;\n            }\n            scanedCount += list.size();\n\n            this.batchAddIndexByMapParams(indexName, list);\n\n            if (logger.isDebugEnabled()) {\n                logger.info(\"segment[{}-{}] put in es success,minId:{}  maxId:{}\", beginPos, endPos, minId, actualMaxId);\n            }\n            minId = actualMaxId;\n            actualCount += (long) list.size();\n            ++runtime;\n        } while (scanedCount < count);\n\n        logger.info(\"db record count={},fetch record count={},runtime={}\", new Object[]{endPos, actualCount, runtime});\n    }\n\n    /**\n     * 重写批量导入es逻辑\n     *\n     * @param newIndexName\n     * @param list\n     */\n    protected void batchAddIndexByMapParams(String newIndexName, List<Map<String, Object>> list) {\n        if (list != null && !list.isEmpty()) {\n            String pattern = \"yyyy-MM-dd HH:mm:ss\";\n            List<IndexDocContentVo> docs = list.parallelStream().filter(doc -> doc != null).collect(Collectors.toList());\n            IndexDocumentVo indexDocumentVo = new IndexDocumentVo(newIndexName, this.mapping.getIndicesTypeName(), docs);\n            this.getSearchIndexService().addData(indexDocumentVo);\n        }\n    }\n\n    /**\n     * 根据总数 分片数 获取每个分片边界\n     *\n     * @param shardNums\n     * @param total\n     * @return\n     */\n    public static long[] splitShard(int shardNums, long total) {\n        if (total <= shardNums || total <= 1000) {\n            return new long[]{total};\n        }\n        long constTotal = total;\n        int shardIndex = 1;\n        long[] counts = new long[shardNums];\n        long everShard = total / shardNums;\n        while (constTotal - everShard * shardIndex > 0) {\n            long newTotal = total - everShard * shardIndex;\n            counts[shardIndex - 1] = total - newTotal;\n            total = newTotal;\n            shardIndex++;\n        }\n        counts[shardNums - 1] = constTotal;\n        return counts;\n    }\n\n    public static class Params {\n        BaseMapper mapper;\n        DataSourceVo dataSourceVo;\n        TableToIndexMappingDto mapping;\n        Wrapper wrapper;\n        WrapperDto wrapperDto;\n        ListWrapper listWrapper;\n        ListWrapperDto listWrapperDto;\n\n        /**\n         * 这里分片 4 * 2(核)片 ，每个线程取一部分数据，各自开始load\n         */\n        int shard = 8;\n\n        public void runIndex() {\n            IndexExecutor indexExecutor = new IndexExecutor(this);\n            indexExecutor.build();\n        }\n\n        public IndexExecutor build() {\n            IndexExecutor indexExecutor = new IndexExecutor(this);\n            return indexExecutor;\n        }\n\n        public Params withMapper(BaseMapper mapper) {\n            this.mapper = mapper;\n            return this;\n        }\n\n        public Params withMapping(TableToIndexMappingDto mapping) {\n            this.mapping = mapping;\n            return this;\n        }\n\n        public Params withShard(int shard) {\n            this.shard = shard;\n            return this;\n        }\n\n        public Params withWrapper(Wrapper wrapper) {\n            this.wrapper = wrapper;\n            return this;\n        }\n\n        public Params withWrapperDto(WrapperDto wrapperDto) {\n            this.wrapperDto = wrapperDto;\n            return this;\n        }\n\n        public Params withDataSourceVo(String beanName) {\n            DataSourceVo bean = context.getBean(beanName, DataSourceVo.class);\n            this.dataSourceVo = bean;\n            return this;\n        }\n\n        public Params withListMapper(ListWrapper listMapper) {\n            this.listWrapper = listMapper;\n            return this;\n        }\n\n        public Params withListDtoMapper(ListWrapperDto listMapper) {\n            this.listWrapperDto = listMapper;\n            return this;\n        }\n    }\n\n    public interface Wrapper {\n        Map<String, Object> wrapDoc(Map<String, Object> item);\n    }\n\n    public interface ListWrapper {\n        List<Map<String, Object>> wrapBatchDoc(List<Map<String, Object>> item);\n    }\n\n    public interface ListWrapperDto {\n        List<Map<String, Object>> wrapBatchDoc(List item);\n    }\n\n    public interface WrapperDto<T> {\n        T wrapDto(T item);\n\n        Class getTargetClass();\n    }\n}\n```\n\n以上代码的核心点\n> 获取分片边界 long[] splitShard(int shardNums, long total)\n\n> 取数据时按where取数据，而不是limit取数据，可以命中拆分键（存疑。。\n\n> 线程池 & JVM最佳线程数量 cpu核数 * 1.5 （存疑。。\n\n#### SQL调优\n\n* 减少数据库交互次数\n\n++原先一次数据组装耗时100s-500s不可控，优化后稳定在1s左右++\n\n> 查询数据库的过程如果涉及for循环，看是否可以修改for循环取数据为in查询，减少数据库交互次数\n\n**原先**\n\n```\nfor (UserDto docValue : docValues) {\n    UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(docValue.getPersonId());\n    //...\n}\n```\n\n**优化后**\n\n```\nString personIds = docValues.stream()\n                .filter(item -> item != null && item.getPersonId() != null)\n                .map(item -> item.getPersonId().toString()).collect(Collectors.joining(\",\"));\nList<UserPersonalInfoDto> userPersonInfos = userPersonalInfoMapper.findByIds(personIds);\nMap<Long, UserPersonalInfoDto> userPersonalInfoMap = userPersonInfos.stream().collect(Collectors.toMap(UserPersonalInfoDto::getId, Function.identity()));\n```\n\n> 同库情况下使用join代替多次数据库查询。用子查询优化主表，核心是先筛选，再join。减少表关联的数量级。\n\n```\nSELECT\n    b.id,\n    b.`level`,\n    b.max_level,\n    b.`status`,\n    b.last_active_month,\n    b.create_time,\n    b.create_person,\n    b.update_person,\n    b.update_time,\n    b.tenant_id,\n    b.instance_id,\n    b.create_time\nFROM\n(\n    SELECT member_id from mm_card_map_user where dr = 0 and user_id in (${userIds}) \n) as a\nLEFT JOIN mm_member b ON b.id = a.member_id\nwhere b.dr = 0\nGROUP by b.id;\n```\n\n* 把多数据源聚合的过程的同步调用异步化\n\n**原来代码**\n\n```\n/**\n * 补全信息\n *\n * @param item\n * @author zhou.shilong\n */\npublic UserDto wrapFullItem(UserDto item) {\n    if (item != null && null != item.getId()) {\n        //personal\n        UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(item.getPersonId());\n        if (null != personalInfo) {\n            item.setPersonalInfo(personalInfo);\n        }\n        //member\n        MemberDto memberDto = memberMapper.findByUserId(item.getId());\n        if (null != memberDto) {\n            item.setMember(memberDto);\n        }\n\n        //userRef\n        List<UserRefDto> usernames = userMapper.findUsrNameByUserId(item.getId());\n        List<UserRefDto> userphones = userMapper.findUserPhoneByUserId(item.getId());\n        List<UserRefDto> userCardNums = userMapper.findUserCardNumByUserId(item.getId());\n        item.setUserRName(usernames);\n        item.setUserRPhone(userphones);\n        item.setUserRCardnum(userCardNums);\n\n        ///usercloud云商信息<单独同步，查询聚合>\n        ///identification 身份证信息\n        UserIdentificationDto identification = identificationMapper.findUsrNameByUserId(item.getId());\n        item.setIdentification(identification);\n        ///qq\\weichat第三方信息\n    }\n\n    return item;\n}\n```\n\n**优化后**\n\n```\n/**\n * 补全信息\n *\n * @param item\n * @author zhou.shilong\n */\npublic UserDto wrapFullItem(UserDto item) {\n    if (item != null && null != item.getId()) {\n        AsyncExecuter.init(4).execute(() -> {\n            //personal\n            UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(item.getPersonId());\n            if (null != personalInfo) {\n                item.setPersonalInfo(personalInfo);\n            }\n        }).execute(() -> {\n            //member\n            MemberDto memberDto = memberMapper.findByUserId(item.getId());\n            if (null != memberDto) {\n                item.setMember(memberDto);\n            }\n        }).execute(() -> {\n            //userRef\n            List<UserRefDto> userCardNums = userMapper.findByUserId(\"us_user_r_cardnum\", item.getId());\n            List<UserRefDto> userphones = userMapper.findByUserId(\"us_user_r_phone\", item.getId());\n            List<UserRefDto> usernames = userMapper.findByUserId(\"us_user_r_username\", item.getId());\n            item.setUserRName(usernames);\n            item.setUserRPhone(userphones);\n            item.setUserRCardnum(userCardNums);\n        }).execute(() -> {\n            ///usercloud云商信息<单独同步，查询聚合>\n            ///identification 身份证信息\n            UserIdentificationDto identification = identificationMapper.findUsrNameByUserId(item.getId());\n            item.setIdentification(identification);\n            ///qq\\weichat第三方信息\n        }).await();\n    }\n    return item;\n}\n\n/***\n * 异步执行器\n */\npublic class AsyncExecuter {\n    /**\n     * 限制最多同时8个线程在运行\n     */\n    private static final int             MAX_THREAD_NUM = 8;\n    private static       ExecutorService executor       = Executors.newFixedThreadPool(MAX_THREAD_NUM);\n    private static       Logger          logger         = LoggerFactory.getLogger(AsyncExecuter.class);\n    private              CountDownLatch  countDownLatch;\n    private              long            timeout;\n    private              int             taskCount      = 0;\n    private              int             currentTask    = 0;\n\n    private AsyncExecuter(int count, long timeout) {\n        Assert.isTrue(count > 0, \"count greater than 0\");\n        this.timeout = timeout;\n        this.taskCount = count;\n        this.countDownLatch = new CountDownLatch(count);\n    }\n\n    /**\n     * @param count    执行任务数\n     * @param milltime 等待超时时间\n     * @return\n     */\n    public static AsyncExecuter init(int count, long milltime) {\n        return new AsyncExecuter(count, milltime);\n    }\n\n    public static AsyncExecuter init(int count) {\n        return new AsyncExecuter(count, -1);\n    }\n\n    /**\n     * 异步执行一个线程\n     *\n     * @param runnable\n     * @return\n     */\n    public AsyncExecuter execute(Runnable runnable) {\n        this.currentTask++;\n        if (this.currentTask > this.taskCount) {\n            throw new IllegalStateException(\"execute task nums can not greater then count\");\n        }\n        executor.execute(() -> {\n            try {\n                runnable.run();\n            } catch (Throwable e) {\n                logger.error(\"\", e);\n            } finally {\n                countDownLatch.countDown();\n            }\n        });\n        return this;\n    }\n\n    /**\n     * 阻塞直到所有子任务完成\n     */\n    public void await() {\n        try {\n            if (this.timeout == -1) {\n                countDownLatch.await();\n            } else {\n                countDownLatch.await(timeout, TimeUnit.MILLISECONDS);\n            }\n        } catch (Throwable e) {\n            logger.error(\"\", e);\n        }\n    }\n}\n```\n\n* 避免跨库关联数据\n\n++数据库是DRDS，数据量大概在3亿+，预计2年内增量到5亿+。优化前数据库超时导致基本不可执行，优化后可正常导数据++\n\n> DRDS海量数据导入ES的策略优化，DRDS对调用层隐藏了分库分表的复杂性，方便了方法调用的统一，但因为对调用者透明，开发同学很容易无意间写出全库扫描的sql，反而降低了效率。在我们数据迁移的场景中，需要扫描所有数据做全量迁移，所以这里先列出所有数据库，针对具体的库并行调用扫描提高效率。\n\n```\n列出所有分库\nmysql> SHOW TOPOLOGY FROM LJLTEST;\n+------+----------------+------------+\n| ID   | GROUP_NAME     | TABLE_NAME |\n+------+----------------+------------+\n|    0 | TDDL5_00_GROUP | ljltest_00 |\n|    1 | TDDL5_00_GROUP | ljltest_01 |\n|    2 | TDDL5_00_GROUP | ljltest_02 |\n|    3 | TDDL5_01_GROUP | ljltest_03 |\n|    4 | TDDL5_01_GROUP | ljltest_04 |\n|    5 | TDDL5_01_GROUP | ljltest_05 |\n|    6 | TDDL5_02_GROUP | ljltest_06 |\n|    7 | TDDL5_02_GROUP | ljltest_07 |\n|    8 | TDDL5_02_GROUP | ljltest_08 |\n|    9 | TDDL5_03_GROUP | ljltest_09 |\n|   10 | TDDL5_03_GROUP | ljltest_10 |\n|   11 | TDDL5_03_GROUP | ljltest_11 |\n+------+----------------+------------+\n12 rows in set (0.06 sec)\n\n从某分库查询数据\n/!TDDL:node='TDDL5_00_GROUP'*/ select * from ljltest_00;\n```\n\n### 其他工作\n* 增强组件对shardingJDBC分表扫描特性\n* 业务功能：优惠券、收货地址建立索引等\n\n## 总结\n\n**方法论**\n\n* 沿着业务的逻辑线路梳理流程节点，针对节点之间的通路，节点内部，用可量化的标准，找出瓶颈并优化。\n* 充分利用多核CPU的性能，多做并行处理\n* 使用批量调用接口替代单次调用接口，减少性能损耗\n* 优化SQL join的数量级(并非列举所有优化策略，仅仅是讲在此次完美压测用到的部分内容)\n\n## 其他大佬的建议\n1. 线程池资源释放没有处理；\n2. 建议采用callable与futrueTask；\n3. 数据同步锁；\n4. DB IO峰值检测；\n5. ES分片\n\n","source":"_posts/压测调优.md","raw":"---\ntitle: 压测性能调优总结\ndate: 2019-04-25 10:00:00\ntags: 性能优化\ncategories: 其他\n---\n\n> 来自公司同事压测性能调优的分享\n\n<!-- more -->\n\n\n## 前情提要\n完美中国项目进入压测环节，就是业务都做完啦，通过压测优化让系统性能达到设计标准，通过客户验收即可交付。这边有几个平衡点\n* 总体预算大体不变的框架下进行资源分配优化\n* 大体需求不变的前提下做功能效率优化\n\n> 基于这两点，盲目说~~性能不够加机器~~，~~砍功能说无法实现~~都是不可以的，压测的目的就是要攻克难关。\n\n## 优化场景\n\n### 数据同步效率优化\n#### 从问题出发\n> - mysql数据为什么要同步到es？\n\n#### 设计\n![压测性能调优_01](/image/压测性能调优_01.png)\n\n可能的瓶颈点\n（红字处\n\n#### 优化手段\n\n* 对数据进行多线程分片执行，对数据集进行分片，每个分片由单独线程执行，充分利用多核CPU的优势。\n\n++原先一个大表（2000w+数据）全量同步需要20+h，优化后在1h内同步完成++\n\n> 示例代码(非可执行代码)\n\n```\npublic class IndexExecutor<K, T>{\n    private static final int MAX_SAHRD_NUM = 32;\n    /**\n     * 最多32个线程\n     */\n    private static ExecutorService executor = Executors.newFixedThreadPool(MAX_SAHRD_NUM);\n\n    public IndexExecutor() {\n    }\n\n    private IndexExecutor(Params params) {\n        Assert.isTrue(params.shard < MAX_SAHRD_NUM, \"must small than MAX_SAHRD_NUM(32)\");\n        this.mapper = params.mapper;\n        this.mapping = params.mapping;\n        this.params = params;\n        super.setApplicationContext(context);\n        super.setMapping(this.mapping);\n        super.setMapper(this.mapper);\n    }\n\n    private Params params;\n    private BaseMapper mapper;\n    private TableToIndexMappingDto mapping;\n\n    public void build() {\n        // 非空校验\n        Objects.requireNonNull(params.mapper);\n        Objects.requireNonNull(params.mapping);\n        List<String> tableNames = this.findTableNames();\n\n        // 不阻塞调用请求\n        new Thread(() -> {\n            String indexAliasesName = this.mapping.getIndicesAliasesName();\n            String newIndexName = this.createIndexNewName(indexAliasesName);\n            this.createIndexAndMapping(newIndexName);\n            int shard = params.shard;\n            long begin = 0;\n            long[] counts = null;\n\n            // 遍历每个tableName\n            for (String tableName : tableNames) {\n                Long count = 0L;\n                begin = System.currentTimeMillis();\n                if (tableNames.size() > 1) {\n                    PartitionFeatureMapper partitionFeatureMapper = (PartitionFeatureMapper) mapper;\n                    count = partitionFeatureMapper.countAllByTableName(tableName);\n                } else {\n                    count = mapper.countAll();\n                }\n\n                counts = splitShard(shard, count);\n                CountDownLatch cd = new CountDownLatch(counts.length - 1);\n                for (int i = 0; i < counts.length; i++) {\n                    long segmentCount = counts[i];\n                    long lastCount = i == 0 ? 0L : counts[i - 1];\n                    logger.info(\"分片序号：{} 位置 {}-{} 开始\", i, lastCount, segmentCount);\n                    executor.execute(() -> {\n                        this.runShard(tableName, lastCount, segmentCount, newIndexName);\n                        cd.countDown();\n                        logger.info(\"{} 等待其他分片执行完毕，剩余分片数量 ：{}\", tableName, cd.getCount());\n                    });\n                    // 错开数据库io峰\n                    try {\n                        TimeUnit.SECONDS.sleep(1);\n                    } catch (InterruptedException e) {\n                        logger.error(\"\", e);\n                    }\n                }\n                try {\n                    cd.await();\n                } catch (InterruptedException e) {\n                    logger.error(\"{} 表，全量更新索引失败,{} \", tableName, newIndexName, e);\n                }\n            }\n            this.addOrUpdateIndexWithAliasesRef(indexAliasesName, newIndexName);\n            logger.info(\"迁移索引别名到新索引成功，alies {} index {}，耗时：{}ms\", indexAliasesName, newIndexName, System.currentTimeMillis() - begin);\n        }).start();\n    }\n\n    /**\n     * 如果是表名是着正则就按正则查出所有表名，\n     * 否则直接返回表名\n     *\n     * @return\n     */\n    public List<String> findTableNames() {\n        List<String> tableNames = null;\n        String tableName = this.mapping.getTableName();\n        if (this.mapper instanceof PartitionFeatureMapper) {\n            Connection connection = null;\n            String schema = null;\n            try {\n                // 这坨代码为了取库名\n                String jdbcUrl = this.params.dataSourceVo.getJdbcUrl();\n                String jdbcUserName = this.params.dataSourceVo.getJdbcUserName();\n                String jdbcUserPassword = this.params.dataSourceVo.getJdbcUserPassword();\n                connection = DriverManager.getConnection(jdbcUrl, jdbcUserName, jdbcUserPassword);\n                Field dbName = connection.getClass().getDeclaredField(\"dbName\");\n                dbName.setAccessible(true);\n                schema = String.valueOf(dbName.get(connection));\n            } catch (Throwable e) {\n                logger.error(\"\", e);\n            } finally {\n                if (connection != null) {\n                    try {\n                        connection.close();\n                    } catch (Throwable e) {\n                        logger.error(\"\", e);\n                    }\n                }\n            }\n            PartitionFeatureMapper partitionFeatureMapper = (PartitionFeatureMapper) this.mapper;\n            // 从该schema 查询所有表名\n            String tableRegex = tableName;\n            tableNames = partitionFeatureMapper.findTablesByRegex(schema, tableRegex);\n        } else if (this.mapper instanceof ExectuorMapper) {\n            tableNames = Lists.newArrayList(tableName);\n        }\n        return tableNames;\n    }\n\n    /**\n     * 每个分片的任务\n     *\n     * @param beginPos\n     * @param endPos\n     * @param indexName\n     */\n    private void runShard(String tableName, long beginPos, long endPos, String indexName) {\n        Map<String, String> map = null;\n        long count = endPos - beginPos;\n        if (this.mapper instanceof PartitionFeatureMapper) {\n            PartitionFeatureMapper mapper = (PartitionFeatureMapper) this.getMapper();\n            map = mapper.findMaxAndMinIdPartion(tableName, beginPos, count);\n        } else if (this.mapper instanceof ExectuorMapper) {\n            ExectuorMapper mapper = (ExectuorMapper) this.getMapper();\n            map = mapper.findMaxAndMinIdLimit(beginPos, count);\n        }\n        if (map == null || map.isEmpty()) {\n            logger.warn(\"beginPos{},count{},indexName{} map empty\", beginPos, endPos, indexName);\n            return;\n        }\n        String minId = String.valueOf(map.get(\"minId\"));\n        String actualMaxId = null;\n        long scanedCount = 0L;\n        long actualCount = 0L;\n        int batch = (int) (endPos > 1000 ? 1000 : endPos);\n        int runtime = 0;\n        List list = null;\n        do {\n            if (this.mapper instanceof PartitionFeatureMapper) {\n                PartitionFeatureMapper mapper = (PartitionFeatureMapper) this.getMapper();\n                actualMaxId = String.valueOf(mapper.findMaxIdPartition(tableName, minId, batch));\n\n                list = mapper.findByMaxAndMinIdPartition(tableName, minId, actualMaxId);\n\n            } else if (this.mapper instanceof ExectuorMapper) {\n                actualMaxId = String.valueOf(this.getMapper().findMaxId(minId, batch));\n                //mapper用dto接收\n                list = this.getMapper().findByMaxAndMinId(minId, actualMaxId);\n            }\n            if (logger.isDebugEnabled()) {\n                logger.info(\"segment[{}-{}] load from db success,minId:{}  maxId:{}\", beginPos, endPos, minId, actualMaxId);\n            }\n            if (list.isEmpty()) {\n                break;\n            }\n            scanedCount += list.size();\n\n            this.batchAddIndexByMapParams(indexName, list);\n\n            if (logger.isDebugEnabled()) {\n                logger.info(\"segment[{}-{}] put in es success,minId:{}  maxId:{}\", beginPos, endPos, minId, actualMaxId);\n            }\n            minId = actualMaxId;\n            actualCount += (long) list.size();\n            ++runtime;\n        } while (scanedCount < count);\n\n        logger.info(\"db record count={},fetch record count={},runtime={}\", new Object[]{endPos, actualCount, runtime});\n    }\n\n    /**\n     * 重写批量导入es逻辑\n     *\n     * @param newIndexName\n     * @param list\n     */\n    protected void batchAddIndexByMapParams(String newIndexName, List<Map<String, Object>> list) {\n        if (list != null && !list.isEmpty()) {\n            String pattern = \"yyyy-MM-dd HH:mm:ss\";\n            List<IndexDocContentVo> docs = list.parallelStream().filter(doc -> doc != null).collect(Collectors.toList());\n            IndexDocumentVo indexDocumentVo = new IndexDocumentVo(newIndexName, this.mapping.getIndicesTypeName(), docs);\n            this.getSearchIndexService().addData(indexDocumentVo);\n        }\n    }\n\n    /**\n     * 根据总数 分片数 获取每个分片边界\n     *\n     * @param shardNums\n     * @param total\n     * @return\n     */\n    public static long[] splitShard(int shardNums, long total) {\n        if (total <= shardNums || total <= 1000) {\n            return new long[]{total};\n        }\n        long constTotal = total;\n        int shardIndex = 1;\n        long[] counts = new long[shardNums];\n        long everShard = total / shardNums;\n        while (constTotal - everShard * shardIndex > 0) {\n            long newTotal = total - everShard * shardIndex;\n            counts[shardIndex - 1] = total - newTotal;\n            total = newTotal;\n            shardIndex++;\n        }\n        counts[shardNums - 1] = constTotal;\n        return counts;\n    }\n\n    public static class Params {\n        BaseMapper mapper;\n        DataSourceVo dataSourceVo;\n        TableToIndexMappingDto mapping;\n        Wrapper wrapper;\n        WrapperDto wrapperDto;\n        ListWrapper listWrapper;\n        ListWrapperDto listWrapperDto;\n\n        /**\n         * 这里分片 4 * 2(核)片 ，每个线程取一部分数据，各自开始load\n         */\n        int shard = 8;\n\n        public void runIndex() {\n            IndexExecutor indexExecutor = new IndexExecutor(this);\n            indexExecutor.build();\n        }\n\n        public IndexExecutor build() {\n            IndexExecutor indexExecutor = new IndexExecutor(this);\n            return indexExecutor;\n        }\n\n        public Params withMapper(BaseMapper mapper) {\n            this.mapper = mapper;\n            return this;\n        }\n\n        public Params withMapping(TableToIndexMappingDto mapping) {\n            this.mapping = mapping;\n            return this;\n        }\n\n        public Params withShard(int shard) {\n            this.shard = shard;\n            return this;\n        }\n\n        public Params withWrapper(Wrapper wrapper) {\n            this.wrapper = wrapper;\n            return this;\n        }\n\n        public Params withWrapperDto(WrapperDto wrapperDto) {\n            this.wrapperDto = wrapperDto;\n            return this;\n        }\n\n        public Params withDataSourceVo(String beanName) {\n            DataSourceVo bean = context.getBean(beanName, DataSourceVo.class);\n            this.dataSourceVo = bean;\n            return this;\n        }\n\n        public Params withListMapper(ListWrapper listMapper) {\n            this.listWrapper = listMapper;\n            return this;\n        }\n\n        public Params withListDtoMapper(ListWrapperDto listMapper) {\n            this.listWrapperDto = listMapper;\n            return this;\n        }\n    }\n\n    public interface Wrapper {\n        Map<String, Object> wrapDoc(Map<String, Object> item);\n    }\n\n    public interface ListWrapper {\n        List<Map<String, Object>> wrapBatchDoc(List<Map<String, Object>> item);\n    }\n\n    public interface ListWrapperDto {\n        List<Map<String, Object>> wrapBatchDoc(List item);\n    }\n\n    public interface WrapperDto<T> {\n        T wrapDto(T item);\n\n        Class getTargetClass();\n    }\n}\n```\n\n以上代码的核心点\n> 获取分片边界 long[] splitShard(int shardNums, long total)\n\n> 取数据时按where取数据，而不是limit取数据，可以命中拆分键（存疑。。\n\n> 线程池 & JVM最佳线程数量 cpu核数 * 1.5 （存疑。。\n\n#### SQL调优\n\n* 减少数据库交互次数\n\n++原先一次数据组装耗时100s-500s不可控，优化后稳定在1s左右++\n\n> 查询数据库的过程如果涉及for循环，看是否可以修改for循环取数据为in查询，减少数据库交互次数\n\n**原先**\n\n```\nfor (UserDto docValue : docValues) {\n    UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(docValue.getPersonId());\n    //...\n}\n```\n\n**优化后**\n\n```\nString personIds = docValues.stream()\n                .filter(item -> item != null && item.getPersonId() != null)\n                .map(item -> item.getPersonId().toString()).collect(Collectors.joining(\",\"));\nList<UserPersonalInfoDto> userPersonInfos = userPersonalInfoMapper.findByIds(personIds);\nMap<Long, UserPersonalInfoDto> userPersonalInfoMap = userPersonInfos.stream().collect(Collectors.toMap(UserPersonalInfoDto::getId, Function.identity()));\n```\n\n> 同库情况下使用join代替多次数据库查询。用子查询优化主表，核心是先筛选，再join。减少表关联的数量级。\n\n```\nSELECT\n    b.id,\n    b.`level`,\n    b.max_level,\n    b.`status`,\n    b.last_active_month,\n    b.create_time,\n    b.create_person,\n    b.update_person,\n    b.update_time,\n    b.tenant_id,\n    b.instance_id,\n    b.create_time\nFROM\n(\n    SELECT member_id from mm_card_map_user where dr = 0 and user_id in (${userIds}) \n) as a\nLEFT JOIN mm_member b ON b.id = a.member_id\nwhere b.dr = 0\nGROUP by b.id;\n```\n\n* 把多数据源聚合的过程的同步调用异步化\n\n**原来代码**\n\n```\n/**\n * 补全信息\n *\n * @param item\n * @author zhou.shilong\n */\npublic UserDto wrapFullItem(UserDto item) {\n    if (item != null && null != item.getId()) {\n        //personal\n        UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(item.getPersonId());\n        if (null != personalInfo) {\n            item.setPersonalInfo(personalInfo);\n        }\n        //member\n        MemberDto memberDto = memberMapper.findByUserId(item.getId());\n        if (null != memberDto) {\n            item.setMember(memberDto);\n        }\n\n        //userRef\n        List<UserRefDto> usernames = userMapper.findUsrNameByUserId(item.getId());\n        List<UserRefDto> userphones = userMapper.findUserPhoneByUserId(item.getId());\n        List<UserRefDto> userCardNums = userMapper.findUserCardNumByUserId(item.getId());\n        item.setUserRName(usernames);\n        item.setUserRPhone(userphones);\n        item.setUserRCardnum(userCardNums);\n\n        ///usercloud云商信息<单独同步，查询聚合>\n        ///identification 身份证信息\n        UserIdentificationDto identification = identificationMapper.findUsrNameByUserId(item.getId());\n        item.setIdentification(identification);\n        ///qq\\weichat第三方信息\n    }\n\n    return item;\n}\n```\n\n**优化后**\n\n```\n/**\n * 补全信息\n *\n * @param item\n * @author zhou.shilong\n */\npublic UserDto wrapFullItem(UserDto item) {\n    if (item != null && null != item.getId()) {\n        AsyncExecuter.init(4).execute(() -> {\n            //personal\n            UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(item.getPersonId());\n            if (null != personalInfo) {\n                item.setPersonalInfo(personalInfo);\n            }\n        }).execute(() -> {\n            //member\n            MemberDto memberDto = memberMapper.findByUserId(item.getId());\n            if (null != memberDto) {\n                item.setMember(memberDto);\n            }\n        }).execute(() -> {\n            //userRef\n            List<UserRefDto> userCardNums = userMapper.findByUserId(\"us_user_r_cardnum\", item.getId());\n            List<UserRefDto> userphones = userMapper.findByUserId(\"us_user_r_phone\", item.getId());\n            List<UserRefDto> usernames = userMapper.findByUserId(\"us_user_r_username\", item.getId());\n            item.setUserRName(usernames);\n            item.setUserRPhone(userphones);\n            item.setUserRCardnum(userCardNums);\n        }).execute(() -> {\n            ///usercloud云商信息<单独同步，查询聚合>\n            ///identification 身份证信息\n            UserIdentificationDto identification = identificationMapper.findUsrNameByUserId(item.getId());\n            item.setIdentification(identification);\n            ///qq\\weichat第三方信息\n        }).await();\n    }\n    return item;\n}\n\n/***\n * 异步执行器\n */\npublic class AsyncExecuter {\n    /**\n     * 限制最多同时8个线程在运行\n     */\n    private static final int             MAX_THREAD_NUM = 8;\n    private static       ExecutorService executor       = Executors.newFixedThreadPool(MAX_THREAD_NUM);\n    private static       Logger          logger         = LoggerFactory.getLogger(AsyncExecuter.class);\n    private              CountDownLatch  countDownLatch;\n    private              long            timeout;\n    private              int             taskCount      = 0;\n    private              int             currentTask    = 0;\n\n    private AsyncExecuter(int count, long timeout) {\n        Assert.isTrue(count > 0, \"count greater than 0\");\n        this.timeout = timeout;\n        this.taskCount = count;\n        this.countDownLatch = new CountDownLatch(count);\n    }\n\n    /**\n     * @param count    执行任务数\n     * @param milltime 等待超时时间\n     * @return\n     */\n    public static AsyncExecuter init(int count, long milltime) {\n        return new AsyncExecuter(count, milltime);\n    }\n\n    public static AsyncExecuter init(int count) {\n        return new AsyncExecuter(count, -1);\n    }\n\n    /**\n     * 异步执行一个线程\n     *\n     * @param runnable\n     * @return\n     */\n    public AsyncExecuter execute(Runnable runnable) {\n        this.currentTask++;\n        if (this.currentTask > this.taskCount) {\n            throw new IllegalStateException(\"execute task nums can not greater then count\");\n        }\n        executor.execute(() -> {\n            try {\n                runnable.run();\n            } catch (Throwable e) {\n                logger.error(\"\", e);\n            } finally {\n                countDownLatch.countDown();\n            }\n        });\n        return this;\n    }\n\n    /**\n     * 阻塞直到所有子任务完成\n     */\n    public void await() {\n        try {\n            if (this.timeout == -1) {\n                countDownLatch.await();\n            } else {\n                countDownLatch.await(timeout, TimeUnit.MILLISECONDS);\n            }\n        } catch (Throwable e) {\n            logger.error(\"\", e);\n        }\n    }\n}\n```\n\n* 避免跨库关联数据\n\n++数据库是DRDS，数据量大概在3亿+，预计2年内增量到5亿+。优化前数据库超时导致基本不可执行，优化后可正常导数据++\n\n> DRDS海量数据导入ES的策略优化，DRDS对调用层隐藏了分库分表的复杂性，方便了方法调用的统一，但因为对调用者透明，开发同学很容易无意间写出全库扫描的sql，反而降低了效率。在我们数据迁移的场景中，需要扫描所有数据做全量迁移，所以这里先列出所有数据库，针对具体的库并行调用扫描提高效率。\n\n```\n列出所有分库\nmysql> SHOW TOPOLOGY FROM LJLTEST;\n+------+----------------+------------+\n| ID   | GROUP_NAME     | TABLE_NAME |\n+------+----------------+------------+\n|    0 | TDDL5_00_GROUP | ljltest_00 |\n|    1 | TDDL5_00_GROUP | ljltest_01 |\n|    2 | TDDL5_00_GROUP | ljltest_02 |\n|    3 | TDDL5_01_GROUP | ljltest_03 |\n|    4 | TDDL5_01_GROUP | ljltest_04 |\n|    5 | TDDL5_01_GROUP | ljltest_05 |\n|    6 | TDDL5_02_GROUP | ljltest_06 |\n|    7 | TDDL5_02_GROUP | ljltest_07 |\n|    8 | TDDL5_02_GROUP | ljltest_08 |\n|    9 | TDDL5_03_GROUP | ljltest_09 |\n|   10 | TDDL5_03_GROUP | ljltest_10 |\n|   11 | TDDL5_03_GROUP | ljltest_11 |\n+------+----------------+------------+\n12 rows in set (0.06 sec)\n\n从某分库查询数据\n/!TDDL:node='TDDL5_00_GROUP'*/ select * from ljltest_00;\n```\n\n### 其他工作\n* 增强组件对shardingJDBC分表扫描特性\n* 业务功能：优惠券、收货地址建立索引等\n\n## 总结\n\n**方法论**\n\n* 沿着业务的逻辑线路梳理流程节点，针对节点之间的通路，节点内部，用可量化的标准，找出瓶颈并优化。\n* 充分利用多核CPU的性能，多做并行处理\n* 使用批量调用接口替代单次调用接口，减少性能损耗\n* 优化SQL join的数量级(并非列举所有优化策略，仅仅是讲在此次完美压测用到的部分内容)\n\n## 其他大佬的建议\n1. 线程池资源释放没有处理；\n2. 建议采用callable与futrueTask；\n3. 数据同步锁；\n4. DB IO峰值检测；\n5. ES分片\n\n","slug":"压测调优","published":1,"updated":"2019-08-26T07:57:30.980Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl6q005gqotnmm44rypf","content":"<blockquote>\n<p>来自公司同事压测性能调优的分享</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"前情提要\"><a href=\"#前情提要\" class=\"headerlink\" title=\"前情提要\"></a>前情提要</h2><p>完美中国项目进入压测环节，就是业务都做完啦，通过压测优化让系统性能达到设计标准，通过客户验收即可交付。这边有几个平衡点</p>\n<ul>\n<li>总体预算大体不变的框架下进行资源分配优化</li>\n<li>大体需求不变的前提下做功能效率优化</li>\n</ul>\n<blockquote>\n<p>基于这两点，盲目说<del>性能不够加机器</del>，<del>砍功能说无法实现</del>都是不可以的，压测的目的就是要攻克难关。</p>\n</blockquote>\n<h2 id=\"优化场景\"><a href=\"#优化场景\" class=\"headerlink\" title=\"优化场景\"></a>优化场景</h2><h3 id=\"数据同步效率优化\"><a href=\"#数据同步效率优化\" class=\"headerlink\" title=\"数据同步效率优化\"></a>数据同步效率优化</h3><h4 id=\"从问题出发\"><a href=\"#从问题出发\" class=\"headerlink\" title=\"从问题出发\"></a>从问题出发</h4><blockquote>\n<ul>\n<li>mysql数据为什么要同步到es？</li>\n</ul>\n</blockquote>\n<h4 id=\"设计\"><a href=\"#设计\" class=\"headerlink\" title=\"设计\"></a>设计</h4><p><img src=\"/image/压测性能调优_01.png\" alt=\"压测性能调优_01\"></p>\n<p>可能的瓶颈点<br>（红字处</p>\n<h4 id=\"优化手段\"><a href=\"#优化手段\" class=\"headerlink\" title=\"优化手段\"></a>优化手段</h4><ul>\n<li>对数据进行多线程分片执行，对数据集进行分片，每个分片由单独线程执行，充分利用多核CPU的优势。</li>\n</ul>\n<p>++原先一个大表（2000w+数据）全量同步需要20+h，优化后在1h内同步完成++</p>\n<blockquote>\n<p>示例代码(非可执行代码)</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class IndexExecutor&lt;K, T&gt;&#123;</span><br><span class=\"line\">    private static final int MAX_SAHRD_NUM = 32;</span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 最多32个线程</span><br><span class=\"line\">     */</span><br><span class=\"line\">    private static ExecutorService executor = Executors.newFixedThreadPool(MAX_SAHRD_NUM);</span><br><span class=\"line\"></span><br><span class=\"line\">    public IndexExecutor() &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    private IndexExecutor(Params params) &#123;</span><br><span class=\"line\">        Assert.isTrue(params.shard &lt; MAX_SAHRD_NUM, &quot;must small than MAX_SAHRD_NUM(32)&quot;);</span><br><span class=\"line\">        this.mapper = params.mapper;</span><br><span class=\"line\">        this.mapping = params.mapping;</span><br><span class=\"line\">        this.params = params;</span><br><span class=\"line\">        super.setApplicationContext(context);</span><br><span class=\"line\">        super.setMapping(this.mapping);</span><br><span class=\"line\">        super.setMapper(this.mapper);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    private Params params;</span><br><span class=\"line\">    private BaseMapper mapper;</span><br><span class=\"line\">    private TableToIndexMappingDto mapping;</span><br><span class=\"line\"></span><br><span class=\"line\">    public void build() &#123;</span><br><span class=\"line\">        // 非空校验</span><br><span class=\"line\">        Objects.requireNonNull(params.mapper);</span><br><span class=\"line\">        Objects.requireNonNull(params.mapping);</span><br><span class=\"line\">        List&lt;String&gt; tableNames = this.findTableNames();</span><br><span class=\"line\"></span><br><span class=\"line\">        // 不阻塞调用请求</span><br><span class=\"line\">        new Thread(() -&gt; &#123;</span><br><span class=\"line\">            String indexAliasesName = this.mapping.getIndicesAliasesName();</span><br><span class=\"line\">            String newIndexName = this.createIndexNewName(indexAliasesName);</span><br><span class=\"line\">            this.createIndexAndMapping(newIndexName);</span><br><span class=\"line\">            int shard = params.shard;</span><br><span class=\"line\">            long begin = 0;</span><br><span class=\"line\">            long[] counts = null;</span><br><span class=\"line\"></span><br><span class=\"line\">            // 遍历每个tableName</span><br><span class=\"line\">            for (String tableName : tableNames) &#123;</span><br><span class=\"line\">                Long count = 0L;</span><br><span class=\"line\">                begin = System.currentTimeMillis();</span><br><span class=\"line\">                if (tableNames.size() &gt; 1) &#123;</span><br><span class=\"line\">                    PartitionFeatureMapper partitionFeatureMapper = (PartitionFeatureMapper) mapper;</span><br><span class=\"line\">                    count = partitionFeatureMapper.countAllByTableName(tableName);</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    count = mapper.countAll();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                counts = splitShard(shard, count);</span><br><span class=\"line\">                CountDownLatch cd = new CountDownLatch(counts.length - 1);</span><br><span class=\"line\">                for (int i = 0; i &lt; counts.length; i++) &#123;</span><br><span class=\"line\">                    long segmentCount = counts[i];</span><br><span class=\"line\">                    long lastCount = i == 0 ? 0L : counts[i - 1];</span><br><span class=\"line\">                    logger.info(&quot;分片序号：&#123;&#125; 位置 &#123;&#125;-&#123;&#125; 开始&quot;, i, lastCount, segmentCount);</span><br><span class=\"line\">                    executor.execute(() -&gt; &#123;</span><br><span class=\"line\">                        this.runShard(tableName, lastCount, segmentCount, newIndexName);</span><br><span class=\"line\">                        cd.countDown();</span><br><span class=\"line\">                        logger.info(&quot;&#123;&#125; 等待其他分片执行完毕，剩余分片数量 ：&#123;&#125;&quot;, tableName, cd.getCount());</span><br><span class=\"line\">                    &#125;);</span><br><span class=\"line\">                    // 错开数据库io峰</span><br><span class=\"line\">                    try &#123;</span><br><span class=\"line\">                        TimeUnit.SECONDS.sleep(1);</span><br><span class=\"line\">                    &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">                        logger.error(&quot;&quot;, e);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    cd.await();</span><br><span class=\"line\">                &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">                    logger.error(&quot;&#123;&#125; 表，全量更新索引失败,&#123;&#125; &quot;, tableName, newIndexName, e);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            this.addOrUpdateIndexWithAliasesRef(indexAliasesName, newIndexName);</span><br><span class=\"line\">            logger.info(&quot;迁移索引别名到新索引成功，alies &#123;&#125; index &#123;&#125;，耗时：&#123;&#125;ms&quot;, indexAliasesName, newIndexName, System.currentTimeMillis() - begin);</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 如果是表名是着正则就按正则查出所有表名，</span><br><span class=\"line\">     * 否则直接返回表名</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public List&lt;String&gt; findTableNames() &#123;</span><br><span class=\"line\">        List&lt;String&gt; tableNames = null;</span><br><span class=\"line\">        String tableName = this.mapping.getTableName();</span><br><span class=\"line\">        if (this.mapper instanceof PartitionFeatureMapper) &#123;</span><br><span class=\"line\">            Connection connection = null;</span><br><span class=\"line\">            String schema = null;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                // 这坨代码为了取库名</span><br><span class=\"line\">                String jdbcUrl = this.params.dataSourceVo.getJdbcUrl();</span><br><span class=\"line\">                String jdbcUserName = this.params.dataSourceVo.getJdbcUserName();</span><br><span class=\"line\">                String jdbcUserPassword = this.params.dataSourceVo.getJdbcUserPassword();</span><br><span class=\"line\">                connection = DriverManager.getConnection(jdbcUrl, jdbcUserName, jdbcUserPassword);</span><br><span class=\"line\">                Field dbName = connection.getClass().getDeclaredField(&quot;dbName&quot;);</span><br><span class=\"line\">                dbName.setAccessible(true);</span><br><span class=\"line\">                schema = String.valueOf(dbName.get(connection));</span><br><span class=\"line\">            &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                logger.error(&quot;&quot;, e);</span><br><span class=\"line\">            &#125; finally &#123;</span><br><span class=\"line\">                if (connection != null) &#123;</span><br><span class=\"line\">                    try &#123;</span><br><span class=\"line\">                        connection.close();</span><br><span class=\"line\">                    &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                        logger.error(&quot;&quot;, e);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            PartitionFeatureMapper partitionFeatureMapper = (PartitionFeatureMapper) this.mapper;</span><br><span class=\"line\">            // 从该schema 查询所有表名</span><br><span class=\"line\">            String tableRegex = tableName;</span><br><span class=\"line\">            tableNames = partitionFeatureMapper.findTablesByRegex(schema, tableRegex);</span><br><span class=\"line\">        &#125; else if (this.mapper instanceof ExectuorMapper) &#123;</span><br><span class=\"line\">            tableNames = Lists.newArrayList(tableName);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return tableNames;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 每个分片的任务</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param beginPos</span><br><span class=\"line\">     * @param endPos</span><br><span class=\"line\">     * @param indexName</span><br><span class=\"line\">     */</span><br><span class=\"line\">    private void runShard(String tableName, long beginPos, long endPos, String indexName) &#123;</span><br><span class=\"line\">        Map&lt;String, String&gt; map = null;</span><br><span class=\"line\">        long count = endPos - beginPos;</span><br><span class=\"line\">        if (this.mapper instanceof PartitionFeatureMapper) &#123;</span><br><span class=\"line\">            PartitionFeatureMapper mapper = (PartitionFeatureMapper) this.getMapper();</span><br><span class=\"line\">            map = mapper.findMaxAndMinIdPartion(tableName, beginPos, count);</span><br><span class=\"line\">        &#125; else if (this.mapper instanceof ExectuorMapper) &#123;</span><br><span class=\"line\">            ExectuorMapper mapper = (ExectuorMapper) this.getMapper();</span><br><span class=\"line\">            map = mapper.findMaxAndMinIdLimit(beginPos, count);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (map == null || map.isEmpty()) &#123;</span><br><span class=\"line\">            logger.warn(&quot;beginPos&#123;&#125;,count&#123;&#125;,indexName&#123;&#125; map empty&quot;, beginPos, endPos, indexName);</span><br><span class=\"line\">            return;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        String minId = String.valueOf(map.get(&quot;minId&quot;));</span><br><span class=\"line\">        String actualMaxId = null;</span><br><span class=\"line\">        long scanedCount = 0L;</span><br><span class=\"line\">        long actualCount = 0L;</span><br><span class=\"line\">        int batch = (int) (endPos &gt; 1000 ? 1000 : endPos);</span><br><span class=\"line\">        int runtime = 0;</span><br><span class=\"line\">        List list = null;</span><br><span class=\"line\">        do &#123;</span><br><span class=\"line\">            if (this.mapper instanceof PartitionFeatureMapper) &#123;</span><br><span class=\"line\">                PartitionFeatureMapper mapper = (PartitionFeatureMapper) this.getMapper();</span><br><span class=\"line\">                actualMaxId = String.valueOf(mapper.findMaxIdPartition(tableName, minId, batch));</span><br><span class=\"line\"></span><br><span class=\"line\">                list = mapper.findByMaxAndMinIdPartition(tableName, minId, actualMaxId);</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125; else if (this.mapper instanceof ExectuorMapper) &#123;</span><br><span class=\"line\">                actualMaxId = String.valueOf(this.getMapper().findMaxId(minId, batch));</span><br><span class=\"line\">                //mapper用dto接收</span><br><span class=\"line\">                list = this.getMapper().findByMaxAndMinId(minId, actualMaxId);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">                logger.info(&quot;segment[&#123;&#125;-&#123;&#125;] load from db success,minId:&#123;&#125;  maxId:&#123;&#125;&quot;, beginPos, endPos, minId, actualMaxId);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (list.isEmpty()) &#123;</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            scanedCount += list.size();</span><br><span class=\"line\"></span><br><span class=\"line\">            this.batchAddIndexByMapParams(indexName, list);</span><br><span class=\"line\"></span><br><span class=\"line\">            if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">                logger.info(&quot;segment[&#123;&#125;-&#123;&#125;] put in es success,minId:&#123;&#125;  maxId:&#123;&#125;&quot;, beginPos, endPos, minId, actualMaxId);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            minId = actualMaxId;</span><br><span class=\"line\">            actualCount += (long) list.size();</span><br><span class=\"line\">            ++runtime;</span><br><span class=\"line\">        &#125; while (scanedCount &lt; count);</span><br><span class=\"line\"></span><br><span class=\"line\">        logger.info(&quot;db record count=&#123;&#125;,fetch record count=&#123;&#125;,runtime=&#123;&#125;&quot;, new Object[]&#123;endPos, actualCount, runtime&#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 重写批量导入es逻辑</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param newIndexName</span><br><span class=\"line\">     * @param list</span><br><span class=\"line\">     */</span><br><span class=\"line\">    protected void batchAddIndexByMapParams(String newIndexName, List&lt;Map&lt;String, Object&gt;&gt; list) &#123;</span><br><span class=\"line\">        if (list != null &amp;&amp; !list.isEmpty()) &#123;</span><br><span class=\"line\">            String pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;;</span><br><span class=\"line\">            List&lt;IndexDocContentVo&gt; docs = list.parallelStream().filter(doc -&gt; doc != null).collect(Collectors.toList());</span><br><span class=\"line\">            IndexDocumentVo indexDocumentVo = new IndexDocumentVo(newIndexName, this.mapping.getIndicesTypeName(), docs);</span><br><span class=\"line\">            this.getSearchIndexService().addData(indexDocumentVo);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 根据总数 分片数 获取每个分片边界</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param shardNums</span><br><span class=\"line\">     * @param total</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public static long[] splitShard(int shardNums, long total) &#123;</span><br><span class=\"line\">        if (total &lt;= shardNums || total &lt;= 1000) &#123;</span><br><span class=\"line\">            return new long[]&#123;total&#125;;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        long constTotal = total;</span><br><span class=\"line\">        int shardIndex = 1;</span><br><span class=\"line\">        long[] counts = new long[shardNums];</span><br><span class=\"line\">        long everShard = total / shardNums;</span><br><span class=\"line\">        while (constTotal - everShard * shardIndex &gt; 0) &#123;</span><br><span class=\"line\">            long newTotal = total - everShard * shardIndex;</span><br><span class=\"line\">            counts[shardIndex - 1] = total - newTotal;</span><br><span class=\"line\">            total = newTotal;</span><br><span class=\"line\">            shardIndex++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        counts[shardNums - 1] = constTotal;</span><br><span class=\"line\">        return counts;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public static class Params &#123;</span><br><span class=\"line\">        BaseMapper mapper;</span><br><span class=\"line\">        DataSourceVo dataSourceVo;</span><br><span class=\"line\">        TableToIndexMappingDto mapping;</span><br><span class=\"line\">        Wrapper wrapper;</span><br><span class=\"line\">        WrapperDto wrapperDto;</span><br><span class=\"line\">        ListWrapper listWrapper;</span><br><span class=\"line\">        ListWrapperDto listWrapperDto;</span><br><span class=\"line\"></span><br><span class=\"line\">        /**</span><br><span class=\"line\">         * 这里分片 4 * 2(核)片 ，每个线程取一部分数据，各自开始load</span><br><span class=\"line\">         */</span><br><span class=\"line\">        int shard = 8;</span><br><span class=\"line\"></span><br><span class=\"line\">        public void runIndex() &#123;</span><br><span class=\"line\">            IndexExecutor indexExecutor = new IndexExecutor(this);</span><br><span class=\"line\">            indexExecutor.build();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public IndexExecutor build() &#123;</span><br><span class=\"line\">            IndexExecutor indexExecutor = new IndexExecutor(this);</span><br><span class=\"line\">            return indexExecutor;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withMapper(BaseMapper mapper) &#123;</span><br><span class=\"line\">            this.mapper = mapper;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withMapping(TableToIndexMappingDto mapping) &#123;</span><br><span class=\"line\">            this.mapping = mapping;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withShard(int shard) &#123;</span><br><span class=\"line\">            this.shard = shard;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withWrapper(Wrapper wrapper) &#123;</span><br><span class=\"line\">            this.wrapper = wrapper;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withWrapperDto(WrapperDto wrapperDto) &#123;</span><br><span class=\"line\">            this.wrapperDto = wrapperDto;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withDataSourceVo(String beanName) &#123;</span><br><span class=\"line\">            DataSourceVo bean = context.getBean(beanName, DataSourceVo.class);</span><br><span class=\"line\">            this.dataSourceVo = bean;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withListMapper(ListWrapper listMapper) &#123;</span><br><span class=\"line\">            this.listWrapper = listMapper;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withListDtoMapper(ListWrapperDto listMapper) &#123;</span><br><span class=\"line\">            this.listWrapperDto = listMapper;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public interface Wrapper &#123;</span><br><span class=\"line\">        Map&lt;String, Object&gt; wrapDoc(Map&lt;String, Object&gt; item);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public interface ListWrapper &#123;</span><br><span class=\"line\">        List&lt;Map&lt;String, Object&gt;&gt; wrapBatchDoc(List&lt;Map&lt;String, Object&gt;&gt; item);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public interface ListWrapperDto &#123;</span><br><span class=\"line\">        List&lt;Map&lt;String, Object&gt;&gt; wrapBatchDoc(List item);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public interface WrapperDto&lt;T&gt; &#123;</span><br><span class=\"line\">        T wrapDto(T item);</span><br><span class=\"line\"></span><br><span class=\"line\">        Class getTargetClass();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上代码的核心点</p>\n<blockquote>\n<p>获取分片边界 long[] splitShard(int shardNums, long total)</p>\n</blockquote>\n<blockquote>\n<p>取数据时按where取数据，而不是limit取数据，可以命中拆分键（存疑。。</p>\n</blockquote>\n<blockquote>\n<p>线程池 &amp; JVM最佳线程数量 cpu核数 * 1.5 （存疑。。</p>\n</blockquote>\n<h4 id=\"SQL调优\"><a href=\"#SQL调优\" class=\"headerlink\" title=\"SQL调优\"></a>SQL调优</h4><ul>\n<li>减少数据库交互次数</li>\n</ul>\n<p>++原先一次数据组装耗时100s-500s不可控，优化后稳定在1s左右++</p>\n<blockquote>\n<p>查询数据库的过程如果涉及for循环，看是否可以修改for循环取数据为in查询，减少数据库交互次数</p>\n</blockquote>\n<p><strong>原先</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for (UserDto docValue : docValues) &#123;</span><br><span class=\"line\">    UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(docValue.getPersonId());</span><br><span class=\"line\">    //...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>优化后</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String personIds = docValues.stream()</span><br><span class=\"line\">                .filter(item -&gt; item != null &amp;&amp; item.getPersonId() != null)</span><br><span class=\"line\">                .map(item -&gt; item.getPersonId().toString()).collect(Collectors.joining(&quot;,&quot;));</span><br><span class=\"line\">List&lt;UserPersonalInfoDto&gt; userPersonInfos = userPersonalInfoMapper.findByIds(personIds);</span><br><span class=\"line\">Map&lt;Long, UserPersonalInfoDto&gt; userPersonalInfoMap = userPersonInfos.stream().collect(Collectors.toMap(UserPersonalInfoDto::getId, Function.identity()));</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>同库情况下使用join代替多次数据库查询。用子查询优化主表，核心是先筛选，再join。减少表关联的数量级。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT</span><br><span class=\"line\">    b.id,</span><br><span class=\"line\">    b.`level`,</span><br><span class=\"line\">    b.max_level,</span><br><span class=\"line\">    b.`status`,</span><br><span class=\"line\">    b.last_active_month,</span><br><span class=\"line\">    b.create_time,</span><br><span class=\"line\">    b.create_person,</span><br><span class=\"line\">    b.update_person,</span><br><span class=\"line\">    b.update_time,</span><br><span class=\"line\">    b.tenant_id,</span><br><span class=\"line\">    b.instance_id,</span><br><span class=\"line\">    b.create_time</span><br><span class=\"line\">FROM</span><br><span class=\"line\">(</span><br><span class=\"line\">    SELECT member_id from mm_card_map_user where dr = 0 and user_id in ($&#123;userIds&#125;) </span><br><span class=\"line\">) as a</span><br><span class=\"line\">LEFT JOIN mm_member b ON b.id = a.member_id</span><br><span class=\"line\">where b.dr = 0</span><br><span class=\"line\">GROUP by b.id;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>把多数据源聚合的过程的同步调用异步化</li>\n</ul>\n<p><strong>原来代码</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * 补全信息</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param item</span><br><span class=\"line\"> * @author zhou.shilong</span><br><span class=\"line\"> */</span><br><span class=\"line\">public UserDto wrapFullItem(UserDto item) &#123;</span><br><span class=\"line\">    if (item != null &amp;&amp; null != item.getId()) &#123;</span><br><span class=\"line\">        //personal</span><br><span class=\"line\">        UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(item.getPersonId());</span><br><span class=\"line\">        if (null != personalInfo) &#123;</span><br><span class=\"line\">            item.setPersonalInfo(personalInfo);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //member</span><br><span class=\"line\">        MemberDto memberDto = memberMapper.findByUserId(item.getId());</span><br><span class=\"line\">        if (null != memberDto) &#123;</span><br><span class=\"line\">            item.setMember(memberDto);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        //userRef</span><br><span class=\"line\">        List&lt;UserRefDto&gt; usernames = userMapper.findUsrNameByUserId(item.getId());</span><br><span class=\"line\">        List&lt;UserRefDto&gt; userphones = userMapper.findUserPhoneByUserId(item.getId());</span><br><span class=\"line\">        List&lt;UserRefDto&gt; userCardNums = userMapper.findUserCardNumByUserId(item.getId());</span><br><span class=\"line\">        item.setUserRName(usernames);</span><br><span class=\"line\">        item.setUserRPhone(userphones);</span><br><span class=\"line\">        item.setUserRCardnum(userCardNums);</span><br><span class=\"line\"></span><br><span class=\"line\">        ///usercloud云商信息&lt;单独同步，查询聚合&gt;</span><br><span class=\"line\">        ///identification 身份证信息</span><br><span class=\"line\">        UserIdentificationDto identification = identificationMapper.findUsrNameByUserId(item.getId());</span><br><span class=\"line\">        item.setIdentification(identification);</span><br><span class=\"line\">        ///qq\\weichat第三方信息</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    return item;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>优化后</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * 补全信息</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param item</span><br><span class=\"line\"> * @author zhou.shilong</span><br><span class=\"line\"> */</span><br><span class=\"line\">public UserDto wrapFullItem(UserDto item) &#123;</span><br><span class=\"line\">    if (item != null &amp;&amp; null != item.getId()) &#123;</span><br><span class=\"line\">        AsyncExecuter.init(4).execute(() -&gt; &#123;</span><br><span class=\"line\">            //personal</span><br><span class=\"line\">            UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(item.getPersonId());</span><br><span class=\"line\">            if (null != personalInfo) &#123;</span><br><span class=\"line\">                item.setPersonalInfo(personalInfo);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).execute(() -&gt; &#123;</span><br><span class=\"line\">            //member</span><br><span class=\"line\">            MemberDto memberDto = memberMapper.findByUserId(item.getId());</span><br><span class=\"line\">            if (null != memberDto) &#123;</span><br><span class=\"line\">                item.setMember(memberDto);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).execute(() -&gt; &#123;</span><br><span class=\"line\">            //userRef</span><br><span class=\"line\">            List&lt;UserRefDto&gt; userCardNums = userMapper.findByUserId(&quot;us_user_r_cardnum&quot;, item.getId());</span><br><span class=\"line\">            List&lt;UserRefDto&gt; userphones = userMapper.findByUserId(&quot;us_user_r_phone&quot;, item.getId());</span><br><span class=\"line\">            List&lt;UserRefDto&gt; usernames = userMapper.findByUserId(&quot;us_user_r_username&quot;, item.getId());</span><br><span class=\"line\">            item.setUserRName(usernames);</span><br><span class=\"line\">            item.setUserRPhone(userphones);</span><br><span class=\"line\">            item.setUserRCardnum(userCardNums);</span><br><span class=\"line\">        &#125;).execute(() -&gt; &#123;</span><br><span class=\"line\">            ///usercloud云商信息&lt;单独同步，查询聚合&gt;</span><br><span class=\"line\">            ///identification 身份证信息</span><br><span class=\"line\">            UserIdentificationDto identification = identificationMapper.findUsrNameByUserId(item.getId());</span><br><span class=\"line\">            item.setIdentification(identification);</span><br><span class=\"line\">            ///qq\\weichat第三方信息</span><br><span class=\"line\">        &#125;).await();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return item;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/***</span><br><span class=\"line\"> * 异步执行器</span><br><span class=\"line\"> */</span><br><span class=\"line\">public class AsyncExecuter &#123;</span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 限制最多同时8个线程在运行</span><br><span class=\"line\">     */</span><br><span class=\"line\">    private static final int             MAX_THREAD_NUM = 8;</span><br><span class=\"line\">    private static       ExecutorService executor       = Executors.newFixedThreadPool(MAX_THREAD_NUM);</span><br><span class=\"line\">    private static       Logger          logger         = LoggerFactory.getLogger(AsyncExecuter.class);</span><br><span class=\"line\">    private              CountDownLatch  countDownLatch;</span><br><span class=\"line\">    private              long            timeout;</span><br><span class=\"line\">    private              int             taskCount      = 0;</span><br><span class=\"line\">    private              int             currentTask    = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">    private AsyncExecuter(int count, long timeout) &#123;</span><br><span class=\"line\">        Assert.isTrue(count &gt; 0, &quot;count greater than 0&quot;);</span><br><span class=\"line\">        this.timeout = timeout;</span><br><span class=\"line\">        this.taskCount = count;</span><br><span class=\"line\">        this.countDownLatch = new CountDownLatch(count);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * @param count    执行任务数</span><br><span class=\"line\">     * @param milltime 等待超时时间</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public static AsyncExecuter init(int count, long milltime) &#123;</span><br><span class=\"line\">        return new AsyncExecuter(count, milltime);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public static AsyncExecuter init(int count) &#123;</span><br><span class=\"line\">        return new AsyncExecuter(count, -1);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 异步执行一个线程</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param runnable</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public AsyncExecuter execute(Runnable runnable) &#123;</span><br><span class=\"line\">        this.currentTask++;</span><br><span class=\"line\">        if (this.currentTask &gt; this.taskCount) &#123;</span><br><span class=\"line\">            throw new IllegalStateException(&quot;execute task nums can not greater then count&quot;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        executor.execute(() -&gt; &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                runnable.run();</span><br><span class=\"line\">            &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                logger.error(&quot;&quot;, e);</span><br><span class=\"line\">            &#125; finally &#123;</span><br><span class=\"line\">                countDownLatch.countDown();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">        return this;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 阻塞直到所有子任务完成</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public void await() &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            if (this.timeout == -1) &#123;</span><br><span class=\"line\">                countDownLatch.await();</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                countDownLatch.await(timeout, TimeUnit.MILLISECONDS);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">            logger.error(&quot;&quot;, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>避免跨库关联数据</li>\n</ul>\n<p>++数据库是DRDS，数据量大概在3亿+，预计2年内增量到5亿+。优化前数据库超时导致基本不可执行，优化后可正常导数据++</p>\n<blockquote>\n<p>DRDS海量数据导入ES的策略优化，DRDS对调用层隐藏了分库分表的复杂性，方便了方法调用的统一，但因为对调用者透明，开发同学很容易无意间写出全库扫描的sql，反而降低了效率。在我们数据迁移的场景中，需要扫描所有数据做全量迁移，所以这里先列出所有数据库，针对具体的库并行调用扫描提高效率。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">列出所有分库</span><br><span class=\"line\">mysql&gt; SHOW TOPOLOGY FROM LJLTEST;</span><br><span class=\"line\">+------+----------------+------------+</span><br><span class=\"line\">| ID   | GROUP_NAME     | TABLE_NAME |</span><br><span class=\"line\">+------+----------------+------------+</span><br><span class=\"line\">|    0 | TDDL5_00_GROUP | ljltest_00 |</span><br><span class=\"line\">|    1 | TDDL5_00_GROUP | ljltest_01 |</span><br><span class=\"line\">|    2 | TDDL5_00_GROUP | ljltest_02 |</span><br><span class=\"line\">|    3 | TDDL5_01_GROUP | ljltest_03 |</span><br><span class=\"line\">|    4 | TDDL5_01_GROUP | ljltest_04 |</span><br><span class=\"line\">|    5 | TDDL5_01_GROUP | ljltest_05 |</span><br><span class=\"line\">|    6 | TDDL5_02_GROUP | ljltest_06 |</span><br><span class=\"line\">|    7 | TDDL5_02_GROUP | ljltest_07 |</span><br><span class=\"line\">|    8 | TDDL5_02_GROUP | ljltest_08 |</span><br><span class=\"line\">|    9 | TDDL5_03_GROUP | ljltest_09 |</span><br><span class=\"line\">|   10 | TDDL5_03_GROUP | ljltest_10 |</span><br><span class=\"line\">|   11 | TDDL5_03_GROUP | ljltest_11 |</span><br><span class=\"line\">+------+----------------+------------+</span><br><span class=\"line\">12 rows in set (0.06 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">从某分库查询数据</span><br><span class=\"line\">/!TDDL:node=&apos;TDDL5_00_GROUP&apos;*/ select * from ljltest_00;</span><br></pre></td></tr></table></figure>\n<h3 id=\"其他工作\"><a href=\"#其他工作\" class=\"headerlink\" title=\"其他工作\"></a>其他工作</h3><ul>\n<li>增强组件对shardingJDBC分表扫描特性</li>\n<li>业务功能：优惠券、收货地址建立索引等</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p><strong>方法论</strong></p>\n<ul>\n<li>沿着业务的逻辑线路梳理流程节点，针对节点之间的通路，节点内部，用可量化的标准，找出瓶颈并优化。</li>\n<li>充分利用多核CPU的性能，多做并行处理</li>\n<li>使用批量调用接口替代单次调用接口，减少性能损耗</li>\n<li>优化SQL join的数量级(并非列举所有优化策略，仅仅是讲在此次完美压测用到的部分内容)</li>\n</ul>\n<h2 id=\"其他大佬的建议\"><a href=\"#其他大佬的建议\" class=\"headerlink\" title=\"其他大佬的建议\"></a>其他大佬的建议</h2><ol>\n<li>线程池资源释放没有处理；</li>\n<li>建议采用callable与futrueTask；</li>\n<li>数据同步锁；</li>\n<li>DB IO峰值检测；</li>\n<li>ES分片</li>\n</ol>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>来自公司同事压测性能调优的分享</p>\n</blockquote>","more":"<h2 id=\"前情提要\"><a href=\"#前情提要\" class=\"headerlink\" title=\"前情提要\"></a>前情提要</h2><p>完美中国项目进入压测环节，就是业务都做完啦，通过压测优化让系统性能达到设计标准，通过客户验收即可交付。这边有几个平衡点</p>\n<ul>\n<li>总体预算大体不变的框架下进行资源分配优化</li>\n<li>大体需求不变的前提下做功能效率优化</li>\n</ul>\n<blockquote>\n<p>基于这两点，盲目说<del>性能不够加机器</del>，<del>砍功能说无法实现</del>都是不可以的，压测的目的就是要攻克难关。</p>\n</blockquote>\n<h2 id=\"优化场景\"><a href=\"#优化场景\" class=\"headerlink\" title=\"优化场景\"></a>优化场景</h2><h3 id=\"数据同步效率优化\"><a href=\"#数据同步效率优化\" class=\"headerlink\" title=\"数据同步效率优化\"></a>数据同步效率优化</h3><h4 id=\"从问题出发\"><a href=\"#从问题出发\" class=\"headerlink\" title=\"从问题出发\"></a>从问题出发</h4><blockquote>\n<ul>\n<li>mysql数据为什么要同步到es？</li>\n</ul>\n</blockquote>\n<h4 id=\"设计\"><a href=\"#设计\" class=\"headerlink\" title=\"设计\"></a>设计</h4><p><img src=\"/image/压测性能调优_01.png\" alt=\"压测性能调优_01\"></p>\n<p>可能的瓶颈点<br>（红字处</p>\n<h4 id=\"优化手段\"><a href=\"#优化手段\" class=\"headerlink\" title=\"优化手段\"></a>优化手段</h4><ul>\n<li>对数据进行多线程分片执行，对数据集进行分片，每个分片由单独线程执行，充分利用多核CPU的优势。</li>\n</ul>\n<p>++原先一个大表（2000w+数据）全量同步需要20+h，优化后在1h内同步完成++</p>\n<blockquote>\n<p>示例代码(非可执行代码)</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">public class IndexExecutor&lt;K, T&gt;&#123;</span><br><span class=\"line\">    private static final int MAX_SAHRD_NUM = 32;</span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 最多32个线程</span><br><span class=\"line\">     */</span><br><span class=\"line\">    private static ExecutorService executor = Executors.newFixedThreadPool(MAX_SAHRD_NUM);</span><br><span class=\"line\"></span><br><span class=\"line\">    public IndexExecutor() &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    private IndexExecutor(Params params) &#123;</span><br><span class=\"line\">        Assert.isTrue(params.shard &lt; MAX_SAHRD_NUM, &quot;must small than MAX_SAHRD_NUM(32)&quot;);</span><br><span class=\"line\">        this.mapper = params.mapper;</span><br><span class=\"line\">        this.mapping = params.mapping;</span><br><span class=\"line\">        this.params = params;</span><br><span class=\"line\">        super.setApplicationContext(context);</span><br><span class=\"line\">        super.setMapping(this.mapping);</span><br><span class=\"line\">        super.setMapper(this.mapper);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    private Params params;</span><br><span class=\"line\">    private BaseMapper mapper;</span><br><span class=\"line\">    private TableToIndexMappingDto mapping;</span><br><span class=\"line\"></span><br><span class=\"line\">    public void build() &#123;</span><br><span class=\"line\">        // 非空校验</span><br><span class=\"line\">        Objects.requireNonNull(params.mapper);</span><br><span class=\"line\">        Objects.requireNonNull(params.mapping);</span><br><span class=\"line\">        List&lt;String&gt; tableNames = this.findTableNames();</span><br><span class=\"line\"></span><br><span class=\"line\">        // 不阻塞调用请求</span><br><span class=\"line\">        new Thread(() -&gt; &#123;</span><br><span class=\"line\">            String indexAliasesName = this.mapping.getIndicesAliasesName();</span><br><span class=\"line\">            String newIndexName = this.createIndexNewName(indexAliasesName);</span><br><span class=\"line\">            this.createIndexAndMapping(newIndexName);</span><br><span class=\"line\">            int shard = params.shard;</span><br><span class=\"line\">            long begin = 0;</span><br><span class=\"line\">            long[] counts = null;</span><br><span class=\"line\"></span><br><span class=\"line\">            // 遍历每个tableName</span><br><span class=\"line\">            for (String tableName : tableNames) &#123;</span><br><span class=\"line\">                Long count = 0L;</span><br><span class=\"line\">                begin = System.currentTimeMillis();</span><br><span class=\"line\">                if (tableNames.size() &gt; 1) &#123;</span><br><span class=\"line\">                    PartitionFeatureMapper partitionFeatureMapper = (PartitionFeatureMapper) mapper;</span><br><span class=\"line\">                    count = partitionFeatureMapper.countAllByTableName(tableName);</span><br><span class=\"line\">                &#125; else &#123;</span><br><span class=\"line\">                    count = mapper.countAll();</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">                counts = splitShard(shard, count);</span><br><span class=\"line\">                CountDownLatch cd = new CountDownLatch(counts.length - 1);</span><br><span class=\"line\">                for (int i = 0; i &lt; counts.length; i++) &#123;</span><br><span class=\"line\">                    long segmentCount = counts[i];</span><br><span class=\"line\">                    long lastCount = i == 0 ? 0L : counts[i - 1];</span><br><span class=\"line\">                    logger.info(&quot;分片序号：&#123;&#125; 位置 &#123;&#125;-&#123;&#125; 开始&quot;, i, lastCount, segmentCount);</span><br><span class=\"line\">                    executor.execute(() -&gt; &#123;</span><br><span class=\"line\">                        this.runShard(tableName, lastCount, segmentCount, newIndexName);</span><br><span class=\"line\">                        cd.countDown();</span><br><span class=\"line\">                        logger.info(&quot;&#123;&#125; 等待其他分片执行完毕，剩余分片数量 ：&#123;&#125;&quot;, tableName, cd.getCount());</span><br><span class=\"line\">                    &#125;);</span><br><span class=\"line\">                    // 错开数据库io峰</span><br><span class=\"line\">                    try &#123;</span><br><span class=\"line\">                        TimeUnit.SECONDS.sleep(1);</span><br><span class=\"line\">                    &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">                        logger.error(&quot;&quot;, e);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                try &#123;</span><br><span class=\"line\">                    cd.await();</span><br><span class=\"line\">                &#125; catch (InterruptedException e) &#123;</span><br><span class=\"line\">                    logger.error(&quot;&#123;&#125; 表，全量更新索引失败,&#123;&#125; &quot;, tableName, newIndexName, e);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            this.addOrUpdateIndexWithAliasesRef(indexAliasesName, newIndexName);</span><br><span class=\"line\">            logger.info(&quot;迁移索引别名到新索引成功，alies &#123;&#125; index &#123;&#125;，耗时：&#123;&#125;ms&quot;, indexAliasesName, newIndexName, System.currentTimeMillis() - begin);</span><br><span class=\"line\">        &#125;).start();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 如果是表名是着正则就按正则查出所有表名，</span><br><span class=\"line\">     * 否则直接返回表名</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public List&lt;String&gt; findTableNames() &#123;</span><br><span class=\"line\">        List&lt;String&gt; tableNames = null;</span><br><span class=\"line\">        String tableName = this.mapping.getTableName();</span><br><span class=\"line\">        if (this.mapper instanceof PartitionFeatureMapper) &#123;</span><br><span class=\"line\">            Connection connection = null;</span><br><span class=\"line\">            String schema = null;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                // 这坨代码为了取库名</span><br><span class=\"line\">                String jdbcUrl = this.params.dataSourceVo.getJdbcUrl();</span><br><span class=\"line\">                String jdbcUserName = this.params.dataSourceVo.getJdbcUserName();</span><br><span class=\"line\">                String jdbcUserPassword = this.params.dataSourceVo.getJdbcUserPassword();</span><br><span class=\"line\">                connection = DriverManager.getConnection(jdbcUrl, jdbcUserName, jdbcUserPassword);</span><br><span class=\"line\">                Field dbName = connection.getClass().getDeclaredField(&quot;dbName&quot;);</span><br><span class=\"line\">                dbName.setAccessible(true);</span><br><span class=\"line\">                schema = String.valueOf(dbName.get(connection));</span><br><span class=\"line\">            &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                logger.error(&quot;&quot;, e);</span><br><span class=\"line\">            &#125; finally &#123;</span><br><span class=\"line\">                if (connection != null) &#123;</span><br><span class=\"line\">                    try &#123;</span><br><span class=\"line\">                        connection.close();</span><br><span class=\"line\">                    &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                        logger.error(&quot;&quot;, e);</span><br><span class=\"line\">                    &#125;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            PartitionFeatureMapper partitionFeatureMapper = (PartitionFeatureMapper) this.mapper;</span><br><span class=\"line\">            // 从该schema 查询所有表名</span><br><span class=\"line\">            String tableRegex = tableName;</span><br><span class=\"line\">            tableNames = partitionFeatureMapper.findTablesByRegex(schema, tableRegex);</span><br><span class=\"line\">        &#125; else if (this.mapper instanceof ExectuorMapper) &#123;</span><br><span class=\"line\">            tableNames = Lists.newArrayList(tableName);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        return tableNames;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 每个分片的任务</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param beginPos</span><br><span class=\"line\">     * @param endPos</span><br><span class=\"line\">     * @param indexName</span><br><span class=\"line\">     */</span><br><span class=\"line\">    private void runShard(String tableName, long beginPos, long endPos, String indexName) &#123;</span><br><span class=\"line\">        Map&lt;String, String&gt; map = null;</span><br><span class=\"line\">        long count = endPos - beginPos;</span><br><span class=\"line\">        if (this.mapper instanceof PartitionFeatureMapper) &#123;</span><br><span class=\"line\">            PartitionFeatureMapper mapper = (PartitionFeatureMapper) this.getMapper();</span><br><span class=\"line\">            map = mapper.findMaxAndMinIdPartion(tableName, beginPos, count);</span><br><span class=\"line\">        &#125; else if (this.mapper instanceof ExectuorMapper) &#123;</span><br><span class=\"line\">            ExectuorMapper mapper = (ExectuorMapper) this.getMapper();</span><br><span class=\"line\">            map = mapper.findMaxAndMinIdLimit(beginPos, count);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        if (map == null || map.isEmpty()) &#123;</span><br><span class=\"line\">            logger.warn(&quot;beginPos&#123;&#125;,count&#123;&#125;,indexName&#123;&#125; map empty&quot;, beginPos, endPos, indexName);</span><br><span class=\"line\">            return;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        String minId = String.valueOf(map.get(&quot;minId&quot;));</span><br><span class=\"line\">        String actualMaxId = null;</span><br><span class=\"line\">        long scanedCount = 0L;</span><br><span class=\"line\">        long actualCount = 0L;</span><br><span class=\"line\">        int batch = (int) (endPos &gt; 1000 ? 1000 : endPos);</span><br><span class=\"line\">        int runtime = 0;</span><br><span class=\"line\">        List list = null;</span><br><span class=\"line\">        do &#123;</span><br><span class=\"line\">            if (this.mapper instanceof PartitionFeatureMapper) &#123;</span><br><span class=\"line\">                PartitionFeatureMapper mapper = (PartitionFeatureMapper) this.getMapper();</span><br><span class=\"line\">                actualMaxId = String.valueOf(mapper.findMaxIdPartition(tableName, minId, batch));</span><br><span class=\"line\"></span><br><span class=\"line\">                list = mapper.findByMaxAndMinIdPartition(tableName, minId, actualMaxId);</span><br><span class=\"line\"></span><br><span class=\"line\">            &#125; else if (this.mapper instanceof ExectuorMapper) &#123;</span><br><span class=\"line\">                actualMaxId = String.valueOf(this.getMapper().findMaxId(minId, batch));</span><br><span class=\"line\">                //mapper用dto接收</span><br><span class=\"line\">                list = this.getMapper().findByMaxAndMinId(minId, actualMaxId);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">                logger.info(&quot;segment[&#123;&#125;-&#123;&#125;] load from db success,minId:&#123;&#125;  maxId:&#123;&#125;&quot;, beginPos, endPos, minId, actualMaxId);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            if (list.isEmpty()) &#123;</span><br><span class=\"line\">                break;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            scanedCount += list.size();</span><br><span class=\"line\"></span><br><span class=\"line\">            this.batchAddIndexByMapParams(indexName, list);</span><br><span class=\"line\"></span><br><span class=\"line\">            if (logger.isDebugEnabled()) &#123;</span><br><span class=\"line\">                logger.info(&quot;segment[&#123;&#125;-&#123;&#125;] put in es success,minId:&#123;&#125;  maxId:&#123;&#125;&quot;, beginPos, endPos, minId, actualMaxId);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            minId = actualMaxId;</span><br><span class=\"line\">            actualCount += (long) list.size();</span><br><span class=\"line\">            ++runtime;</span><br><span class=\"line\">        &#125; while (scanedCount &lt; count);</span><br><span class=\"line\"></span><br><span class=\"line\">        logger.info(&quot;db record count=&#123;&#125;,fetch record count=&#123;&#125;,runtime=&#123;&#125;&quot;, new Object[]&#123;endPos, actualCount, runtime&#125;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 重写批量导入es逻辑</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param newIndexName</span><br><span class=\"line\">     * @param list</span><br><span class=\"line\">     */</span><br><span class=\"line\">    protected void batchAddIndexByMapParams(String newIndexName, List&lt;Map&lt;String, Object&gt;&gt; list) &#123;</span><br><span class=\"line\">        if (list != null &amp;&amp; !list.isEmpty()) &#123;</span><br><span class=\"line\">            String pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;;</span><br><span class=\"line\">            List&lt;IndexDocContentVo&gt; docs = list.parallelStream().filter(doc -&gt; doc != null).collect(Collectors.toList());</span><br><span class=\"line\">            IndexDocumentVo indexDocumentVo = new IndexDocumentVo(newIndexName, this.mapping.getIndicesTypeName(), docs);</span><br><span class=\"line\">            this.getSearchIndexService().addData(indexDocumentVo);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 根据总数 分片数 获取每个分片边界</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param shardNums</span><br><span class=\"line\">     * @param total</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public static long[] splitShard(int shardNums, long total) &#123;</span><br><span class=\"line\">        if (total &lt;= shardNums || total &lt;= 1000) &#123;</span><br><span class=\"line\">            return new long[]&#123;total&#125;;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        long constTotal = total;</span><br><span class=\"line\">        int shardIndex = 1;</span><br><span class=\"line\">        long[] counts = new long[shardNums];</span><br><span class=\"line\">        long everShard = total / shardNums;</span><br><span class=\"line\">        while (constTotal - everShard * shardIndex &gt; 0) &#123;</span><br><span class=\"line\">            long newTotal = total - everShard * shardIndex;</span><br><span class=\"line\">            counts[shardIndex - 1] = total - newTotal;</span><br><span class=\"line\">            total = newTotal;</span><br><span class=\"line\">            shardIndex++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        counts[shardNums - 1] = constTotal;</span><br><span class=\"line\">        return counts;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public static class Params &#123;</span><br><span class=\"line\">        BaseMapper mapper;</span><br><span class=\"line\">        DataSourceVo dataSourceVo;</span><br><span class=\"line\">        TableToIndexMappingDto mapping;</span><br><span class=\"line\">        Wrapper wrapper;</span><br><span class=\"line\">        WrapperDto wrapperDto;</span><br><span class=\"line\">        ListWrapper listWrapper;</span><br><span class=\"line\">        ListWrapperDto listWrapperDto;</span><br><span class=\"line\"></span><br><span class=\"line\">        /**</span><br><span class=\"line\">         * 这里分片 4 * 2(核)片 ，每个线程取一部分数据，各自开始load</span><br><span class=\"line\">         */</span><br><span class=\"line\">        int shard = 8;</span><br><span class=\"line\"></span><br><span class=\"line\">        public void runIndex() &#123;</span><br><span class=\"line\">            IndexExecutor indexExecutor = new IndexExecutor(this);</span><br><span class=\"line\">            indexExecutor.build();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public IndexExecutor build() &#123;</span><br><span class=\"line\">            IndexExecutor indexExecutor = new IndexExecutor(this);</span><br><span class=\"line\">            return indexExecutor;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withMapper(BaseMapper mapper) &#123;</span><br><span class=\"line\">            this.mapper = mapper;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withMapping(TableToIndexMappingDto mapping) &#123;</span><br><span class=\"line\">            this.mapping = mapping;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withShard(int shard) &#123;</span><br><span class=\"line\">            this.shard = shard;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withWrapper(Wrapper wrapper) &#123;</span><br><span class=\"line\">            this.wrapper = wrapper;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withWrapperDto(WrapperDto wrapperDto) &#123;</span><br><span class=\"line\">            this.wrapperDto = wrapperDto;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withDataSourceVo(String beanName) &#123;</span><br><span class=\"line\">            DataSourceVo bean = context.getBean(beanName, DataSourceVo.class);</span><br><span class=\"line\">            this.dataSourceVo = bean;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withListMapper(ListWrapper listMapper) &#123;</span><br><span class=\"line\">            this.listWrapper = listMapper;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        public Params withListDtoMapper(ListWrapperDto listMapper) &#123;</span><br><span class=\"line\">            this.listWrapperDto = listMapper;</span><br><span class=\"line\">            return this;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public interface Wrapper &#123;</span><br><span class=\"line\">        Map&lt;String, Object&gt; wrapDoc(Map&lt;String, Object&gt; item);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public interface ListWrapper &#123;</span><br><span class=\"line\">        List&lt;Map&lt;String, Object&gt;&gt; wrapBatchDoc(List&lt;Map&lt;String, Object&gt;&gt; item);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public interface ListWrapperDto &#123;</span><br><span class=\"line\">        List&lt;Map&lt;String, Object&gt;&gt; wrapBatchDoc(List item);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public interface WrapperDto&lt;T&gt; &#123;</span><br><span class=\"line\">        T wrapDto(T item);</span><br><span class=\"line\"></span><br><span class=\"line\">        Class getTargetClass();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上代码的核心点</p>\n<blockquote>\n<p>获取分片边界 long[] splitShard(int shardNums, long total)</p>\n</blockquote>\n<blockquote>\n<p>取数据时按where取数据，而不是limit取数据，可以命中拆分键（存疑。。</p>\n</blockquote>\n<blockquote>\n<p>线程池 &amp; JVM最佳线程数量 cpu核数 * 1.5 （存疑。。</p>\n</blockquote>\n<h4 id=\"SQL调优\"><a href=\"#SQL调优\" class=\"headerlink\" title=\"SQL调优\"></a>SQL调优</h4><ul>\n<li>减少数据库交互次数</li>\n</ul>\n<p>++原先一次数据组装耗时100s-500s不可控，优化后稳定在1s左右++</p>\n<blockquote>\n<p>查询数据库的过程如果涉及for循环，看是否可以修改for循环取数据为in查询，减少数据库交互次数</p>\n</blockquote>\n<p><strong>原先</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for (UserDto docValue : docValues) &#123;</span><br><span class=\"line\">    UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(docValue.getPersonId());</span><br><span class=\"line\">    //...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>优化后</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String personIds = docValues.stream()</span><br><span class=\"line\">                .filter(item -&gt; item != null &amp;&amp; item.getPersonId() != null)</span><br><span class=\"line\">                .map(item -&gt; item.getPersonId().toString()).collect(Collectors.joining(&quot;,&quot;));</span><br><span class=\"line\">List&lt;UserPersonalInfoDto&gt; userPersonInfos = userPersonalInfoMapper.findByIds(personIds);</span><br><span class=\"line\">Map&lt;Long, UserPersonalInfoDto&gt; userPersonalInfoMap = userPersonInfos.stream().collect(Collectors.toMap(UserPersonalInfoDto::getId, Function.identity()));</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>同库情况下使用join代替多次数据库查询。用子查询优化主表，核心是先筛选，再join。减少表关联的数量级。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SELECT</span><br><span class=\"line\">    b.id,</span><br><span class=\"line\">    b.`level`,</span><br><span class=\"line\">    b.max_level,</span><br><span class=\"line\">    b.`status`,</span><br><span class=\"line\">    b.last_active_month,</span><br><span class=\"line\">    b.create_time,</span><br><span class=\"line\">    b.create_person,</span><br><span class=\"line\">    b.update_person,</span><br><span class=\"line\">    b.update_time,</span><br><span class=\"line\">    b.tenant_id,</span><br><span class=\"line\">    b.instance_id,</span><br><span class=\"line\">    b.create_time</span><br><span class=\"line\">FROM</span><br><span class=\"line\">(</span><br><span class=\"line\">    SELECT member_id from mm_card_map_user where dr = 0 and user_id in ($&#123;userIds&#125;) </span><br><span class=\"line\">) as a</span><br><span class=\"line\">LEFT JOIN mm_member b ON b.id = a.member_id</span><br><span class=\"line\">where b.dr = 0</span><br><span class=\"line\">GROUP by b.id;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>把多数据源聚合的过程的同步调用异步化</li>\n</ul>\n<p><strong>原来代码</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * 补全信息</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param item</span><br><span class=\"line\"> * @author zhou.shilong</span><br><span class=\"line\"> */</span><br><span class=\"line\">public UserDto wrapFullItem(UserDto item) &#123;</span><br><span class=\"line\">    if (item != null &amp;&amp; null != item.getId()) &#123;</span><br><span class=\"line\">        //personal</span><br><span class=\"line\">        UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(item.getPersonId());</span><br><span class=\"line\">        if (null != personalInfo) &#123;</span><br><span class=\"line\">            item.setPersonalInfo(personalInfo);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        //member</span><br><span class=\"line\">        MemberDto memberDto = memberMapper.findByUserId(item.getId());</span><br><span class=\"line\">        if (null != memberDto) &#123;</span><br><span class=\"line\">            item.setMember(memberDto);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        //userRef</span><br><span class=\"line\">        List&lt;UserRefDto&gt; usernames = userMapper.findUsrNameByUserId(item.getId());</span><br><span class=\"line\">        List&lt;UserRefDto&gt; userphones = userMapper.findUserPhoneByUserId(item.getId());</span><br><span class=\"line\">        List&lt;UserRefDto&gt; userCardNums = userMapper.findUserCardNumByUserId(item.getId());</span><br><span class=\"line\">        item.setUserRName(usernames);</span><br><span class=\"line\">        item.setUserRPhone(userphones);</span><br><span class=\"line\">        item.setUserRCardnum(userCardNums);</span><br><span class=\"line\"></span><br><span class=\"line\">        ///usercloud云商信息&lt;单独同步，查询聚合&gt;</span><br><span class=\"line\">        ///identification 身份证信息</span><br><span class=\"line\">        UserIdentificationDto identification = identificationMapper.findUsrNameByUserId(item.getId());</span><br><span class=\"line\">        item.setIdentification(identification);</span><br><span class=\"line\">        ///qq\\weichat第三方信息</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    return item;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>优化后</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * 补全信息</span><br><span class=\"line\"> *</span><br><span class=\"line\"> * @param item</span><br><span class=\"line\"> * @author zhou.shilong</span><br><span class=\"line\"> */</span><br><span class=\"line\">public UserDto wrapFullItem(UserDto item) &#123;</span><br><span class=\"line\">    if (item != null &amp;&amp; null != item.getId()) &#123;</span><br><span class=\"line\">        AsyncExecuter.init(4).execute(() -&gt; &#123;</span><br><span class=\"line\">            //personal</span><br><span class=\"line\">            UserPersonalInfoDto personalInfo = userPersonalInfoMapper.findById(item.getPersonId());</span><br><span class=\"line\">            if (null != personalInfo) &#123;</span><br><span class=\"line\">                item.setPersonalInfo(personalInfo);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).execute(() -&gt; &#123;</span><br><span class=\"line\">            //member</span><br><span class=\"line\">            MemberDto memberDto = memberMapper.findByUserId(item.getId());</span><br><span class=\"line\">            if (null != memberDto) &#123;</span><br><span class=\"line\">                item.setMember(memberDto);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;).execute(() -&gt; &#123;</span><br><span class=\"line\">            //userRef</span><br><span class=\"line\">            List&lt;UserRefDto&gt; userCardNums = userMapper.findByUserId(&quot;us_user_r_cardnum&quot;, item.getId());</span><br><span class=\"line\">            List&lt;UserRefDto&gt; userphones = userMapper.findByUserId(&quot;us_user_r_phone&quot;, item.getId());</span><br><span class=\"line\">            List&lt;UserRefDto&gt; usernames = userMapper.findByUserId(&quot;us_user_r_username&quot;, item.getId());</span><br><span class=\"line\">            item.setUserRName(usernames);</span><br><span class=\"line\">            item.setUserRPhone(userphones);</span><br><span class=\"line\">            item.setUserRCardnum(userCardNums);</span><br><span class=\"line\">        &#125;).execute(() -&gt; &#123;</span><br><span class=\"line\">            ///usercloud云商信息&lt;单独同步，查询聚合&gt;</span><br><span class=\"line\">            ///identification 身份证信息</span><br><span class=\"line\">            UserIdentificationDto identification = identificationMapper.findUsrNameByUserId(item.getId());</span><br><span class=\"line\">            item.setIdentification(identification);</span><br><span class=\"line\">            ///qq\\weichat第三方信息</span><br><span class=\"line\">        &#125;).await();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    return item;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/***</span><br><span class=\"line\"> * 异步执行器</span><br><span class=\"line\"> */</span><br><span class=\"line\">public class AsyncExecuter &#123;</span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 限制最多同时8个线程在运行</span><br><span class=\"line\">     */</span><br><span class=\"line\">    private static final int             MAX_THREAD_NUM = 8;</span><br><span class=\"line\">    private static       ExecutorService executor       = Executors.newFixedThreadPool(MAX_THREAD_NUM);</span><br><span class=\"line\">    private static       Logger          logger         = LoggerFactory.getLogger(AsyncExecuter.class);</span><br><span class=\"line\">    private              CountDownLatch  countDownLatch;</span><br><span class=\"line\">    private              long            timeout;</span><br><span class=\"line\">    private              int             taskCount      = 0;</span><br><span class=\"line\">    private              int             currentTask    = 0;</span><br><span class=\"line\"></span><br><span class=\"line\">    private AsyncExecuter(int count, long timeout) &#123;</span><br><span class=\"line\">        Assert.isTrue(count &gt; 0, &quot;count greater than 0&quot;);</span><br><span class=\"line\">        this.timeout = timeout;</span><br><span class=\"line\">        this.taskCount = count;</span><br><span class=\"line\">        this.countDownLatch = new CountDownLatch(count);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * @param count    执行任务数</span><br><span class=\"line\">     * @param milltime 等待超时时间</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public static AsyncExecuter init(int count, long milltime) &#123;</span><br><span class=\"line\">        return new AsyncExecuter(count, milltime);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    public static AsyncExecuter init(int count) &#123;</span><br><span class=\"line\">        return new AsyncExecuter(count, -1);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 异步执行一个线程</span><br><span class=\"line\">     *</span><br><span class=\"line\">     * @param runnable</span><br><span class=\"line\">     * @return</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public AsyncExecuter execute(Runnable runnable) &#123;</span><br><span class=\"line\">        this.currentTask++;</span><br><span class=\"line\">        if (this.currentTask &gt; this.taskCount) &#123;</span><br><span class=\"line\">            throw new IllegalStateException(&quot;execute task nums can not greater then count&quot;);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        executor.execute(() -&gt; &#123;</span><br><span class=\"line\">            try &#123;</span><br><span class=\"line\">                runnable.run();</span><br><span class=\"line\">            &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">                logger.error(&quot;&quot;, e);</span><br><span class=\"line\">            &#125; finally &#123;</span><br><span class=\"line\">                countDownLatch.countDown();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">        return this;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    /**</span><br><span class=\"line\">     * 阻塞直到所有子任务完成</span><br><span class=\"line\">     */</span><br><span class=\"line\">    public void await() &#123;</span><br><span class=\"line\">        try &#123;</span><br><span class=\"line\">            if (this.timeout == -1) &#123;</span><br><span class=\"line\">                countDownLatch.await();</span><br><span class=\"line\">            &#125; else &#123;</span><br><span class=\"line\">                countDownLatch.await(timeout, TimeUnit.MILLISECONDS);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125; catch (Throwable e) &#123;</span><br><span class=\"line\">            logger.error(&quot;&quot;, e);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>避免跨库关联数据</li>\n</ul>\n<p>++数据库是DRDS，数据量大概在3亿+，预计2年内增量到5亿+。优化前数据库超时导致基本不可执行，优化后可正常导数据++</p>\n<blockquote>\n<p>DRDS海量数据导入ES的策略优化，DRDS对调用层隐藏了分库分表的复杂性，方便了方法调用的统一，但因为对调用者透明，开发同学很容易无意间写出全库扫描的sql，反而降低了效率。在我们数据迁移的场景中，需要扫描所有数据做全量迁移，所以这里先列出所有数据库，针对具体的库并行调用扫描提高效率。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">列出所有分库</span><br><span class=\"line\">mysql&gt; SHOW TOPOLOGY FROM LJLTEST;</span><br><span class=\"line\">+------+----------------+------------+</span><br><span class=\"line\">| ID   | GROUP_NAME     | TABLE_NAME |</span><br><span class=\"line\">+------+----------------+------------+</span><br><span class=\"line\">|    0 | TDDL5_00_GROUP | ljltest_00 |</span><br><span class=\"line\">|    1 | TDDL5_00_GROUP | ljltest_01 |</span><br><span class=\"line\">|    2 | TDDL5_00_GROUP | ljltest_02 |</span><br><span class=\"line\">|    3 | TDDL5_01_GROUP | ljltest_03 |</span><br><span class=\"line\">|    4 | TDDL5_01_GROUP | ljltest_04 |</span><br><span class=\"line\">|    5 | TDDL5_01_GROUP | ljltest_05 |</span><br><span class=\"line\">|    6 | TDDL5_02_GROUP | ljltest_06 |</span><br><span class=\"line\">|    7 | TDDL5_02_GROUP | ljltest_07 |</span><br><span class=\"line\">|    8 | TDDL5_02_GROUP | ljltest_08 |</span><br><span class=\"line\">|    9 | TDDL5_03_GROUP | ljltest_09 |</span><br><span class=\"line\">|   10 | TDDL5_03_GROUP | ljltest_10 |</span><br><span class=\"line\">|   11 | TDDL5_03_GROUP | ljltest_11 |</span><br><span class=\"line\">+------+----------------+------------+</span><br><span class=\"line\">12 rows in set (0.06 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">从某分库查询数据</span><br><span class=\"line\">/!TDDL:node=&apos;TDDL5_00_GROUP&apos;*/ select * from ljltest_00;</span><br></pre></td></tr></table></figure>\n<h3 id=\"其他工作\"><a href=\"#其他工作\" class=\"headerlink\" title=\"其他工作\"></a>其他工作</h3><ul>\n<li>增强组件对shardingJDBC分表扫描特性</li>\n<li>业务功能：优惠券、收货地址建立索引等</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p><strong>方法论</strong></p>\n<ul>\n<li>沿着业务的逻辑线路梳理流程节点，针对节点之间的通路，节点内部，用可量化的标准，找出瓶颈并优化。</li>\n<li>充分利用多核CPU的性能，多做并行处理</li>\n<li>使用批量调用接口替代单次调用接口，减少性能损耗</li>\n<li>优化SQL join的数量级(并非列举所有优化策略，仅仅是讲在此次完美压测用到的部分内容)</li>\n</ul>\n<h2 id=\"其他大佬的建议\"><a href=\"#其他大佬的建议\" class=\"headerlink\" title=\"其他大佬的建议\"></a>其他大佬的建议</h2><ol>\n<li>线程池资源释放没有处理；</li>\n<li>建议采用callable与futrueTask；</li>\n<li>数据同步锁；</li>\n<li>DB IO峰值检测；</li>\n<li>ES分片</li>\n</ol>"},{"title":"线程模型","date":"2018-10-31T02:00:00.000Z","_content":"\n# 线程模型分享 （上）\n\n本篇文章是公司大佬**约拿**上周五给我培训的文档，分享给大家。非常感谢百忙之中给我培训。\n\n<!-- more -->\n\n## 引言\n> 为什么有这篇文章？\n\n起先看我的目标是看netty的线程模型，但是在看netty的过程中，我发现很多知识点是互相关联的。比如netty的EventLoop，EventLoopGroup其实是继承自JDK的线程池。学习netty的线程模型前需要懂得预备知识。基于这个理由，我把预备内容部分也写下来。分享一共会分为上下两篇，这里是第上篇，这篇主要是先导，给【下篇】的知识打基础，有了上篇的基础再看下篇就容易多了。\n\n> 这篇文章会有什么内容？\n- JDK线程池的类继承层次\n- 构建线程池的几个核心要素\n- JDK线程池关键方法的分析\n- JDK线程池存在的问题\n- 常见的线程模型举例\n- 线程模型适用场景分析 \n- 线程竞争与锁\n\n> 文章目的\n- 可以自定义JDK线程池，了解JDK线程池的局限场景\n- 了解线程模型的原理及适用场景\n- 了解锁的目的及分类\n\n## 线程启动与停止\n> 如何启动线程\n\n这个比较基础的不说了\n\n> 如何停止线程\n\n1. 线程类有stop，suspend方法，但是被弃用了。\n- **stop** 会立即杀死线程，可能导致执行一半的程序被终结导致数据不一致的风险\n- **suspend** 会挂起线程，但是不会释放锁，可能会造成死锁\n- 线程池有个 **shutdown** 方法只是阻止线程池接受新的线程 ，并不会停止已存在的线程。\n2. 正确的方法\n- 线程自己运行完成\n- 设置终止标志，在循环中检查这个标志\n\n\n## JDK线程池继承层次\n### 结构图\n![image](https://user-images.githubusercontent.com/5201798/47539254-f5648380-d901-11e8-9446-8a4705430539.png)\n\n这个图上很多类不用看，因为都是Executors类的内部类，代理类，核心就是下图的几个接口和类。\n\n![image](https://user-images.githubusercontent.com/5201798/47539187-a74f8000-d901-11e8-9f94-f8f4be0477a0.png)\n\n\t\n### 线程池核心要素\n- 核心线程池大小 corePoolSize\n> 设置一个线程池中的核心线程数 如果设置allowCoreThreadTimeOut为false的情况下： 即使当线程池中的线程处于空闲状态，这些线程也不会被线程池中移除。 如果设置了allowCoreThreadTimeOut为true, 那么当核心线程在空闲了一段时间后依旧没有用于工作，那么将会从线程池中移除。 注意:(allowCoreThreadTimeOut默认为false，通常情况下也无需做修改)\n\n- 线程保持活跃时间\n> keepAliveTime:当线程池中的线程数量大于核心线程数，如果这些多出的线程在经过了keepAliveTime时间后，依然处于空闲状态，那么这些多出的空闲线程将会被结束其生命周期。\n\n- 时间单位unit\n> keepAliveTime的时间单位\n\n- 最大线程池大小 maximumPoolSize\n> 线程池中所允许创建最大线程数量，除了受JVM内存大小限制外，Linux下还受/proc/sys/kernel/pid_max（即系统允许的最大pid）、/proc/sys/kernel/threads-max（系统支持的最大线程数）、max_user_process（ulimit-u）（每个用户允许的最大进程数）、/proc/sys/vm/max_map_count（Linux支持虚拟内存，也就是交换空间,可以把磁盘的一部分作为RAM的扩展，逻辑存储和物理存储的映射就要保存在地址映射表中。max_map_count限制了线程可以拥有的VMAs ）\n\n- 拒绝策略handler\n> 当线程池中的线程数量达到最大并且阻塞队列也已经满了无法再添加任务时，线程池所采取的处理策略，JDK有四种内建的拒绝策略，下面会讲到。\n\n- 等待队列workQueue\n> 用于存放任务的阻塞队列，当线程池中的核心线程都处在执行任务时，提交的任务将被存储在workQueue进行缓冲。该队列只能存放通过execute方法提交的Runnable任务，如果是个ScheduledThreadPoolExecutor，那么这个队列不仅需要阻塞，而且还是个优先队列。\n\n### 核心代码分析  \nThreadPoolExecutor 一个根正苗红的线程池继承类。\n- 我们看看他的excute方法\n```\n这里是调用\nint corePoolSize = 1;\nint maximumPoolSize = 2;\nlong keepAliveTime = 60;\nTimeUnit unit = TimeUnit.SECONDS;\nBlockingQueue<Runnable> workQueue = new LinkedBlockingDeque<>();\n\nThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime\n        , unit, workQueue, Executors.defaultThreadFactory(), new RejectedExecutionHandler() {\n    @Override\n    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n        throw new RejectedExecutionException(\"Task \" + r.toString() +\n                \" rejected from \" +\n                e.toString());\n    }\n});\n\nthreadPoolExecutor.execute(new Runnable() {\n    @Override\n    public void run() {\n        System.out.println(\"execute!\");\n    }\n});\n=========================\n\n看看execute的源码\npublic void execute(Runnable command) {\n    if (command == null)\n        throw new NullPointerException();\n    int c = ctl.get();\n    // workerCountOf 从ctl中取工作线程的数量，这里有一定的技巧性，下面详细讲一下\n    if (workerCountOf(c) < corePoolSize) {\n        if (addWorker(command, true))\n            return;\n        c = ctl.get();\n    }\n    // 看当前线程池状态是否Running，这里也是从ctl取值，有点意思\n    // 把任务用offer方法塞进工作队列，如果插入成功，则返回ture\n    if (isRunning(c) && workQueue.offer(command)) {\n        int recheck = ctl.get();\n        // 二次检查线程池状态是否为Running，以及从任务队列获取当前任务是否成功\n        if (! isRunning(recheck) && remove(command))\n            reject(command);\n        else if (workerCountOf(recheck) == 0)\n            // addWorker方法里通过两个for循环通过ctl判断线程池的当前状态是否能新增线程，通过CAS机制修改线程池状态。最后新建worker对象，插入worker队列。\n            addWorker(null, false);\n    }\n    // 线程池的线程数量不够了，增加线程，增加失败的话就拒绝这次execute调用\n    else if (!addWorker(command, false))\n        // reject方法里其实是调用定义线程池的时候构造函数传入的handler，JDK内建了四个拒绝策略AbortPolicy、DiscardPolicy、DiscardOldestPolicy、CallerRunsPolicy，含义分别是：抛出RejectedExecutionException异常、直接忽略提交的任务、把之前提交的任务移除，添加新的任务、让当前线程直接处理这个任务。用户也可以实现RejectedExecutionHandler接口，完成自己的拒绝策略。\n        reject(command);\n    }\n```\n\n- DefaultThreadFactory  \n```\nstatic class DefaultThreadFactory implements ThreadFactory {\n    private static final AtomicInteger poolNumber = new AtomicInteger(1);\n    private final ThreadGroup group;\n    private final AtomicInteger threadNumber = new AtomicInteger(1);\n    private final String namePrefix;\n\n    DefaultThreadFactory() {\n        SecurityManager s = System.getSecurityManager();\n        group = (s != null) ? s.getThreadGroup() :\n                              Thread.currentThread().getThreadGroup();\n        namePrefix = \"pool-\" +\n                      poolNumber.getAndIncrement() +\n                     \"-thread-\";\n    }\n\n    // 核心是这个newThread方法\n    public Thread newThread(Runnable r) {\n        Thread t = new Thread(group, r,\n                              namePrefix + threadNumber.getAndIncrement(),\n                              0);\n        if (t.isDaemon())\n            t.setDaemon(false);\n        if (t.getPriority() != Thread.NORM_PRIORITY)\n            t.setPriority(Thread.NORM_PRIORITY);\n        return t;\n    }\n}\n```\n- ctl是如何存储线程状态和数量的\n```\n定义\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\nprivate static final int COUNT_BITS = Integer.SIZE - 3;\nprivate static final int CAPACITY   = (1 << COUNT_BITS) - 1;\n\n// runState is stored in the high-order bits\nprivate static final int RUNNING    = -1 << COUNT_BITS;\nprivate static final int SHUTDOWN   =  0 << COUNT_BITS;\nprivate static final int STOP       =  1 << COUNT_BITS;\nprivate static final int TIDYING    =  2 << COUNT_BITS;\nprivate static final int TERMINATED =  3 << COUNT_BITS;\n\n// Packing and unpacking ctl\nprivate static int runStateOf(int c)     { return c & ~CAPACITY; }\nprivate static int workerCountOf(int c)  { return c & CAPACITY; }\nprivate static int ctlOf(int rs, int wc) { return rs | wc; }\n\n上面那串定义看了可能有点懵，源码中使用了一个AtomicInteger对将当前线程的工作状态和工作线程数量(有效线程数)使用同一个整数进行包装。\n为了将两个数值包装在同一个整数中，它将32位的高3位表示线程的状态值，而后29位来表示线程的数量。\n其实这样设计的理由很简单，因为线程的状态和数量往往需要同时更新，然而线程池天生处在一个并发的环境下，那么当对2个变量进行修改时，那么就势必需要通过锁来进行线程安全的处理，从而保证2个变量修改具备原子性；但是这种做法对于性能的影响是非常严重的，因此在ThreadPoolExecutor将两个变量的分别包装在一个变量中，最后的并发操作发生在AtomicInteger上，而AtomicInteger恰恰就是具有一个无锁原子操作类,这样既可以解决线程安全的问题，又可以规避避免所的使用，从而提供性能。\n```\n- ScheduledThreadPoolExecutor如何实现调度\n```\nTODO\n优先队列\n```\n        \n### JDK线程池存在的问题\n- FixedThreadPool 和 SingleThreadPool 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。\n- CachedThreadPool 和 ScheduledThreadPool允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 \n- 多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。\n- ScheduledExecutorService并发执行大量调度时候有瓶颈，大并发量的线程调度应该用时间环模式。 \n\n~~不要感觉自己写几千行的类是很烂的代码，ThreadPoolExecutor也有2100多行（含注释）~~\n\n## 线程竞争\n### 线程竞争的定义\n在多线程中，每个线程的执行顺序，是无法预测不可控制的，那么在对数据进行读写的时候便存在由于读写顺序多乱而造成数据混乱错误的可能性。这里涉及到线程锁\n\n### 用锁控制线程间的竞争\n> 这里介绍锁的基本概念以及常见分类，详细在另外的时间再做。\n\n- 共享锁/排它锁 \n\n```\n共享锁和排他锁是从同一时刻是否允许多个线程持有该锁的角度来划分。\n共享锁允许同一时刻多个线程进入持有锁，访问临界区资源。而排他锁就是通常意义上的锁，同一时刻只允许一个线程访问临界资源。对于共享锁，主要是指对数据库读操作中的读锁，在读写资源的时候如果没有线程持有写锁和请求写锁，则此时允许多个线程持有读锁。 \n在这里理解共享锁的时候，不是任意时刻都允许多线程持有共享锁的，而是在某些特殊情况下才允许多线程持有共享锁，在某些情况下不允许多个线程持有共享锁，否则，如果没有前提条件任意时刻都允许线程任意持有共享锁，则共享锁的存在无意义的。例如读写锁中的读锁，只有当没有写锁和写锁请求的时候，就可以允许多个线程同时持有读锁。这里的前提条件就是“没有写锁和写锁请求”，而不是任意时刻都允许多线程持有共享读锁。\n```\n- 悲观锁/乐观锁  \n\n```\n主要用于数据库数据的操作中，而对于线程锁中较为少见。\n悲观锁和乐观锁是一种加锁思想。对于乐观锁，在进行数据读取的时候不会加锁，而在进行写入操作的时候会判断一下数据是否被其它线程修改过，如果修改则更新数据，如果没有则继续进行数据写入操作。乐观锁不是系统中自带的锁，而是一种数据读取写入思想。应用场景例如：在向数据库中插入数据的时候，先从数据库中读取记录修改版本标识字段，如果该字段没有发生变化（没有其他线程对数据进行写操作）则执行写入操作，如果发生变化则重新计算数据。\n对于悲观锁，无论是进行读操作还是进行写操作都会进行加锁操作。对于悲观锁，如果并发量较大则比较耗费资源，当然保证了数据的安全性。\n```\n- 可重入锁/不可重入\n\n```\n这两个概念是从同一个线程在已经持有锁的前提下能否再次持有锁的角度来区分的。\n对于可重入锁，如果该线程已经获取到锁且未释放的情况下允许再次获取该锁访问临界区资源。此种情况主要是用在递归调用的情况下和不同的临界区使用相同的锁的情况下。\n对于不可重入锁，则不允许同一线程在持有锁的情况下再次获取该锁并访问临界区资源。对于不可重入锁，使用的时候需要小心以免造成死锁。\n```\n- 公平锁/非公平锁\n\n```\n这两个概念主要使用线程获取锁的顺序角度来区分的。\n对于公平锁，所有等待的线程按照按照请求锁的先后循序分别依次获取锁。\n对于非公平锁，等待线程的线程获取锁的顺序和请求的先后不是对应关系。有可能是随机的获取锁，也有可能按照其他策略获取锁，总之不是按照FIFO的顺序获取锁。\n在使用ReentrantLock的时候可以通过构造方法主动选择是实现公平锁还是非公平锁。\n```\n- 自旋锁/非自旋锁\n\n```\n这两种概念是从线程等待的处理机制来区分的。\n自旋锁在进行锁请求等待的时候不进行wait挂起，不释放CPU资源，执行while空循环。直至获取锁访问临界区资源。适用于等待锁时间较短的情景，如果等待时间较长，则会耗费大量的CPU资源。而如果等待时间较短则可以节约大量的线程切换资源。\n非自旋锁在进行锁等待的时候会释放CPU资源，可以通多sleep wait 或者CPU中断切换上下文，切换该线程。在线程等待时间较长的情况下可以选择此种实现机制。\n除此之外还有一种介于两者之间的锁机制——自适应自旋锁。当线程进行等待的时候先进性自旋等待，在自旋一定时间(次数)之后如果依旧没有持有锁则挂起等待。在jvm中synchronized锁已经使用该机制进行处理锁等待的情况。\n在工作中可以根据不同的情况选取合适的锁进行使用。无论使用哪种锁，其目的都是保证程序能够按照要求顺利执行，避免数据混乱情况的发生。\n```\n详细的[参考](https://www.cnblogs.com/PerkinsZhu/p/7392006.html)这里\n### 锁的弊端\n不管是何种锁，本质上都是对资源的访问加以限制，让同一时间只有一个线程访问资源。在高并发的时候，锁往往会成为系统的瓶颈，更不用说同时带来的死锁风险。\n\n### 不用锁解决线程安全的方式\n我们接下来讨论有无高效解决线程竞争的模式，避免锁带来的以上问题。\n\n## 常见线程模型\n\n### 线程模型的定义\n线程模型决定了应用或框架如何执行代码，所以选择正确的线程模型是很重要的事情。通俗的讲，如果同样给你一定数量的线程如（100个），分析实际的业务场景，如何让它们的效率最大化。这就是选取线程模型应该做的事情。\n> 同时线程模型也指线程映射到操作系统进程的模型 https://blog.csdn.net/lyc201219/article/details/79228575\n\n- Future模型\n\n结合Callable接口配合使用，Callable是类似于Runnable的接口。Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。如果不使用Future模型，就需要使用到一个全局变量来保存子线程处理之后的结果。子线程处理结束之后，把结果保存在全局变量中供主线程进行调用。一旦涉及到全局能量便存在着多线程读写全局变量错误的风险。\n\n```\nExecutorService executorService = Executors.newFixedThreadPool(5);\nFuture<?> future = executorService.submit(new Callable<Object>() {\n    @Override\n    public Object call() throws Exception {\n\n        return null;\n    }\n});\nObject o = future.get();\n```\n- fork&join 模型\n\n该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果\n\n```\n/**\n * 将num*2 用frok&join的思想做\n */\nstatic class ResultTask extends RecursiveTask<Integer> {\n    private int num;\n\n    public ResultTask(int num) {\n        this.num = num;\n    }\n\n    @Override\n    protected Integer compute() {\n        if (num < 10) {\n            return num * 2;\n        } else {\n            //对任务进行拆分，注意这里不仅仅可以一分为二进行拆分，也可以拆为多个子任务\n            int temp = num / 2;\n            ResultTask left = new ResultTask(temp);\n            ResultTask right = new ResultTask(num - temp);\n            left.fork();\n            right.fork();\n            //对子任务处理的结果进行合并\n            int result = left.join() + right.join();\n            return result;\n        }\n    }\n}\n\npublic static void main(String[] args) throws Exception {\n    ForkJoinPool pool = new ForkJoinPool();\n    ForkJoinTask<Integer> future = pool.submit(new ResultTask(100));\n    try {\n        Integer integer = future.get();\n        System.out.println(integer);\n        pool.awaitTermination(1000, TimeUnit.MILLISECONDS);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n    pool.shutdown();\n}\n```\n- 生产者消费者模型\n\n生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题\n\n- master-worker模型\n\nmaster-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master\n\n- actor消息模型\n\nactor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继续传递（分发）给其它actor进行处理。Actors一大重要特征在于actors之间相互隔离，它们并不互相共享内存。这点区别于上述的对象。也就是说，一个actor能维持一个私有的状态，并且这个状态不可能被另一个actor所改变。\n\nactor并发模型的应用场景？\n适合有状态或者称可变状态的业务场景，如果用DDD术语，适合聚合根，具体案例如订单，订单有状态，比如未付款未发货，已经付款未发货，已付款已发货，导致订单状态的变化是事件行为，比如付款行为导致顶大状态切换到\"已经付款未发货\"。\n\nactor的原理\n行为导致状态变化，行为执行是依靠线程，比如用户发出一个付款的请求，服务器后端派出一个线程来执行付款请求，携带付款的金额和银行卡等等信息，当付款请求被成功完成后，线程还要做的事情就是改变订单状态，这时线程访问订单的一个方法比如changeState。如果后台有管理员同时修改这个订单状态，那么实际有两个线程共同访问同一个数据，这时就必须锁，比如我们在changeState方法前加上sychronized这样同步语法。使用同步语法坏处是每次只能一个线程进行处理，如同上厕所，只有一个蹲坑，人多就必须排队，这种情况性能很低。\n\n避免changeState方法被外部两个线程同时占用访问，那么我们自己设计专门的线程守护订单状态，而不是普通方法代码，普通方法代码比较弱势，容易被外部线程hold住，而我们设计的这个对象没有普通方法，只有线程，这样就变成Order的守护线程和外部访问请求线程的通讯问题了。Actor采取的这种类似消息机制的方式，实际在守护线程和外部线程之间有一个队列，俗称信箱，外部线程只要把请求放入，守护线程就读取进行处理。这种异步高效方式是Actor基本原理，以ERlang和Scala语言为主要特征，他们封装得更好，类似将消息队列微观化了。\n参考[使用Akka Actor和Java 8构建反应式应用](http://www.infoq.com/cn/articles/Building-Reactive-Applications-with-Akka)\n\n- reactor模型\n\n一图胜千言，来看看Doug Lea大神画的图（Scalable IO in Java）\n![image](https://images2018.cnblogs.com/blog/1424165/201808/1424165-20180803142242491-1328318201.png)\n\n\n## 参考资料\n- https://www.jianshu.com/p/20b7327f9f56 ThreadPoolExecutor源码分析\n- https://blog.csdn.net/wangjinnan16/article/details/78377642  Netty4实战第十五章：选择正确的线程模型\n- https://www.cnblogs.com/PerkinsZhu/p/7570775.html 常见线程模型介绍\n- http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf Scalable IO in Java","source":"_posts/线程模型.md","raw":"---\ntitle: 线程模型\ndate: 2018-10-31 10:00:00\ntags: Java\ncategories: Java\n---\n\n# 线程模型分享 （上）\n\n本篇文章是公司大佬**约拿**上周五给我培训的文档，分享给大家。非常感谢百忙之中给我培训。\n\n<!-- more -->\n\n## 引言\n> 为什么有这篇文章？\n\n起先看我的目标是看netty的线程模型，但是在看netty的过程中，我发现很多知识点是互相关联的。比如netty的EventLoop，EventLoopGroup其实是继承自JDK的线程池。学习netty的线程模型前需要懂得预备知识。基于这个理由，我把预备内容部分也写下来。分享一共会分为上下两篇，这里是第上篇，这篇主要是先导，给【下篇】的知识打基础，有了上篇的基础再看下篇就容易多了。\n\n> 这篇文章会有什么内容？\n- JDK线程池的类继承层次\n- 构建线程池的几个核心要素\n- JDK线程池关键方法的分析\n- JDK线程池存在的问题\n- 常见的线程模型举例\n- 线程模型适用场景分析 \n- 线程竞争与锁\n\n> 文章目的\n- 可以自定义JDK线程池，了解JDK线程池的局限场景\n- 了解线程模型的原理及适用场景\n- 了解锁的目的及分类\n\n## 线程启动与停止\n> 如何启动线程\n\n这个比较基础的不说了\n\n> 如何停止线程\n\n1. 线程类有stop，suspend方法，但是被弃用了。\n- **stop** 会立即杀死线程，可能导致执行一半的程序被终结导致数据不一致的风险\n- **suspend** 会挂起线程，但是不会释放锁，可能会造成死锁\n- 线程池有个 **shutdown** 方法只是阻止线程池接受新的线程 ，并不会停止已存在的线程。\n2. 正确的方法\n- 线程自己运行完成\n- 设置终止标志，在循环中检查这个标志\n\n\n## JDK线程池继承层次\n### 结构图\n![image](https://user-images.githubusercontent.com/5201798/47539254-f5648380-d901-11e8-9446-8a4705430539.png)\n\n这个图上很多类不用看，因为都是Executors类的内部类，代理类，核心就是下图的几个接口和类。\n\n![image](https://user-images.githubusercontent.com/5201798/47539187-a74f8000-d901-11e8-9f94-f8f4be0477a0.png)\n\n\t\n### 线程池核心要素\n- 核心线程池大小 corePoolSize\n> 设置一个线程池中的核心线程数 如果设置allowCoreThreadTimeOut为false的情况下： 即使当线程池中的线程处于空闲状态，这些线程也不会被线程池中移除。 如果设置了allowCoreThreadTimeOut为true, 那么当核心线程在空闲了一段时间后依旧没有用于工作，那么将会从线程池中移除。 注意:(allowCoreThreadTimeOut默认为false，通常情况下也无需做修改)\n\n- 线程保持活跃时间\n> keepAliveTime:当线程池中的线程数量大于核心线程数，如果这些多出的线程在经过了keepAliveTime时间后，依然处于空闲状态，那么这些多出的空闲线程将会被结束其生命周期。\n\n- 时间单位unit\n> keepAliveTime的时间单位\n\n- 最大线程池大小 maximumPoolSize\n> 线程池中所允许创建最大线程数量，除了受JVM内存大小限制外，Linux下还受/proc/sys/kernel/pid_max（即系统允许的最大pid）、/proc/sys/kernel/threads-max（系统支持的最大线程数）、max_user_process（ulimit-u）（每个用户允许的最大进程数）、/proc/sys/vm/max_map_count（Linux支持虚拟内存，也就是交换空间,可以把磁盘的一部分作为RAM的扩展，逻辑存储和物理存储的映射就要保存在地址映射表中。max_map_count限制了线程可以拥有的VMAs ）\n\n- 拒绝策略handler\n> 当线程池中的线程数量达到最大并且阻塞队列也已经满了无法再添加任务时，线程池所采取的处理策略，JDK有四种内建的拒绝策略，下面会讲到。\n\n- 等待队列workQueue\n> 用于存放任务的阻塞队列，当线程池中的核心线程都处在执行任务时，提交的任务将被存储在workQueue进行缓冲。该队列只能存放通过execute方法提交的Runnable任务，如果是个ScheduledThreadPoolExecutor，那么这个队列不仅需要阻塞，而且还是个优先队列。\n\n### 核心代码分析  \nThreadPoolExecutor 一个根正苗红的线程池继承类。\n- 我们看看他的excute方法\n```\n这里是调用\nint corePoolSize = 1;\nint maximumPoolSize = 2;\nlong keepAliveTime = 60;\nTimeUnit unit = TimeUnit.SECONDS;\nBlockingQueue<Runnable> workQueue = new LinkedBlockingDeque<>();\n\nThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime\n        , unit, workQueue, Executors.defaultThreadFactory(), new RejectedExecutionHandler() {\n    @Override\n    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {\n        throw new RejectedExecutionException(\"Task \" + r.toString() +\n                \" rejected from \" +\n                e.toString());\n    }\n});\n\nthreadPoolExecutor.execute(new Runnable() {\n    @Override\n    public void run() {\n        System.out.println(\"execute!\");\n    }\n});\n=========================\n\n看看execute的源码\npublic void execute(Runnable command) {\n    if (command == null)\n        throw new NullPointerException();\n    int c = ctl.get();\n    // workerCountOf 从ctl中取工作线程的数量，这里有一定的技巧性，下面详细讲一下\n    if (workerCountOf(c) < corePoolSize) {\n        if (addWorker(command, true))\n            return;\n        c = ctl.get();\n    }\n    // 看当前线程池状态是否Running，这里也是从ctl取值，有点意思\n    // 把任务用offer方法塞进工作队列，如果插入成功，则返回ture\n    if (isRunning(c) && workQueue.offer(command)) {\n        int recheck = ctl.get();\n        // 二次检查线程池状态是否为Running，以及从任务队列获取当前任务是否成功\n        if (! isRunning(recheck) && remove(command))\n            reject(command);\n        else if (workerCountOf(recheck) == 0)\n            // addWorker方法里通过两个for循环通过ctl判断线程池的当前状态是否能新增线程，通过CAS机制修改线程池状态。最后新建worker对象，插入worker队列。\n            addWorker(null, false);\n    }\n    // 线程池的线程数量不够了，增加线程，增加失败的话就拒绝这次execute调用\n    else if (!addWorker(command, false))\n        // reject方法里其实是调用定义线程池的时候构造函数传入的handler，JDK内建了四个拒绝策略AbortPolicy、DiscardPolicy、DiscardOldestPolicy、CallerRunsPolicy，含义分别是：抛出RejectedExecutionException异常、直接忽略提交的任务、把之前提交的任务移除，添加新的任务、让当前线程直接处理这个任务。用户也可以实现RejectedExecutionHandler接口，完成自己的拒绝策略。\n        reject(command);\n    }\n```\n\n- DefaultThreadFactory  \n```\nstatic class DefaultThreadFactory implements ThreadFactory {\n    private static final AtomicInteger poolNumber = new AtomicInteger(1);\n    private final ThreadGroup group;\n    private final AtomicInteger threadNumber = new AtomicInteger(1);\n    private final String namePrefix;\n\n    DefaultThreadFactory() {\n        SecurityManager s = System.getSecurityManager();\n        group = (s != null) ? s.getThreadGroup() :\n                              Thread.currentThread().getThreadGroup();\n        namePrefix = \"pool-\" +\n                      poolNumber.getAndIncrement() +\n                     \"-thread-\";\n    }\n\n    // 核心是这个newThread方法\n    public Thread newThread(Runnable r) {\n        Thread t = new Thread(group, r,\n                              namePrefix + threadNumber.getAndIncrement(),\n                              0);\n        if (t.isDaemon())\n            t.setDaemon(false);\n        if (t.getPriority() != Thread.NORM_PRIORITY)\n            t.setPriority(Thread.NORM_PRIORITY);\n        return t;\n    }\n}\n```\n- ctl是如何存储线程状态和数量的\n```\n定义\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\nprivate static final int COUNT_BITS = Integer.SIZE - 3;\nprivate static final int CAPACITY   = (1 << COUNT_BITS) - 1;\n\n// runState is stored in the high-order bits\nprivate static final int RUNNING    = -1 << COUNT_BITS;\nprivate static final int SHUTDOWN   =  0 << COUNT_BITS;\nprivate static final int STOP       =  1 << COUNT_BITS;\nprivate static final int TIDYING    =  2 << COUNT_BITS;\nprivate static final int TERMINATED =  3 << COUNT_BITS;\n\n// Packing and unpacking ctl\nprivate static int runStateOf(int c)     { return c & ~CAPACITY; }\nprivate static int workerCountOf(int c)  { return c & CAPACITY; }\nprivate static int ctlOf(int rs, int wc) { return rs | wc; }\n\n上面那串定义看了可能有点懵，源码中使用了一个AtomicInteger对将当前线程的工作状态和工作线程数量(有效线程数)使用同一个整数进行包装。\n为了将两个数值包装在同一个整数中，它将32位的高3位表示线程的状态值，而后29位来表示线程的数量。\n其实这样设计的理由很简单，因为线程的状态和数量往往需要同时更新，然而线程池天生处在一个并发的环境下，那么当对2个变量进行修改时，那么就势必需要通过锁来进行线程安全的处理，从而保证2个变量修改具备原子性；但是这种做法对于性能的影响是非常严重的，因此在ThreadPoolExecutor将两个变量的分别包装在一个变量中，最后的并发操作发生在AtomicInteger上，而AtomicInteger恰恰就是具有一个无锁原子操作类,这样既可以解决线程安全的问题，又可以规避避免所的使用，从而提供性能。\n```\n- ScheduledThreadPoolExecutor如何实现调度\n```\nTODO\n优先队列\n```\n        \n### JDK线程池存在的问题\n- FixedThreadPool 和 SingleThreadPool 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。\n- CachedThreadPool 和 ScheduledThreadPool允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 \n- 多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。\n- ScheduledExecutorService并发执行大量调度时候有瓶颈，大并发量的线程调度应该用时间环模式。 \n\n~~不要感觉自己写几千行的类是很烂的代码，ThreadPoolExecutor也有2100多行（含注释）~~\n\n## 线程竞争\n### 线程竞争的定义\n在多线程中，每个线程的执行顺序，是无法预测不可控制的，那么在对数据进行读写的时候便存在由于读写顺序多乱而造成数据混乱错误的可能性。这里涉及到线程锁\n\n### 用锁控制线程间的竞争\n> 这里介绍锁的基本概念以及常见分类，详细在另外的时间再做。\n\n- 共享锁/排它锁 \n\n```\n共享锁和排他锁是从同一时刻是否允许多个线程持有该锁的角度来划分。\n共享锁允许同一时刻多个线程进入持有锁，访问临界区资源。而排他锁就是通常意义上的锁，同一时刻只允许一个线程访问临界资源。对于共享锁，主要是指对数据库读操作中的读锁，在读写资源的时候如果没有线程持有写锁和请求写锁，则此时允许多个线程持有读锁。 \n在这里理解共享锁的时候，不是任意时刻都允许多线程持有共享锁的，而是在某些特殊情况下才允许多线程持有共享锁，在某些情况下不允许多个线程持有共享锁，否则，如果没有前提条件任意时刻都允许线程任意持有共享锁，则共享锁的存在无意义的。例如读写锁中的读锁，只有当没有写锁和写锁请求的时候，就可以允许多个线程同时持有读锁。这里的前提条件就是“没有写锁和写锁请求”，而不是任意时刻都允许多线程持有共享读锁。\n```\n- 悲观锁/乐观锁  \n\n```\n主要用于数据库数据的操作中，而对于线程锁中较为少见。\n悲观锁和乐观锁是一种加锁思想。对于乐观锁，在进行数据读取的时候不会加锁，而在进行写入操作的时候会判断一下数据是否被其它线程修改过，如果修改则更新数据，如果没有则继续进行数据写入操作。乐观锁不是系统中自带的锁，而是一种数据读取写入思想。应用场景例如：在向数据库中插入数据的时候，先从数据库中读取记录修改版本标识字段，如果该字段没有发生变化（没有其他线程对数据进行写操作）则执行写入操作，如果发生变化则重新计算数据。\n对于悲观锁，无论是进行读操作还是进行写操作都会进行加锁操作。对于悲观锁，如果并发量较大则比较耗费资源，当然保证了数据的安全性。\n```\n- 可重入锁/不可重入\n\n```\n这两个概念是从同一个线程在已经持有锁的前提下能否再次持有锁的角度来区分的。\n对于可重入锁，如果该线程已经获取到锁且未释放的情况下允许再次获取该锁访问临界区资源。此种情况主要是用在递归调用的情况下和不同的临界区使用相同的锁的情况下。\n对于不可重入锁，则不允许同一线程在持有锁的情况下再次获取该锁并访问临界区资源。对于不可重入锁，使用的时候需要小心以免造成死锁。\n```\n- 公平锁/非公平锁\n\n```\n这两个概念主要使用线程获取锁的顺序角度来区分的。\n对于公平锁，所有等待的线程按照按照请求锁的先后循序分别依次获取锁。\n对于非公平锁，等待线程的线程获取锁的顺序和请求的先后不是对应关系。有可能是随机的获取锁，也有可能按照其他策略获取锁，总之不是按照FIFO的顺序获取锁。\n在使用ReentrantLock的时候可以通过构造方法主动选择是实现公平锁还是非公平锁。\n```\n- 自旋锁/非自旋锁\n\n```\n这两种概念是从线程等待的处理机制来区分的。\n自旋锁在进行锁请求等待的时候不进行wait挂起，不释放CPU资源，执行while空循环。直至获取锁访问临界区资源。适用于等待锁时间较短的情景，如果等待时间较长，则会耗费大量的CPU资源。而如果等待时间较短则可以节约大量的线程切换资源。\n非自旋锁在进行锁等待的时候会释放CPU资源，可以通多sleep wait 或者CPU中断切换上下文，切换该线程。在线程等待时间较长的情况下可以选择此种实现机制。\n除此之外还有一种介于两者之间的锁机制——自适应自旋锁。当线程进行等待的时候先进性自旋等待，在自旋一定时间(次数)之后如果依旧没有持有锁则挂起等待。在jvm中synchronized锁已经使用该机制进行处理锁等待的情况。\n在工作中可以根据不同的情况选取合适的锁进行使用。无论使用哪种锁，其目的都是保证程序能够按照要求顺利执行，避免数据混乱情况的发生。\n```\n详细的[参考](https://www.cnblogs.com/PerkinsZhu/p/7392006.html)这里\n### 锁的弊端\n不管是何种锁，本质上都是对资源的访问加以限制，让同一时间只有一个线程访问资源。在高并发的时候，锁往往会成为系统的瓶颈，更不用说同时带来的死锁风险。\n\n### 不用锁解决线程安全的方式\n我们接下来讨论有无高效解决线程竞争的模式，避免锁带来的以上问题。\n\n## 常见线程模型\n\n### 线程模型的定义\n线程模型决定了应用或框架如何执行代码，所以选择正确的线程模型是很重要的事情。通俗的讲，如果同样给你一定数量的线程如（100个），分析实际的业务场景，如何让它们的效率最大化。这就是选取线程模型应该做的事情。\n> 同时线程模型也指线程映射到操作系统进程的模型 https://blog.csdn.net/lyc201219/article/details/79228575\n\n- Future模型\n\n结合Callable接口配合使用，Callable是类似于Runnable的接口。Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。如果不使用Future模型，就需要使用到一个全局变量来保存子线程处理之后的结果。子线程处理结束之后，把结果保存在全局变量中供主线程进行调用。一旦涉及到全局能量便存在着多线程读写全局变量错误的风险。\n\n```\nExecutorService executorService = Executors.newFixedThreadPool(5);\nFuture<?> future = executorService.submit(new Callable<Object>() {\n    @Override\n    public Object call() throws Exception {\n\n        return null;\n    }\n});\nObject o = future.get();\n```\n- fork&join 模型\n\n该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果\n\n```\n/**\n * 将num*2 用frok&join的思想做\n */\nstatic class ResultTask extends RecursiveTask<Integer> {\n    private int num;\n\n    public ResultTask(int num) {\n        this.num = num;\n    }\n\n    @Override\n    protected Integer compute() {\n        if (num < 10) {\n            return num * 2;\n        } else {\n            //对任务进行拆分，注意这里不仅仅可以一分为二进行拆分，也可以拆为多个子任务\n            int temp = num / 2;\n            ResultTask left = new ResultTask(temp);\n            ResultTask right = new ResultTask(num - temp);\n            left.fork();\n            right.fork();\n            //对子任务处理的结果进行合并\n            int result = left.join() + right.join();\n            return result;\n        }\n    }\n}\n\npublic static void main(String[] args) throws Exception {\n    ForkJoinPool pool = new ForkJoinPool();\n    ForkJoinTask<Integer> future = pool.submit(new ResultTask(100));\n    try {\n        Integer integer = future.get();\n        System.out.println(integer);\n        pool.awaitTermination(1000, TimeUnit.MILLISECONDS);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n    pool.shutdown();\n}\n```\n- 生产者消费者模型\n\n生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题\n\n- master-worker模型\n\nmaster-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master\n\n- actor消息模型\n\nactor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继续传递（分发）给其它actor进行处理。Actors一大重要特征在于actors之间相互隔离，它们并不互相共享内存。这点区别于上述的对象。也就是说，一个actor能维持一个私有的状态，并且这个状态不可能被另一个actor所改变。\n\nactor并发模型的应用场景？\n适合有状态或者称可变状态的业务场景，如果用DDD术语，适合聚合根，具体案例如订单，订单有状态，比如未付款未发货，已经付款未发货，已付款已发货，导致订单状态的变化是事件行为，比如付款行为导致顶大状态切换到\"已经付款未发货\"。\n\nactor的原理\n行为导致状态变化，行为执行是依靠线程，比如用户发出一个付款的请求，服务器后端派出一个线程来执行付款请求，携带付款的金额和银行卡等等信息，当付款请求被成功完成后，线程还要做的事情就是改变订单状态，这时线程访问订单的一个方法比如changeState。如果后台有管理员同时修改这个订单状态，那么实际有两个线程共同访问同一个数据，这时就必须锁，比如我们在changeState方法前加上sychronized这样同步语法。使用同步语法坏处是每次只能一个线程进行处理，如同上厕所，只有一个蹲坑，人多就必须排队，这种情况性能很低。\n\n避免changeState方法被外部两个线程同时占用访问，那么我们自己设计专门的线程守护订单状态，而不是普通方法代码，普通方法代码比较弱势，容易被外部线程hold住，而我们设计的这个对象没有普通方法，只有线程，这样就变成Order的守护线程和外部访问请求线程的通讯问题了。Actor采取的这种类似消息机制的方式，实际在守护线程和外部线程之间有一个队列，俗称信箱，外部线程只要把请求放入，守护线程就读取进行处理。这种异步高效方式是Actor基本原理，以ERlang和Scala语言为主要特征，他们封装得更好，类似将消息队列微观化了。\n参考[使用Akka Actor和Java 8构建反应式应用](http://www.infoq.com/cn/articles/Building-Reactive-Applications-with-Akka)\n\n- reactor模型\n\n一图胜千言，来看看Doug Lea大神画的图（Scalable IO in Java）\n![image](https://images2018.cnblogs.com/blog/1424165/201808/1424165-20180803142242491-1328318201.png)\n\n\n## 参考资料\n- https://www.jianshu.com/p/20b7327f9f56 ThreadPoolExecutor源码分析\n- https://blog.csdn.net/wangjinnan16/article/details/78377642  Netty4实战第十五章：选择正确的线程模型\n- https://www.cnblogs.com/PerkinsZhu/p/7570775.html 常见线程模型介绍\n- http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf Scalable IO in Java","slug":"线程模型","published":1,"updated":"2019-08-26T07:54:42.995Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl6s005iqotnd7ubjb1m","content":"<h1 id=\"线程模型分享-（上）\"><a href=\"#线程模型分享-（上）\" class=\"headerlink\" title=\"线程模型分享 （上）\"></a>线程模型分享 （上）</h1><p>本篇文章是公司大佬<strong>约拿</strong>上周五给我培训的文档，分享给大家。非常感谢百忙之中给我培训。</p>\n<a id=\"more\"></a>\n<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><blockquote>\n<p>为什么有这篇文章？</p>\n</blockquote>\n<p>起先看我的目标是看netty的线程模型，但是在看netty的过程中，我发现很多知识点是互相关联的。比如netty的EventLoop，EventLoopGroup其实是继承自JDK的线程池。学习netty的线程模型前需要懂得预备知识。基于这个理由，我把预备内容部分也写下来。分享一共会分为上下两篇，这里是第上篇，这篇主要是先导，给【下篇】的知识打基础，有了上篇的基础再看下篇就容易多了。</p>\n<blockquote>\n<p>这篇文章会有什么内容？</p>\n<ul>\n<li>JDK线程池的类继承层次</li>\n<li>构建线程池的几个核心要素</li>\n<li>JDK线程池关键方法的分析</li>\n<li>JDK线程池存在的问题</li>\n<li>常见的线程模型举例</li>\n<li>线程模型适用场景分析 </li>\n<li>线程竞争与锁</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>文章目的</p>\n<ul>\n<li>可以自定义JDK线程池，了解JDK线程池的局限场景</li>\n<li>了解线程模型的原理及适用场景</li>\n<li>了解锁的目的及分类</li>\n</ul>\n</blockquote>\n<h2 id=\"线程启动与停止\"><a href=\"#线程启动与停止\" class=\"headerlink\" title=\"线程启动与停止\"></a>线程启动与停止</h2><blockquote>\n<p>如何启动线程</p>\n</blockquote>\n<p>这个比较基础的不说了</p>\n<blockquote>\n<p>如何停止线程</p>\n</blockquote>\n<ol>\n<li>线程类有stop，suspend方法，但是被弃用了。</li>\n</ol>\n<ul>\n<li><strong>stop</strong> 会立即杀死线程，可能导致执行一半的程序被终结导致数据不一致的风险</li>\n<li><strong>suspend</strong> 会挂起线程，但是不会释放锁，可能会造成死锁</li>\n<li>线程池有个 <strong>shutdown</strong> 方法只是阻止线程池接受新的线程 ，并不会停止已存在的线程。</li>\n</ul>\n<ol start=\"2\">\n<li>正确的方法</li>\n</ol>\n<ul>\n<li>线程自己运行完成</li>\n<li>设置终止标志，在循环中检查这个标志</li>\n</ul>\n<h2 id=\"JDK线程池继承层次\"><a href=\"#JDK线程池继承层次\" class=\"headerlink\" title=\"JDK线程池继承层次\"></a>JDK线程池继承层次</h2><h3 id=\"结构图\"><a href=\"#结构图\" class=\"headerlink\" title=\"结构图\"></a>结构图</h3><p><img src=\"https://user-images.githubusercontent.com/5201798/47539254-f5648380-d901-11e8-9446-8a4705430539.png\" alt=\"image\"></p>\n<p>这个图上很多类不用看，因为都是Executors类的内部类，代理类，核心就是下图的几个接口和类。</p>\n<p><img src=\"https://user-images.githubusercontent.com/5201798/47539187-a74f8000-d901-11e8-9f94-f8f4be0477a0.png\" alt=\"image\"></p>\n<h3 id=\"线程池核心要素\"><a href=\"#线程池核心要素\" class=\"headerlink\" title=\"线程池核心要素\"></a>线程池核心要素</h3><ul>\n<li><p>核心线程池大小 corePoolSize</p>\n<blockquote>\n<p>设置一个线程池中的核心线程数 如果设置allowCoreThreadTimeOut为false的情况下： 即使当线程池中的线程处于空闲状态，这些线程也不会被线程池中移除。 如果设置了allowCoreThreadTimeOut为true, 那么当核心线程在空闲了一段时间后依旧没有用于工作，那么将会从线程池中移除。 注意:(allowCoreThreadTimeOut默认为false，通常情况下也无需做修改)</p>\n</blockquote>\n</li>\n<li><p>线程保持活跃时间</p>\n<blockquote>\n<p>keepAliveTime:当线程池中的线程数量大于核心线程数，如果这些多出的线程在经过了keepAliveTime时间后，依然处于空闲状态，那么这些多出的空闲线程将会被结束其生命周期。</p>\n</blockquote>\n</li>\n<li><p>时间单位unit</p>\n<blockquote>\n<p>keepAliveTime的时间单位</p>\n</blockquote>\n</li>\n<li><p>最大线程池大小 maximumPoolSize</p>\n<blockquote>\n<p>线程池中所允许创建最大线程数量，除了受JVM内存大小限制外，Linux下还受/proc/sys/kernel/pid_max（即系统允许的最大pid）、/proc/sys/kernel/threads-max（系统支持的最大线程数）、max_user_process（ulimit-u）（每个用户允许的最大进程数）、/proc/sys/vm/max_map_count（Linux支持虚拟内存，也就是交换空间,可以把磁盘的一部分作为RAM的扩展，逻辑存储和物理存储的映射就要保存在地址映射表中。max_map_count限制了线程可以拥有的VMAs ）</p>\n</blockquote>\n</li>\n<li><p>拒绝策略handler</p>\n<blockquote>\n<p>当线程池中的线程数量达到最大并且阻塞队列也已经满了无法再添加任务时，线程池所采取的处理策略，JDK有四种内建的拒绝策略，下面会讲到。</p>\n</blockquote>\n</li>\n<li><p>等待队列workQueue</p>\n<blockquote>\n<p>用于存放任务的阻塞队列，当线程池中的核心线程都处在执行任务时，提交的任务将被存储在workQueue进行缓冲。该队列只能存放通过execute方法提交的Runnable任务，如果是个ScheduledThreadPoolExecutor，那么这个队列不仅需要阻塞，而且还是个优先队列。</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"核心代码分析\"><a href=\"#核心代码分析\" class=\"headerlink\" title=\"核心代码分析\"></a>核心代码分析</h3><p>ThreadPoolExecutor 一个根正苗红的线程池继承类。</p>\n<ul>\n<li><p>我们看看他的excute方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">这里是调用</span><br><span class=\"line\">int corePoolSize = 1;</span><br><span class=\"line\">int maximumPoolSize = 2;</span><br><span class=\"line\">long keepAliveTime = 60;</span><br><span class=\"line\">TimeUnit unit = TimeUnit.SECONDS;</span><br><span class=\"line\">BlockingQueue&lt;Runnable&gt; workQueue = new LinkedBlockingDeque&lt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime</span><br><span class=\"line\">        , unit, workQueue, Executors.defaultThreadFactory(), new RejectedExecutionHandler() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;</span><br><span class=\"line\">        throw new RejectedExecutionException(&quot;Task &quot; + r.toString() +</span><br><span class=\"line\">                &quot; rejected from &quot; +</span><br><span class=\"line\">                e.toString());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">threadPoolExecutor.execute(new Runnable() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void run() &#123;</span><br><span class=\"line\">        System.out.println(&quot;execute!&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">=========================</span><br><span class=\"line\"></span><br><span class=\"line\">看看execute的源码</span><br><span class=\"line\">public void execute(Runnable command) &#123;</span><br><span class=\"line\">    if (command == null)</span><br><span class=\"line\">        throw new NullPointerException();</span><br><span class=\"line\">    int c = ctl.get();</span><br><span class=\"line\">    // workerCountOf 从ctl中取工作线程的数量，这里有一定的技巧性，下面详细讲一下</span><br><span class=\"line\">    if (workerCountOf(c) &lt; corePoolSize) &#123;</span><br><span class=\"line\">        if (addWorker(command, true))</span><br><span class=\"line\">            return;</span><br><span class=\"line\">        c = ctl.get();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // 看当前线程池状态是否Running，这里也是从ctl取值，有点意思</span><br><span class=\"line\">    // 把任务用offer方法塞进工作队列，如果插入成功，则返回ture</span><br><span class=\"line\">    if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class=\"line\">        int recheck = ctl.get();</span><br><span class=\"line\">        // 二次检查线程池状态是否为Running，以及从任务队列获取当前任务是否成功</span><br><span class=\"line\">        if (! isRunning(recheck) &amp;&amp; remove(command))</span><br><span class=\"line\">            reject(command);</span><br><span class=\"line\">        else if (workerCountOf(recheck) == 0)</span><br><span class=\"line\">            // addWorker方法里通过两个for循环通过ctl判断线程池的当前状态是否能新增线程，通过CAS机制修改线程池状态。最后新建worker对象，插入worker队列。</span><br><span class=\"line\">            addWorker(null, false);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // 线程池的线程数量不够了，增加线程，增加失败的话就拒绝这次execute调用</span><br><span class=\"line\">    else if (!addWorker(command, false))</span><br><span class=\"line\">        // reject方法里其实是调用定义线程池的时候构造函数传入的handler，JDK内建了四个拒绝策略AbortPolicy、DiscardPolicy、DiscardOldestPolicy、CallerRunsPolicy，含义分别是：抛出RejectedExecutionException异常、直接忽略提交的任务、把之前提交的任务移除，添加新的任务、让当前线程直接处理这个任务。用户也可以实现RejectedExecutionHandler接口，完成自己的拒绝策略。</span><br><span class=\"line\">        reject(command);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>DefaultThreadFactory  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static class DefaultThreadFactory implements ThreadFactory &#123;</span><br><span class=\"line\">    private static final AtomicInteger poolNumber = new AtomicInteger(1);</span><br><span class=\"line\">    private final ThreadGroup group;</span><br><span class=\"line\">    private final AtomicInteger threadNumber = new AtomicInteger(1);</span><br><span class=\"line\">    private final String namePrefix;</span><br><span class=\"line\"></span><br><span class=\"line\">    DefaultThreadFactory() &#123;</span><br><span class=\"line\">        SecurityManager s = System.getSecurityManager();</span><br><span class=\"line\">        group = (s != null) ? s.getThreadGroup() :</span><br><span class=\"line\">                              Thread.currentThread().getThreadGroup();</span><br><span class=\"line\">        namePrefix = &quot;pool-&quot; +</span><br><span class=\"line\">                      poolNumber.getAndIncrement() +</span><br><span class=\"line\">                     &quot;-thread-&quot;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 核心是这个newThread方法</span><br><span class=\"line\">    public Thread newThread(Runnable r) &#123;</span><br><span class=\"line\">        Thread t = new Thread(group, r,</span><br><span class=\"line\">                              namePrefix + threadNumber.getAndIncrement(),</span><br><span class=\"line\">                              0);</span><br><span class=\"line\">        if (t.isDaemon())</span><br><span class=\"line\">            t.setDaemon(false);</span><br><span class=\"line\">        if (t.getPriority() != Thread.NORM_PRIORITY)</span><br><span class=\"line\">            t.setPriority(Thread.NORM_PRIORITY);</span><br><span class=\"line\">        return t;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>ctl是如何存储线程状态和数量的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">定义</span><br><span class=\"line\">private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));</span><br><span class=\"line\">private static final int COUNT_BITS = Integer.SIZE - 3;</span><br><span class=\"line\">private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;</span><br><span class=\"line\"></span><br><span class=\"line\">// runState is stored in the high-order bits</span><br><span class=\"line\">private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\">private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\">private static final int STOP       =  1 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\">private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\">private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\"></span><br><span class=\"line\">// Packing and unpacking ctl</span><br><span class=\"line\">private static int runStateOf(int c)     &#123; return c &amp; ~CAPACITY; &#125;</span><br><span class=\"line\">private static int workerCountOf(int c)  &#123; return c &amp; CAPACITY; &#125;</span><br><span class=\"line\">private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">上面那串定义看了可能有点懵，源码中使用了一个AtomicInteger对将当前线程的工作状态和工作线程数量(有效线程数)使用同一个整数进行包装。</span><br><span class=\"line\">为了将两个数值包装在同一个整数中，它将32位的高3位表示线程的状态值，而后29位来表示线程的数量。</span><br><span class=\"line\">其实这样设计的理由很简单，因为线程的状态和数量往往需要同时更新，然而线程池天生处在一个并发的环境下，那么当对2个变量进行修改时，那么就势必需要通过锁来进行线程安全的处理，从而保证2个变量修改具备原子性；但是这种做法对于性能的影响是非常严重的，因此在ThreadPoolExecutor将两个变量的分别包装在一个变量中，最后的并发操作发生在AtomicInteger上，而AtomicInteger恰恰就是具有一个无锁原子操作类,这样既可以解决线程安全的问题，又可以规避避免所的使用，从而提供性能。</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>ScheduledThreadPoolExecutor如何实现调度</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TODO</span><br><span class=\"line\">优先队列</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"JDK线程池存在的问题\"><a href=\"#JDK线程池存在的问题\" class=\"headerlink\" title=\"JDK线程池存在的问题\"></a>JDK线程池存在的问题</h3><ul>\n<li>FixedThreadPool 和 SingleThreadPool 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。</li>\n<li>CachedThreadPool 和 ScheduledThreadPool允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 </li>\n<li>多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。</li>\n<li>ScheduledExecutorService并发执行大量调度时候有瓶颈，大并发量的线程调度应该用时间环模式。 </li>\n</ul>\n<p><del>不要感觉自己写几千行的类是很烂的代码，ThreadPoolExecutor也有2100多行（含注释）</del></p>\n<h2 id=\"线程竞争\"><a href=\"#线程竞争\" class=\"headerlink\" title=\"线程竞争\"></a>线程竞争</h2><h3 id=\"线程竞争的定义\"><a href=\"#线程竞争的定义\" class=\"headerlink\" title=\"线程竞争的定义\"></a>线程竞争的定义</h3><p>在多线程中，每个线程的执行顺序，是无法预测不可控制的，那么在对数据进行读写的时候便存在由于读写顺序多乱而造成数据混乱错误的可能性。这里涉及到线程锁</p>\n<h3 id=\"用锁控制线程间的竞争\"><a href=\"#用锁控制线程间的竞争\" class=\"headerlink\" title=\"用锁控制线程间的竞争\"></a>用锁控制线程间的竞争</h3><blockquote>\n<p>这里介绍锁的基本概念以及常见分类，详细在另外的时间再做。</p>\n</blockquote>\n<ul>\n<li>共享锁/排它锁 </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">共享锁和排他锁是从同一时刻是否允许多个线程持有该锁的角度来划分。</span><br><span class=\"line\">共享锁允许同一时刻多个线程进入持有锁，访问临界区资源。而排他锁就是通常意义上的锁，同一时刻只允许一个线程访问临界资源。对于共享锁，主要是指对数据库读操作中的读锁，在读写资源的时候如果没有线程持有写锁和请求写锁，则此时允许多个线程持有读锁。 </span><br><span class=\"line\">在这里理解共享锁的时候，不是任意时刻都允许多线程持有共享锁的，而是在某些特殊情况下才允许多线程持有共享锁，在某些情况下不允许多个线程持有共享锁，否则，如果没有前提条件任意时刻都允许线程任意持有共享锁，则共享锁的存在无意义的。例如读写锁中的读锁，只有当没有写锁和写锁请求的时候，就可以允许多个线程同时持有读锁。这里的前提条件就是“没有写锁和写锁请求”，而不是任意时刻都允许多线程持有共享读锁。</span><br></pre></td></tr></table></figure>\n<ul>\n<li>悲观锁/乐观锁  </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主要用于数据库数据的操作中，而对于线程锁中较为少见。</span><br><span class=\"line\">悲观锁和乐观锁是一种加锁思想。对于乐观锁，在进行数据读取的时候不会加锁，而在进行写入操作的时候会判断一下数据是否被其它线程修改过，如果修改则更新数据，如果没有则继续进行数据写入操作。乐观锁不是系统中自带的锁，而是一种数据读取写入思想。应用场景例如：在向数据库中插入数据的时候，先从数据库中读取记录修改版本标识字段，如果该字段没有发生变化（没有其他线程对数据进行写操作）则执行写入操作，如果发生变化则重新计算数据。</span><br><span class=\"line\">对于悲观锁，无论是进行读操作还是进行写操作都会进行加锁操作。对于悲观锁，如果并发量较大则比较耗费资源，当然保证了数据的安全性。</span><br></pre></td></tr></table></figure>\n<ul>\n<li>可重入锁/不可重入</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">这两个概念是从同一个线程在已经持有锁的前提下能否再次持有锁的角度来区分的。</span><br><span class=\"line\">对于可重入锁，如果该线程已经获取到锁且未释放的情况下允许再次获取该锁访问临界区资源。此种情况主要是用在递归调用的情况下和不同的临界区使用相同的锁的情况下。</span><br><span class=\"line\">对于不可重入锁，则不允许同一线程在持有锁的情况下再次获取该锁并访问临界区资源。对于不可重入锁，使用的时候需要小心以免造成死锁。</span><br></pre></td></tr></table></figure>\n<ul>\n<li>公平锁/非公平锁</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">这两个概念主要使用线程获取锁的顺序角度来区分的。</span><br><span class=\"line\">对于公平锁，所有等待的线程按照按照请求锁的先后循序分别依次获取锁。</span><br><span class=\"line\">对于非公平锁，等待线程的线程获取锁的顺序和请求的先后不是对应关系。有可能是随机的获取锁，也有可能按照其他策略获取锁，总之不是按照FIFO的顺序获取锁。</span><br><span class=\"line\">在使用ReentrantLock的时候可以通过构造方法主动选择是实现公平锁还是非公平锁。</span><br></pre></td></tr></table></figure>\n<ul>\n<li>自旋锁/非自旋锁</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">这两种概念是从线程等待的处理机制来区分的。</span><br><span class=\"line\">自旋锁在进行锁请求等待的时候不进行wait挂起，不释放CPU资源，执行while空循环。直至获取锁访问临界区资源。适用于等待锁时间较短的情景，如果等待时间较长，则会耗费大量的CPU资源。而如果等待时间较短则可以节约大量的线程切换资源。</span><br><span class=\"line\">非自旋锁在进行锁等待的时候会释放CPU资源，可以通多sleep wait 或者CPU中断切换上下文，切换该线程。在线程等待时间较长的情况下可以选择此种实现机制。</span><br><span class=\"line\">除此之外还有一种介于两者之间的锁机制——自适应自旋锁。当线程进行等待的时候先进性自旋等待，在自旋一定时间(次数)之后如果依旧没有持有锁则挂起等待。在jvm中synchronized锁已经使用该机制进行处理锁等待的情况。</span><br><span class=\"line\">在工作中可以根据不同的情况选取合适的锁进行使用。无论使用哪种锁，其目的都是保证程序能够按照要求顺利执行，避免数据混乱情况的发生。</span><br></pre></td></tr></table></figure>\n<p>详细的<a href=\"https://www.cnblogs.com/PerkinsZhu/p/7392006.html\" target=\"_blank\" rel=\"noopener\">参考</a>这里</p>\n<h3 id=\"锁的弊端\"><a href=\"#锁的弊端\" class=\"headerlink\" title=\"锁的弊端\"></a>锁的弊端</h3><p>不管是何种锁，本质上都是对资源的访问加以限制，让同一时间只有一个线程访问资源。在高并发的时候，锁往往会成为系统的瓶颈，更不用说同时带来的死锁风险。</p>\n<h3 id=\"不用锁解决线程安全的方式\"><a href=\"#不用锁解决线程安全的方式\" class=\"headerlink\" title=\"不用锁解决线程安全的方式\"></a>不用锁解决线程安全的方式</h3><p>我们接下来讨论有无高效解决线程竞争的模式，避免锁带来的以上问题。</p>\n<h2 id=\"常见线程模型\"><a href=\"#常见线程模型\" class=\"headerlink\" title=\"常见线程模型\"></a>常见线程模型</h2><h3 id=\"线程模型的定义\"><a href=\"#线程模型的定义\" class=\"headerlink\" title=\"线程模型的定义\"></a>线程模型的定义</h3><p>线程模型决定了应用或框架如何执行代码，所以选择正确的线程模型是很重要的事情。通俗的讲，如果同样给你一定数量的线程如（100个），分析实际的业务场景，如何让它们的效率最大化。这就是选取线程模型应该做的事情。</p>\n<blockquote>\n<p>同时线程模型也指线程映射到操作系统进程的模型 <a href=\"https://blog.csdn.net/lyc201219/article/details/79228575\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lyc201219/article/details/79228575</a></p>\n</blockquote>\n<ul>\n<li>Future模型</li>\n</ul>\n<p>结合Callable接口配合使用，Callable是类似于Runnable的接口。Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。如果不使用Future模型，就需要使用到一个全局变量来保存子线程处理之后的结果。子线程处理结束之后，把结果保存在全局变量中供主线程进行调用。一旦涉及到全局能量便存在着多线程读写全局变量错误的风险。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ExecutorService executorService = Executors.newFixedThreadPool(5);</span><br><span class=\"line\">Future&lt;?&gt; future = executorService.submit(new Callable&lt;Object&gt;() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public Object call() throws Exception &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        return null;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">Object o = future.get();</span><br></pre></td></tr></table></figure>\n<ul>\n<li>fork&amp;join 模型</li>\n</ul>\n<p>该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * 将num*2 用frok&amp;join的思想做</span><br><span class=\"line\"> */</span><br><span class=\"line\">static class ResultTask extends RecursiveTask&lt;Integer&gt; &#123;</span><br><span class=\"line\">    private int num;</span><br><span class=\"line\"></span><br><span class=\"line\">    public ResultTask(int num) &#123;</span><br><span class=\"line\">        this.num = num;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    protected Integer compute() &#123;</span><br><span class=\"line\">        if (num &lt; 10) &#123;</span><br><span class=\"line\">            return num * 2;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            //对任务进行拆分，注意这里不仅仅可以一分为二进行拆分，也可以拆为多个子任务</span><br><span class=\"line\">            int temp = num / 2;</span><br><span class=\"line\">            ResultTask left = new ResultTask(temp);</span><br><span class=\"line\">            ResultTask right = new ResultTask(num - temp);</span><br><span class=\"line\">            left.fork();</span><br><span class=\"line\">            right.fork();</span><br><span class=\"line\">            //对子任务处理的结果进行合并</span><br><span class=\"line\">            int result = left.join() + right.join();</span><br><span class=\"line\">            return result;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">public static void main(String[] args) throws Exception &#123;</span><br><span class=\"line\">    ForkJoinPool pool = new ForkJoinPool();</span><br><span class=\"line\">    ForkJoinTask&lt;Integer&gt; future = pool.submit(new ResultTask(100));</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        Integer integer = future.get();</span><br><span class=\"line\">        System.out.println(integer);</span><br><span class=\"line\">        pool.awaitTermination(1000, TimeUnit.MILLISECONDS);</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    pool.shutdown();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>生产者消费者模型</li>\n</ul>\n<p>生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题</p>\n<ul>\n<li>master-worker模型</li>\n</ul>\n<p>master-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master</p>\n<ul>\n<li>actor消息模型</li>\n</ul>\n<p>actor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继续传递（分发）给其它actor进行处理。Actors一大重要特征在于actors之间相互隔离，它们并不互相共享内存。这点区别于上述的对象。也就是说，一个actor能维持一个私有的状态，并且这个状态不可能被另一个actor所改变。</p>\n<p>actor并发模型的应用场景？<br>适合有状态或者称可变状态的业务场景，如果用DDD术语，适合聚合根，具体案例如订单，订单有状态，比如未付款未发货，已经付款未发货，已付款已发货，导致订单状态的变化是事件行为，比如付款行为导致顶大状态切换到”已经付款未发货”。</p>\n<p>actor的原理<br>行为导致状态变化，行为执行是依靠线程，比如用户发出一个付款的请求，服务器后端派出一个线程来执行付款请求，携带付款的金额和银行卡等等信息，当付款请求被成功完成后，线程还要做的事情就是改变订单状态，这时线程访问订单的一个方法比如changeState。如果后台有管理员同时修改这个订单状态，那么实际有两个线程共同访问同一个数据，这时就必须锁，比如我们在changeState方法前加上sychronized这样同步语法。使用同步语法坏处是每次只能一个线程进行处理，如同上厕所，只有一个蹲坑，人多就必须排队，这种情况性能很低。</p>\n<p>避免changeState方法被外部两个线程同时占用访问，那么我们自己设计专门的线程守护订单状态，而不是普通方法代码，普通方法代码比较弱势，容易被外部线程hold住，而我们设计的这个对象没有普通方法，只有线程，这样就变成Order的守护线程和外部访问请求线程的通讯问题了。Actor采取的这种类似消息机制的方式，实际在守护线程和外部线程之间有一个队列，俗称信箱，外部线程只要把请求放入，守护线程就读取进行处理。这种异步高效方式是Actor基本原理，以ERlang和Scala语言为主要特征，他们封装得更好，类似将消息队列微观化了。<br>参考<a href=\"http://www.infoq.com/cn/articles/Building-Reactive-Applications-with-Akka\" target=\"_blank\" rel=\"noopener\">使用Akka Actor和Java 8构建反应式应用</a></p>\n<ul>\n<li>reactor模型</li>\n</ul>\n<p>一图胜千言，来看看Doug Lea大神画的图（Scalable IO in Java）<br><img src=\"https://images2018.cnblogs.com/blog/1424165/201808/1424165-20180803142242491-1328318201.png\" alt=\"image\"></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://www.jianshu.com/p/20b7327f9f56\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/20b7327f9f56</a> ThreadPoolExecutor源码分析</li>\n<li><a href=\"https://blog.csdn.net/wangjinnan16/article/details/78377642\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/wangjinnan16/article/details/78377642</a>  Netty4实战第十五章：选择正确的线程模型</li>\n<li><a href=\"https://www.cnblogs.com/PerkinsZhu/p/7570775.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/PerkinsZhu/p/7570775.html</a> 常见线程模型介绍</li>\n<li><a href=\"http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\" target=\"_blank\" rel=\"noopener\">http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf</a> Scalable IO in Java</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"线程模型分享-（上）\"><a href=\"#线程模型分享-（上）\" class=\"headerlink\" title=\"线程模型分享 （上）\"></a>线程模型分享 （上）</h1><p>本篇文章是公司大佬<strong>约拿</strong>上周五给我培训的文档，分享给大家。非常感谢百忙之中给我培训。</p>","more":"<h2 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h2><blockquote>\n<p>为什么有这篇文章？</p>\n</blockquote>\n<p>起先看我的目标是看netty的线程模型，但是在看netty的过程中，我发现很多知识点是互相关联的。比如netty的EventLoop，EventLoopGroup其实是继承自JDK的线程池。学习netty的线程模型前需要懂得预备知识。基于这个理由，我把预备内容部分也写下来。分享一共会分为上下两篇，这里是第上篇，这篇主要是先导，给【下篇】的知识打基础，有了上篇的基础再看下篇就容易多了。</p>\n<blockquote>\n<p>这篇文章会有什么内容？</p>\n<ul>\n<li>JDK线程池的类继承层次</li>\n<li>构建线程池的几个核心要素</li>\n<li>JDK线程池关键方法的分析</li>\n<li>JDK线程池存在的问题</li>\n<li>常见的线程模型举例</li>\n<li>线程模型适用场景分析 </li>\n<li>线程竞争与锁</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>文章目的</p>\n<ul>\n<li>可以自定义JDK线程池，了解JDK线程池的局限场景</li>\n<li>了解线程模型的原理及适用场景</li>\n<li>了解锁的目的及分类</li>\n</ul>\n</blockquote>\n<h2 id=\"线程启动与停止\"><a href=\"#线程启动与停止\" class=\"headerlink\" title=\"线程启动与停止\"></a>线程启动与停止</h2><blockquote>\n<p>如何启动线程</p>\n</blockquote>\n<p>这个比较基础的不说了</p>\n<blockquote>\n<p>如何停止线程</p>\n</blockquote>\n<ol>\n<li>线程类有stop，suspend方法，但是被弃用了。</li>\n</ol>\n<ul>\n<li><strong>stop</strong> 会立即杀死线程，可能导致执行一半的程序被终结导致数据不一致的风险</li>\n<li><strong>suspend</strong> 会挂起线程，但是不会释放锁，可能会造成死锁</li>\n<li>线程池有个 <strong>shutdown</strong> 方法只是阻止线程池接受新的线程 ，并不会停止已存在的线程。</li>\n</ul>\n<ol start=\"2\">\n<li>正确的方法</li>\n</ol>\n<ul>\n<li>线程自己运行完成</li>\n<li>设置终止标志，在循环中检查这个标志</li>\n</ul>\n<h2 id=\"JDK线程池继承层次\"><a href=\"#JDK线程池继承层次\" class=\"headerlink\" title=\"JDK线程池继承层次\"></a>JDK线程池继承层次</h2><h3 id=\"结构图\"><a href=\"#结构图\" class=\"headerlink\" title=\"结构图\"></a>结构图</h3><p><img src=\"https://user-images.githubusercontent.com/5201798/47539254-f5648380-d901-11e8-9446-8a4705430539.png\" alt=\"image\"></p>\n<p>这个图上很多类不用看，因为都是Executors类的内部类，代理类，核心就是下图的几个接口和类。</p>\n<p><img src=\"https://user-images.githubusercontent.com/5201798/47539187-a74f8000-d901-11e8-9f94-f8f4be0477a0.png\" alt=\"image\"></p>\n<h3 id=\"线程池核心要素\"><a href=\"#线程池核心要素\" class=\"headerlink\" title=\"线程池核心要素\"></a>线程池核心要素</h3><ul>\n<li><p>核心线程池大小 corePoolSize</p>\n<blockquote>\n<p>设置一个线程池中的核心线程数 如果设置allowCoreThreadTimeOut为false的情况下： 即使当线程池中的线程处于空闲状态，这些线程也不会被线程池中移除。 如果设置了allowCoreThreadTimeOut为true, 那么当核心线程在空闲了一段时间后依旧没有用于工作，那么将会从线程池中移除。 注意:(allowCoreThreadTimeOut默认为false，通常情况下也无需做修改)</p>\n</blockquote>\n</li>\n<li><p>线程保持活跃时间</p>\n<blockquote>\n<p>keepAliveTime:当线程池中的线程数量大于核心线程数，如果这些多出的线程在经过了keepAliveTime时间后，依然处于空闲状态，那么这些多出的空闲线程将会被结束其生命周期。</p>\n</blockquote>\n</li>\n<li><p>时间单位unit</p>\n<blockquote>\n<p>keepAliveTime的时间单位</p>\n</blockquote>\n</li>\n<li><p>最大线程池大小 maximumPoolSize</p>\n<blockquote>\n<p>线程池中所允许创建最大线程数量，除了受JVM内存大小限制外，Linux下还受/proc/sys/kernel/pid_max（即系统允许的最大pid）、/proc/sys/kernel/threads-max（系统支持的最大线程数）、max_user_process（ulimit-u）（每个用户允许的最大进程数）、/proc/sys/vm/max_map_count（Linux支持虚拟内存，也就是交换空间,可以把磁盘的一部分作为RAM的扩展，逻辑存储和物理存储的映射就要保存在地址映射表中。max_map_count限制了线程可以拥有的VMAs ）</p>\n</blockquote>\n</li>\n<li><p>拒绝策略handler</p>\n<blockquote>\n<p>当线程池中的线程数量达到最大并且阻塞队列也已经满了无法再添加任务时，线程池所采取的处理策略，JDK有四种内建的拒绝策略，下面会讲到。</p>\n</blockquote>\n</li>\n<li><p>等待队列workQueue</p>\n<blockquote>\n<p>用于存放任务的阻塞队列，当线程池中的核心线程都处在执行任务时，提交的任务将被存储在workQueue进行缓冲。该队列只能存放通过execute方法提交的Runnable任务，如果是个ScheduledThreadPoolExecutor，那么这个队列不仅需要阻塞，而且还是个优先队列。</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"核心代码分析\"><a href=\"#核心代码分析\" class=\"headerlink\" title=\"核心代码分析\"></a>核心代码分析</h3><p>ThreadPoolExecutor 一个根正苗红的线程池继承类。</p>\n<ul>\n<li><p>我们看看他的excute方法</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">这里是调用</span><br><span class=\"line\">int corePoolSize = 1;</span><br><span class=\"line\">int maximumPoolSize = 2;</span><br><span class=\"line\">long keepAliveTime = 60;</span><br><span class=\"line\">TimeUnit unit = TimeUnit.SECONDS;</span><br><span class=\"line\">BlockingQueue&lt;Runnable&gt; workQueue = new LinkedBlockingDeque&lt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime</span><br><span class=\"line\">        , unit, workQueue, Executors.defaultThreadFactory(), new RejectedExecutionHandler() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123;</span><br><span class=\"line\">        throw new RejectedExecutionException(&quot;Task &quot; + r.toString() +</span><br><span class=\"line\">                &quot; rejected from &quot; +</span><br><span class=\"line\">                e.toString());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">threadPoolExecutor.execute(new Runnable() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public void run() &#123;</span><br><span class=\"line\">        System.out.println(&quot;execute!&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">=========================</span><br><span class=\"line\"></span><br><span class=\"line\">看看execute的源码</span><br><span class=\"line\">public void execute(Runnable command) &#123;</span><br><span class=\"line\">    if (command == null)</span><br><span class=\"line\">        throw new NullPointerException();</span><br><span class=\"line\">    int c = ctl.get();</span><br><span class=\"line\">    // workerCountOf 从ctl中取工作线程的数量，这里有一定的技巧性，下面详细讲一下</span><br><span class=\"line\">    if (workerCountOf(c) &lt; corePoolSize) &#123;</span><br><span class=\"line\">        if (addWorker(command, true))</span><br><span class=\"line\">            return;</span><br><span class=\"line\">        c = ctl.get();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // 看当前线程池状态是否Running，这里也是从ctl取值，有点意思</span><br><span class=\"line\">    // 把任务用offer方法塞进工作队列，如果插入成功，则返回ture</span><br><span class=\"line\">    if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class=\"line\">        int recheck = ctl.get();</span><br><span class=\"line\">        // 二次检查线程池状态是否为Running，以及从任务队列获取当前任务是否成功</span><br><span class=\"line\">        if (! isRunning(recheck) &amp;&amp; remove(command))</span><br><span class=\"line\">            reject(command);</span><br><span class=\"line\">        else if (workerCountOf(recheck) == 0)</span><br><span class=\"line\">            // addWorker方法里通过两个for循环通过ctl判断线程池的当前状态是否能新增线程，通过CAS机制修改线程池状态。最后新建worker对象，插入worker队列。</span><br><span class=\"line\">            addWorker(null, false);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // 线程池的线程数量不够了，增加线程，增加失败的话就拒绝这次execute调用</span><br><span class=\"line\">    else if (!addWorker(command, false))</span><br><span class=\"line\">        // reject方法里其实是调用定义线程池的时候构造函数传入的handler，JDK内建了四个拒绝策略AbortPolicy、DiscardPolicy、DiscardOldestPolicy、CallerRunsPolicy，含义分别是：抛出RejectedExecutionException异常、直接忽略提交的任务、把之前提交的任务移除，添加新的任务、让当前线程直接处理这个任务。用户也可以实现RejectedExecutionHandler接口，完成自己的拒绝策略。</span><br><span class=\"line\">        reject(command);</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>DefaultThreadFactory  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">static class DefaultThreadFactory implements ThreadFactory &#123;</span><br><span class=\"line\">    private static final AtomicInteger poolNumber = new AtomicInteger(1);</span><br><span class=\"line\">    private final ThreadGroup group;</span><br><span class=\"line\">    private final AtomicInteger threadNumber = new AtomicInteger(1);</span><br><span class=\"line\">    private final String namePrefix;</span><br><span class=\"line\"></span><br><span class=\"line\">    DefaultThreadFactory() &#123;</span><br><span class=\"line\">        SecurityManager s = System.getSecurityManager();</span><br><span class=\"line\">        group = (s != null) ? s.getThreadGroup() :</span><br><span class=\"line\">                              Thread.currentThread().getThreadGroup();</span><br><span class=\"line\">        namePrefix = &quot;pool-&quot; +</span><br><span class=\"line\">                      poolNumber.getAndIncrement() +</span><br><span class=\"line\">                     &quot;-thread-&quot;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // 核心是这个newThread方法</span><br><span class=\"line\">    public Thread newThread(Runnable r) &#123;</span><br><span class=\"line\">        Thread t = new Thread(group, r,</span><br><span class=\"line\">                              namePrefix + threadNumber.getAndIncrement(),</span><br><span class=\"line\">                              0);</span><br><span class=\"line\">        if (t.isDaemon())</span><br><span class=\"line\">            t.setDaemon(false);</span><br><span class=\"line\">        if (t.getPriority() != Thread.NORM_PRIORITY)</span><br><span class=\"line\">            t.setPriority(Thread.NORM_PRIORITY);</span><br><span class=\"line\">        return t;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>ctl是如何存储线程状态和数量的</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">定义</span><br><span class=\"line\">private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));</span><br><span class=\"line\">private static final int COUNT_BITS = Integer.SIZE - 3;</span><br><span class=\"line\">private static final int CAPACITY   = (1 &lt;&lt; COUNT_BITS) - 1;</span><br><span class=\"line\"></span><br><span class=\"line\">// runState is stored in the high-order bits</span><br><span class=\"line\">private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\">private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\">private static final int STOP       =  1 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\">private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\">private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;</span><br><span class=\"line\"></span><br><span class=\"line\">// Packing and unpacking ctl</span><br><span class=\"line\">private static int runStateOf(int c)     &#123; return c &amp; ~CAPACITY; &#125;</span><br><span class=\"line\">private static int workerCountOf(int c)  &#123; return c &amp; CAPACITY; &#125;</span><br><span class=\"line\">private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">上面那串定义看了可能有点懵，源码中使用了一个AtomicInteger对将当前线程的工作状态和工作线程数量(有效线程数)使用同一个整数进行包装。</span><br><span class=\"line\">为了将两个数值包装在同一个整数中，它将32位的高3位表示线程的状态值，而后29位来表示线程的数量。</span><br><span class=\"line\">其实这样设计的理由很简单，因为线程的状态和数量往往需要同时更新，然而线程池天生处在一个并发的环境下，那么当对2个变量进行修改时，那么就势必需要通过锁来进行线程安全的处理，从而保证2个变量修改具备原子性；但是这种做法对于性能的影响是非常严重的，因此在ThreadPoolExecutor将两个变量的分别包装在一个变量中，最后的并发操作发生在AtomicInteger上，而AtomicInteger恰恰就是具有一个无锁原子操作类,这样既可以解决线程安全的问题，又可以规避避免所的使用，从而提供性能。</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>ScheduledThreadPoolExecutor如何实现调度</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TODO</span><br><span class=\"line\">优先队列</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"JDK线程池存在的问题\"><a href=\"#JDK线程池存在的问题\" class=\"headerlink\" title=\"JDK线程池存在的问题\"></a>JDK线程池存在的问题</h3><ul>\n<li>FixedThreadPool 和 SingleThreadPool 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。</li>\n<li>CachedThreadPool 和 ScheduledThreadPool允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 </li>\n<li>多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用 ScheduledExecutorService 则没有这个问题。</li>\n<li>ScheduledExecutorService并发执行大量调度时候有瓶颈，大并发量的线程调度应该用时间环模式。 </li>\n</ul>\n<p><del>不要感觉自己写几千行的类是很烂的代码，ThreadPoolExecutor也有2100多行（含注释）</del></p>\n<h2 id=\"线程竞争\"><a href=\"#线程竞争\" class=\"headerlink\" title=\"线程竞争\"></a>线程竞争</h2><h3 id=\"线程竞争的定义\"><a href=\"#线程竞争的定义\" class=\"headerlink\" title=\"线程竞争的定义\"></a>线程竞争的定义</h3><p>在多线程中，每个线程的执行顺序，是无法预测不可控制的，那么在对数据进行读写的时候便存在由于读写顺序多乱而造成数据混乱错误的可能性。这里涉及到线程锁</p>\n<h3 id=\"用锁控制线程间的竞争\"><a href=\"#用锁控制线程间的竞争\" class=\"headerlink\" title=\"用锁控制线程间的竞争\"></a>用锁控制线程间的竞争</h3><blockquote>\n<p>这里介绍锁的基本概念以及常见分类，详细在另外的时间再做。</p>\n</blockquote>\n<ul>\n<li>共享锁/排它锁 </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">共享锁和排他锁是从同一时刻是否允许多个线程持有该锁的角度来划分。</span><br><span class=\"line\">共享锁允许同一时刻多个线程进入持有锁，访问临界区资源。而排他锁就是通常意义上的锁，同一时刻只允许一个线程访问临界资源。对于共享锁，主要是指对数据库读操作中的读锁，在读写资源的时候如果没有线程持有写锁和请求写锁，则此时允许多个线程持有读锁。 </span><br><span class=\"line\">在这里理解共享锁的时候，不是任意时刻都允许多线程持有共享锁的，而是在某些特殊情况下才允许多线程持有共享锁，在某些情况下不允许多个线程持有共享锁，否则，如果没有前提条件任意时刻都允许线程任意持有共享锁，则共享锁的存在无意义的。例如读写锁中的读锁，只有当没有写锁和写锁请求的时候，就可以允许多个线程同时持有读锁。这里的前提条件就是“没有写锁和写锁请求”，而不是任意时刻都允许多线程持有共享读锁。</span><br></pre></td></tr></table></figure>\n<ul>\n<li>悲观锁/乐观锁  </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">主要用于数据库数据的操作中，而对于线程锁中较为少见。</span><br><span class=\"line\">悲观锁和乐观锁是一种加锁思想。对于乐观锁，在进行数据读取的时候不会加锁，而在进行写入操作的时候会判断一下数据是否被其它线程修改过，如果修改则更新数据，如果没有则继续进行数据写入操作。乐观锁不是系统中自带的锁，而是一种数据读取写入思想。应用场景例如：在向数据库中插入数据的时候，先从数据库中读取记录修改版本标识字段，如果该字段没有发生变化（没有其他线程对数据进行写操作）则执行写入操作，如果发生变化则重新计算数据。</span><br><span class=\"line\">对于悲观锁，无论是进行读操作还是进行写操作都会进行加锁操作。对于悲观锁，如果并发量较大则比较耗费资源，当然保证了数据的安全性。</span><br></pre></td></tr></table></figure>\n<ul>\n<li>可重入锁/不可重入</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">这两个概念是从同一个线程在已经持有锁的前提下能否再次持有锁的角度来区分的。</span><br><span class=\"line\">对于可重入锁，如果该线程已经获取到锁且未释放的情况下允许再次获取该锁访问临界区资源。此种情况主要是用在递归调用的情况下和不同的临界区使用相同的锁的情况下。</span><br><span class=\"line\">对于不可重入锁，则不允许同一线程在持有锁的情况下再次获取该锁并访问临界区资源。对于不可重入锁，使用的时候需要小心以免造成死锁。</span><br></pre></td></tr></table></figure>\n<ul>\n<li>公平锁/非公平锁</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">这两个概念主要使用线程获取锁的顺序角度来区分的。</span><br><span class=\"line\">对于公平锁，所有等待的线程按照按照请求锁的先后循序分别依次获取锁。</span><br><span class=\"line\">对于非公平锁，等待线程的线程获取锁的顺序和请求的先后不是对应关系。有可能是随机的获取锁，也有可能按照其他策略获取锁，总之不是按照FIFO的顺序获取锁。</span><br><span class=\"line\">在使用ReentrantLock的时候可以通过构造方法主动选择是实现公平锁还是非公平锁。</span><br></pre></td></tr></table></figure>\n<ul>\n<li>自旋锁/非自旋锁</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">这两种概念是从线程等待的处理机制来区分的。</span><br><span class=\"line\">自旋锁在进行锁请求等待的时候不进行wait挂起，不释放CPU资源，执行while空循环。直至获取锁访问临界区资源。适用于等待锁时间较短的情景，如果等待时间较长，则会耗费大量的CPU资源。而如果等待时间较短则可以节约大量的线程切换资源。</span><br><span class=\"line\">非自旋锁在进行锁等待的时候会释放CPU资源，可以通多sleep wait 或者CPU中断切换上下文，切换该线程。在线程等待时间较长的情况下可以选择此种实现机制。</span><br><span class=\"line\">除此之外还有一种介于两者之间的锁机制——自适应自旋锁。当线程进行等待的时候先进性自旋等待，在自旋一定时间(次数)之后如果依旧没有持有锁则挂起等待。在jvm中synchronized锁已经使用该机制进行处理锁等待的情况。</span><br><span class=\"line\">在工作中可以根据不同的情况选取合适的锁进行使用。无论使用哪种锁，其目的都是保证程序能够按照要求顺利执行，避免数据混乱情况的发生。</span><br></pre></td></tr></table></figure>\n<p>详细的<a href=\"https://www.cnblogs.com/PerkinsZhu/p/7392006.html\" target=\"_blank\" rel=\"noopener\">参考</a>这里</p>\n<h3 id=\"锁的弊端\"><a href=\"#锁的弊端\" class=\"headerlink\" title=\"锁的弊端\"></a>锁的弊端</h3><p>不管是何种锁，本质上都是对资源的访问加以限制，让同一时间只有一个线程访问资源。在高并发的时候，锁往往会成为系统的瓶颈，更不用说同时带来的死锁风险。</p>\n<h3 id=\"不用锁解决线程安全的方式\"><a href=\"#不用锁解决线程安全的方式\" class=\"headerlink\" title=\"不用锁解决线程安全的方式\"></a>不用锁解决线程安全的方式</h3><p>我们接下来讨论有无高效解决线程竞争的模式，避免锁带来的以上问题。</p>\n<h2 id=\"常见线程模型\"><a href=\"#常见线程模型\" class=\"headerlink\" title=\"常见线程模型\"></a>常见线程模型</h2><h3 id=\"线程模型的定义\"><a href=\"#线程模型的定义\" class=\"headerlink\" title=\"线程模型的定义\"></a>线程模型的定义</h3><p>线程模型决定了应用或框架如何执行代码，所以选择正确的线程模型是很重要的事情。通俗的讲，如果同样给你一定数量的线程如（100个），分析实际的业务场景，如何让它们的效率最大化。这就是选取线程模型应该做的事情。</p>\n<blockquote>\n<p>同时线程模型也指线程映射到操作系统进程的模型 <a href=\"https://blog.csdn.net/lyc201219/article/details/79228575\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lyc201219/article/details/79228575</a></p>\n</blockquote>\n<ul>\n<li>Future模型</li>\n</ul>\n<p>结合Callable接口配合使用，Callable是类似于Runnable的接口。Future是把结果放在将来获取，当前主线程并不急于获取处理结果。允许子线程先进行处理一段时间，处理结束之后就把结果保存下来，当主线程需要使用的时候再向子线程索取。如果不使用Future模型，就需要使用到一个全局变量来保存子线程处理之后的结果。子线程处理结束之后，把结果保存在全局变量中供主线程进行调用。一旦涉及到全局能量便存在着多线程读写全局变量错误的风险。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ExecutorService executorService = Executors.newFixedThreadPool(5);</span><br><span class=\"line\">Future&lt;?&gt; future = executorService.submit(new Callable&lt;Object&gt;() &#123;</span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    public Object call() throws Exception &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        return null;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">Object o = future.get();</span><br></pre></td></tr></table></figure>\n<ul>\n<li>fork&amp;join 模型</li>\n</ul>\n<p>该模型包含递归思想和回溯思想，递归用来拆分任务，回溯用合并结果。可以用来处理一些可以进行拆分的大任务。其主要是把一个大任务逐级拆分为多个子任务，然后分别在子线程中执行，当每个子线程执行结束之后逐级回溯，返回结果进行汇总合并，最终得出想要的结果</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * 将num*2 用frok&amp;join的思想做</span><br><span class=\"line\"> */</span><br><span class=\"line\">static class ResultTask extends RecursiveTask&lt;Integer&gt; &#123;</span><br><span class=\"line\">    private int num;</span><br><span class=\"line\"></span><br><span class=\"line\">    public ResultTask(int num) &#123;</span><br><span class=\"line\">        this.num = num;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    @Override</span><br><span class=\"line\">    protected Integer compute() &#123;</span><br><span class=\"line\">        if (num &lt; 10) &#123;</span><br><span class=\"line\">            return num * 2;</span><br><span class=\"line\">        &#125; else &#123;</span><br><span class=\"line\">            //对任务进行拆分，注意这里不仅仅可以一分为二进行拆分，也可以拆为多个子任务</span><br><span class=\"line\">            int temp = num / 2;</span><br><span class=\"line\">            ResultTask left = new ResultTask(temp);</span><br><span class=\"line\">            ResultTask right = new ResultTask(num - temp);</span><br><span class=\"line\">            left.fork();</span><br><span class=\"line\">            right.fork();</span><br><span class=\"line\">            //对子任务处理的结果进行合并</span><br><span class=\"line\">            int result = left.join() + right.join();</span><br><span class=\"line\">            return result;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">public static void main(String[] args) throws Exception &#123;</span><br><span class=\"line\">    ForkJoinPool pool = new ForkJoinPool();</span><br><span class=\"line\">    ForkJoinTask&lt;Integer&gt; future = pool.submit(new ResultTask(100));</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        Integer integer = future.get();</span><br><span class=\"line\">        System.out.println(integer);</span><br><span class=\"line\">        pool.awaitTermination(1000, TimeUnit.MILLISECONDS);</span><br><span class=\"line\">    &#125; catch (Exception e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    pool.shutdown();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>生产者消费者模型</li>\n</ul>\n<p>生产者消费者模型都比较熟悉，其核心是使用一个缓存来保存任务。开启一个/多个线程来生产任务，然后再开启一个/多个来从缓存中取出任务进行处理。这样的好处是任务的生成和处理分隔开，生产者不需要处理任务，只负责向生成任务然后保存到缓存。而消费者只需要从缓存中取出任务进行处理。使用的时候可以根据任务的生成情况和处理情况开启不同的线程来处理。比如，生成的任务速度较快，那么就可以灵活的多开启几个消费者线程进行处理，这样就可以避免任务的处理响应缓慢的问题</p>\n<ul>\n<li>master-worker模型</li>\n</ul>\n<p>master-worker模型类似于任务分发策略，开启一个master线程接收任务，然后在master中根据任务的具体情况进行分发给其它worker子线程，然后由子线程处理任务。如需返回结果，则worker处理结束之后把处理结果返回给master</p>\n<ul>\n<li>actor消息模型</li>\n</ul>\n<p>actor模型属于一种基于消息传递机制并行任务处理思想，它以消息的形式来进行线程间数据传输，避免了全局变量的使用，进而避免了数据同步错误的隐患。actor在接受到消息之后可以自己进行处理，也可以继续传递（分发）给其它actor进行处理。Actors一大重要特征在于actors之间相互隔离，它们并不互相共享内存。这点区别于上述的对象。也就是说，一个actor能维持一个私有的状态，并且这个状态不可能被另一个actor所改变。</p>\n<p>actor并发模型的应用场景？<br>适合有状态或者称可变状态的业务场景，如果用DDD术语，适合聚合根，具体案例如订单，订单有状态，比如未付款未发货，已经付款未发货，已付款已发货，导致订单状态的变化是事件行为，比如付款行为导致顶大状态切换到”已经付款未发货”。</p>\n<p>actor的原理<br>行为导致状态变化，行为执行是依靠线程，比如用户发出一个付款的请求，服务器后端派出一个线程来执行付款请求，携带付款的金额和银行卡等等信息，当付款请求被成功完成后，线程还要做的事情就是改变订单状态，这时线程访问订单的一个方法比如changeState。如果后台有管理员同时修改这个订单状态，那么实际有两个线程共同访问同一个数据，这时就必须锁，比如我们在changeState方法前加上sychronized这样同步语法。使用同步语法坏处是每次只能一个线程进行处理，如同上厕所，只有一个蹲坑，人多就必须排队，这种情况性能很低。</p>\n<p>避免changeState方法被外部两个线程同时占用访问，那么我们自己设计专门的线程守护订单状态，而不是普通方法代码，普通方法代码比较弱势，容易被外部线程hold住，而我们设计的这个对象没有普通方法，只有线程，这样就变成Order的守护线程和外部访问请求线程的通讯问题了。Actor采取的这种类似消息机制的方式，实际在守护线程和外部线程之间有一个队列，俗称信箱，外部线程只要把请求放入，守护线程就读取进行处理。这种异步高效方式是Actor基本原理，以ERlang和Scala语言为主要特征，他们封装得更好，类似将消息队列微观化了。<br>参考<a href=\"http://www.infoq.com/cn/articles/Building-Reactive-Applications-with-Akka\" target=\"_blank\" rel=\"noopener\">使用Akka Actor和Java 8构建反应式应用</a></p>\n<ul>\n<li>reactor模型</li>\n</ul>\n<p>一图胜千言，来看看Doug Lea大神画的图（Scalable IO in Java）<br><img src=\"https://images2018.cnblogs.com/blog/1424165/201808/1424165-20180803142242491-1328318201.png\" alt=\"image\"></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://www.jianshu.com/p/20b7327f9f56\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/20b7327f9f56</a> ThreadPoolExecutor源码分析</li>\n<li><a href=\"https://blog.csdn.net/wangjinnan16/article/details/78377642\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/wangjinnan16/article/details/78377642</a>  Netty4实战第十五章：选择正确的线程模型</li>\n<li><a href=\"https://www.cnblogs.com/PerkinsZhu/p/7570775.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/PerkinsZhu/p/7570775.html</a> 常见线程模型介绍</li>\n<li><a href=\"http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\" target=\"_blank\" rel=\"noopener\">http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf</a> Scalable IO in Java</li>\n</ul>"},{"title":"网络IO模型","date":"2019-05-10T03:00:00.000Z","_content":"\n在学习JAVA NIO的时候有学习到相关的BIO、NIO、AIO的概念，以及一直对阻塞、非阻塞、异步等IO模型的知识感到非常模糊，要清楚JAVA的NIO是什么，以及基础的操作系统的网络IO模型，在此总结下网络IO模型的基础知识。\n\n不得不感叹信息爆炸的时代，想学点东西但是到处都是误人子弟的文章和copy的内容，但是自己还想快餐式的学点重点，先简单学习下，真正细致的学习还是要看看《UNIX网络编程》。\n\n<!-- more -->\n# 几个基础概念\n## 什么是IO\n我们都知道unix世界里、一切皆文件、而文件是什么呢？文件就是一串二进制流而已、不管socket、还是FIFO、管道、终端、对我们来说、一切都是文件、一切都是流、在信息交换的过程中、我们都是对这些流进行数据的收发操作、简称为I/O操作(input and output)、往流中读出数据、系统调用read、写入数据、系统调用write、不过话说回来了、计算机里有这么多的流、我怎么知道要操作哪个流呢？做到这个的就是文件描述符、即通常所说的fd、一个fd就是一个整数、所以对这个整数的操作、就是对这个文件（流）的操作、我们创建一个socket、通过系统调用会返回一个文件描述符、那么剩下对socket的操作就会转化为对这个描述符的操作、不能不说这又是一种分层和抽象的思想。\n\n## IO的交互\n![IO模型00](/image/IO/IO模型00.png)\n\n通常用户进程中的一个完整IO分为两阶段：\n* 用户空间 <-----> 内核空间\n* 内核空间 <-----> 设备空间\n\n![IO模型00](/image/IO/IO模型00.jpg)\n\n内核空间中存放的是内核代码和数据、而进程的用户空间中存放的是用户程序的代码和数据、不管是内核空间还是用户空间、它们都处于虚拟空间中、Linux使用两级保护机制：0级供内核使用、3级供用户程序使用。\n\n操作系统和驱动程序运行在内核空间、应用程序运行在用户空间、两者不能简单地使用指针传递数据、因为Linux使用的虚拟内存机制、其必须通过系统调用请求kernel来协助完成IO动作、内核会为每个IO设备维护一个缓冲区、用户空间的数据可能被换出、当内核空间使用用户空间指针时、对应的数据可能不在内存中。\n\n对于一个输入操作来说、进程IO系统调用后、内核会先看缓冲区中有没有相应的缓存数据、没有的话再到设备中读取、因为设备IO一般速度较慢、需要等待、内核缓冲区有数据则直接复制到进程空间。\n\n所以、对于一个网络输入操作通常包括两个不同阶段：\n1. 等待网络数据到达网卡 –> 读取到内核缓冲区\n2. 从内核缓冲区复制数据 –> 用户空间\n\nIO有内存IO、网络IO和磁盘IO三种、通常我们说的IO指的是后两者\n\n## 用户空间、内核空间\n现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟储存空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操作系统将虚拟空间划分为两个部分，一个部分为内核空间，一部分为用户空间。\n\n如何分配这两个空间的大小也是有讲究的，如windows 32位操作系统，默认的用户空间：内核空间的比例是1:1;而在32位Linux系统中的默认比例是3:1（3G用户空间，1G内核空间）。\n\n## 进程切换\n为了控制进程的执行，内核必须要有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为成为进程的切换。任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。\n\n进程切换的过程，会经过下面这些变化：\n1. 保存处理机上下文，包括程序计数器和其他寄存器。\n2. 更新PCB信息。\n3. 将进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。\n4. 选择另外一个进程执行，并更新PCB。\n5. 更新内存管理的数据结构。\n6. 恢复处理机上下文。\n\n## 缓存IO\n缓存IO又称称为标准IO，大多数文件系统的默认IO操作都是缓存IO。在Linux的缓存IO机制中，操作系统会将IO的数据缓存在文件系统的页缓存（page cache）。也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓存区拷贝到应用程序的地址空间中。\n\n这种做法的缺点就是，需要在应用程序地址空间和内核进行多次拷贝，这些拷贝动作所带来的CPU以及内存开销是非常大的。\n\n## 同步、异步、阻塞、非阻塞\n同步与异步：描述的是用户线程与内核的交互方式，同步指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行；而异步是指用户线程发起IO请求后仍然继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。\n\n阻塞与非阻塞：描述是用户线程调用内核IO操作的方式，阻塞是指IO操作需要彻底完成后才返回到用户空间；而非阻塞是指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成。\n\n## 并行与并发\n先弄明白并发和并行的区别：比如去某部门办事需要依次去几个窗口，办事大厅的人数就是并发数，而窗口的个数就是并行度。就是说并发是同时进行的任务数（如同时服务的http请求），而并行数就是可以同时工作的物理资源数量（如cpu核数）。\n\n通过合理调度任务的不同阶段，并发数可以远远大于并行度。这就是区区几个CPU可以支撑上万个用户并发请求的原因。在这种高并发的情况下，为每个用户请求创建一个进程或者线程的开销非常大。而同步非阻塞方式可以把多个IO请求丢到后台去，这样一个CPU就可以服务大量的并发IO请求。\n\n# Linux IO模型\n网络IO的本质就是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。文章开始的时候也提到了，对于一次IO访问（以read为例），数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间中。所以说，当一个read操作发生时，它会经历两个阶段：\n* 第一个阶段：等待数据准备。\n* 第二个阶段：将数据从内核拷贝到进程中\n\n对于socket流而言：\n* 第一步：通常涉及等待网络上的数据分组到达，然后复制到内核的某个缓冲区。\n* 第二步：把数据从内核缓冲区复制到应用进程缓冲区。\n\n当然，如果内核空间的缓冲区中已经有数据了，那么就可以省略第一步。至于为什么不能直接让磁盘控制器把数据送到应用程序的地址空间中呢？最简单的一个原因就是应用程序不能直接操作底层硬件。\n\n网络应用需要处理的无非就是两大类问题，网络IO，数据计算。相对于后者，网络IO的延迟，给应用带来的性能瓶颈大于后者。网络IO的模型大致分为如下五种：\n\n## 阻塞IO（blocking I/O）\n![IO模型01](/image/IO/IO模型01.png)\n\n在这个模型中，应用程序为了执行这个read操作，会调用相应的一个system call，将系统控制权交给内核，然后就进行等待（这个等待的过程就是被阻塞了），内核开始执行这个system call，执行完毕后会向应用程序返回响应，应用程序得到响应后，就不再阻塞，并进行后面的工作。\n\n用户进程调用了recvfrom这个系统调用，内核就开始了IO的第一个阶段：准备数据。对于网络IO来说，很多时候数据在一开始还没有到达（比如、还没有收到一个完整的UDP包），这个时候内核就要等待足够的数据到来，而在用户进程这边，整个进程会被阻塞。当内核一直等到数据准备好了，它就会将数据从内核中拷贝到用户内存，然后返回结果，用户进程才解除阻塞的状态，重新运行起来，几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv()等接口开始的，这些接口都是阻塞型的。\n\nblocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被阻塞了。\n\n* 典型应用：阻塞Socket、Java BIO\n* 优点：进程阻塞挂起不消耗CPU资源，及时响应每个操作。实现难度低，开发应用较容易。\n* 缺点：对用户来说处于等待就要付出性能代价。适用并发量小的网络应用开发。不适用并发量大的应用。\n\n## 非阻塞IO（noblocking I/O）\n![IO模型02](/image/IO/IO模型02.png)\n\n当用户进程发出read操作时，调用相应的system call，这个system call会立即从内核中返回。但是在返回的这个时间点，内核中的数据可能还没有准备好，也就是说内核只是很快就返回了system call，只有这样才不会阻塞用户进程，对于应用程序，虽然这个IO操作很快就返回了，但是它并不知道这个IO操作是否真的成功了，为了知道IO操作是否成功，应用程序需要主动的循环去问内核。\n\n* 缺点：进程轮询（重复）调用、消耗CPU的资源\n\n## 多路复用IO（I/O multiplexing）\n![IO模型04](/image/IO/IO模型04.png)\n\n多个的进程的IO可以注册到一个复用器（select）上，当用户进程调用该select，select会监听所有注册进来的IO。如果select所有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞，而当任一IO在内核缓冲区中有可数据时，select调用就会返回，而后select调用进程可以自己或通知另外的进程（注册进程）来再次发起读取IO，读取内核中准备好的数据，多个进程注册IO后，只有一个select调用进程被阻塞。\n\nIO复用相对阻塞和非阻塞更难简单说明，所以额外解释一段。其实IO复用模型和阻塞IO模型并没有太大的不同，事实上还更差一些，因为这里需要使用两个系统调用（select和 recvfrom），而阻塞IO模型只有一次系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个连接，所以如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用多线程加阻塞IO的web server性能更好，可能延迟还更大，select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。\n\n在IO复用模型中，对于每一个socket一般都设置成为非阻塞。但是，如上图所示，整个用户的进程其实是一直被阻塞的，只不过进程是被select这个函数阻塞，而不是被socket IO给阻塞。\n\n调用system call之后，并不等待内核的返回结果而是立即返回。虽然返回结果的调用函数是一个异步的方式，但应用程序会被像select、poll和epoll等具有多个文件描述符的函数阻塞住，一直等到这个system call有结果返回了，再通知应用程序。这种情况，从IO操作的实际效果来看，异步阻塞IO和第一种同步阻塞IO是一样的，应用程序都是一直等到IO操作成功之后（数据已经被写入或者读取），才开始进行下面的工作。不同点在于异步阻塞IO用一个select函数可以为多个文件描述符提供通知，提供了并发性。举个例子：例如有一万个并发的read请求，但是网络上仍然没有数据，此时这一万个read会同时各自阻塞，现在用select、poll、epoll这样的函数来专门负责阻塞同时监听这一万个请求的状态，一旦有数据到达了就负责通知，这样就将一万个等待和阻塞转化为一个专门的函数来负责与管理。\n\n多路复用技术应用于JAVA NIO的核心类库多路复用器Selector中，目前支持I/O多路复用的系统调用有select、pselect、poll、epoll，在linux编程中有一段时间一直在使用select做轮询和网络事件通知的，但是select支持一个进程打开的socket描述符（FD）收到了限制，一般为1024，由于这一限制，现在使用了epoll代替了select，而epoll支持一个进程打开的FD不受限制。\n\n异步IO与同步IO的区别在于：同步IO是需要应用程序主动地循环去询问是否有数据，而异步IO是通过像select等IO多路复用函数来同时检测多个事件句柄来告知应用程序是否有数据。\n\n了解了前面三种IO模式，在用户进程进行系统调用的时候，他们在等待数据到来的时候，处理的方式是不一样的，直接等待、轮询、select或poll轮询，两个阶段过程：\n* 第一个阶段有的阻塞，有的不阻塞，有的可以阻塞又可以不阻塞。\n* 第二个阶段都是阻塞的。\n\n从整个IO过程来看，他们都是顺序执行的，因此可以归为同步模型，都是进程自动等待且向内核检查状态。\n\nIO多路复用究竟是同步阻塞还是异步阻塞模型，这里来展开说说：\n\n同步是需要主动等待消息通知，而异步则是被动接受消息通知，通过回调、通知、状态等方式来被动获取消息。IO多路复用在阻塞到select阶段时，用户进程是主动等待并调用select函数来获取就绪状态消息，并且其进程状态为阻塞。所以IO多路复用是同步阻塞模式。\n\n* 典型应用：Java NIO、Nginx（epoll、poll、select）\n\n## 信号驱动IO（signal blocking I/O）\n![IO模型03](/image/IO/IO模型03.png)\n\n信号驱动式IO就是指进程预先告知内核，向内核注册一个信号处理函数，然后用户进程返回不阻塞，当内核数据就绪时会发送一个信号给进程，用户进程便在信号处理函数中调用IO读取数据，从图中明白实际IO内核拷贝到用户进程的过程还是阻塞的，信号驱动式IO并没有实现真正的异步，因为通知到进程之后，依然是由进程来完成IO操作。\n\n这和后面的异步IO模型很容易混淆，需要理解IO交互并结合五种IO模型的比较阅读。\n\n在信号驱动式IO模型中，依然不符合POSIX描述的异步IO，只能算是半异步，并且实际中并不常用。\n\n## 异步IO（asynchronous I/O）\n![IO模型05](/image/IO/IO模型05.png)\n\n用户进程发起aio_read（POSIX异步IO函数aio_或者lio_开头）操作之后、给内核传递描述符、缓冲区指针、缓冲区大小和read相同的三个参数以及文件偏移（与lseek类似），告诉内核当整个操作完成时，如何通知我们，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个aio_read之后，首先它会立刻返回。所以不会对用户进程产生任何阻塞。然后，内核会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，内核会给用户进程发送一个信号，告诉它aio_read操作完成了。\n\n异步IO的工作机制是：告知内核启动某个操作，并让内核在整个操作完成后通知我们。这种模型与信号驱动的IO区别在于，信号驱动IO是由内核通知我们何时可以启动一个IO操作，这个IO操作由用户自定义的信号函数来实现，而异步IO模型是由内核告知我们IO操作何时完成。\n\n这和前面的信号驱动式IO模型很容易混淆，需要理解IO交互并结合五种IO模型的比较阅读。\n\n在异步IO模型中，真正实现了POSIX描述的异步IO，是五种IO模型中唯一的异步模型。\n\n需要操作系统的底层支持，LINUX 2.5 版本内核首现，2.6 版本产品的内核标准特性。\n\n# 五种IO模型比较\n![IO模型05](/image/IO/IO模型07.png)\n## 阻塞IO和非阻塞IO的区别在哪？\n调用阻塞会一直阻塞住对应的进程直到操作完成，而非阻塞IO在内核还没准备数据的情况下会立刻返回。阻塞和非阻塞关注的是进程在等待调用结果时的状态，阻塞是指调用结果返回之前，当前进程会被挂起。调用进程只有在得到结果才会返回，非阻塞调用指不能立刻得到结果，该调用不会阻塞当前进程。\n\n## 同步IO和异步IO区别在哪？\n两者的区别就在于同步做IO操作的时候会将进程阻塞。按照这个定义，之前所述的阻塞IO、非阻塞IO、IO复用、信号驱动都属于同步IO。有人可能会说，非阻塞IO并没有被阻塞啊，这里有个非常狡猾的地方。定义中所指的IO操作是指真实的IO操作，就是例子中的recvfrom这个系统调用，非阻塞IO在执行recvfrom这个系统调用的时候，如果内核的数据没有准备好，这时候不会阻塞进程。但是，当内核中数据准备好的时候，recvfrom会将数据从内核拷贝到用户内存中，这个时候进程是被阻塞了。信号驱动也是同样的道理，在这段时间内，进程是被阻塞的。而异步IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到内核发送一个信号，告诉进程说IO完成，在这整个过程中，进程完全没有被阻塞。\n\n同异步IO的根本区别在于：同步IO主动的调用recvfrom来将数据拷贝到用户内存。而异步则完全不同，它就像是用户进程将整个IO操作交给了他人（内核）完成，然后他人做完后发信号通知，在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。\n\n## POSIX的定义\nA synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes\n\nAn asynchronous I/O operation does not cause the requesting process to be blocked\n\n## 信号驱动式IO和异步IO的区别？\n这里之所以单独拿出来是因为如果还没有清除IO概念很容易混淆，所以理解IO模型之前一定要理解IO概念。如果看完前面两个问题，相信也能理解信号驱动IO与异步IO的区别在于启用异步IO意味着通知内核启动某个IO操作，并让内核在整个操作（包括数据从内核复制到用户缓冲区）完成时通知我们，也就是说，异步IO是由内核通知我们IO操作何时完成，即实际的IO操作也是异步的，信号驱动IO是由内核通知我们何时可以启动一个IO操作，这个IO操作由用户自定义的信号函数来实现。\n\n# 参考资料\n* http://www.360doc.com/content/19/0511/15/64010826_835008660.shtml\n* https://www.cnblogs.com/dongguacai/p/5770287.html\n* https://blog.csdn.net/ZWE7616175/article/details/80591587","source":"_posts/网络IO模型.md","raw":"---\ntitle: 网络IO模型\ndate: 2019-05-10 11:00:00\ntags: 网络IO模型\ncategories: 其他\n---\n\n在学习JAVA NIO的时候有学习到相关的BIO、NIO、AIO的概念，以及一直对阻塞、非阻塞、异步等IO模型的知识感到非常模糊，要清楚JAVA的NIO是什么，以及基础的操作系统的网络IO模型，在此总结下网络IO模型的基础知识。\n\n不得不感叹信息爆炸的时代，想学点东西但是到处都是误人子弟的文章和copy的内容，但是自己还想快餐式的学点重点，先简单学习下，真正细致的学习还是要看看《UNIX网络编程》。\n\n<!-- more -->\n# 几个基础概念\n## 什么是IO\n我们都知道unix世界里、一切皆文件、而文件是什么呢？文件就是一串二进制流而已、不管socket、还是FIFO、管道、终端、对我们来说、一切都是文件、一切都是流、在信息交换的过程中、我们都是对这些流进行数据的收发操作、简称为I/O操作(input and output)、往流中读出数据、系统调用read、写入数据、系统调用write、不过话说回来了、计算机里有这么多的流、我怎么知道要操作哪个流呢？做到这个的就是文件描述符、即通常所说的fd、一个fd就是一个整数、所以对这个整数的操作、就是对这个文件（流）的操作、我们创建一个socket、通过系统调用会返回一个文件描述符、那么剩下对socket的操作就会转化为对这个描述符的操作、不能不说这又是一种分层和抽象的思想。\n\n## IO的交互\n![IO模型00](/image/IO/IO模型00.png)\n\n通常用户进程中的一个完整IO分为两阶段：\n* 用户空间 <-----> 内核空间\n* 内核空间 <-----> 设备空间\n\n![IO模型00](/image/IO/IO模型00.jpg)\n\n内核空间中存放的是内核代码和数据、而进程的用户空间中存放的是用户程序的代码和数据、不管是内核空间还是用户空间、它们都处于虚拟空间中、Linux使用两级保护机制：0级供内核使用、3级供用户程序使用。\n\n操作系统和驱动程序运行在内核空间、应用程序运行在用户空间、两者不能简单地使用指针传递数据、因为Linux使用的虚拟内存机制、其必须通过系统调用请求kernel来协助完成IO动作、内核会为每个IO设备维护一个缓冲区、用户空间的数据可能被换出、当内核空间使用用户空间指针时、对应的数据可能不在内存中。\n\n对于一个输入操作来说、进程IO系统调用后、内核会先看缓冲区中有没有相应的缓存数据、没有的话再到设备中读取、因为设备IO一般速度较慢、需要等待、内核缓冲区有数据则直接复制到进程空间。\n\n所以、对于一个网络输入操作通常包括两个不同阶段：\n1. 等待网络数据到达网卡 –> 读取到内核缓冲区\n2. 从内核缓冲区复制数据 –> 用户空间\n\nIO有内存IO、网络IO和磁盘IO三种、通常我们说的IO指的是后两者\n\n## 用户空间、内核空间\n现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟储存空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操作系统将虚拟空间划分为两个部分，一个部分为内核空间，一部分为用户空间。\n\n如何分配这两个空间的大小也是有讲究的，如windows 32位操作系统，默认的用户空间：内核空间的比例是1:1;而在32位Linux系统中的默认比例是3:1（3G用户空间，1G内核空间）。\n\n## 进程切换\n为了控制进程的执行，内核必须要有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为成为进程的切换。任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。\n\n进程切换的过程，会经过下面这些变化：\n1. 保存处理机上下文，包括程序计数器和其他寄存器。\n2. 更新PCB信息。\n3. 将进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。\n4. 选择另外一个进程执行，并更新PCB。\n5. 更新内存管理的数据结构。\n6. 恢复处理机上下文。\n\n## 缓存IO\n缓存IO又称称为标准IO，大多数文件系统的默认IO操作都是缓存IO。在Linux的缓存IO机制中，操作系统会将IO的数据缓存在文件系统的页缓存（page cache）。也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓存区拷贝到应用程序的地址空间中。\n\n这种做法的缺点就是，需要在应用程序地址空间和内核进行多次拷贝，这些拷贝动作所带来的CPU以及内存开销是非常大的。\n\n## 同步、异步、阻塞、非阻塞\n同步与异步：描述的是用户线程与内核的交互方式，同步指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行；而异步是指用户线程发起IO请求后仍然继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。\n\n阻塞与非阻塞：描述是用户线程调用内核IO操作的方式，阻塞是指IO操作需要彻底完成后才返回到用户空间；而非阻塞是指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成。\n\n## 并行与并发\n先弄明白并发和并行的区别：比如去某部门办事需要依次去几个窗口，办事大厅的人数就是并发数，而窗口的个数就是并行度。就是说并发是同时进行的任务数（如同时服务的http请求），而并行数就是可以同时工作的物理资源数量（如cpu核数）。\n\n通过合理调度任务的不同阶段，并发数可以远远大于并行度。这就是区区几个CPU可以支撑上万个用户并发请求的原因。在这种高并发的情况下，为每个用户请求创建一个进程或者线程的开销非常大。而同步非阻塞方式可以把多个IO请求丢到后台去，这样一个CPU就可以服务大量的并发IO请求。\n\n# Linux IO模型\n网络IO的本质就是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。文章开始的时候也提到了，对于一次IO访问（以read为例），数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间中。所以说，当一个read操作发生时，它会经历两个阶段：\n* 第一个阶段：等待数据准备。\n* 第二个阶段：将数据从内核拷贝到进程中\n\n对于socket流而言：\n* 第一步：通常涉及等待网络上的数据分组到达，然后复制到内核的某个缓冲区。\n* 第二步：把数据从内核缓冲区复制到应用进程缓冲区。\n\n当然，如果内核空间的缓冲区中已经有数据了，那么就可以省略第一步。至于为什么不能直接让磁盘控制器把数据送到应用程序的地址空间中呢？最简单的一个原因就是应用程序不能直接操作底层硬件。\n\n网络应用需要处理的无非就是两大类问题，网络IO，数据计算。相对于后者，网络IO的延迟，给应用带来的性能瓶颈大于后者。网络IO的模型大致分为如下五种：\n\n## 阻塞IO（blocking I/O）\n![IO模型01](/image/IO/IO模型01.png)\n\n在这个模型中，应用程序为了执行这个read操作，会调用相应的一个system call，将系统控制权交给内核，然后就进行等待（这个等待的过程就是被阻塞了），内核开始执行这个system call，执行完毕后会向应用程序返回响应，应用程序得到响应后，就不再阻塞，并进行后面的工作。\n\n用户进程调用了recvfrom这个系统调用，内核就开始了IO的第一个阶段：准备数据。对于网络IO来说，很多时候数据在一开始还没有到达（比如、还没有收到一个完整的UDP包），这个时候内核就要等待足够的数据到来，而在用户进程这边，整个进程会被阻塞。当内核一直等到数据准备好了，它就会将数据从内核中拷贝到用户内存，然后返回结果，用户进程才解除阻塞的状态，重新运行起来，几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv()等接口开始的，这些接口都是阻塞型的。\n\nblocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被阻塞了。\n\n* 典型应用：阻塞Socket、Java BIO\n* 优点：进程阻塞挂起不消耗CPU资源，及时响应每个操作。实现难度低，开发应用较容易。\n* 缺点：对用户来说处于等待就要付出性能代价。适用并发量小的网络应用开发。不适用并发量大的应用。\n\n## 非阻塞IO（noblocking I/O）\n![IO模型02](/image/IO/IO模型02.png)\n\n当用户进程发出read操作时，调用相应的system call，这个system call会立即从内核中返回。但是在返回的这个时间点，内核中的数据可能还没有准备好，也就是说内核只是很快就返回了system call，只有这样才不会阻塞用户进程，对于应用程序，虽然这个IO操作很快就返回了，但是它并不知道这个IO操作是否真的成功了，为了知道IO操作是否成功，应用程序需要主动的循环去问内核。\n\n* 缺点：进程轮询（重复）调用、消耗CPU的资源\n\n## 多路复用IO（I/O multiplexing）\n![IO模型04](/image/IO/IO模型04.png)\n\n多个的进程的IO可以注册到一个复用器（select）上，当用户进程调用该select，select会监听所有注册进来的IO。如果select所有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞，而当任一IO在内核缓冲区中有可数据时，select调用就会返回，而后select调用进程可以自己或通知另外的进程（注册进程）来再次发起读取IO，读取内核中准备好的数据，多个进程注册IO后，只有一个select调用进程被阻塞。\n\nIO复用相对阻塞和非阻塞更难简单说明，所以额外解释一段。其实IO复用模型和阻塞IO模型并没有太大的不同，事实上还更差一些，因为这里需要使用两个系统调用（select和 recvfrom），而阻塞IO模型只有一次系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个连接，所以如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用多线程加阻塞IO的web server性能更好，可能延迟还更大，select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。\n\n在IO复用模型中，对于每一个socket一般都设置成为非阻塞。但是，如上图所示，整个用户的进程其实是一直被阻塞的，只不过进程是被select这个函数阻塞，而不是被socket IO给阻塞。\n\n调用system call之后，并不等待内核的返回结果而是立即返回。虽然返回结果的调用函数是一个异步的方式，但应用程序会被像select、poll和epoll等具有多个文件描述符的函数阻塞住，一直等到这个system call有结果返回了，再通知应用程序。这种情况，从IO操作的实际效果来看，异步阻塞IO和第一种同步阻塞IO是一样的，应用程序都是一直等到IO操作成功之后（数据已经被写入或者读取），才开始进行下面的工作。不同点在于异步阻塞IO用一个select函数可以为多个文件描述符提供通知，提供了并发性。举个例子：例如有一万个并发的read请求，但是网络上仍然没有数据，此时这一万个read会同时各自阻塞，现在用select、poll、epoll这样的函数来专门负责阻塞同时监听这一万个请求的状态，一旦有数据到达了就负责通知，这样就将一万个等待和阻塞转化为一个专门的函数来负责与管理。\n\n多路复用技术应用于JAVA NIO的核心类库多路复用器Selector中，目前支持I/O多路复用的系统调用有select、pselect、poll、epoll，在linux编程中有一段时间一直在使用select做轮询和网络事件通知的，但是select支持一个进程打开的socket描述符（FD）收到了限制，一般为1024，由于这一限制，现在使用了epoll代替了select，而epoll支持一个进程打开的FD不受限制。\n\n异步IO与同步IO的区别在于：同步IO是需要应用程序主动地循环去询问是否有数据，而异步IO是通过像select等IO多路复用函数来同时检测多个事件句柄来告知应用程序是否有数据。\n\n了解了前面三种IO模式，在用户进程进行系统调用的时候，他们在等待数据到来的时候，处理的方式是不一样的，直接等待、轮询、select或poll轮询，两个阶段过程：\n* 第一个阶段有的阻塞，有的不阻塞，有的可以阻塞又可以不阻塞。\n* 第二个阶段都是阻塞的。\n\n从整个IO过程来看，他们都是顺序执行的，因此可以归为同步模型，都是进程自动等待且向内核检查状态。\n\nIO多路复用究竟是同步阻塞还是异步阻塞模型，这里来展开说说：\n\n同步是需要主动等待消息通知，而异步则是被动接受消息通知，通过回调、通知、状态等方式来被动获取消息。IO多路复用在阻塞到select阶段时，用户进程是主动等待并调用select函数来获取就绪状态消息，并且其进程状态为阻塞。所以IO多路复用是同步阻塞模式。\n\n* 典型应用：Java NIO、Nginx（epoll、poll、select）\n\n## 信号驱动IO（signal blocking I/O）\n![IO模型03](/image/IO/IO模型03.png)\n\n信号驱动式IO就是指进程预先告知内核，向内核注册一个信号处理函数，然后用户进程返回不阻塞，当内核数据就绪时会发送一个信号给进程，用户进程便在信号处理函数中调用IO读取数据，从图中明白实际IO内核拷贝到用户进程的过程还是阻塞的，信号驱动式IO并没有实现真正的异步，因为通知到进程之后，依然是由进程来完成IO操作。\n\n这和后面的异步IO模型很容易混淆，需要理解IO交互并结合五种IO模型的比较阅读。\n\n在信号驱动式IO模型中，依然不符合POSIX描述的异步IO，只能算是半异步，并且实际中并不常用。\n\n## 异步IO（asynchronous I/O）\n![IO模型05](/image/IO/IO模型05.png)\n\n用户进程发起aio_read（POSIX异步IO函数aio_或者lio_开头）操作之后、给内核传递描述符、缓冲区指针、缓冲区大小和read相同的三个参数以及文件偏移（与lseek类似），告诉内核当整个操作完成时，如何通知我们，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个aio_read之后，首先它会立刻返回。所以不会对用户进程产生任何阻塞。然后，内核会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，内核会给用户进程发送一个信号，告诉它aio_read操作完成了。\n\n异步IO的工作机制是：告知内核启动某个操作，并让内核在整个操作完成后通知我们。这种模型与信号驱动的IO区别在于，信号驱动IO是由内核通知我们何时可以启动一个IO操作，这个IO操作由用户自定义的信号函数来实现，而异步IO模型是由内核告知我们IO操作何时完成。\n\n这和前面的信号驱动式IO模型很容易混淆，需要理解IO交互并结合五种IO模型的比较阅读。\n\n在异步IO模型中，真正实现了POSIX描述的异步IO，是五种IO模型中唯一的异步模型。\n\n需要操作系统的底层支持，LINUX 2.5 版本内核首现，2.6 版本产品的内核标准特性。\n\n# 五种IO模型比较\n![IO模型05](/image/IO/IO模型07.png)\n## 阻塞IO和非阻塞IO的区别在哪？\n调用阻塞会一直阻塞住对应的进程直到操作完成，而非阻塞IO在内核还没准备数据的情况下会立刻返回。阻塞和非阻塞关注的是进程在等待调用结果时的状态，阻塞是指调用结果返回之前，当前进程会被挂起。调用进程只有在得到结果才会返回，非阻塞调用指不能立刻得到结果，该调用不会阻塞当前进程。\n\n## 同步IO和异步IO区别在哪？\n两者的区别就在于同步做IO操作的时候会将进程阻塞。按照这个定义，之前所述的阻塞IO、非阻塞IO、IO复用、信号驱动都属于同步IO。有人可能会说，非阻塞IO并没有被阻塞啊，这里有个非常狡猾的地方。定义中所指的IO操作是指真实的IO操作，就是例子中的recvfrom这个系统调用，非阻塞IO在执行recvfrom这个系统调用的时候，如果内核的数据没有准备好，这时候不会阻塞进程。但是，当内核中数据准备好的时候，recvfrom会将数据从内核拷贝到用户内存中，这个时候进程是被阻塞了。信号驱动也是同样的道理，在这段时间内，进程是被阻塞的。而异步IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到内核发送一个信号，告诉进程说IO完成，在这整个过程中，进程完全没有被阻塞。\n\n同异步IO的根本区别在于：同步IO主动的调用recvfrom来将数据拷贝到用户内存。而异步则完全不同，它就像是用户进程将整个IO操作交给了他人（内核）完成，然后他人做完后发信号通知，在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。\n\n## POSIX的定义\nA synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes\n\nAn asynchronous I/O operation does not cause the requesting process to be blocked\n\n## 信号驱动式IO和异步IO的区别？\n这里之所以单独拿出来是因为如果还没有清除IO概念很容易混淆，所以理解IO模型之前一定要理解IO概念。如果看完前面两个问题，相信也能理解信号驱动IO与异步IO的区别在于启用异步IO意味着通知内核启动某个IO操作，并让内核在整个操作（包括数据从内核复制到用户缓冲区）完成时通知我们，也就是说，异步IO是由内核通知我们IO操作何时完成，即实际的IO操作也是异步的，信号驱动IO是由内核通知我们何时可以启动一个IO操作，这个IO操作由用户自定义的信号函数来实现。\n\n# 参考资料\n* http://www.360doc.com/content/19/0511/15/64010826_835008660.shtml\n* https://www.cnblogs.com/dongguacai/p/5770287.html\n* https://blog.csdn.net/ZWE7616175/article/details/80591587","slug":"网络IO模型","published":1,"updated":"2019-08-26T07:57:19.429Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl6t005kqotnbd4dtmrh","content":"<p>在学习JAVA NIO的时候有学习到相关的BIO、NIO、AIO的概念，以及一直对阻塞、非阻塞、异步等IO模型的知识感到非常模糊，要清楚JAVA的NIO是什么，以及基础的操作系统的网络IO模型，在此总结下网络IO模型的基础知识。</p>\n<p>不得不感叹信息爆炸的时代，想学点东西但是到处都是误人子弟的文章和copy的内容，但是自己还想快餐式的学点重点，先简单学习下，真正细致的学习还是要看看《UNIX网络编程》。</p>\n<a id=\"more\"></a>\n<h1 id=\"几个基础概念\"><a href=\"#几个基础概念\" class=\"headerlink\" title=\"几个基础概念\"></a>几个基础概念</h1><h2 id=\"什么是IO\"><a href=\"#什么是IO\" class=\"headerlink\" title=\"什么是IO\"></a>什么是IO</h2><p>我们都知道unix世界里、一切皆文件、而文件是什么呢？文件就是一串二进制流而已、不管socket、还是FIFO、管道、终端、对我们来说、一切都是文件、一切都是流、在信息交换的过程中、我们都是对这些流进行数据的收发操作、简称为I/O操作(input and output)、往流中读出数据、系统调用read、写入数据、系统调用write、不过话说回来了、计算机里有这么多的流、我怎么知道要操作哪个流呢？做到这个的就是文件描述符、即通常所说的fd、一个fd就是一个整数、所以对这个整数的操作、就是对这个文件（流）的操作、我们创建一个socket、通过系统调用会返回一个文件描述符、那么剩下对socket的操作就会转化为对这个描述符的操作、不能不说这又是一种分层和抽象的思想。</p>\n<h2 id=\"IO的交互\"><a href=\"#IO的交互\" class=\"headerlink\" title=\"IO的交互\"></a>IO的交互</h2><p><img src=\"/image/IO/IO模型00.png\" alt=\"IO模型00\"></p>\n<p>通常用户进程中的一个完整IO分为两阶段：</p>\n<ul>\n<li>用户空间 <-----> 内核空间</-----></li>\n<li>内核空间 <-----> 设备空间</-----></li>\n</ul>\n<p><img src=\"/image/IO/IO模型00.jpg\" alt=\"IO模型00\"></p>\n<p>内核空间中存放的是内核代码和数据、而进程的用户空间中存放的是用户程序的代码和数据、不管是内核空间还是用户空间、它们都处于虚拟空间中、Linux使用两级保护机制：0级供内核使用、3级供用户程序使用。</p>\n<p>操作系统和驱动程序运行在内核空间、应用程序运行在用户空间、两者不能简单地使用指针传递数据、因为Linux使用的虚拟内存机制、其必须通过系统调用请求kernel来协助完成IO动作、内核会为每个IO设备维护一个缓冲区、用户空间的数据可能被换出、当内核空间使用用户空间指针时、对应的数据可能不在内存中。</p>\n<p>对于一个输入操作来说、进程IO系统调用后、内核会先看缓冲区中有没有相应的缓存数据、没有的话再到设备中读取、因为设备IO一般速度较慢、需要等待、内核缓冲区有数据则直接复制到进程空间。</p>\n<p>所以、对于一个网络输入操作通常包括两个不同阶段：</p>\n<ol>\n<li>等待网络数据到达网卡 –&gt; 读取到内核缓冲区</li>\n<li>从内核缓冲区复制数据 –&gt; 用户空间</li>\n</ol>\n<p>IO有内存IO、网络IO和磁盘IO三种、通常我们说的IO指的是后两者</p>\n<h2 id=\"用户空间、内核空间\"><a href=\"#用户空间、内核空间\" class=\"headerlink\" title=\"用户空间、内核空间\"></a>用户空间、内核空间</h2><p>现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟储存空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操作系统将虚拟空间划分为两个部分，一个部分为内核空间，一部分为用户空间。</p>\n<p>如何分配这两个空间的大小也是有讲究的，如windows 32位操作系统，默认的用户空间：内核空间的比例是1:1;而在32位Linux系统中的默认比例是3:1（3G用户空间，1G内核空间）。</p>\n<h2 id=\"进程切换\"><a href=\"#进程切换\" class=\"headerlink\" title=\"进程切换\"></a>进程切换</h2><p>为了控制进程的执行，内核必须要有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为成为进程的切换。任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。</p>\n<p>进程切换的过程，会经过下面这些变化：</p>\n<ol>\n<li>保存处理机上下文，包括程序计数器和其他寄存器。</li>\n<li>更新PCB信息。</li>\n<li>将进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。</li>\n<li>选择另外一个进程执行，并更新PCB。</li>\n<li>更新内存管理的数据结构。</li>\n<li>恢复处理机上下文。</li>\n</ol>\n<h2 id=\"缓存IO\"><a href=\"#缓存IO\" class=\"headerlink\" title=\"缓存IO\"></a>缓存IO</h2><p>缓存IO又称称为标准IO，大多数文件系统的默认IO操作都是缓存IO。在Linux的缓存IO机制中，操作系统会将IO的数据缓存在文件系统的页缓存（page cache）。也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓存区拷贝到应用程序的地址空间中。</p>\n<p>这种做法的缺点就是，需要在应用程序地址空间和内核进行多次拷贝，这些拷贝动作所带来的CPU以及内存开销是非常大的。</p>\n<h2 id=\"同步、异步、阻塞、非阻塞\"><a href=\"#同步、异步、阻塞、非阻塞\" class=\"headerlink\" title=\"同步、异步、阻塞、非阻塞\"></a>同步、异步、阻塞、非阻塞</h2><p>同步与异步：描述的是用户线程与内核的交互方式，同步指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行；而异步是指用户线程发起IO请求后仍然继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。</p>\n<p>阻塞与非阻塞：描述是用户线程调用内核IO操作的方式，阻塞是指IO操作需要彻底完成后才返回到用户空间；而非阻塞是指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成。</p>\n<h2 id=\"并行与并发\"><a href=\"#并行与并发\" class=\"headerlink\" title=\"并行与并发\"></a>并行与并发</h2><p>先弄明白并发和并行的区别：比如去某部门办事需要依次去几个窗口，办事大厅的人数就是并发数，而窗口的个数就是并行度。就是说并发是同时进行的任务数（如同时服务的http请求），而并行数就是可以同时工作的物理资源数量（如cpu核数）。</p>\n<p>通过合理调度任务的不同阶段，并发数可以远远大于并行度。这就是区区几个CPU可以支撑上万个用户并发请求的原因。在这种高并发的情况下，为每个用户请求创建一个进程或者线程的开销非常大。而同步非阻塞方式可以把多个IO请求丢到后台去，这样一个CPU就可以服务大量的并发IO请求。</p>\n<h1 id=\"Linux-IO模型\"><a href=\"#Linux-IO模型\" class=\"headerlink\" title=\"Linux IO模型\"></a>Linux IO模型</h1><p>网络IO的本质就是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。文章开始的时候也提到了，对于一次IO访问（以read为例），数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间中。所以说，当一个read操作发生时，它会经历两个阶段：</p>\n<ul>\n<li>第一个阶段：等待数据准备。</li>\n<li>第二个阶段：将数据从内核拷贝到进程中</li>\n</ul>\n<p>对于socket流而言：</p>\n<ul>\n<li>第一步：通常涉及等待网络上的数据分组到达，然后复制到内核的某个缓冲区。</li>\n<li>第二步：把数据从内核缓冲区复制到应用进程缓冲区。</li>\n</ul>\n<p>当然，如果内核空间的缓冲区中已经有数据了，那么就可以省略第一步。至于为什么不能直接让磁盘控制器把数据送到应用程序的地址空间中呢？最简单的一个原因就是应用程序不能直接操作底层硬件。</p>\n<p>网络应用需要处理的无非就是两大类问题，网络IO，数据计算。相对于后者，网络IO的延迟，给应用带来的性能瓶颈大于后者。网络IO的模型大致分为如下五种：</p>\n<h2 id=\"阻塞IO（blocking-I-O）\"><a href=\"#阻塞IO（blocking-I-O）\" class=\"headerlink\" title=\"阻塞IO（blocking I/O）\"></a>阻塞IO（blocking I/O）</h2><p><img src=\"/image/IO/IO模型01.png\" alt=\"IO模型01\"></p>\n<p>在这个模型中，应用程序为了执行这个read操作，会调用相应的一个system call，将系统控制权交给内核，然后就进行等待（这个等待的过程就是被阻塞了），内核开始执行这个system call，执行完毕后会向应用程序返回响应，应用程序得到响应后，就不再阻塞，并进行后面的工作。</p>\n<p>用户进程调用了recvfrom这个系统调用，内核就开始了IO的第一个阶段：准备数据。对于网络IO来说，很多时候数据在一开始还没有到达（比如、还没有收到一个完整的UDP包），这个时候内核就要等待足够的数据到来，而在用户进程这边，整个进程会被阻塞。当内核一直等到数据准备好了，它就会将数据从内核中拷贝到用户内存，然后返回结果，用户进程才解除阻塞的状态，重新运行起来，几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv()等接口开始的，这些接口都是阻塞型的。</p>\n<p>blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被阻塞了。</p>\n<ul>\n<li>典型应用：阻塞Socket、Java BIO</li>\n<li>优点：进程阻塞挂起不消耗CPU资源，及时响应每个操作。实现难度低，开发应用较容易。</li>\n<li>缺点：对用户来说处于等待就要付出性能代价。适用并发量小的网络应用开发。不适用并发量大的应用。</li>\n</ul>\n<h2 id=\"非阻塞IO（noblocking-I-O）\"><a href=\"#非阻塞IO（noblocking-I-O）\" class=\"headerlink\" title=\"非阻塞IO（noblocking I/O）\"></a>非阻塞IO（noblocking I/O）</h2><p><img src=\"/image/IO/IO模型02.png\" alt=\"IO模型02\"></p>\n<p>当用户进程发出read操作时，调用相应的system call，这个system call会立即从内核中返回。但是在返回的这个时间点，内核中的数据可能还没有准备好，也就是说内核只是很快就返回了system call，只有这样才不会阻塞用户进程，对于应用程序，虽然这个IO操作很快就返回了，但是它并不知道这个IO操作是否真的成功了，为了知道IO操作是否成功，应用程序需要主动的循环去问内核。</p>\n<ul>\n<li>缺点：进程轮询（重复）调用、消耗CPU的资源</li>\n</ul>\n<h2 id=\"多路复用IO（I-O-multiplexing）\"><a href=\"#多路复用IO（I-O-multiplexing）\" class=\"headerlink\" title=\"多路复用IO（I/O multiplexing）\"></a>多路复用IO（I/O multiplexing）</h2><p><img src=\"/image/IO/IO模型04.png\" alt=\"IO模型04\"></p>\n<p>多个的进程的IO可以注册到一个复用器（select）上，当用户进程调用该select，select会监听所有注册进来的IO。如果select所有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞，而当任一IO在内核缓冲区中有可数据时，select调用就会返回，而后select调用进程可以自己或通知另外的进程（注册进程）来再次发起读取IO，读取内核中准备好的数据，多个进程注册IO后，只有一个select调用进程被阻塞。</p>\n<p>IO复用相对阻塞和非阻塞更难简单说明，所以额外解释一段。其实IO复用模型和阻塞IO模型并没有太大的不同，事实上还更差一些，因为这里需要使用两个系统调用（select和 recvfrom），而阻塞IO模型只有一次系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个连接，所以如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用多线程加阻塞IO的web server性能更好，可能延迟还更大，select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。</p>\n<p>在IO复用模型中，对于每一个socket一般都设置成为非阻塞。但是，如上图所示，整个用户的进程其实是一直被阻塞的，只不过进程是被select这个函数阻塞，而不是被socket IO给阻塞。</p>\n<p>调用system call之后，并不等待内核的返回结果而是立即返回。虽然返回结果的调用函数是一个异步的方式，但应用程序会被像select、poll和epoll等具有多个文件描述符的函数阻塞住，一直等到这个system call有结果返回了，再通知应用程序。这种情况，从IO操作的实际效果来看，异步阻塞IO和第一种同步阻塞IO是一样的，应用程序都是一直等到IO操作成功之后（数据已经被写入或者读取），才开始进行下面的工作。不同点在于异步阻塞IO用一个select函数可以为多个文件描述符提供通知，提供了并发性。举个例子：例如有一万个并发的read请求，但是网络上仍然没有数据，此时这一万个read会同时各自阻塞，现在用select、poll、epoll这样的函数来专门负责阻塞同时监听这一万个请求的状态，一旦有数据到达了就负责通知，这样就将一万个等待和阻塞转化为一个专门的函数来负责与管理。</p>\n<p>多路复用技术应用于JAVA NIO的核心类库多路复用器Selector中，目前支持I/O多路复用的系统调用有select、pselect、poll、epoll，在linux编程中有一段时间一直在使用select做轮询和网络事件通知的，但是select支持一个进程打开的socket描述符（FD）收到了限制，一般为1024，由于这一限制，现在使用了epoll代替了select，而epoll支持一个进程打开的FD不受限制。</p>\n<p>异步IO与同步IO的区别在于：同步IO是需要应用程序主动地循环去询问是否有数据，而异步IO是通过像select等IO多路复用函数来同时检测多个事件句柄来告知应用程序是否有数据。</p>\n<p>了解了前面三种IO模式，在用户进程进行系统调用的时候，他们在等待数据到来的时候，处理的方式是不一样的，直接等待、轮询、select或poll轮询，两个阶段过程：</p>\n<ul>\n<li>第一个阶段有的阻塞，有的不阻塞，有的可以阻塞又可以不阻塞。</li>\n<li>第二个阶段都是阻塞的。</li>\n</ul>\n<p>从整个IO过程来看，他们都是顺序执行的，因此可以归为同步模型，都是进程自动等待且向内核检查状态。</p>\n<p>IO多路复用究竟是同步阻塞还是异步阻塞模型，这里来展开说说：</p>\n<p>同步是需要主动等待消息通知，而异步则是被动接受消息通知，通过回调、通知、状态等方式来被动获取消息。IO多路复用在阻塞到select阶段时，用户进程是主动等待并调用select函数来获取就绪状态消息，并且其进程状态为阻塞。所以IO多路复用是同步阻塞模式。</p>\n<ul>\n<li>典型应用：Java NIO、Nginx（epoll、poll、select）</li>\n</ul>\n<h2 id=\"信号驱动IO（signal-blocking-I-O）\"><a href=\"#信号驱动IO（signal-blocking-I-O）\" class=\"headerlink\" title=\"信号驱动IO（signal blocking I/O）\"></a>信号驱动IO（signal blocking I/O）</h2><p><img src=\"/image/IO/IO模型03.png\" alt=\"IO模型03\"></p>\n<p>信号驱动式IO就是指进程预先告知内核，向内核注册一个信号处理函数，然后用户进程返回不阻塞，当内核数据就绪时会发送一个信号给进程，用户进程便在信号处理函数中调用IO读取数据，从图中明白实际IO内核拷贝到用户进程的过程还是阻塞的，信号驱动式IO并没有实现真正的异步，因为通知到进程之后，依然是由进程来完成IO操作。</p>\n<p>这和后面的异步IO模型很容易混淆，需要理解IO交互并结合五种IO模型的比较阅读。</p>\n<p>在信号驱动式IO模型中，依然不符合POSIX描述的异步IO，只能算是半异步，并且实际中并不常用。</p>\n<h2 id=\"异步IO（asynchronous-I-O）\"><a href=\"#异步IO（asynchronous-I-O）\" class=\"headerlink\" title=\"异步IO（asynchronous I/O）\"></a>异步IO（asynchronous I/O）</h2><p><img src=\"/image/IO/IO模型05.png\" alt=\"IO模型05\"></p>\n<p>用户进程发起aio_read（POSIX异步IO函数aio_或者lio_开头）操作之后、给内核传递描述符、缓冲区指针、缓冲区大小和read相同的三个参数以及文件偏移（与lseek类似），告诉内核当整个操作完成时，如何通知我们，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个aio_read之后，首先它会立刻返回。所以不会对用户进程产生任何阻塞。然后，内核会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，内核会给用户进程发送一个信号，告诉它aio_read操作完成了。</p>\n<p>异步IO的工作机制是：告知内核启动某个操作，并让内核在整个操作完成后通知我们。这种模型与信号驱动的IO区别在于，信号驱动IO是由内核通知我们何时可以启动一个IO操作，这个IO操作由用户自定义的信号函数来实现，而异步IO模型是由内核告知我们IO操作何时完成。</p>\n<p>这和前面的信号驱动式IO模型很容易混淆，需要理解IO交互并结合五种IO模型的比较阅读。</p>\n<p>在异步IO模型中，真正实现了POSIX描述的异步IO，是五种IO模型中唯一的异步模型。</p>\n<p>需要操作系统的底层支持，LINUX 2.5 版本内核首现，2.6 版本产品的内核标准特性。</p>\n<h1 id=\"五种IO模型比较\"><a href=\"#五种IO模型比较\" class=\"headerlink\" title=\"五种IO模型比较\"></a>五种IO模型比较</h1><p><img src=\"/image/IO/IO模型07.png\" alt=\"IO模型05\"></p>\n<h2 id=\"阻塞IO和非阻塞IO的区别在哪？\"><a href=\"#阻塞IO和非阻塞IO的区别在哪？\" class=\"headerlink\" title=\"阻塞IO和非阻塞IO的区别在哪？\"></a>阻塞IO和非阻塞IO的区别在哪？</h2><p>调用阻塞会一直阻塞住对应的进程直到操作完成，而非阻塞IO在内核还没准备数据的情况下会立刻返回。阻塞和非阻塞关注的是进程在等待调用结果时的状态，阻塞是指调用结果返回之前，当前进程会被挂起。调用进程只有在得到结果才会返回，非阻塞调用指不能立刻得到结果，该调用不会阻塞当前进程。</p>\n<h2 id=\"同步IO和异步IO区别在哪？\"><a href=\"#同步IO和异步IO区别在哪？\" class=\"headerlink\" title=\"同步IO和异步IO区别在哪？\"></a>同步IO和异步IO区别在哪？</h2><p>两者的区别就在于同步做IO操作的时候会将进程阻塞。按照这个定义，之前所述的阻塞IO、非阻塞IO、IO复用、信号驱动都属于同步IO。有人可能会说，非阻塞IO并没有被阻塞啊，这里有个非常狡猾的地方。定义中所指的IO操作是指真实的IO操作，就是例子中的recvfrom这个系统调用，非阻塞IO在执行recvfrom这个系统调用的时候，如果内核的数据没有准备好，这时候不会阻塞进程。但是，当内核中数据准备好的时候，recvfrom会将数据从内核拷贝到用户内存中，这个时候进程是被阻塞了。信号驱动也是同样的道理，在这段时间内，进程是被阻塞的。而异步IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到内核发送一个信号，告诉进程说IO完成，在这整个过程中，进程完全没有被阻塞。</p>\n<p>同异步IO的根本区别在于：同步IO主动的调用recvfrom来将数据拷贝到用户内存。而异步则完全不同，它就像是用户进程将整个IO操作交给了他人（内核）完成，然后他人做完后发信号通知，在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。</p>\n<h2 id=\"POSIX的定义\"><a href=\"#POSIX的定义\" class=\"headerlink\" title=\"POSIX的定义\"></a>POSIX的定义</h2><p>A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes</p>\n<p>An asynchronous I/O operation does not cause the requesting process to be blocked</p>\n<h2 id=\"信号驱动式IO和异步IO的区别？\"><a href=\"#信号驱动式IO和异步IO的区别？\" class=\"headerlink\" title=\"信号驱动式IO和异步IO的区别？\"></a>信号驱动式IO和异步IO的区别？</h2><p>这里之所以单独拿出来是因为如果还没有清除IO概念很容易混淆，所以理解IO模型之前一定要理解IO概念。如果看完前面两个问题，相信也能理解信号驱动IO与异步IO的区别在于启用异步IO意味着通知内核启动某个IO操作，并让内核在整个操作（包括数据从内核复制到用户缓冲区）完成时通知我们，也就是说，异步IO是由内核通知我们IO操作何时完成，即实际的IO操作也是异步的，信号驱动IO是由内核通知我们何时可以启动一个IO操作，这个IO操作由用户自定义的信号函数来实现。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"http://www.360doc.com/content/19/0511/15/64010826_835008660.shtml\" target=\"_blank\" rel=\"noopener\">http://www.360doc.com/content/19/0511/15/64010826_835008660.shtml</a></li>\n<li><a href=\"https://www.cnblogs.com/dongguacai/p/5770287.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/dongguacai/p/5770287.html</a></li>\n<li><a href=\"https://blog.csdn.net/ZWE7616175/article/details/80591587\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ZWE7616175/article/details/80591587</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>在学习JAVA NIO的时候有学习到相关的BIO、NIO、AIO的概念，以及一直对阻塞、非阻塞、异步等IO模型的知识感到非常模糊，要清楚JAVA的NIO是什么，以及基础的操作系统的网络IO模型，在此总结下网络IO模型的基础知识。</p>\n<p>不得不感叹信息爆炸的时代，想学点东西但是到处都是误人子弟的文章和copy的内容，但是自己还想快餐式的学点重点，先简单学习下，真正细致的学习还是要看看《UNIX网络编程》。</p>","more":"<h1 id=\"几个基础概念\"><a href=\"#几个基础概念\" class=\"headerlink\" title=\"几个基础概念\"></a>几个基础概念</h1><h2 id=\"什么是IO\"><a href=\"#什么是IO\" class=\"headerlink\" title=\"什么是IO\"></a>什么是IO</h2><p>我们都知道unix世界里、一切皆文件、而文件是什么呢？文件就是一串二进制流而已、不管socket、还是FIFO、管道、终端、对我们来说、一切都是文件、一切都是流、在信息交换的过程中、我们都是对这些流进行数据的收发操作、简称为I/O操作(input and output)、往流中读出数据、系统调用read、写入数据、系统调用write、不过话说回来了、计算机里有这么多的流、我怎么知道要操作哪个流呢？做到这个的就是文件描述符、即通常所说的fd、一个fd就是一个整数、所以对这个整数的操作、就是对这个文件（流）的操作、我们创建一个socket、通过系统调用会返回一个文件描述符、那么剩下对socket的操作就会转化为对这个描述符的操作、不能不说这又是一种分层和抽象的思想。</p>\n<h2 id=\"IO的交互\"><a href=\"#IO的交互\" class=\"headerlink\" title=\"IO的交互\"></a>IO的交互</h2><p><img src=\"/image/IO/IO模型00.png\" alt=\"IO模型00\"></p>\n<p>通常用户进程中的一个完整IO分为两阶段：</p>\n<ul>\n<li>用户空间 <-----> 内核空间</-----></li>\n<li>内核空间 <-----> 设备空间</-----></li>\n</ul>\n<p><img src=\"/image/IO/IO模型00.jpg\" alt=\"IO模型00\"></p>\n<p>内核空间中存放的是内核代码和数据、而进程的用户空间中存放的是用户程序的代码和数据、不管是内核空间还是用户空间、它们都处于虚拟空间中、Linux使用两级保护机制：0级供内核使用、3级供用户程序使用。</p>\n<p>操作系统和驱动程序运行在内核空间、应用程序运行在用户空间、两者不能简单地使用指针传递数据、因为Linux使用的虚拟内存机制、其必须通过系统调用请求kernel来协助完成IO动作、内核会为每个IO设备维护一个缓冲区、用户空间的数据可能被换出、当内核空间使用用户空间指针时、对应的数据可能不在内存中。</p>\n<p>对于一个输入操作来说、进程IO系统调用后、内核会先看缓冲区中有没有相应的缓存数据、没有的话再到设备中读取、因为设备IO一般速度较慢、需要等待、内核缓冲区有数据则直接复制到进程空间。</p>\n<p>所以、对于一个网络输入操作通常包括两个不同阶段：</p>\n<ol>\n<li>等待网络数据到达网卡 –&gt; 读取到内核缓冲区</li>\n<li>从内核缓冲区复制数据 –&gt; 用户空间</li>\n</ol>\n<p>IO有内存IO、网络IO和磁盘IO三种、通常我们说的IO指的是后两者</p>\n<h2 id=\"用户空间、内核空间\"><a href=\"#用户空间、内核空间\" class=\"headerlink\" title=\"用户空间、内核空间\"></a>用户空间、内核空间</h2><p>现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟储存空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操作系统将虚拟空间划分为两个部分，一个部分为内核空间，一部分为用户空间。</p>\n<p>如何分配这两个空间的大小也是有讲究的，如windows 32位操作系统，默认的用户空间：内核空间的比例是1:1;而在32位Linux系统中的默认比例是3:1（3G用户空间，1G内核空间）。</p>\n<h2 id=\"进程切换\"><a href=\"#进程切换\" class=\"headerlink\" title=\"进程切换\"></a>进程切换</h2><p>为了控制进程的执行，内核必须要有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为成为进程的切换。任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。</p>\n<p>进程切换的过程，会经过下面这些变化：</p>\n<ol>\n<li>保存处理机上下文，包括程序计数器和其他寄存器。</li>\n<li>更新PCB信息。</li>\n<li>将进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。</li>\n<li>选择另外一个进程执行，并更新PCB。</li>\n<li>更新内存管理的数据结构。</li>\n<li>恢复处理机上下文。</li>\n</ol>\n<h2 id=\"缓存IO\"><a href=\"#缓存IO\" class=\"headerlink\" title=\"缓存IO\"></a>缓存IO</h2><p>缓存IO又称称为标准IO，大多数文件系统的默认IO操作都是缓存IO。在Linux的缓存IO机制中，操作系统会将IO的数据缓存在文件系统的页缓存（page cache）。也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓存区拷贝到应用程序的地址空间中。</p>\n<p>这种做法的缺点就是，需要在应用程序地址空间和内核进行多次拷贝，这些拷贝动作所带来的CPU以及内存开销是非常大的。</p>\n<h2 id=\"同步、异步、阻塞、非阻塞\"><a href=\"#同步、异步、阻塞、非阻塞\" class=\"headerlink\" title=\"同步、异步、阻塞、非阻塞\"></a>同步、异步、阻塞、非阻塞</h2><p>同步与异步：描述的是用户线程与内核的交互方式，同步指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行；而异步是指用户线程发起IO请求后仍然继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。</p>\n<p>阻塞与非阻塞：描述是用户线程调用内核IO操作的方式，阻塞是指IO操作需要彻底完成后才返回到用户空间；而非阻塞是指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成。</p>\n<h2 id=\"并行与并发\"><a href=\"#并行与并发\" class=\"headerlink\" title=\"并行与并发\"></a>并行与并发</h2><p>先弄明白并发和并行的区别：比如去某部门办事需要依次去几个窗口，办事大厅的人数就是并发数，而窗口的个数就是并行度。就是说并发是同时进行的任务数（如同时服务的http请求），而并行数就是可以同时工作的物理资源数量（如cpu核数）。</p>\n<p>通过合理调度任务的不同阶段，并发数可以远远大于并行度。这就是区区几个CPU可以支撑上万个用户并发请求的原因。在这种高并发的情况下，为每个用户请求创建一个进程或者线程的开销非常大。而同步非阻塞方式可以把多个IO请求丢到后台去，这样一个CPU就可以服务大量的并发IO请求。</p>\n<h1 id=\"Linux-IO模型\"><a href=\"#Linux-IO模型\" class=\"headerlink\" title=\"Linux IO模型\"></a>Linux IO模型</h1><p>网络IO的本质就是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。文章开始的时候也提到了，对于一次IO访问（以read为例），数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间中。所以说，当一个read操作发生时，它会经历两个阶段：</p>\n<ul>\n<li>第一个阶段：等待数据准备。</li>\n<li>第二个阶段：将数据从内核拷贝到进程中</li>\n</ul>\n<p>对于socket流而言：</p>\n<ul>\n<li>第一步：通常涉及等待网络上的数据分组到达，然后复制到内核的某个缓冲区。</li>\n<li>第二步：把数据从内核缓冲区复制到应用进程缓冲区。</li>\n</ul>\n<p>当然，如果内核空间的缓冲区中已经有数据了，那么就可以省略第一步。至于为什么不能直接让磁盘控制器把数据送到应用程序的地址空间中呢？最简单的一个原因就是应用程序不能直接操作底层硬件。</p>\n<p>网络应用需要处理的无非就是两大类问题，网络IO，数据计算。相对于后者，网络IO的延迟，给应用带来的性能瓶颈大于后者。网络IO的模型大致分为如下五种：</p>\n<h2 id=\"阻塞IO（blocking-I-O）\"><a href=\"#阻塞IO（blocking-I-O）\" class=\"headerlink\" title=\"阻塞IO（blocking I/O）\"></a>阻塞IO（blocking I/O）</h2><p><img src=\"/image/IO/IO模型01.png\" alt=\"IO模型01\"></p>\n<p>在这个模型中，应用程序为了执行这个read操作，会调用相应的一个system call，将系统控制权交给内核，然后就进行等待（这个等待的过程就是被阻塞了），内核开始执行这个system call，执行完毕后会向应用程序返回响应，应用程序得到响应后，就不再阻塞，并进行后面的工作。</p>\n<p>用户进程调用了recvfrom这个系统调用，内核就开始了IO的第一个阶段：准备数据。对于网络IO来说，很多时候数据在一开始还没有到达（比如、还没有收到一个完整的UDP包），这个时候内核就要等待足够的数据到来，而在用户进程这边，整个进程会被阻塞。当内核一直等到数据准备好了，它就会将数据从内核中拷贝到用户内存，然后返回结果，用户进程才解除阻塞的状态，重新运行起来，几乎所有的程序员第一次接触到的网络编程都是从listen()、send()、recv()等接口开始的，这些接口都是阻塞型的。</p>\n<p>blocking IO的特点就是在IO执行的两个阶段（等待数据和拷贝数据两个阶段）都被阻塞了。</p>\n<ul>\n<li>典型应用：阻塞Socket、Java BIO</li>\n<li>优点：进程阻塞挂起不消耗CPU资源，及时响应每个操作。实现难度低，开发应用较容易。</li>\n<li>缺点：对用户来说处于等待就要付出性能代价。适用并发量小的网络应用开发。不适用并发量大的应用。</li>\n</ul>\n<h2 id=\"非阻塞IO（noblocking-I-O）\"><a href=\"#非阻塞IO（noblocking-I-O）\" class=\"headerlink\" title=\"非阻塞IO（noblocking I/O）\"></a>非阻塞IO（noblocking I/O）</h2><p><img src=\"/image/IO/IO模型02.png\" alt=\"IO模型02\"></p>\n<p>当用户进程发出read操作时，调用相应的system call，这个system call会立即从内核中返回。但是在返回的这个时间点，内核中的数据可能还没有准备好，也就是说内核只是很快就返回了system call，只有这样才不会阻塞用户进程，对于应用程序，虽然这个IO操作很快就返回了，但是它并不知道这个IO操作是否真的成功了，为了知道IO操作是否成功，应用程序需要主动的循环去问内核。</p>\n<ul>\n<li>缺点：进程轮询（重复）调用、消耗CPU的资源</li>\n</ul>\n<h2 id=\"多路复用IO（I-O-multiplexing）\"><a href=\"#多路复用IO（I-O-multiplexing）\" class=\"headerlink\" title=\"多路复用IO（I/O multiplexing）\"></a>多路复用IO（I/O multiplexing）</h2><p><img src=\"/image/IO/IO模型04.png\" alt=\"IO模型04\"></p>\n<p>多个的进程的IO可以注册到一个复用器（select）上，当用户进程调用该select，select会监听所有注册进来的IO。如果select所有监听的IO在内核缓冲区都没有可读数据，select调用进程会被阻塞，而当任一IO在内核缓冲区中有可数据时，select调用就会返回，而后select调用进程可以自己或通知另外的进程（注册进程）来再次发起读取IO，读取内核中准备好的数据，多个进程注册IO后，只有一个select调用进程被阻塞。</p>\n<p>IO复用相对阻塞和非阻塞更难简单说明，所以额外解释一段。其实IO复用模型和阻塞IO模型并没有太大的不同，事实上还更差一些，因为这里需要使用两个系统调用（select和 recvfrom），而阻塞IO模型只有一次系统调用(recvfrom)。但是，用select的优势在于它可以同时处理多个连接，所以如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用多线程加阻塞IO的web server性能更好，可能延迟还更大，select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。</p>\n<p>在IO复用模型中，对于每一个socket一般都设置成为非阻塞。但是，如上图所示，整个用户的进程其实是一直被阻塞的，只不过进程是被select这个函数阻塞，而不是被socket IO给阻塞。</p>\n<p>调用system call之后，并不等待内核的返回结果而是立即返回。虽然返回结果的调用函数是一个异步的方式，但应用程序会被像select、poll和epoll等具有多个文件描述符的函数阻塞住，一直等到这个system call有结果返回了，再通知应用程序。这种情况，从IO操作的实际效果来看，异步阻塞IO和第一种同步阻塞IO是一样的，应用程序都是一直等到IO操作成功之后（数据已经被写入或者读取），才开始进行下面的工作。不同点在于异步阻塞IO用一个select函数可以为多个文件描述符提供通知，提供了并发性。举个例子：例如有一万个并发的read请求，但是网络上仍然没有数据，此时这一万个read会同时各自阻塞，现在用select、poll、epoll这样的函数来专门负责阻塞同时监听这一万个请求的状态，一旦有数据到达了就负责通知，这样就将一万个等待和阻塞转化为一个专门的函数来负责与管理。</p>\n<p>多路复用技术应用于JAVA NIO的核心类库多路复用器Selector中，目前支持I/O多路复用的系统调用有select、pselect、poll、epoll，在linux编程中有一段时间一直在使用select做轮询和网络事件通知的，但是select支持一个进程打开的socket描述符（FD）收到了限制，一般为1024，由于这一限制，现在使用了epoll代替了select，而epoll支持一个进程打开的FD不受限制。</p>\n<p>异步IO与同步IO的区别在于：同步IO是需要应用程序主动地循环去询问是否有数据，而异步IO是通过像select等IO多路复用函数来同时检测多个事件句柄来告知应用程序是否有数据。</p>\n<p>了解了前面三种IO模式，在用户进程进行系统调用的时候，他们在等待数据到来的时候，处理的方式是不一样的，直接等待、轮询、select或poll轮询，两个阶段过程：</p>\n<ul>\n<li>第一个阶段有的阻塞，有的不阻塞，有的可以阻塞又可以不阻塞。</li>\n<li>第二个阶段都是阻塞的。</li>\n</ul>\n<p>从整个IO过程来看，他们都是顺序执行的，因此可以归为同步模型，都是进程自动等待且向内核检查状态。</p>\n<p>IO多路复用究竟是同步阻塞还是异步阻塞模型，这里来展开说说：</p>\n<p>同步是需要主动等待消息通知，而异步则是被动接受消息通知，通过回调、通知、状态等方式来被动获取消息。IO多路复用在阻塞到select阶段时，用户进程是主动等待并调用select函数来获取就绪状态消息，并且其进程状态为阻塞。所以IO多路复用是同步阻塞模式。</p>\n<ul>\n<li>典型应用：Java NIO、Nginx（epoll、poll、select）</li>\n</ul>\n<h2 id=\"信号驱动IO（signal-blocking-I-O）\"><a href=\"#信号驱动IO（signal-blocking-I-O）\" class=\"headerlink\" title=\"信号驱动IO（signal blocking I/O）\"></a>信号驱动IO（signal blocking I/O）</h2><p><img src=\"/image/IO/IO模型03.png\" alt=\"IO模型03\"></p>\n<p>信号驱动式IO就是指进程预先告知内核，向内核注册一个信号处理函数，然后用户进程返回不阻塞，当内核数据就绪时会发送一个信号给进程，用户进程便在信号处理函数中调用IO读取数据，从图中明白实际IO内核拷贝到用户进程的过程还是阻塞的，信号驱动式IO并没有实现真正的异步，因为通知到进程之后，依然是由进程来完成IO操作。</p>\n<p>这和后面的异步IO模型很容易混淆，需要理解IO交互并结合五种IO模型的比较阅读。</p>\n<p>在信号驱动式IO模型中，依然不符合POSIX描述的异步IO，只能算是半异步，并且实际中并不常用。</p>\n<h2 id=\"异步IO（asynchronous-I-O）\"><a href=\"#异步IO（asynchronous-I-O）\" class=\"headerlink\" title=\"异步IO（asynchronous I/O）\"></a>异步IO（asynchronous I/O）</h2><p><img src=\"/image/IO/IO模型05.png\" alt=\"IO模型05\"></p>\n<p>用户进程发起aio_read（POSIX异步IO函数aio_或者lio_开头）操作之后、给内核传递描述符、缓冲区指针、缓冲区大小和read相同的三个参数以及文件偏移（与lseek类似），告诉内核当整个操作完成时，如何通知我们，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个aio_read之后，首先它会立刻返回。所以不会对用户进程产生任何阻塞。然后，内核会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，内核会给用户进程发送一个信号，告诉它aio_read操作完成了。</p>\n<p>异步IO的工作机制是：告知内核启动某个操作，并让内核在整个操作完成后通知我们。这种模型与信号驱动的IO区别在于，信号驱动IO是由内核通知我们何时可以启动一个IO操作，这个IO操作由用户自定义的信号函数来实现，而异步IO模型是由内核告知我们IO操作何时完成。</p>\n<p>这和前面的信号驱动式IO模型很容易混淆，需要理解IO交互并结合五种IO模型的比较阅读。</p>\n<p>在异步IO模型中，真正实现了POSIX描述的异步IO，是五种IO模型中唯一的异步模型。</p>\n<p>需要操作系统的底层支持，LINUX 2.5 版本内核首现，2.6 版本产品的内核标准特性。</p>\n<h1 id=\"五种IO模型比较\"><a href=\"#五种IO模型比较\" class=\"headerlink\" title=\"五种IO模型比较\"></a>五种IO模型比较</h1><p><img src=\"/image/IO/IO模型07.png\" alt=\"IO模型05\"></p>\n<h2 id=\"阻塞IO和非阻塞IO的区别在哪？\"><a href=\"#阻塞IO和非阻塞IO的区别在哪？\" class=\"headerlink\" title=\"阻塞IO和非阻塞IO的区别在哪？\"></a>阻塞IO和非阻塞IO的区别在哪？</h2><p>调用阻塞会一直阻塞住对应的进程直到操作完成，而非阻塞IO在内核还没准备数据的情况下会立刻返回。阻塞和非阻塞关注的是进程在等待调用结果时的状态，阻塞是指调用结果返回之前，当前进程会被挂起。调用进程只有在得到结果才会返回，非阻塞调用指不能立刻得到结果，该调用不会阻塞当前进程。</p>\n<h2 id=\"同步IO和异步IO区别在哪？\"><a href=\"#同步IO和异步IO区别在哪？\" class=\"headerlink\" title=\"同步IO和异步IO区别在哪？\"></a>同步IO和异步IO区别在哪？</h2><p>两者的区别就在于同步做IO操作的时候会将进程阻塞。按照这个定义，之前所述的阻塞IO、非阻塞IO、IO复用、信号驱动都属于同步IO。有人可能会说，非阻塞IO并没有被阻塞啊，这里有个非常狡猾的地方。定义中所指的IO操作是指真实的IO操作，就是例子中的recvfrom这个系统调用，非阻塞IO在执行recvfrom这个系统调用的时候，如果内核的数据没有准备好，这时候不会阻塞进程。但是，当内核中数据准备好的时候，recvfrom会将数据从内核拷贝到用户内存中，这个时候进程是被阻塞了。信号驱动也是同样的道理，在这段时间内，进程是被阻塞的。而异步IO则不一样，当进程发起IO操作之后，就直接返回再也不理睬了，直到内核发送一个信号，告诉进程说IO完成，在这整个过程中，进程完全没有被阻塞。</p>\n<p>同异步IO的根本区别在于：同步IO主动的调用recvfrom来将数据拷贝到用户内存。而异步则完全不同，它就像是用户进程将整个IO操作交给了他人（内核）完成，然后他人做完后发信号通知，在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。</p>\n<h2 id=\"POSIX的定义\"><a href=\"#POSIX的定义\" class=\"headerlink\" title=\"POSIX的定义\"></a>POSIX的定义</h2><p>A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes</p>\n<p>An asynchronous I/O operation does not cause the requesting process to be blocked</p>\n<h2 id=\"信号驱动式IO和异步IO的区别？\"><a href=\"#信号驱动式IO和异步IO的区别？\" class=\"headerlink\" title=\"信号驱动式IO和异步IO的区别？\"></a>信号驱动式IO和异步IO的区别？</h2><p>这里之所以单独拿出来是因为如果还没有清除IO概念很容易混淆，所以理解IO模型之前一定要理解IO概念。如果看完前面两个问题，相信也能理解信号驱动IO与异步IO的区别在于启用异步IO意味着通知内核启动某个IO操作，并让内核在整个操作（包括数据从内核复制到用户缓冲区）完成时通知我们，也就是说，异步IO是由内核通知我们IO操作何时完成，即实际的IO操作也是异步的，信号驱动IO是由内核通知我们何时可以启动一个IO操作，这个IO操作由用户自定义的信号函数来实现。</p>\n<h1 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h1><ul>\n<li><a href=\"http://www.360doc.com/content/19/0511/15/64010826_835008660.shtml\" target=\"_blank\" rel=\"noopener\">http://www.360doc.com/content/19/0511/15/64010826_835008660.shtml</a></li>\n<li><a href=\"https://www.cnblogs.com/dongguacai/p/5770287.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/dongguacai/p/5770287.html</a></li>\n<li><a href=\"https://blog.csdn.net/ZWE7616175/article/details/80591587\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ZWE7616175/article/details/80591587</a></li>\n</ul>"},{"title":"Stream","date":"2018-11-19T02:53:00.000Z","_content":"\n>最近在学习JAVA8 Stream的API，找到了这篇文章，觉得内容很好就抄了过来，文章来源：https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/\n\n# 为什么需要 Stream\n\nStream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。它也不同于 StAX 对 XML 解析的 Stream，也不是 Amazon Kinesis 对大数据实时处理的 Stream。Java 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。所以说，Java 8 中首次出现的 java.util.stream 是一个函数式语言+多核时代综合影响的产物。\n\n<!-- more -->\n\n## 什么是聚合操作\n\n在传统的 J2EE 应用中，Java 代码经常不得不依赖于关系型数据库的聚合操作来完成诸如：\n* 客户每月平均消费金额\n* 最昂贵的在售商品\n* 本周完成的有效订单（排除了无效的）\n* 取十个数据样本作为首页推荐\n\n但在当今这个数据大爆炸的时代，在数据来源多样化、数据海量化的今天，很多时候不得不脱离 RDBMS，或者以底层返回的数据为基础进行更上层的数据统计。而 Java 的集合 API 中，仅仅有极少量的辅助型方法，更多的时候是程序员需要用 Iterator 来遍历集合，完成相关的聚合应用逻辑。这是一种远不够高效、笨拙的方法。在 Java 7 中，如果要发现 type 为 grocery 的所有交易，然后返回以交易值降序排序好的交易 ID 集合，我们需要这样写：\n\neg1. Java 7 的排序、取值实现\n```java\nList<Transaction> groceryTransactions = new Arraylist<>();\nfor (Transaction t : transactions) {\n    if (t.getType() == Transaction.GROCERY) {\n        groceryTransactions.add(t);\n    }\n}\nCollections.sort(groceryTransactions, new Comparator() {\n    public int compare(Transaction t1, Transaction t2) {\n        return t2.getValue().compareTo(t1.getValue());\n    }\n});\nList<Integer> transactionIds = new ArrayList<>();\nfor (Transaction t : groceryTransactions) {\n    transactionsIds.add(t.getId());\n}\n```\n\n而在 Java 8 使用 Stream，代码更加简洁易读；而且使用并发模式，程序执行速度更快。\n\neg2. Java 8 的排序、取值实现\n```java\nList<Integer> transactionsIds = transactions.parallelStream().\n    filter(t -> t.getType() == Transaction.GROCERY).\n    sorted(comparing(Transaction::getValue).reversed()).\n    map(Transaction::getId).\n    collect(toList());\n```\n\n# Stream 总览\n\n## 什么是流\n\nStream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，比如 “过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。\n\nStream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。\n\n而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架（JSR166y）来拆分任务和加速处理过程。Java 的并行 API 演变历程基本如下：\n\n1. 1.0-1.4 中的 java.lang.Thread\n2. 5.0 中的 java.util.concurrent\n3. 6.0 中的 Phasers 等\n4. 7.0 中的 Fork/Join 框架\n5. 8.0 中的 Lambda\n\nStream 的另外一大特点是，数据源本身可以是无限的。\n\n## 流的构成\n\n当我们使用一个流的时候，通常包括三个基本步骤：\n\n获取一个数据源（source）→ 数据转换→执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道，如下图所示。\n\n流管道 (Stream Pipeline) 的构成\n\n![StreamPipeline-photo](https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/img001.png)\n\n### 有多种方式生成 Stream Source：\n\n#### 从 Collection 和数组\n\n* Collection.stream()\n* Collection.parallelStream()\n* Arrays.stream(T array) or Stream.of()\n\n#### 从 BufferedReader\n\n* java.io.BufferedReader.lines()\n\n#### 静态工厂\n\n* java.util.stream.IntStream.range()\n* java.nio.file.Files.walk()\n\n#### 自己构建\n\n* java.util.Spliterator\n\n#### 其它\n\n* Random.ints()\n* BitSet.stream()\n* Pattern.splitAsStream(java.lang.CharSequence)\n* JarFile.stream()\n\n### 流的操作类型分为两种：\n\n* ***Intermediate***：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。\n\n* ***Terminal***：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。\n\n在对于一个 Stream 进行多次转换操作 (Intermediate 操作)，每次都对 Stream 的每个元素进行转换，而且是执行多次，这样时间复杂度就是 N（转换次数）个 for 循环里把所有操作都做掉的总和吗？其实不是这样的，转换操作都是 lazy 的，多个转换操作只会在 Terminal 操作的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream 里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在 Terminal 操作的时候循环 Stream 对应的集合，然后对每个元素执行所有的函数。\n\n还有一种操作被称为 ***short-circuiting***。用以指：\n\n* 对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。\n* 对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。\n\n当操作一个无限大的 Stream，而又希望在有限时间内完成操作，则在管道内拥有一个 short-circuiting 操作是必要非充分条件。\n\neg3. 一个流操作的示例\n```java\nint sum = widgets.stream()\n    .filter(w -> w.getColor() == RED)\n    .mapToInt(w -> w.getWeight())\n    .sum();\n```\n\nstream() 获取当前小物件的 source，filter 和 mapToInt 为 intermediate 操作，进行数据筛选和转换，最后一个 sum() 为 terminal 操作，对符合条件的全部小物件作重量求和。\n\n# 流的使用详解\n\n简单说，对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果，或者导致一个副作用（side effect）。\n\n## 流的构造与转换\n\n下面提供最常见的几种构造 Stream 的样例。\n\neg4. 构造流的几种常见方法\n```java\n// 1. Individual values\nStream stream = Stream.of(\"a\", \"b\", \"c\");\n// 2. Arrays\nString [] strArray = new String[] {\"a\", \"b\", \"c\"};\nstream = Stream.of(strArray);\nstream = Arrays.stream(strArray);\n// 3. Collections\nList<String> list = Arrays.asList(strArray);\nstream = list.stream();\n```\n\n需要注意的是，对于基本数值型，目前有三种对应的包装类型 Stream：\n\nIntStream、LongStream、DoubleStream。当然我们也可以用 Stream<Integer>、Stream<Long> >、Stream<Double>，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。\n\nJava 8 中还没有提供其它数值型 Stream，因为这将导致扩增的内容较多。而常规的数值型聚合运算可以通过上面三种 Stream 进行。\n\neg5. 数值流的构造\n```java\nIntStream.of(new int[]{1, 2, 3}).forEach(System.out::println);\nIntStream.range(1, 3).forEach(System.out::println);\nIntStream.rangeClosed(1, 3).forEach(System.out::println);\n```\n\neg6. 流转换为其它数据结构\n```java\n// 1. Array\nString[] strArray1 = stream.toArray(String[]::new);\n// 2. Collection\nList<String> list1 = stream.collect(Collectors.toList());\nList<String> list2 = stream.collect(Collectors.toCollection(ArrayList::new));\nSet set1 = stream.collect(Collectors.toSet());\nStack stack1 = stream.collect(Collectors.toCollection(Stack::new));\n// 3. String\nString str = stream.collect(Collectors.joining()).toString();\n```\n\n一个 Stream 只可以使用一次，上面的代码为了简洁而重复使用了数次。\n\n## 流的操作\n\n接下来，当把一个数据结构包装成 Stream 后，就要开始对里面的元素进行各类操作了。常见的操作可以归类如下。\n\n* Intermediate：\n\n    map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered\n\n* Terminal：\n\n    forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator\n\n* Short-circuiting：\n\n    anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit\n\n### map/flatMap\n\n我们先来看 map。如果你熟悉 scala 这类函数式语言，对这个方法应该很了解，它的作用就是把 input Stream 的每一个元素，映射成 output Stream 的另外一个元素。\n\neg7. 转换大写\n```java\nList<String> output = wordList.stream().\nmap(String::toUpperCase).\ncollect(Collectors.toList());\n```\n\n这段代码把所有的单词转换为大写。\n\neg8. 平方数\n```java\nList<Integer> nums = Arrays.asList(1, 2, 3, 4);\nList<Integer> squareNums = nums.stream().\nmap(n -> n * n).\ncollect(Collectors.toList());\n```\n\n这段代码生成一个整数 list 的平方数 {1, 4, 9, 16}。\n\n从上面例子可以看出，map 生成的是个 1:1 映射，每个输入元素，都按照规则转换成为另外一个元素。还有一些场景，是一对多映射关系的，这时需要 flatMap。\n\neg9. 一对多\n```java\nStream<List<Integer>> inputStream = Stream.of(\n Arrays.asList(1),\n Arrays.asList(2, 3),\n Arrays.asList(4, 5, 6)\n );\nStream<Integer> outputStream = inputStream.\nflatMap((childList) -> childList.stream());\n```\n\nflatMap 把 input Stream 中的层级结构扁平化，就是将最底层元素抽出来放到一起，最终 output 的新 Stream 里面已经没有 List 了，都是直接的数字。\n\n### filter\n\nfilter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream。\n\neg10. 留下偶数\n```java\nInteger[] sixNums = {1, 2, 3, 4, 5, 6};\nInteger[] evens =\nStream.of(sixNums).filter(n -> n%2 == 0).toArray(Integer[]::new);\n```\n\n经过条件“被 2 整除”的 filter，剩下的数字为 {2, 4, 6}。\n\neg11. 把单词挑出来\n```java\nList<String> output = reader.lines().\n    flatMap(line -> Stream.of(line.split(REGEXP))).\n    filter(word -> word.length() > 0).\n    collect(Collectors.toList());\n```\n\n这段代码首先把每行的单词用 flatMap 整理到新的 Stream，然后保留长度不为 0 的，就是整篇文章中的全部单词了。\n\n\n### forEach\n\nforEach 方法接收一个 Lambda 表达式，然后在 Stream 的每一个元素上执行该表达式。\n\neg12. 打印姓名（forEach 和 pre-java8 的对比）\n```java\n// Java 8\nroster.stream()\n    .filter(p -> p.getGender() == Person.Sex.MALE)\n    .forEach(p -> System.out.println(p.getName()));\n// Pre-Java 8\nfor (Person p : roster) {\n    if (p.getGender() == Person.Sex.MALE) {\n        System.out.println(p.getName());\n    }\n}\n```\n对一个人员集合遍历，找出男性并打印姓名。可以看出来，forEach 是为 Lambda 而设计的，保持了最紧凑的风格。而且 Lambda 表达式本身是可以重用的，非常方便。当需要为多核系统优化时，可以 parallelStream().forEach()，只是此时原有元素的次序没法保证，并行的情况下将改变串行时操作的行为，此时 forEach 本身的实现不需要调整，而 Java8 以前的 for 循环 code 可能需要加入额外的多线程逻辑。\n\n但一般认为，forEach 和常规 for 循环的差异不涉及到性能，它们仅仅是函数式风格与传统 Java 风格的差别。\n\n另外一点需要注意，forEach 是 terminal 操作，因此它执行后，Stream 的元素就被“消费”掉了，你无法对一个 Stream 进行两次 terminal 运算。下面的代码是错误的：\n\n```java\nstream.forEach(element -> doOneThing(element));\nstream.forEa\nch(element -> doAnotherThing(element));\n```\n\n相反，具有相似功能的 intermediate 操作 peek 可以达到上述目的。如下是出现在该 api javadoc 上的一个示例。\n\neg13. peek 对每个元素执行操作并返回一个新的 Stream\n```java\nStream.of(\"one\", \"two\", \"three\", \"four\")\n    .filter(e -> e.length() > 3)\n    .peek(e -> System.out.println(\"Filtered value: \" + e))\n    .map(String::toUpperCase)\n    .peek(e -> System.out.println(\"Mapped value: \" + e))\n    .collect(Collectors.toList());\n ```\n\nforEach 不能修改自己包含的本地变量值，也不能用 break/return 之类的关键字提前结束循环。\n\n### findFirst\n\n这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。\n\n这里比较重点的是它的返回值类型：Optional。这也是一个模仿 Scala 语言中的概念，作为一个容器，它可能含有某值，或者不包含。使用它的目的是尽可能避免 NullPointerException。\n\neg14. Optional 的两个用例\n```java\nString strA = \" abcd \", strB = null;\nprint(strA);\nprint(\"\");\nprint(strB);\ngetLength(strA);\ngetLength(\"\");\ngetLength(strB);\npublic static void print(String text) {\n    // Java 8\n    Optional.ofNullable(text).ifPresent(System.out::println);\n    // Pre-Java 8\n    if (text != null) {\n        System.out.println(text);\n    }\n }\npublic static int getLength(String text) {\n    // Java 8\n    return Optional.ofNullable(text).map(String::length).orElse(-1);\n    // Pre-Java 8\n    // return if (text != null) ? text.length() : -1;\n};\n```\n在更复杂的 if (xx != null) 的情况中，使用 Optional 代码的可读性更好，而且它提供的是编译时检查，能极大的降低 NPE 这种 Runtime Exception 对程序的影响，或者迫使程序员更早的在编码阶段处理空值问题，而不是留到运行时再发现和调试。\n\nStream 中的 findAny、max/min、reduce 等方法等返回 Optional 值。还有例如 IntStream.average() 返回 OptionalDouble 等等。\n\n### reduce\n\n这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。例如 Stream 的 sum 就相当于\n\nInteger sum = integers.reduce(0, (a, b) -> a+b); 或\n\nInteger sum = integers.reduce(0, Integer::sum);\n\n也有没有起始值的情况，这时会把 Stream 的前面两个元素组合起来，返回的是 Optional。\n\neg15. reduce 的用例\n```java\n// 字符串连接，concat = \"ABCD\"\nString concat = Stream.of(\"A\", \"B\", \"C\", \"D\").reduce(\"\", String::concat); \n// 求最小值，minValue = -3.0\ndouble minValue = Stream.of(-1.5, 1.0, -3.0, -2.0).reduce(Double.MAX_VALUE, Double::min); \n// 求和，sumValue = 10, 有起始值\nint sumValue = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum);\n// 求和，sumValue = 10, 无起始值\nsumValue = Stream.of(1, 2, 3, 4).reduce(Integer::sum).get();\n// 过滤，字符串连接，concat = \"ace\"\nconcat = Stream.of(\"a\", \"B\", \"c\", \"D\", \"e\", \"F\").\n    filter(x -> x.compareTo(\"Z\") > 0).\n    reduce(\"\", String::concat);\n```\n\n上面代码例如第一个示例的 reduce()，第一个参数（空白字符）即为起始值，第二个参数（String::concat）为 BinaryOperator。这类有起始值的 reduce() 都返回具体的对象。而对于第四个示例没有起始值的 reduce()，由于可能没有足够的元素，返回的是 Optional，请留意这个区别。\n\n### limit/skip\n\nlimit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来）。\n\neg16. limit 和 skip 对运行次数的影响\n```java        \npublic void testLimitAndSkip () {\n    List<Person> persons = new ArrayList();\n    for (int i = 1; i <= 10000; i++) {\n        Person person = new Person(i, \"name\" + i);\n        persons.add(person);\n    }\n    List<String> personList2 = persons.stream().\n            map(Person::getName).limit(10).skip(3).collect(Collectors.toList());\n    System.out.println(personList2);\n}\nprivate class Person {\n    public int no;\n    private String name;\n\n    public Person(int no, String name) {\n        this.no = no;\n        this.name = name;\n    }\n\n    public String getName() {\n        System.out.println(name);\n        return name;\n    }\n}\n```\n\n输出结果为：\n```java\nname1\nname2\nname3\nname4\nname5\nname6\nname7\nname8\nname9\nname10\n[name4, name5, name6, name7, name8, name9, name10]\n```\n这是一个有 10，000 个元素的 Stream，但在 short-circuiting 操作 limit 和 skip 的作用下，管道中 map 操作指定的 getName() 方法的执行次数为 limit 所限定的 10 次，而最终返回结果在跳过前 3 个元素后只有后面 7 个返回。\n\n有一种情况是 limit/skip 无法达到 short-circuiting 目的的，就是把它们放在 Stream 的排序操作后，原因跟 sorted 这个 intermediate 操作有关：此时系统并不知道 Stream 排序后的次序如何，所以 sorted 中的操作看上去就像完全没有被 limit 或者 skip 一样。\n\neg17. limit 和 skip 对 sorted 后的运行次数无影响\n```java\nList<Person> persons = new ArrayList();\nfor (int i = 1; i <= 5; i++) {\n    Person person = new Person(i, \"name\" + i);\n    persons.add(person);\n}\nList<Person> personList2 = persons.stream().sorted((p1, p2) ->\n    p1.getName().compareTo(p2.getName())).limit(2).collect(Collectors.toList());\nSystem.out.println(personList2);\n```\n\n上面的示例对清单 13 做了微调，首先对 5 个元素的 Stream 排序，然后进行 limit 操作。输出结果为：\n```java\nname2\nname1\nname3\nname2\nname4\nname3\nname5\nname4\n[stream.StreamDW$Person@816f27d, stream.StreamDW$Person@87aac27]\n```\n\n即虽然最后的返回元素数量是 2，但整个管道中的 sorted 表达式执行次数没有像前面例子相应减少。\n\n最后有一点需要注意的是，对一个 parallel 的 Steam 管道来说，如果其元素是有序的，那么 limit 操作的成本会比较大，因为它的返回对象必须是前 n 个也有一样次序的元素。取而代之的策略是取消元素间的次序，或者不要用 parallel Stream。\n\n### sorted\n\n对 Stream 的排序通过 sorted 进行，它比数组的排序更强之处在于你可以首先对 Stream 进行各类 map、filter、limit、skip 甚至 distinct 来减少元素数量后，再排序，这能帮助程序明显缩短执行时间。我们对清单 14 进行优化：\n\neg18. 优化：排序前进行 limit 和 skip\n```java\nList<Person> persons = new ArrayList();\nfor (int i = 1; i <= 5; i++) {\n    Person person = new Person(i, \"name\" + i);\n    persons.add(person);\n}\nList<Person> personList2 = persons.stream().limit(2).sorted((p1, p2) -> p1.getName().compareTo(p2.getName())).collect(Collectors.toList());\nSystem.out.println(personList2);\n```\n\n结果会简单很多：\n\n```java\nname2\nname1\n[stream.StreamDW$Person@6ce253f1, stream.StreamDW$Person@53d8d10a]\n```\n\n当然，这种优化是有 business logic 上的局限性的：即不要求排序后再取值。\n\n### min/max/distinct\n\nmin 和 max 的功能也可以通过对 Stream 元素先排序，再 findFirst 来实现，但前者的性能会更好，为 O(n)，而 sorted 的成本是 O(n log n)。同时它们作为特殊的 reduce 方法被独立出来也是因为求最大最小值是很常见的操作。\n\neg19. 找出最长一行的长度\n```java\nBufferedReader br = new BufferedReader(new FileReader(\"c:\\\\SUService.log\"));\nint longest = br.lines().\n    mapToInt(String::length).\n    max().\n    getAsInt();\nbr.close();\nSystem.out.println(longest);\n```\n\n下面的例子则使用 distinct 来找出不重复的单词。\n\neg20. 找出全文的单词，转小写，并排序\n```java\nList<String> words = br.lines().\nflatMap(line -> Stream.of(line.split(\" \"))).\nfilter(word -> word.length() > 0).\nmap(String::toLowerCase).\ndistinct().\nsorted().\ncollect(Collectors.toList());\nbr.close();\nSystem.out.println(words);\n```\n\n### Match\n\nStream 有三个 match 方法，从语义上说：\n\n* allMatch：Stream 中全部元素符合传入的 predicate，返回 true\n* anyMatch：Stream 中只要有一个元素符合传入的 predicate，返回 true\n* noneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true\n\n它们都不是要遍历全部元素才能返回结果。例如 allMatch 只要一个元素不满足条件，就 skip 剩下的所有元素，返回 false。对清单 13 中的 Person 类稍做修改，加入一个 age 属性和 getAge 方法。\n\neg21. 使用 Match\n```java\nList<Person> persons = new ArrayList();\npersons.add(new Person(1, \"name\" + 1, 10));\npersons.add(new Person(2, \"name\" + 2, 21));\npersons.add(new Person(3, \"name\" + 3, 34));\npersons.add(new Person(4, \"name\" + 4, 6));\npersons.add(new Person(5, \"name\" + 5, 55));\nboolean isAllAdult = persons.stream().allMatch(p -> p.getAge() > 18);\nSystem.out.println(\"All are adult? \" + isAllAdult);\nboolean isThereAnyChild = persons.stream().anyMatch(p -> p.getAge() < 12);\nSystem.out.println(\"Any child? \" + isThereAnyChild);\n```\n输出结果：\n```java\nAll are adult? false\nAny child? true\n```\n\n## 进阶：自己生成流\n\n### Stream.generate\n\n通过实现 Supplier 接口，你可以自己来控制流的生成。这种情形通常用于随机数、常量的 Stream，或者需要前后元素间维持着某种状态信息的 Stream。把 Supplier 实例传递给 Stream.generate() 生成的 Stream，默认是串行（相对 parallel 而言）但无序的（相对 ordered 而言）。由于它是无限的，在管道中，必须利用 limit 之类的操作限制 Stream 大小。\n\neg22. 生成 10 个随机整数\n```java\nRandom seed = new Random();\nSupplier<Integer> random = seed::nextInt;\nStream.generate(random).limit(10).forEach(System.out::println);\n//Another way\nIntStream.generate(() -> (int) (System.nanoTime() % 100)).\nlimit(10).forEach(System.out::println);\n```\n\nStream.generate() 还接受自己实现的 Supplier。例如在构造海量测试数据的时候，用某种自动的规则给每一个变量赋值；或者依据公式计算 Stream 的每个元素值。这些都是维持状态信息的情形。\n\neg23. 自实现 Supplier\n```java\nStream.generate(new PersonSupplier()).\n        limit(10).\n        forEach(p -> System.out.println(p.getName() + \", \" + p.getAge()));\nprivate class PersonSupplier implements Supplier<Person> {\n    private int index = 0;\n    private Random random = new Random();\n    @Override\n    public Person get() {\n        return new Person(index++, \"StormTestUser\" + index, random.nextInt(100));\n    }\n}\n```\n\n输出结果：\n```java\nStormTestUser1, 9\nStormTestUser2, 12\nStormTestUser3, 88\nStormTestUser4, 51\nStormTestUser5, 22\nStormTestUser6, 28\nStormTestUser7, 81\nStormTestUser8, 51\nStormTestUser9, 4\nStormTestUser10, 76\n```\n\n### Stream.iterate\n\niterate 跟 reduce 操作很像，接受一个种子值，和一个 UnaryOperator（例如 f）。然后种子值成为 Stream 的第一个元素，f(seed) 为第二个，f(f(seed)) 第三个，以此类推。\n\neg24. 生成一个等差数列\n```java\nStream.iterate(0, n -> n + 3).limit(10). forEach(x -> System.out.print(x + \" \"));\n```\n\n输出结果：\n```java\n0 3 6 9 12 15 18 21 24 27\n```\n\n与 Stream.generate 相仿，在 iterate 时候管道必须有 limit 这样的操作来限制 Stream 大小。\n\n## 进阶：用 Collectors 来进行 reduction 操作\n\njava.util.stream.Collectors 类的主要作用就是辅助进行各类有用的 reduction 操作，例如转变输出为 Collection，把 Stream 元素进行归组。\n\n### groupingBy/partitioningBy\n\neg25. 按照年龄归组\n```java\nMap<Integer, List<Person>> personGroups = Stream.generate(new PersonSupplier()).\n        limit(100).\n        collect(Collectors.groupingBy(Person::getAge));\nIterator it = personGroups.entrySet().iterator();\nwhile (it.hasNext()) {\n    Map.Entry<Integer, List<Person>> persons = (Map.Entry) it.next();\n    System.out.println(\"Age \" + persons.getKey() + \" = \" + persons.getValue().size());\n}\n```\n\n上面的 code，首先生成 100 人的信息，然后按照年龄归组，相同年龄的人放到同一个 list 中，可以看到如下的输出：\n\n```java\nAge 0 = 2\nAge 1 = 2\nAge 5 = 2\nAge 8 = 1\nAge 9 = 1\nAge 11 = 2\n……\n```\n\neg26. 按照未成年人和成年人归组\n```java\nMap<Boolean, List<Person>> children = Stream.generate(new PersonSupplier()).\n    limit(100).\n    collect(Collectors.partitioningBy(p -> p.getAge() < 18));\nSystem.out.println(\"Children number: \" + children.get(true).size());\nSystem.out.println(\"Adult number: \" + children.get(false).size());\n```\n\n输出结果：\n\n```java\nChildren number: 23 \nAdult number: 77\n```\n\n在使用条件“年龄小于 18”进行分组后可以看到，不到 18 岁的未成年人是一组，成年人是另外一组。partitioningBy 其实是一种特殊的 groupingBy，它依照条件测试的是否两种结果来构造返回的数据结构，get(true) 和 get(false) 能即为全部的元素对象。\n\n# 结束语\n\n总之，Stream 的特性可以归纳为：\n\n* 不是数据结构\n\n    它没有内部存储，它只是用操作管道从 source（数据结构、数组、generator function、IO channel）抓取数据。\n\n    它也绝不修改自己所封装的底层数据结构的数据。例如 Stream 的 filter 操作会产生一个不包含被过滤元素的新 Stream，而不是从 source 删除那些元素。\n\n* 所有 Stream 的操作必须以 lambda 表达式为参数\n\n* 不支持索引访问\n\n    你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。不过请参阅下一项。\n\n* 很容易生成数组或者 List\n\n* 惰性化\n\n    很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。\n\n    Intermediate 操作永远是惰性化的。\n\n* 并行能力\n\n    当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的。\n\n* 可以是无限的\n\n    集合有固定大小，Stream 则不必。limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。","source":"_posts/Stream.md","raw":"---\ntitle: Stream\ndate: 2018-11-19 10:53:00\ntags: Java\ncategories: Java\n---\n\n>最近在学习JAVA8 Stream的API，找到了这篇文章，觉得内容很好就抄了过来，文章来源：https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/\n\n# 为什么需要 Stream\n\nStream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。它也不同于 StAX 对 XML 解析的 Stream，也不是 Amazon Kinesis 对大数据实时处理的 Stream。Java 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。所以说，Java 8 中首次出现的 java.util.stream 是一个函数式语言+多核时代综合影响的产物。\n\n<!-- more -->\n\n## 什么是聚合操作\n\n在传统的 J2EE 应用中，Java 代码经常不得不依赖于关系型数据库的聚合操作来完成诸如：\n* 客户每月平均消费金额\n* 最昂贵的在售商品\n* 本周完成的有效订单（排除了无效的）\n* 取十个数据样本作为首页推荐\n\n但在当今这个数据大爆炸的时代，在数据来源多样化、数据海量化的今天，很多时候不得不脱离 RDBMS，或者以底层返回的数据为基础进行更上层的数据统计。而 Java 的集合 API 中，仅仅有极少量的辅助型方法，更多的时候是程序员需要用 Iterator 来遍历集合，完成相关的聚合应用逻辑。这是一种远不够高效、笨拙的方法。在 Java 7 中，如果要发现 type 为 grocery 的所有交易，然后返回以交易值降序排序好的交易 ID 集合，我们需要这样写：\n\neg1. Java 7 的排序、取值实现\n```java\nList<Transaction> groceryTransactions = new Arraylist<>();\nfor (Transaction t : transactions) {\n    if (t.getType() == Transaction.GROCERY) {\n        groceryTransactions.add(t);\n    }\n}\nCollections.sort(groceryTransactions, new Comparator() {\n    public int compare(Transaction t1, Transaction t2) {\n        return t2.getValue().compareTo(t1.getValue());\n    }\n});\nList<Integer> transactionIds = new ArrayList<>();\nfor (Transaction t : groceryTransactions) {\n    transactionsIds.add(t.getId());\n}\n```\n\n而在 Java 8 使用 Stream，代码更加简洁易读；而且使用并发模式，程序执行速度更快。\n\neg2. Java 8 的排序、取值实现\n```java\nList<Integer> transactionsIds = transactions.parallelStream().\n    filter(t -> t.getType() == Transaction.GROCERY).\n    sorted(comparing(Transaction::getValue).reversed()).\n    map(Transaction::getId).\n    collect(toList());\n```\n\n# Stream 总览\n\n## 什么是流\n\nStream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，比如 “过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。\n\nStream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。\n\n而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架（JSR166y）来拆分任务和加速处理过程。Java 的并行 API 演变历程基本如下：\n\n1. 1.0-1.4 中的 java.lang.Thread\n2. 5.0 中的 java.util.concurrent\n3. 6.0 中的 Phasers 等\n4. 7.0 中的 Fork/Join 框架\n5. 8.0 中的 Lambda\n\nStream 的另外一大特点是，数据源本身可以是无限的。\n\n## 流的构成\n\n当我们使用一个流的时候，通常包括三个基本步骤：\n\n获取一个数据源（source）→ 数据转换→执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道，如下图所示。\n\n流管道 (Stream Pipeline) 的构成\n\n![StreamPipeline-photo](https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/img001.png)\n\n### 有多种方式生成 Stream Source：\n\n#### 从 Collection 和数组\n\n* Collection.stream()\n* Collection.parallelStream()\n* Arrays.stream(T array) or Stream.of()\n\n#### 从 BufferedReader\n\n* java.io.BufferedReader.lines()\n\n#### 静态工厂\n\n* java.util.stream.IntStream.range()\n* java.nio.file.Files.walk()\n\n#### 自己构建\n\n* java.util.Spliterator\n\n#### 其它\n\n* Random.ints()\n* BitSet.stream()\n* Pattern.splitAsStream(java.lang.CharSequence)\n* JarFile.stream()\n\n### 流的操作类型分为两种：\n\n* ***Intermediate***：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。\n\n* ***Terminal***：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。\n\n在对于一个 Stream 进行多次转换操作 (Intermediate 操作)，每次都对 Stream 的每个元素进行转换，而且是执行多次，这样时间复杂度就是 N（转换次数）个 for 循环里把所有操作都做掉的总和吗？其实不是这样的，转换操作都是 lazy 的，多个转换操作只会在 Terminal 操作的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream 里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在 Terminal 操作的时候循环 Stream 对应的集合，然后对每个元素执行所有的函数。\n\n还有一种操作被称为 ***short-circuiting***。用以指：\n\n* 对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。\n* 对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。\n\n当操作一个无限大的 Stream，而又希望在有限时间内完成操作，则在管道内拥有一个 short-circuiting 操作是必要非充分条件。\n\neg3. 一个流操作的示例\n```java\nint sum = widgets.stream()\n    .filter(w -> w.getColor() == RED)\n    .mapToInt(w -> w.getWeight())\n    .sum();\n```\n\nstream() 获取当前小物件的 source，filter 和 mapToInt 为 intermediate 操作，进行数据筛选和转换，最后一个 sum() 为 terminal 操作，对符合条件的全部小物件作重量求和。\n\n# 流的使用详解\n\n简单说，对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果，或者导致一个副作用（side effect）。\n\n## 流的构造与转换\n\n下面提供最常见的几种构造 Stream 的样例。\n\neg4. 构造流的几种常见方法\n```java\n// 1. Individual values\nStream stream = Stream.of(\"a\", \"b\", \"c\");\n// 2. Arrays\nString [] strArray = new String[] {\"a\", \"b\", \"c\"};\nstream = Stream.of(strArray);\nstream = Arrays.stream(strArray);\n// 3. Collections\nList<String> list = Arrays.asList(strArray);\nstream = list.stream();\n```\n\n需要注意的是，对于基本数值型，目前有三种对应的包装类型 Stream：\n\nIntStream、LongStream、DoubleStream。当然我们也可以用 Stream<Integer>、Stream<Long> >、Stream<Double>，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。\n\nJava 8 中还没有提供其它数值型 Stream，因为这将导致扩增的内容较多。而常规的数值型聚合运算可以通过上面三种 Stream 进行。\n\neg5. 数值流的构造\n```java\nIntStream.of(new int[]{1, 2, 3}).forEach(System.out::println);\nIntStream.range(1, 3).forEach(System.out::println);\nIntStream.rangeClosed(1, 3).forEach(System.out::println);\n```\n\neg6. 流转换为其它数据结构\n```java\n// 1. Array\nString[] strArray1 = stream.toArray(String[]::new);\n// 2. Collection\nList<String> list1 = stream.collect(Collectors.toList());\nList<String> list2 = stream.collect(Collectors.toCollection(ArrayList::new));\nSet set1 = stream.collect(Collectors.toSet());\nStack stack1 = stream.collect(Collectors.toCollection(Stack::new));\n// 3. String\nString str = stream.collect(Collectors.joining()).toString();\n```\n\n一个 Stream 只可以使用一次，上面的代码为了简洁而重复使用了数次。\n\n## 流的操作\n\n接下来，当把一个数据结构包装成 Stream 后，就要开始对里面的元素进行各类操作了。常见的操作可以归类如下。\n\n* Intermediate：\n\n    map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered\n\n* Terminal：\n\n    forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator\n\n* Short-circuiting：\n\n    anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit\n\n### map/flatMap\n\n我们先来看 map。如果你熟悉 scala 这类函数式语言，对这个方法应该很了解，它的作用就是把 input Stream 的每一个元素，映射成 output Stream 的另外一个元素。\n\neg7. 转换大写\n```java\nList<String> output = wordList.stream().\nmap(String::toUpperCase).\ncollect(Collectors.toList());\n```\n\n这段代码把所有的单词转换为大写。\n\neg8. 平方数\n```java\nList<Integer> nums = Arrays.asList(1, 2, 3, 4);\nList<Integer> squareNums = nums.stream().\nmap(n -> n * n).\ncollect(Collectors.toList());\n```\n\n这段代码生成一个整数 list 的平方数 {1, 4, 9, 16}。\n\n从上面例子可以看出，map 生成的是个 1:1 映射，每个输入元素，都按照规则转换成为另外一个元素。还有一些场景，是一对多映射关系的，这时需要 flatMap。\n\neg9. 一对多\n```java\nStream<List<Integer>> inputStream = Stream.of(\n Arrays.asList(1),\n Arrays.asList(2, 3),\n Arrays.asList(4, 5, 6)\n );\nStream<Integer> outputStream = inputStream.\nflatMap((childList) -> childList.stream());\n```\n\nflatMap 把 input Stream 中的层级结构扁平化，就是将最底层元素抽出来放到一起，最终 output 的新 Stream 里面已经没有 List 了，都是直接的数字。\n\n### filter\n\nfilter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream。\n\neg10. 留下偶数\n```java\nInteger[] sixNums = {1, 2, 3, 4, 5, 6};\nInteger[] evens =\nStream.of(sixNums).filter(n -> n%2 == 0).toArray(Integer[]::new);\n```\n\n经过条件“被 2 整除”的 filter，剩下的数字为 {2, 4, 6}。\n\neg11. 把单词挑出来\n```java\nList<String> output = reader.lines().\n    flatMap(line -> Stream.of(line.split(REGEXP))).\n    filter(word -> word.length() > 0).\n    collect(Collectors.toList());\n```\n\n这段代码首先把每行的单词用 flatMap 整理到新的 Stream，然后保留长度不为 0 的，就是整篇文章中的全部单词了。\n\n\n### forEach\n\nforEach 方法接收一个 Lambda 表达式，然后在 Stream 的每一个元素上执行该表达式。\n\neg12. 打印姓名（forEach 和 pre-java8 的对比）\n```java\n// Java 8\nroster.stream()\n    .filter(p -> p.getGender() == Person.Sex.MALE)\n    .forEach(p -> System.out.println(p.getName()));\n// Pre-Java 8\nfor (Person p : roster) {\n    if (p.getGender() == Person.Sex.MALE) {\n        System.out.println(p.getName());\n    }\n}\n```\n对一个人员集合遍历，找出男性并打印姓名。可以看出来，forEach 是为 Lambda 而设计的，保持了最紧凑的风格。而且 Lambda 表达式本身是可以重用的，非常方便。当需要为多核系统优化时，可以 parallelStream().forEach()，只是此时原有元素的次序没法保证，并行的情况下将改变串行时操作的行为，此时 forEach 本身的实现不需要调整，而 Java8 以前的 for 循环 code 可能需要加入额外的多线程逻辑。\n\n但一般认为，forEach 和常规 for 循环的差异不涉及到性能，它们仅仅是函数式风格与传统 Java 风格的差别。\n\n另外一点需要注意，forEach 是 terminal 操作，因此它执行后，Stream 的元素就被“消费”掉了，你无法对一个 Stream 进行两次 terminal 运算。下面的代码是错误的：\n\n```java\nstream.forEach(element -> doOneThing(element));\nstream.forEa\nch(element -> doAnotherThing(element));\n```\n\n相反，具有相似功能的 intermediate 操作 peek 可以达到上述目的。如下是出现在该 api javadoc 上的一个示例。\n\neg13. peek 对每个元素执行操作并返回一个新的 Stream\n```java\nStream.of(\"one\", \"two\", \"three\", \"four\")\n    .filter(e -> e.length() > 3)\n    .peek(e -> System.out.println(\"Filtered value: \" + e))\n    .map(String::toUpperCase)\n    .peek(e -> System.out.println(\"Mapped value: \" + e))\n    .collect(Collectors.toList());\n ```\n\nforEach 不能修改自己包含的本地变量值，也不能用 break/return 之类的关键字提前结束循环。\n\n### findFirst\n\n这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。\n\n这里比较重点的是它的返回值类型：Optional。这也是一个模仿 Scala 语言中的概念，作为一个容器，它可能含有某值，或者不包含。使用它的目的是尽可能避免 NullPointerException。\n\neg14. Optional 的两个用例\n```java\nString strA = \" abcd \", strB = null;\nprint(strA);\nprint(\"\");\nprint(strB);\ngetLength(strA);\ngetLength(\"\");\ngetLength(strB);\npublic static void print(String text) {\n    // Java 8\n    Optional.ofNullable(text).ifPresent(System.out::println);\n    // Pre-Java 8\n    if (text != null) {\n        System.out.println(text);\n    }\n }\npublic static int getLength(String text) {\n    // Java 8\n    return Optional.ofNullable(text).map(String::length).orElse(-1);\n    // Pre-Java 8\n    // return if (text != null) ? text.length() : -1;\n};\n```\n在更复杂的 if (xx != null) 的情况中，使用 Optional 代码的可读性更好，而且它提供的是编译时检查，能极大的降低 NPE 这种 Runtime Exception 对程序的影响，或者迫使程序员更早的在编码阶段处理空值问题，而不是留到运行时再发现和调试。\n\nStream 中的 findAny、max/min、reduce 等方法等返回 Optional 值。还有例如 IntStream.average() 返回 OptionalDouble 等等。\n\n### reduce\n\n这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。例如 Stream 的 sum 就相当于\n\nInteger sum = integers.reduce(0, (a, b) -> a+b); 或\n\nInteger sum = integers.reduce(0, Integer::sum);\n\n也有没有起始值的情况，这时会把 Stream 的前面两个元素组合起来，返回的是 Optional。\n\neg15. reduce 的用例\n```java\n// 字符串连接，concat = \"ABCD\"\nString concat = Stream.of(\"A\", \"B\", \"C\", \"D\").reduce(\"\", String::concat); \n// 求最小值，minValue = -3.0\ndouble minValue = Stream.of(-1.5, 1.0, -3.0, -2.0).reduce(Double.MAX_VALUE, Double::min); \n// 求和，sumValue = 10, 有起始值\nint sumValue = Stream.of(1, 2, 3, 4).reduce(0, Integer::sum);\n// 求和，sumValue = 10, 无起始值\nsumValue = Stream.of(1, 2, 3, 4).reduce(Integer::sum).get();\n// 过滤，字符串连接，concat = \"ace\"\nconcat = Stream.of(\"a\", \"B\", \"c\", \"D\", \"e\", \"F\").\n    filter(x -> x.compareTo(\"Z\") > 0).\n    reduce(\"\", String::concat);\n```\n\n上面代码例如第一个示例的 reduce()，第一个参数（空白字符）即为起始值，第二个参数（String::concat）为 BinaryOperator。这类有起始值的 reduce() 都返回具体的对象。而对于第四个示例没有起始值的 reduce()，由于可能没有足够的元素，返回的是 Optional，请留意这个区别。\n\n### limit/skip\n\nlimit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来）。\n\neg16. limit 和 skip 对运行次数的影响\n```java        \npublic void testLimitAndSkip () {\n    List<Person> persons = new ArrayList();\n    for (int i = 1; i <= 10000; i++) {\n        Person person = new Person(i, \"name\" + i);\n        persons.add(person);\n    }\n    List<String> personList2 = persons.stream().\n            map(Person::getName).limit(10).skip(3).collect(Collectors.toList());\n    System.out.println(personList2);\n}\nprivate class Person {\n    public int no;\n    private String name;\n\n    public Person(int no, String name) {\n        this.no = no;\n        this.name = name;\n    }\n\n    public String getName() {\n        System.out.println(name);\n        return name;\n    }\n}\n```\n\n输出结果为：\n```java\nname1\nname2\nname3\nname4\nname5\nname6\nname7\nname8\nname9\nname10\n[name4, name5, name6, name7, name8, name9, name10]\n```\n这是一个有 10，000 个元素的 Stream，但在 short-circuiting 操作 limit 和 skip 的作用下，管道中 map 操作指定的 getName() 方法的执行次数为 limit 所限定的 10 次，而最终返回结果在跳过前 3 个元素后只有后面 7 个返回。\n\n有一种情况是 limit/skip 无法达到 short-circuiting 目的的，就是把它们放在 Stream 的排序操作后，原因跟 sorted 这个 intermediate 操作有关：此时系统并不知道 Stream 排序后的次序如何，所以 sorted 中的操作看上去就像完全没有被 limit 或者 skip 一样。\n\neg17. limit 和 skip 对 sorted 后的运行次数无影响\n```java\nList<Person> persons = new ArrayList();\nfor (int i = 1; i <= 5; i++) {\n    Person person = new Person(i, \"name\" + i);\n    persons.add(person);\n}\nList<Person> personList2 = persons.stream().sorted((p1, p2) ->\n    p1.getName().compareTo(p2.getName())).limit(2).collect(Collectors.toList());\nSystem.out.println(personList2);\n```\n\n上面的示例对清单 13 做了微调，首先对 5 个元素的 Stream 排序，然后进行 limit 操作。输出结果为：\n```java\nname2\nname1\nname3\nname2\nname4\nname3\nname5\nname4\n[stream.StreamDW$Person@816f27d, stream.StreamDW$Person@87aac27]\n```\n\n即虽然最后的返回元素数量是 2，但整个管道中的 sorted 表达式执行次数没有像前面例子相应减少。\n\n最后有一点需要注意的是，对一个 parallel 的 Steam 管道来说，如果其元素是有序的，那么 limit 操作的成本会比较大，因为它的返回对象必须是前 n 个也有一样次序的元素。取而代之的策略是取消元素间的次序，或者不要用 parallel Stream。\n\n### sorted\n\n对 Stream 的排序通过 sorted 进行，它比数组的排序更强之处在于你可以首先对 Stream 进行各类 map、filter、limit、skip 甚至 distinct 来减少元素数量后，再排序，这能帮助程序明显缩短执行时间。我们对清单 14 进行优化：\n\neg18. 优化：排序前进行 limit 和 skip\n```java\nList<Person> persons = new ArrayList();\nfor (int i = 1; i <= 5; i++) {\n    Person person = new Person(i, \"name\" + i);\n    persons.add(person);\n}\nList<Person> personList2 = persons.stream().limit(2).sorted((p1, p2) -> p1.getName().compareTo(p2.getName())).collect(Collectors.toList());\nSystem.out.println(personList2);\n```\n\n结果会简单很多：\n\n```java\nname2\nname1\n[stream.StreamDW$Person@6ce253f1, stream.StreamDW$Person@53d8d10a]\n```\n\n当然，这种优化是有 business logic 上的局限性的：即不要求排序后再取值。\n\n### min/max/distinct\n\nmin 和 max 的功能也可以通过对 Stream 元素先排序，再 findFirst 来实现，但前者的性能会更好，为 O(n)，而 sorted 的成本是 O(n log n)。同时它们作为特殊的 reduce 方法被独立出来也是因为求最大最小值是很常见的操作。\n\neg19. 找出最长一行的长度\n```java\nBufferedReader br = new BufferedReader(new FileReader(\"c:\\\\SUService.log\"));\nint longest = br.lines().\n    mapToInt(String::length).\n    max().\n    getAsInt();\nbr.close();\nSystem.out.println(longest);\n```\n\n下面的例子则使用 distinct 来找出不重复的单词。\n\neg20. 找出全文的单词，转小写，并排序\n```java\nList<String> words = br.lines().\nflatMap(line -> Stream.of(line.split(\" \"))).\nfilter(word -> word.length() > 0).\nmap(String::toLowerCase).\ndistinct().\nsorted().\ncollect(Collectors.toList());\nbr.close();\nSystem.out.println(words);\n```\n\n### Match\n\nStream 有三个 match 方法，从语义上说：\n\n* allMatch：Stream 中全部元素符合传入的 predicate，返回 true\n* anyMatch：Stream 中只要有一个元素符合传入的 predicate，返回 true\n* noneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true\n\n它们都不是要遍历全部元素才能返回结果。例如 allMatch 只要一个元素不满足条件，就 skip 剩下的所有元素，返回 false。对清单 13 中的 Person 类稍做修改，加入一个 age 属性和 getAge 方法。\n\neg21. 使用 Match\n```java\nList<Person> persons = new ArrayList();\npersons.add(new Person(1, \"name\" + 1, 10));\npersons.add(new Person(2, \"name\" + 2, 21));\npersons.add(new Person(3, \"name\" + 3, 34));\npersons.add(new Person(4, \"name\" + 4, 6));\npersons.add(new Person(5, \"name\" + 5, 55));\nboolean isAllAdult = persons.stream().allMatch(p -> p.getAge() > 18);\nSystem.out.println(\"All are adult? \" + isAllAdult);\nboolean isThereAnyChild = persons.stream().anyMatch(p -> p.getAge() < 12);\nSystem.out.println(\"Any child? \" + isThereAnyChild);\n```\n输出结果：\n```java\nAll are adult? false\nAny child? true\n```\n\n## 进阶：自己生成流\n\n### Stream.generate\n\n通过实现 Supplier 接口，你可以自己来控制流的生成。这种情形通常用于随机数、常量的 Stream，或者需要前后元素间维持着某种状态信息的 Stream。把 Supplier 实例传递给 Stream.generate() 生成的 Stream，默认是串行（相对 parallel 而言）但无序的（相对 ordered 而言）。由于它是无限的，在管道中，必须利用 limit 之类的操作限制 Stream 大小。\n\neg22. 生成 10 个随机整数\n```java\nRandom seed = new Random();\nSupplier<Integer> random = seed::nextInt;\nStream.generate(random).limit(10).forEach(System.out::println);\n//Another way\nIntStream.generate(() -> (int) (System.nanoTime() % 100)).\nlimit(10).forEach(System.out::println);\n```\n\nStream.generate() 还接受自己实现的 Supplier。例如在构造海量测试数据的时候，用某种自动的规则给每一个变量赋值；或者依据公式计算 Stream 的每个元素值。这些都是维持状态信息的情形。\n\neg23. 自实现 Supplier\n```java\nStream.generate(new PersonSupplier()).\n        limit(10).\n        forEach(p -> System.out.println(p.getName() + \", \" + p.getAge()));\nprivate class PersonSupplier implements Supplier<Person> {\n    private int index = 0;\n    private Random random = new Random();\n    @Override\n    public Person get() {\n        return new Person(index++, \"StormTestUser\" + index, random.nextInt(100));\n    }\n}\n```\n\n输出结果：\n```java\nStormTestUser1, 9\nStormTestUser2, 12\nStormTestUser3, 88\nStormTestUser4, 51\nStormTestUser5, 22\nStormTestUser6, 28\nStormTestUser7, 81\nStormTestUser8, 51\nStormTestUser9, 4\nStormTestUser10, 76\n```\n\n### Stream.iterate\n\niterate 跟 reduce 操作很像，接受一个种子值，和一个 UnaryOperator（例如 f）。然后种子值成为 Stream 的第一个元素，f(seed) 为第二个，f(f(seed)) 第三个，以此类推。\n\neg24. 生成一个等差数列\n```java\nStream.iterate(0, n -> n + 3).limit(10). forEach(x -> System.out.print(x + \" \"));\n```\n\n输出结果：\n```java\n0 3 6 9 12 15 18 21 24 27\n```\n\n与 Stream.generate 相仿，在 iterate 时候管道必须有 limit 这样的操作来限制 Stream 大小。\n\n## 进阶：用 Collectors 来进行 reduction 操作\n\njava.util.stream.Collectors 类的主要作用就是辅助进行各类有用的 reduction 操作，例如转变输出为 Collection，把 Stream 元素进行归组。\n\n### groupingBy/partitioningBy\n\neg25. 按照年龄归组\n```java\nMap<Integer, List<Person>> personGroups = Stream.generate(new PersonSupplier()).\n        limit(100).\n        collect(Collectors.groupingBy(Person::getAge));\nIterator it = personGroups.entrySet().iterator();\nwhile (it.hasNext()) {\n    Map.Entry<Integer, List<Person>> persons = (Map.Entry) it.next();\n    System.out.println(\"Age \" + persons.getKey() + \" = \" + persons.getValue().size());\n}\n```\n\n上面的 code，首先生成 100 人的信息，然后按照年龄归组，相同年龄的人放到同一个 list 中，可以看到如下的输出：\n\n```java\nAge 0 = 2\nAge 1 = 2\nAge 5 = 2\nAge 8 = 1\nAge 9 = 1\nAge 11 = 2\n……\n```\n\neg26. 按照未成年人和成年人归组\n```java\nMap<Boolean, List<Person>> children = Stream.generate(new PersonSupplier()).\n    limit(100).\n    collect(Collectors.partitioningBy(p -> p.getAge() < 18));\nSystem.out.println(\"Children number: \" + children.get(true).size());\nSystem.out.println(\"Adult number: \" + children.get(false).size());\n```\n\n输出结果：\n\n```java\nChildren number: 23 \nAdult number: 77\n```\n\n在使用条件“年龄小于 18”进行分组后可以看到，不到 18 岁的未成年人是一组，成年人是另外一组。partitioningBy 其实是一种特殊的 groupingBy，它依照条件测试的是否两种结果来构造返回的数据结构，get(true) 和 get(false) 能即为全部的元素对象。\n\n# 结束语\n\n总之，Stream 的特性可以归纳为：\n\n* 不是数据结构\n\n    它没有内部存储，它只是用操作管道从 source（数据结构、数组、generator function、IO channel）抓取数据。\n\n    它也绝不修改自己所封装的底层数据结构的数据。例如 Stream 的 filter 操作会产生一个不包含被过滤元素的新 Stream，而不是从 source 删除那些元素。\n\n* 所有 Stream 的操作必须以 lambda 表达式为参数\n\n* 不支持索引访问\n\n    你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。不过请参阅下一项。\n\n* 很容易生成数组或者 List\n\n* 惰性化\n\n    很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。\n\n    Intermediate 操作永远是惰性化的。\n\n* 并行能力\n\n    当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的。\n\n* 可以是无限的\n\n    集合有固定大小，Stream 则不必。limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。","slug":"Stream","published":1,"updated":"2019-08-26T07:53:06.518Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckahwzl8p005vqotn9wuacnc9","content":"<blockquote>\n<p>最近在学习JAVA8 Stream的API，找到了这篇文章，觉得内容很好就抄了过来，文章来源：<a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/</a></p>\n</blockquote>\n<h1 id=\"为什么需要-Stream\"><a href=\"#为什么需要-Stream\" class=\"headerlink\" title=\"为什么需要 Stream\"></a>为什么需要 Stream</h1><p>Stream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。它也不同于 StAX 对 XML 解析的 Stream，也不是 Amazon Kinesis 对大数据实时处理的 Stream。Java 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。所以说，Java 8 中首次出现的 java.util.stream 是一个函数式语言+多核时代综合影响的产物。</p>\n<a id=\"more\"></a>\n<h2 id=\"什么是聚合操作\"><a href=\"#什么是聚合操作\" class=\"headerlink\" title=\"什么是聚合操作\"></a>什么是聚合操作</h2><p>在传统的 J2EE 应用中，Java 代码经常不得不依赖于关系型数据库的聚合操作来完成诸如：</p>\n<ul>\n<li>客户每月平均消费金额</li>\n<li>最昂贵的在售商品</li>\n<li>本周完成的有效订单（排除了无效的）</li>\n<li>取十个数据样本作为首页推荐</li>\n</ul>\n<p>但在当今这个数据大爆炸的时代，在数据来源多样化、数据海量化的今天，很多时候不得不脱离 RDBMS，或者以底层返回的数据为基础进行更上层的数据统计。而 Java 的集合 API 中，仅仅有极少量的辅助型方法，更多的时候是程序员需要用 Iterator 来遍历集合，完成相关的聚合应用逻辑。这是一种远不够高效、笨拙的方法。在 Java 7 中，如果要发现 type 为 grocery 的所有交易，然后返回以交易值降序排序好的交易 ID 集合，我们需要这样写：</p>\n<p>eg1. Java 7 的排序、取值实现<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Transaction&gt; groceryTransactions = <span class=\"keyword\">new</span> Arraylist&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (Transaction t : transactions) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (t.getType() == Transaction.GROCERY) &#123;</span><br><span class=\"line\">        groceryTransactions.add(t);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">Collections.sort(groceryTransactions, <span class=\"keyword\">new</span> Comparator() &#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">compare</span><span class=\"params\">(Transaction t1, Transaction t2)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> t2.getValue().compareTo(t1.getValue());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">List&lt;Integer&gt; transactionIds = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (Transaction t : groceryTransactions) &#123;</span><br><span class=\"line\">    transactionsIds.add(t.getId());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>而在 Java 8 使用 Stream，代码更加简洁易读；而且使用并发模式，程序执行速度更快。</p>\n<p>eg2. Java 8 的排序、取值实现<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Integer&gt; transactionsIds = transactions.parallelStream().</span><br><span class=\"line\">    filter(t -&gt; t.getType() == Transaction.GROCERY).</span><br><span class=\"line\">    sorted(comparing(Transaction::getValue).reversed()).</span><br><span class=\"line\">    map(Transaction::getId).</span><br><span class=\"line\">    collect(toList());</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Stream-总览\"><a href=\"#Stream-总览\" class=\"headerlink\" title=\"Stream 总览\"></a>Stream 总览</h1><h2 id=\"什么是流\"><a href=\"#什么是流\" class=\"headerlink\" title=\"什么是流\"></a>什么是流</h2><p>Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，比如 “过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。</p>\n<p>Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。</p>\n<p>而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架（JSR166y）来拆分任务和加速处理过程。Java 的并行 API 演变历程基本如下：</p>\n<ol>\n<li>1.0-1.4 中的 java.lang.Thread</li>\n<li>5.0 中的 java.util.concurrent</li>\n<li>6.0 中的 Phasers 等</li>\n<li>7.0 中的 Fork/Join 框架</li>\n<li>8.0 中的 Lambda</li>\n</ol>\n<p>Stream 的另外一大特点是，数据源本身可以是无限的。</p>\n<h2 id=\"流的构成\"><a href=\"#流的构成\" class=\"headerlink\" title=\"流的构成\"></a>流的构成</h2><p>当我们使用一个流的时候，通常包括三个基本步骤：</p>\n<p>获取一个数据源（source）→ 数据转换→执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道，如下图所示。</p>\n<p>流管道 (Stream Pipeline) 的构成</p>\n<p><img src=\"https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/img001.png\" alt=\"StreamPipeline-photo\"></p>\n<h3 id=\"有多种方式生成-Stream-Source：\"><a href=\"#有多种方式生成-Stream-Source：\" class=\"headerlink\" title=\"有多种方式生成 Stream Source：\"></a>有多种方式生成 Stream Source：</h3><h4 id=\"从-Collection-和数组\"><a href=\"#从-Collection-和数组\" class=\"headerlink\" title=\"从 Collection 和数组\"></a>从 Collection 和数组</h4><ul>\n<li>Collection.stream()</li>\n<li>Collection.parallelStream()</li>\n<li>Arrays.stream(T array) or Stream.of()</li>\n</ul>\n<h4 id=\"从-BufferedReader\"><a href=\"#从-BufferedReader\" class=\"headerlink\" title=\"从 BufferedReader\"></a>从 BufferedReader</h4><ul>\n<li>java.io.BufferedReader.lines()</li>\n</ul>\n<h4 id=\"静态工厂\"><a href=\"#静态工厂\" class=\"headerlink\" title=\"静态工厂\"></a>静态工厂</h4><ul>\n<li>java.util.stream.IntStream.range()</li>\n<li>java.nio.file.Files.walk()</li>\n</ul>\n<h4 id=\"自己构建\"><a href=\"#自己构建\" class=\"headerlink\" title=\"自己构建\"></a>自己构建</h4><ul>\n<li>java.util.Spliterator</li>\n</ul>\n<h4 id=\"其它\"><a href=\"#其它\" class=\"headerlink\" title=\"其它\"></a>其它</h4><ul>\n<li>Random.ints()</li>\n<li>BitSet.stream()</li>\n<li>Pattern.splitAsStream(java.lang.CharSequence)</li>\n<li>JarFile.stream()</li>\n</ul>\n<h3 id=\"流的操作类型分为两种：\"><a href=\"#流的操作类型分为两种：\" class=\"headerlink\" title=\"流的操作类型分为两种：\"></a>流的操作类型分为两种：</h3><ul>\n<li><p><strong><em>Intermediate</em></strong>：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。</p>\n</li>\n<li><p><strong><em>Terminal</em></strong>：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。</p>\n</li>\n</ul>\n<p>在对于一个 Stream 进行多次转换操作 (Intermediate 操作)，每次都对 Stream 的每个元素进行转换，而且是执行多次，这样时间复杂度就是 N（转换次数）个 for 循环里把所有操作都做掉的总和吗？其实不是这样的，转换操作都是 lazy 的，多个转换操作只会在 Terminal 操作的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream 里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在 Terminal 操作的时候循环 Stream 对应的集合，然后对每个元素执行所有的函数。</p>\n<p>还有一种操作被称为 <strong><em>short-circuiting</em></strong>。用以指：</p>\n<ul>\n<li>对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。</li>\n<li>对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。</li>\n</ul>\n<p>当操作一个无限大的 Stream，而又希望在有限时间内完成操作，则在管道内拥有一个 short-circuiting 操作是必要非充分条件。</p>\n<p>eg3. 一个流操作的示例<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> sum = widgets.stream()</span><br><span class=\"line\">    .filter(w -&gt; w.getColor() == RED)</span><br><span class=\"line\">    .mapToInt(w -&gt; w.getWeight())</span><br><span class=\"line\">    .sum();</span><br></pre></td></tr></table></figure></p>\n<p>stream() 获取当前小物件的 source，filter 和 mapToInt 为 intermediate 操作，进行数据筛选和转换，最后一个 sum() 为 terminal 操作，对符合条件的全部小物件作重量求和。</p>\n<h1 id=\"流的使用详解\"><a href=\"#流的使用详解\" class=\"headerlink\" title=\"流的使用详解\"></a>流的使用详解</h1><p>简单说，对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果，或者导致一个副作用（side effect）。</p>\n<h2 id=\"流的构造与转换\"><a href=\"#流的构造与转换\" class=\"headerlink\" title=\"流的构造与转换\"></a>流的构造与转换</h2><p>下面提供最常见的几种构造 Stream 的样例。</p>\n<p>eg4. 构造流的几种常见方法<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 1. Individual values</span></span><br><span class=\"line\">Stream stream = Stream.of(<span class=\"string\">\"a\"</span>, <span class=\"string\">\"b\"</span>, <span class=\"string\">\"c\"</span>);</span><br><span class=\"line\"><span class=\"comment\">// 2. Arrays</span></span><br><span class=\"line\">String [] strArray = <span class=\"keyword\">new</span> String[] &#123;<span class=\"string\">\"a\"</span>, <span class=\"string\">\"b\"</span>, <span class=\"string\">\"c\"</span>&#125;;</span><br><span class=\"line\">stream = Stream.of(strArray);</span><br><span class=\"line\">stream = Arrays.stream(strArray);</span><br><span class=\"line\"><span class=\"comment\">// 3. Collections</span></span><br><span class=\"line\">List&lt;String&gt; list = Arrays.asList(strArray);</span><br><span class=\"line\">stream = list.stream();</span><br></pre></td></tr></table></figure></p>\n<p>需要注意的是，对于基本数值型，目前有三种对应的包装类型 Stream：</p>\n<p>IntStream、LongStream、DoubleStream。当然我们也可以用 Stream<integer>、Stream<long> &gt;、Stream<double>，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。</double></long></integer></p>\n<p>Java 8 中还没有提供其它数值型 Stream，因为这将导致扩增的内容较多。而常规的数值型聚合运算可以通过上面三种 Stream 进行。</p>\n<p>eg5. 数值流的构造<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">IntStream.of(<span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[]&#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>&#125;).forEach(System.out::println);</span><br><span class=\"line\">IntStream.range(<span class=\"number\">1</span>, <span class=\"number\">3</span>).forEach(System.out::println);</span><br><span class=\"line\">IntStream.rangeClosed(<span class=\"number\">1</span>, <span class=\"number\">3</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure></p>\n<p>eg6. 流转换为其它数据结构<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 1. Array</span></span><br><span class=\"line\">String[] strArray1 = stream.toArray(String[]::<span class=\"keyword\">new</span>);</span><br><span class=\"line\"><span class=\"comment\">// 2. Collection</span></span><br><span class=\"line\">List&lt;String&gt; list1 = stream.collect(Collectors.toList());</span><br><span class=\"line\">List&lt;String&gt; list2 = stream.collect(Collectors.toCollection(ArrayList::<span class=\"keyword\">new</span>));</span><br><span class=\"line\">Set set1 = stream.collect(Collectors.toSet());</span><br><span class=\"line\">Stack stack1 = stream.collect(Collectors.toCollection(Stack::<span class=\"keyword\">new</span>));</span><br><span class=\"line\"><span class=\"comment\">// 3. String</span></span><br><span class=\"line\">String str = stream.collect(Collectors.joining()).toString();</span><br></pre></td></tr></table></figure></p>\n<p>一个 Stream 只可以使用一次，上面的代码为了简洁而重复使用了数次。</p>\n<h2 id=\"流的操作\"><a href=\"#流的操作\" class=\"headerlink\" title=\"流的操作\"></a>流的操作</h2><p>接下来，当把一个数据结构包装成 Stream 后，就要开始对里面的元素进行各类操作了。常见的操作可以归类如下。</p>\n<ul>\n<li><p>Intermediate：</p>\n<p>  map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered</p>\n</li>\n<li><p>Terminal：</p>\n<p>  forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator</p>\n</li>\n<li><p>Short-circuiting：</p>\n<p>  anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit</p>\n</li>\n</ul>\n<h3 id=\"map-flatMap\"><a href=\"#map-flatMap\" class=\"headerlink\" title=\"map/flatMap\"></a>map/flatMap</h3><p>我们先来看 map。如果你熟悉 scala 这类函数式语言，对这个方法应该很了解，它的作用就是把 input Stream 的每一个元素，映射成 output Stream 的另外一个元素。</p>\n<p>eg7. 转换大写<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;String&gt; output = wordList.stream().</span><br><span class=\"line\">map(String::toUpperCase).</span><br><span class=\"line\">collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>\n<p>这段代码把所有的单词转换为大写。</p>\n<p>eg8. 平方数<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Integer&gt; nums = Arrays.asList(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>);</span><br><span class=\"line\">List&lt;Integer&gt; squareNums = nums.stream().</span><br><span class=\"line\">map(n -&gt; n * n).</span><br><span class=\"line\">collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>\n<p>这段代码生成一个整数 list 的平方数 {1, 4, 9, 16}。</p>\n<p>从上面例子可以看出，map 生成的是个 1:1 映射，每个输入元素，都按照规则转换成为另外一个元素。还有一些场景，是一对多映射关系的，这时需要 flatMap。</p>\n<p>eg9. 一对多<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Stream&lt;List&lt;Integer&gt;&gt; inputStream = Stream.of(</span><br><span class=\"line\"> Arrays.asList(<span class=\"number\">1</span>),</span><br><span class=\"line\"> Arrays.asList(<span class=\"number\">2</span>, <span class=\"number\">3</span>),</span><br><span class=\"line\"> Arrays.asList(<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>)</span><br><span class=\"line\"> );</span><br><span class=\"line\">Stream&lt;Integer&gt; outputStream = inputStream.</span><br><span class=\"line\">flatMap((childList) -&gt; childList.stream());</span><br></pre></td></tr></table></figure></p>\n<p>flatMap 把 input Stream 中的层级结构扁平化，就是将最底层元素抽出来放到一起，最终 output 的新 Stream 里面已经没有 List 了，都是直接的数字。</p>\n<h3 id=\"filter\"><a href=\"#filter\" class=\"headerlink\" title=\"filter\"></a>filter</h3><p>filter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream。</p>\n<p>eg10. 留下偶数<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Integer[] sixNums = &#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>&#125;;</span><br><span class=\"line\">Integer[] evens =</span><br><span class=\"line\">Stream.of(sixNums).filter(n -&gt; n%<span class=\"number\">2</span> == <span class=\"number\">0</span>).toArray(Integer[]::<span class=\"keyword\">new</span>);</span><br></pre></td></tr></table></figure></p>\n<p>经过条件“被 2 整除”的 filter，剩下的数字为 {2, 4, 6}。</p>\n<p>eg11. 把单词挑出来<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;String&gt; output = reader.lines().</span><br><span class=\"line\">    flatMap(line -&gt; Stream.of(line.split(REGEXP))).</span><br><span class=\"line\">    filter(word -&gt; word.length() &gt; <span class=\"number\">0</span>).</span><br><span class=\"line\">    collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>\n<p>这段代码首先把每行的单词用 flatMap 整理到新的 Stream，然后保留长度不为 0 的，就是整篇文章中的全部单词了。</p>\n<h3 id=\"forEach\"><a href=\"#forEach\" class=\"headerlink\" title=\"forEach\"></a>forEach</h3><p>forEach 方法接收一个 Lambda 表达式，然后在 Stream 的每一个元素上执行该表达式。</p>\n<p>eg12. 打印姓名（forEach 和 pre-java8 的对比）<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Java 8</span></span><br><span class=\"line\">roster.stream()</span><br><span class=\"line\">    .filter(p -&gt; p.getGender() == Person.Sex.MALE)</span><br><span class=\"line\">    .forEach(p -&gt; System.out.println(p.getName()));</span><br><span class=\"line\"><span class=\"comment\">// Pre-Java 8</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (Person p : roster) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p.getGender() == Person.Sex.MALE) &#123;</span><br><span class=\"line\">        System.out.println(p.getName());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>对一个人员集合遍历，找出男性并打印姓名。可以看出来，forEach 是为 Lambda 而设计的，保持了最紧凑的风格。而且 Lambda 表达式本身是可以重用的，非常方便。当需要为多核系统优化时，可以 parallelStream().forEach()，只是此时原有元素的次序没法保证，并行的情况下将改变串行时操作的行为，此时 forEach 本身的实现不需要调整，而 Java8 以前的 for 循环 code 可能需要加入额外的多线程逻辑。</p>\n<p>但一般认为，forEach 和常规 for 循环的差异不涉及到性能，它们仅仅是函数式风格与传统 Java 风格的差别。</p>\n<p>另外一点需要注意，forEach 是 terminal 操作，因此它执行后，Stream 的元素就被“消费”掉了，你无法对一个 Stream 进行两次 terminal 运算。下面的代码是错误的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stream.forEach(element -&gt; doOneThing(element));</span><br><span class=\"line\">stream.forEa</span><br><span class=\"line\">ch(element -&gt; doAnotherThing(element));</span><br></pre></td></tr></table></figure>\n<p>相反，具有相似功能的 intermediate 操作 peek 可以达到上述目的。如下是出现在该 api javadoc 上的一个示例。</p>\n<p>eg13. peek 对每个元素执行操作并返回一个新的 Stream<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Stream.of(<span class=\"string\">\"one\"</span>, <span class=\"string\">\"two\"</span>, <span class=\"string\">\"three\"</span>, <span class=\"string\">\"four\"</span>)</span><br><span class=\"line\">    .filter(e -&gt; e.length() &gt; <span class=\"number\">3</span>)</span><br><span class=\"line\">    .peek(e -&gt; System.out.println(<span class=\"string\">\"Filtered value: \"</span> + e))</span><br><span class=\"line\">    .map(String::toUpperCase)</span><br><span class=\"line\">    .peek(e -&gt; System.out.println(<span class=\"string\">\"Mapped value: \"</span> + e))</span><br><span class=\"line\">    .collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>\n<p>forEach 不能修改自己包含的本地变量值，也不能用 break/return 之类的关键字提前结束循环。</p>\n<h3 id=\"findFirst\"><a href=\"#findFirst\" class=\"headerlink\" title=\"findFirst\"></a>findFirst</h3><p>这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。</p>\n<p>这里比较重点的是它的返回值类型：Optional。这也是一个模仿 Scala 语言中的概念，作为一个容器，它可能含有某值，或者不包含。使用它的目的是尽可能避免 NullPointerException。</p>\n<p>eg14. Optional 的两个用例<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String strA = <span class=\"string\">\" abcd \"</span>, strB = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">print(strA);</span><br><span class=\"line\">print(<span class=\"string\">\"\"</span>);</span><br><span class=\"line\">print(strB);</span><br><span class=\"line\">getLength(strA);</span><br><span class=\"line\">getLength(<span class=\"string\">\"\"</span>);</span><br><span class=\"line\">getLength(strB);</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">(String text)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Java 8</span></span><br><span class=\"line\">    Optional.ofNullable(text).ifPresent(System.out::println);</span><br><span class=\"line\">    <span class=\"comment\">// Pre-Java 8</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (text != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        System.out.println(text);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> <span class=\"title\">getLength</span><span class=\"params\">(String text)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Java 8</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> Optional.ofNullable(text).map(String::length).orElse(-<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"comment\">// Pre-Java 8</span></span><br><span class=\"line\">    <span class=\"comment\">// return if (text != null) ? text.length() : -1;</span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<p>在更复杂的 if (xx != null) 的情况中，使用 Optional 代码的可读性更好，而且它提供的是编译时检查，能极大的降低 NPE 这种 Runtime Exception 对程序的影响，或者迫使程序员更早的在编码阶段处理空值问题，而不是留到运行时再发现和调试。</p>\n<p>Stream 中的 findAny、max/min、reduce 等方法等返回 Optional 值。还有例如 IntStream.average() 返回 OptionalDouble 等等。</p>\n<h3 id=\"reduce\"><a href=\"#reduce\" class=\"headerlink\" title=\"reduce\"></a>reduce</h3><p>这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。例如 Stream 的 sum 就相当于</p>\n<p>Integer sum = integers.reduce(0, (a, b) -&gt; a+b); 或</p>\n<p>Integer sum = integers.reduce(0, Integer::sum);</p>\n<p>也有没有起始值的情况，这时会把 Stream 的前面两个元素组合起来，返回的是 Optional。</p>\n<p>eg15. reduce 的用例<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 字符串连接，concat = \"ABCD\"</span></span><br><span class=\"line\">String concat = Stream.of(<span class=\"string\">\"A\"</span>, <span class=\"string\">\"B\"</span>, <span class=\"string\">\"C\"</span>, <span class=\"string\">\"D\"</span>).reduce(<span class=\"string\">\"\"</span>, String::concat); </span><br><span class=\"line\"><span class=\"comment\">// 求最小值，minValue = -3.0</span></span><br><span class=\"line\"><span class=\"keyword\">double</span> minValue = Stream.of(-<span class=\"number\">1.5</span>, <span class=\"number\">1.0</span>, -<span class=\"number\">3.0</span>, -<span class=\"number\">2.0</span>).reduce(Double.MAX_VALUE, Double::min); </span><br><span class=\"line\"><span class=\"comment\">// 求和，sumValue = 10, 有起始值</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> sumValue = Stream.of(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>).reduce(<span class=\"number\">0</span>, Integer::sum);</span><br><span class=\"line\"><span class=\"comment\">// 求和，sumValue = 10, 无起始值</span></span><br><span class=\"line\">sumValue = Stream.of(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>).reduce(Integer::sum).get();</span><br><span class=\"line\"><span class=\"comment\">// 过滤，字符串连接，concat = \"ace\"</span></span><br><span class=\"line\">concat = Stream.of(<span class=\"string\">\"a\"</span>, <span class=\"string\">\"B\"</span>, <span class=\"string\">\"c\"</span>, <span class=\"string\">\"D\"</span>, <span class=\"string\">\"e\"</span>, <span class=\"string\">\"F\"</span>).</span><br><span class=\"line\">    filter(x -&gt; x.compareTo(<span class=\"string\">\"Z\"</span>) &gt; <span class=\"number\">0</span>).</span><br><span class=\"line\">    reduce(<span class=\"string\">\"\"</span>, String::concat);</span><br></pre></td></tr></table></figure></p>\n<p>上面代码例如第一个示例的 reduce()，第一个参数（空白字符）即为起始值，第二个参数（String::concat）为 BinaryOperator。这类有起始值的 reduce() 都返回具体的对象。而对于第四个示例没有起始值的 reduce()，由于可能没有足够的元素，返回的是 Optional，请留意这个区别。</p>\n<h3 id=\"limit-skip\"><a href=\"#limit-skip\" class=\"headerlink\" title=\"limit/skip\"></a>limit/skip</h3><p>limit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来）。</p>\n<p>eg16. limit 和 skip 对运行次数的影响<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">testLimitAndSkip</span> <span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    List&lt;Person&gt; persons = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= <span class=\"number\">10000</span>; i++) &#123;</span><br><span class=\"line\">        Person person = <span class=\"keyword\">new</span> Person(i, <span class=\"string\">\"name\"</span> + i);</span><br><span class=\"line\">        persons.add(person);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    List&lt;String&gt; personList2 = persons.stream().</span><br><span class=\"line\">            map(Person::getName).limit(<span class=\"number\">10</span>).skip(<span class=\"number\">3</span>).collect(Collectors.toList());</span><br><span class=\"line\">    System.out.println(personList2);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Person</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span> no;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String name;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Person</span><span class=\"params\">(<span class=\"keyword\">int</span> no, String name)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.no = no;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.name = name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getName</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(name);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>输出结果为：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name1</span><br><span class=\"line\">name2</span><br><span class=\"line\">name3</span><br><span class=\"line\">name4</span><br><span class=\"line\">name5</span><br><span class=\"line\">name6</span><br><span class=\"line\">name7</span><br><span class=\"line\">name8</span><br><span class=\"line\">name9</span><br><span class=\"line\">name10</span><br><span class=\"line\">[name4, name5, name6, name7, name8, name9, name10]</span><br></pre></td></tr></table></figure></p>\n<p>这是一个有 10，000 个元素的 Stream，但在 short-circuiting 操作 limit 和 skip 的作用下，管道中 map 操作指定的 getName() 方法的执行次数为 limit 所限定的 10 次，而最终返回结果在跳过前 3 个元素后只有后面 7 个返回。</p>\n<p>有一种情况是 limit/skip 无法达到 short-circuiting 目的的，就是把它们放在 Stream 的排序操作后，原因跟 sorted 这个 intermediate 操作有关：此时系统并不知道 Stream 排序后的次序如何，所以 sorted 中的操作看上去就像完全没有被 limit 或者 skip 一样。</p>\n<p>eg17. limit 和 skip 对 sorted 后的运行次数无影响<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Person&gt; persons = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</span><br><span class=\"line\">    Person person = <span class=\"keyword\">new</span> Person(i, <span class=\"string\">\"name\"</span> + i);</span><br><span class=\"line\">    persons.add(person);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">List&lt;Person&gt; personList2 = persons.stream().sorted((p1, p2) -&gt;</span><br><span class=\"line\">    p1.getName().compareTo(p2.getName())).limit(<span class=\"number\">2</span>).collect(Collectors.toList());</span><br><span class=\"line\">System.out.println(personList2);</span><br></pre></td></tr></table></figure></p>\n<p>上面的示例对清单 13 做了微调，首先对 5 个元素的 Stream 排序，然后进行 limit 操作。输出结果为：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name2</span><br><span class=\"line\">name1</span><br><span class=\"line\">name3</span><br><span class=\"line\">name2</span><br><span class=\"line\">name4</span><br><span class=\"line\">name3</span><br><span class=\"line\">name5</span><br><span class=\"line\">name4</span><br><span class=\"line\">[stream.StreamDW$Person@<span class=\"number\">816f</span>27d, stream.StreamDW$Person@<span class=\"number\">87</span>aac27]</span><br></pre></td></tr></table></figure></p>\n<p>即虽然最后的返回元素数量是 2，但整个管道中的 sorted 表达式执行次数没有像前面例子相应减少。</p>\n<p>最后有一点需要注意的是，对一个 parallel 的 Steam 管道来说，如果其元素是有序的，那么 limit 操作的成本会比较大，因为它的返回对象必须是前 n 个也有一样次序的元素。取而代之的策略是取消元素间的次序，或者不要用 parallel Stream。</p>\n<h3 id=\"sorted\"><a href=\"#sorted\" class=\"headerlink\" title=\"sorted\"></a>sorted</h3><p>对 Stream 的排序通过 sorted 进行，它比数组的排序更强之处在于你可以首先对 Stream 进行各类 map、filter、limit、skip 甚至 distinct 来减少元素数量后，再排序，这能帮助程序明显缩短执行时间。我们对清单 14 进行优化：</p>\n<p>eg18. 优化：排序前进行 limit 和 skip<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Person&gt; persons = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</span><br><span class=\"line\">    Person person = <span class=\"keyword\">new</span> Person(i, <span class=\"string\">\"name\"</span> + i);</span><br><span class=\"line\">    persons.add(person);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">List&lt;Person&gt; personList2 = persons.stream().limit(<span class=\"number\">2</span>).sorted((p1, p2) -&gt; p1.getName().compareTo(p2.getName())).collect(Collectors.toList());</span><br><span class=\"line\">System.out.println(personList2);</span><br></pre></td></tr></table></figure></p>\n<p>结果会简单很多：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name2</span><br><span class=\"line\">name1</span><br><span class=\"line\">[stream.StreamDW$Person@<span class=\"number\">6</span>ce253f1, stream.StreamDW$Person@<span class=\"number\">53</span>d8d10a]</span><br></pre></td></tr></table></figure>\n<p>当然，这种优化是有 business logic 上的局限性的：即不要求排序后再取值。</p>\n<h3 id=\"min-max-distinct\"><a href=\"#min-max-distinct\" class=\"headerlink\" title=\"min/max/distinct\"></a>min/max/distinct</h3><p>min 和 max 的功能也可以通过对 Stream 元素先排序，再 findFirst 来实现，但前者的性能会更好，为 O(n)，而 sorted 的成本是 O(n log n)。同时它们作为特殊的 reduce 方法被独立出来也是因为求最大最小值是很常见的操作。</p>\n<p>eg19. 找出最长一行的长度<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BufferedReader br = <span class=\"keyword\">new</span> BufferedReader(<span class=\"keyword\">new</span> FileReader(<span class=\"string\">\"c:\\\\SUService.log\"</span>));</span><br><span class=\"line\"><span class=\"keyword\">int</span> longest = br.lines().</span><br><span class=\"line\">    mapToInt(String::length).</span><br><span class=\"line\">    max().</span><br><span class=\"line\">    getAsInt();</span><br><span class=\"line\">br.close();</span><br><span class=\"line\">System.out.println(longest);</span><br></pre></td></tr></table></figure></p>\n<p>下面的例子则使用 distinct 来找出不重复的单词。</p>\n<p>eg20. 找出全文的单词，转小写，并排序<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;String&gt; words = br.lines().</span><br><span class=\"line\">flatMap(line -&gt; Stream.of(line.split(<span class=\"string\">\" \"</span>))).</span><br><span class=\"line\">filter(word -&gt; word.length() &gt; <span class=\"number\">0</span>).</span><br><span class=\"line\">map(String::toLowerCase).</span><br><span class=\"line\">distinct().</span><br><span class=\"line\">sorted().</span><br><span class=\"line\">collect(Collectors.toList());</span><br><span class=\"line\">br.close();</span><br><span class=\"line\">System.out.println(words);</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Match\"><a href=\"#Match\" class=\"headerlink\" title=\"Match\"></a>Match</h3><p>Stream 有三个 match 方法，从语义上说：</p>\n<ul>\n<li>allMatch：Stream 中全部元素符合传入的 predicate，返回 true</li>\n<li>anyMatch：Stream 中只要有一个元素符合传入的 predicate，返回 true</li>\n<li>noneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true</li>\n</ul>\n<p>它们都不是要遍历全部元素才能返回结果。例如 allMatch 只要一个元素不满足条件，就 skip 剩下的所有元素，返回 false。对清单 13 中的 Person 类稍做修改，加入一个 age 属性和 getAge 方法。</p>\n<p>eg21. 使用 Match<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Person&gt; persons = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">1</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">1</span>, <span class=\"number\">10</span>));</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">2</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">2</span>, <span class=\"number\">21</span>));</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">3</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">3</span>, <span class=\"number\">34</span>));</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">4</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">4</span>, <span class=\"number\">6</span>));</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">5</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">5</span>, <span class=\"number\">55</span>));</span><br><span class=\"line\"><span class=\"keyword\">boolean</span> isAllAdult = persons.stream().allMatch(p -&gt; p.getAge() &gt; <span class=\"number\">18</span>);</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"All are adult? \"</span> + isAllAdult);</span><br><span class=\"line\"><span class=\"keyword\">boolean</span> isThereAnyChild = persons.stream().anyMatch(p -&gt; p.getAge() &lt; <span class=\"number\">12</span>);</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"Any child? \"</span> + isThereAnyChild);</span><br></pre></td></tr></table></figure></p>\n<p>输出结果：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">All are adult? <span class=\"keyword\">false</span></span><br><span class=\"line\">Any child? <span class=\"keyword\">true</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"进阶：自己生成流\"><a href=\"#进阶：自己生成流\" class=\"headerlink\" title=\"进阶：自己生成流\"></a>进阶：自己生成流</h2><h3 id=\"Stream-generate\"><a href=\"#Stream-generate\" class=\"headerlink\" title=\"Stream.generate\"></a>Stream.generate</h3><p>通过实现 Supplier 接口，你可以自己来控制流的生成。这种情形通常用于随机数、常量的 Stream，或者需要前后元素间维持着某种状态信息的 Stream。把 Supplier 实例传递给 Stream.generate() 生成的 Stream，默认是串行（相对 parallel 而言）但无序的（相对 ordered 而言）。由于它是无限的，在管道中，必须利用 limit 之类的操作限制 Stream 大小。</p>\n<p>eg22. 生成 10 个随机整数<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Random seed = <span class=\"keyword\">new</span> Random();</span><br><span class=\"line\">Supplier&lt;Integer&gt; random = seed::nextInt;</span><br><span class=\"line\">Stream.generate(random).limit(<span class=\"number\">10</span>).forEach(System.out::println);</span><br><span class=\"line\"><span class=\"comment\">//Another way</span></span><br><span class=\"line\">IntStream.generate(() -&gt; (<span class=\"keyword\">int</span>) (System.nanoTime() % <span class=\"number\">100</span>)).</span><br><span class=\"line\">limit(<span class=\"number\">10</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure></p>\n<p>Stream.generate() 还接受自己实现的 Supplier。例如在构造海量测试数据的时候，用某种自动的规则给每一个变量赋值；或者依据公式计算 Stream 的每个元素值。这些都是维持状态信息的情形。</p>\n<p>eg23. 自实现 Supplier<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Stream.generate(<span class=\"keyword\">new</span> PersonSupplier()).</span><br><span class=\"line\">        limit(<span class=\"number\">10</span>).</span><br><span class=\"line\">        forEach(p -&gt; System.out.println(p.getName() + <span class=\"string\">\", \"</span> + p.getAge()));</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PersonSupplier</span> <span class=\"keyword\">implements</span> <span class=\"title\">Supplier</span>&lt;<span class=\"title\">Person</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">int</span> index = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> Random random = <span class=\"keyword\">new</span> Random();</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Person <span class=\"title\">get</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> Person(index++, <span class=\"string\">\"StormTestUser\"</span> + index, random.nextInt(<span class=\"number\">100</span>));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>输出结果：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StormTestUser1, <span class=\"number\">9</span></span><br><span class=\"line\">StormTestUser2, <span class=\"number\">12</span></span><br><span class=\"line\">StormTestUser3, <span class=\"number\">88</span></span><br><span class=\"line\">StormTestUser4, <span class=\"number\">51</span></span><br><span class=\"line\">StormTestUser5, <span class=\"number\">22</span></span><br><span class=\"line\">StormTestUser6, <span class=\"number\">28</span></span><br><span class=\"line\">StormTestUser7, <span class=\"number\">81</span></span><br><span class=\"line\">StormTestUser8, <span class=\"number\">51</span></span><br><span class=\"line\">StormTestUser9, <span class=\"number\">4</span></span><br><span class=\"line\">StormTestUser10, <span class=\"number\">76</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Stream-iterate\"><a href=\"#Stream-iterate\" class=\"headerlink\" title=\"Stream.iterate\"></a>Stream.iterate</h3><p>iterate 跟 reduce 操作很像，接受一个种子值，和一个 UnaryOperator（例如 f）。然后种子值成为 Stream 的第一个元素，f(seed) 为第二个，f(f(seed)) 第三个，以此类推。</p>\n<p>eg24. 生成一个等差数列<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Stream.iterate(<span class=\"number\">0</span>, n -&gt; n + <span class=\"number\">3</span>).limit(<span class=\"number\">10</span>). forEach(x -&gt; System.out.print(x + <span class=\"string\">\" \"</span>));</span><br></pre></td></tr></table></figure></p>\n<p>输出结果：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">0</span> <span class=\"number\">3</span> <span class=\"number\">6</span> <span class=\"number\">9</span> <span class=\"number\">12</span> <span class=\"number\">15</span> <span class=\"number\">18</span> <span class=\"number\">21</span> <span class=\"number\">24</span> <span class=\"number\">27</span></span><br></pre></td></tr></table></figure></p>\n<p>与 Stream.generate 相仿，在 iterate 时候管道必须有 limit 这样的操作来限制 Stream 大小。</p>\n<h2 id=\"进阶：用-Collectors-来进行-reduction-操作\"><a href=\"#进阶：用-Collectors-来进行-reduction-操作\" class=\"headerlink\" title=\"进阶：用 Collectors 来进行 reduction 操作\"></a>进阶：用 Collectors 来进行 reduction 操作</h2><p>java.util.stream.Collectors 类的主要作用就是辅助进行各类有用的 reduction 操作，例如转变输出为 Collection，把 Stream 元素进行归组。</p>\n<h3 id=\"groupingBy-partitioningBy\"><a href=\"#groupingBy-partitioningBy\" class=\"headerlink\" title=\"groupingBy/partitioningBy\"></a>groupingBy/partitioningBy</h3><p>eg25. 按照年龄归组<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;Integer, List&lt;Person&gt;&gt; personGroups = Stream.generate(<span class=\"keyword\">new</span> PersonSupplier()).</span><br><span class=\"line\">        limit(<span class=\"number\">100</span>).</span><br><span class=\"line\">        collect(Collectors.groupingBy(Person::getAge));</span><br><span class=\"line\">Iterator it = personGroups.entrySet().iterator();</span><br><span class=\"line\"><span class=\"keyword\">while</span> (it.hasNext()) &#123;</span><br><span class=\"line\">    Map.Entry&lt;Integer, List&lt;Person&gt;&gt; persons = (Map.Entry) it.next();</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"Age \"</span> + persons.getKey() + <span class=\"string\">\" = \"</span> + persons.getValue().size());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>上面的 code，首先生成 100 人的信息，然后按照年龄归组，相同年龄的人放到同一个 list 中，可以看到如下的输出：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Age <span class=\"number\">0</span> = <span class=\"number\">2</span></span><br><span class=\"line\">Age <span class=\"number\">1</span> = <span class=\"number\">2</span></span><br><span class=\"line\">Age <span class=\"number\">5</span> = <span class=\"number\">2</span></span><br><span class=\"line\">Age <span class=\"number\">8</span> = <span class=\"number\">1</span></span><br><span class=\"line\">Age <span class=\"number\">9</span> = <span class=\"number\">1</span></span><br><span class=\"line\">Age <span class=\"number\">11</span> = <span class=\"number\">2</span></span><br><span class=\"line\">……</span><br></pre></td></tr></table></figure>\n<p>eg26. 按照未成年人和成年人归组<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;Boolean, List&lt;Person&gt;&gt; children = Stream.generate(<span class=\"keyword\">new</span> PersonSupplier()).</span><br><span class=\"line\">    limit(<span class=\"number\">100</span>).</span><br><span class=\"line\">    collect(Collectors.partitioningBy(p -&gt; p.getAge() &lt; <span class=\"number\">18</span>));</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"Children number: \"</span> + children.get(<span class=\"keyword\">true</span>).size());</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"Adult number: \"</span> + children.get(<span class=\"keyword\">false</span>).size());</span><br></pre></td></tr></table></figure></p>\n<p>输出结果：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Children number: <span class=\"number\">23</span> </span><br><span class=\"line\">Adult number: <span class=\"number\">77</span></span><br></pre></td></tr></table></figure>\n<p>在使用条件“年龄小于 18”进行分组后可以看到，不到 18 岁的未成年人是一组，成年人是另外一组。partitioningBy 其实是一种特殊的 groupingBy，它依照条件测试的是否两种结果来构造返回的数据结构，get(true) 和 get(false) 能即为全部的元素对象。</p>\n<h1 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h1><p>总之，Stream 的特性可以归纳为：</p>\n<ul>\n<li><p>不是数据结构</p>\n<p>  它没有内部存储，它只是用操作管道从 source（数据结构、数组、generator function、IO channel）抓取数据。</p>\n<p>  它也绝不修改自己所封装的底层数据结构的数据。例如 Stream 的 filter 操作会产生一个不包含被过滤元素的新 Stream，而不是从 source 删除那些元素。</p>\n</li>\n<li><p>所有 Stream 的操作必须以 lambda 表达式为参数</p>\n</li>\n<li><p>不支持索引访问</p>\n<p>  你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。不过请参阅下一项。</p>\n</li>\n<li><p>很容易生成数组或者 List</p>\n</li>\n<li><p>惰性化</p>\n<p>  很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。</p>\n<p>  Intermediate 操作永远是惰性化的。</p>\n</li>\n<li><p>并行能力</p>\n<p>  当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的。</p>\n</li>\n<li><p>可以是无限的</p>\n<p>  集合有固定大小，Stream 则不必。limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>最近在学习JAVA8 Stream的API，找到了这篇文章，觉得内容很好就抄了过来，文章来源：<a href=\"https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/</a></p>\n</blockquote>\n<h1 id=\"为什么需要-Stream\"><a href=\"#为什么需要-Stream\" class=\"headerlink\" title=\"为什么需要 Stream\"></a>为什么需要 Stream</h1><p>Stream 作为 Java 8 的一大亮点，它与 java.io 包里的 InputStream 和 OutputStream 是完全不同的概念。它也不同于 StAX 对 XML 解析的 Stream，也不是 Amazon Kinesis 对大数据实时处理的 Stream。Java 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。所以说，Java 8 中首次出现的 java.util.stream 是一个函数式语言+多核时代综合影响的产物。</p>","more":"<h2 id=\"什么是聚合操作\"><a href=\"#什么是聚合操作\" class=\"headerlink\" title=\"什么是聚合操作\"></a>什么是聚合操作</h2><p>在传统的 J2EE 应用中，Java 代码经常不得不依赖于关系型数据库的聚合操作来完成诸如：</p>\n<ul>\n<li>客户每月平均消费金额</li>\n<li>最昂贵的在售商品</li>\n<li>本周完成的有效订单（排除了无效的）</li>\n<li>取十个数据样本作为首页推荐</li>\n</ul>\n<p>但在当今这个数据大爆炸的时代，在数据来源多样化、数据海量化的今天，很多时候不得不脱离 RDBMS，或者以底层返回的数据为基础进行更上层的数据统计。而 Java 的集合 API 中，仅仅有极少量的辅助型方法，更多的时候是程序员需要用 Iterator 来遍历集合，完成相关的聚合应用逻辑。这是一种远不够高效、笨拙的方法。在 Java 7 中，如果要发现 type 为 grocery 的所有交易，然后返回以交易值降序排序好的交易 ID 集合，我们需要这样写：</p>\n<p>eg1. Java 7 的排序、取值实现<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Transaction&gt; groceryTransactions = <span class=\"keyword\">new</span> Arraylist&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (Transaction t : transactions) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (t.getType() == Transaction.GROCERY) &#123;</span><br><span class=\"line\">        groceryTransactions.add(t);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">Collections.sort(groceryTransactions, <span class=\"keyword\">new</span> Comparator() &#123;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">int</span> <span class=\"title\">compare</span><span class=\"params\">(Transaction t1, Transaction t2)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> t2.getValue().compareTo(t1.getValue());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">List&lt;Integer&gt; transactionIds = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (Transaction t : groceryTransactions) &#123;</span><br><span class=\"line\">    transactionsIds.add(t.getId());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>而在 Java 8 使用 Stream，代码更加简洁易读；而且使用并发模式，程序执行速度更快。</p>\n<p>eg2. Java 8 的排序、取值实现<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Integer&gt; transactionsIds = transactions.parallelStream().</span><br><span class=\"line\">    filter(t -&gt; t.getType() == Transaction.GROCERY).</span><br><span class=\"line\">    sorted(comparing(Transaction::getValue).reversed()).</span><br><span class=\"line\">    map(Transaction::getId).</span><br><span class=\"line\">    collect(toList());</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"Stream-总览\"><a href=\"#Stream-总览\" class=\"headerlink\" title=\"Stream 总览\"></a>Stream 总览</h1><h2 id=\"什么是流\"><a href=\"#什么是流\" class=\"headerlink\" title=\"什么是流\"></a>什么是流</h2><p>Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，比如 “过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。</p>\n<p>Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。</p>\n<p>而和迭代器又不同的是，Stream 可以并行化操作，迭代器只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架（JSR166y）来拆分任务和加速处理过程。Java 的并行 API 演变历程基本如下：</p>\n<ol>\n<li>1.0-1.4 中的 java.lang.Thread</li>\n<li>5.0 中的 java.util.concurrent</li>\n<li>6.0 中的 Phasers 等</li>\n<li>7.0 中的 Fork/Join 框架</li>\n<li>8.0 中的 Lambda</li>\n</ol>\n<p>Stream 的另外一大特点是，数据源本身可以是无限的。</p>\n<h2 id=\"流的构成\"><a href=\"#流的构成\" class=\"headerlink\" title=\"流的构成\"></a>流的构成</h2><p>当我们使用一个流的时候，通常包括三个基本步骤：</p>\n<p>获取一个数据源（source）→ 数据转换→执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道，如下图所示。</p>\n<p>流管道 (Stream Pipeline) 的构成</p>\n<p><img src=\"https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/img001.png\" alt=\"StreamPipeline-photo\"></p>\n<h3 id=\"有多种方式生成-Stream-Source：\"><a href=\"#有多种方式生成-Stream-Source：\" class=\"headerlink\" title=\"有多种方式生成 Stream Source：\"></a>有多种方式生成 Stream Source：</h3><h4 id=\"从-Collection-和数组\"><a href=\"#从-Collection-和数组\" class=\"headerlink\" title=\"从 Collection 和数组\"></a>从 Collection 和数组</h4><ul>\n<li>Collection.stream()</li>\n<li>Collection.parallelStream()</li>\n<li>Arrays.stream(T array) or Stream.of()</li>\n</ul>\n<h4 id=\"从-BufferedReader\"><a href=\"#从-BufferedReader\" class=\"headerlink\" title=\"从 BufferedReader\"></a>从 BufferedReader</h4><ul>\n<li>java.io.BufferedReader.lines()</li>\n</ul>\n<h4 id=\"静态工厂\"><a href=\"#静态工厂\" class=\"headerlink\" title=\"静态工厂\"></a>静态工厂</h4><ul>\n<li>java.util.stream.IntStream.range()</li>\n<li>java.nio.file.Files.walk()</li>\n</ul>\n<h4 id=\"自己构建\"><a href=\"#自己构建\" class=\"headerlink\" title=\"自己构建\"></a>自己构建</h4><ul>\n<li>java.util.Spliterator</li>\n</ul>\n<h4 id=\"其它\"><a href=\"#其它\" class=\"headerlink\" title=\"其它\"></a>其它</h4><ul>\n<li>Random.ints()</li>\n<li>BitSet.stream()</li>\n<li>Pattern.splitAsStream(java.lang.CharSequence)</li>\n<li>JarFile.stream()</li>\n</ul>\n<h3 id=\"流的操作类型分为两种：\"><a href=\"#流的操作类型分为两种：\" class=\"headerlink\" title=\"流的操作类型分为两种：\"></a>流的操作类型分为两种：</h3><ul>\n<li><p><strong><em>Intermediate</em></strong>：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。</p>\n</li>\n<li><p><strong><em>Terminal</em></strong>：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。</p>\n</li>\n</ul>\n<p>在对于一个 Stream 进行多次转换操作 (Intermediate 操作)，每次都对 Stream 的每个元素进行转换，而且是执行多次，这样时间复杂度就是 N（转换次数）个 for 循环里把所有操作都做掉的总和吗？其实不是这样的，转换操作都是 lazy 的，多个转换操作只会在 Terminal 操作的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream 里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在 Terminal 操作的时候循环 Stream 对应的集合，然后对每个元素执行所有的函数。</p>\n<p>还有一种操作被称为 <strong><em>short-circuiting</em></strong>。用以指：</p>\n<ul>\n<li>对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。</li>\n<li>对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。</li>\n</ul>\n<p>当操作一个无限大的 Stream，而又希望在有限时间内完成操作，则在管道内拥有一个 short-circuiting 操作是必要非充分条件。</p>\n<p>eg3. 一个流操作的示例<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> sum = widgets.stream()</span><br><span class=\"line\">    .filter(w -&gt; w.getColor() == RED)</span><br><span class=\"line\">    .mapToInt(w -&gt; w.getWeight())</span><br><span class=\"line\">    .sum();</span><br></pre></td></tr></table></figure></p>\n<p>stream() 获取当前小物件的 source，filter 和 mapToInt 为 intermediate 操作，进行数据筛选和转换，最后一个 sum() 为 terminal 操作，对符合条件的全部小物件作重量求和。</p>\n<h1 id=\"流的使用详解\"><a href=\"#流的使用详解\" class=\"headerlink\" title=\"流的使用详解\"></a>流的使用详解</h1><p>简单说，对 Stream 的使用就是实现一个 filter-map-reduce 过程，产生一个最终结果，或者导致一个副作用（side effect）。</p>\n<h2 id=\"流的构造与转换\"><a href=\"#流的构造与转换\" class=\"headerlink\" title=\"流的构造与转换\"></a>流的构造与转换</h2><p>下面提供最常见的几种构造 Stream 的样例。</p>\n<p>eg4. 构造流的几种常见方法<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 1. Individual values</span></span><br><span class=\"line\">Stream stream = Stream.of(<span class=\"string\">\"a\"</span>, <span class=\"string\">\"b\"</span>, <span class=\"string\">\"c\"</span>);</span><br><span class=\"line\"><span class=\"comment\">// 2. Arrays</span></span><br><span class=\"line\">String [] strArray = <span class=\"keyword\">new</span> String[] &#123;<span class=\"string\">\"a\"</span>, <span class=\"string\">\"b\"</span>, <span class=\"string\">\"c\"</span>&#125;;</span><br><span class=\"line\">stream = Stream.of(strArray);</span><br><span class=\"line\">stream = Arrays.stream(strArray);</span><br><span class=\"line\"><span class=\"comment\">// 3. Collections</span></span><br><span class=\"line\">List&lt;String&gt; list = Arrays.asList(strArray);</span><br><span class=\"line\">stream = list.stream();</span><br></pre></td></tr></table></figure></p>\n<p>需要注意的是，对于基本数值型，目前有三种对应的包装类型 Stream：</p>\n<p>IntStream、LongStream、DoubleStream。当然我们也可以用 Stream<integer>、Stream<long> &gt;、Stream<double>，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。</double></long></integer></p>\n<p>Java 8 中还没有提供其它数值型 Stream，因为这将导致扩增的内容较多。而常规的数值型聚合运算可以通过上面三种 Stream 进行。</p>\n<p>eg5. 数值流的构造<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">IntStream.of(<span class=\"keyword\">new</span> <span class=\"keyword\">int</span>[]&#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>&#125;).forEach(System.out::println);</span><br><span class=\"line\">IntStream.range(<span class=\"number\">1</span>, <span class=\"number\">3</span>).forEach(System.out::println);</span><br><span class=\"line\">IntStream.rangeClosed(<span class=\"number\">1</span>, <span class=\"number\">3</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure></p>\n<p>eg6. 流转换为其它数据结构<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 1. Array</span></span><br><span class=\"line\">String[] strArray1 = stream.toArray(String[]::<span class=\"keyword\">new</span>);</span><br><span class=\"line\"><span class=\"comment\">// 2. Collection</span></span><br><span class=\"line\">List&lt;String&gt; list1 = stream.collect(Collectors.toList());</span><br><span class=\"line\">List&lt;String&gt; list2 = stream.collect(Collectors.toCollection(ArrayList::<span class=\"keyword\">new</span>));</span><br><span class=\"line\">Set set1 = stream.collect(Collectors.toSet());</span><br><span class=\"line\">Stack stack1 = stream.collect(Collectors.toCollection(Stack::<span class=\"keyword\">new</span>));</span><br><span class=\"line\"><span class=\"comment\">// 3. String</span></span><br><span class=\"line\">String str = stream.collect(Collectors.joining()).toString();</span><br></pre></td></tr></table></figure></p>\n<p>一个 Stream 只可以使用一次，上面的代码为了简洁而重复使用了数次。</p>\n<h2 id=\"流的操作\"><a href=\"#流的操作\" class=\"headerlink\" title=\"流的操作\"></a>流的操作</h2><p>接下来，当把一个数据结构包装成 Stream 后，就要开始对里面的元素进行各类操作了。常见的操作可以归类如下。</p>\n<ul>\n<li><p>Intermediate：</p>\n<p>  map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered</p>\n</li>\n<li><p>Terminal：</p>\n<p>  forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator</p>\n</li>\n<li><p>Short-circuiting：</p>\n<p>  anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit</p>\n</li>\n</ul>\n<h3 id=\"map-flatMap\"><a href=\"#map-flatMap\" class=\"headerlink\" title=\"map/flatMap\"></a>map/flatMap</h3><p>我们先来看 map。如果你熟悉 scala 这类函数式语言，对这个方法应该很了解，它的作用就是把 input Stream 的每一个元素，映射成 output Stream 的另外一个元素。</p>\n<p>eg7. 转换大写<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;String&gt; output = wordList.stream().</span><br><span class=\"line\">map(String::toUpperCase).</span><br><span class=\"line\">collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>\n<p>这段代码把所有的单词转换为大写。</p>\n<p>eg8. 平方数<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Integer&gt; nums = Arrays.asList(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>);</span><br><span class=\"line\">List&lt;Integer&gt; squareNums = nums.stream().</span><br><span class=\"line\">map(n -&gt; n * n).</span><br><span class=\"line\">collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>\n<p>这段代码生成一个整数 list 的平方数 {1, 4, 9, 16}。</p>\n<p>从上面例子可以看出，map 生成的是个 1:1 映射，每个输入元素，都按照规则转换成为另外一个元素。还有一些场景，是一对多映射关系的，这时需要 flatMap。</p>\n<p>eg9. 一对多<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Stream&lt;List&lt;Integer&gt;&gt; inputStream = Stream.of(</span><br><span class=\"line\"> Arrays.asList(<span class=\"number\">1</span>),</span><br><span class=\"line\"> Arrays.asList(<span class=\"number\">2</span>, <span class=\"number\">3</span>),</span><br><span class=\"line\"> Arrays.asList(<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>)</span><br><span class=\"line\"> );</span><br><span class=\"line\">Stream&lt;Integer&gt; outputStream = inputStream.</span><br><span class=\"line\">flatMap((childList) -&gt; childList.stream());</span><br></pre></td></tr></table></figure></p>\n<p>flatMap 把 input Stream 中的层级结构扁平化，就是将最底层元素抽出来放到一起，最终 output 的新 Stream 里面已经没有 List 了，都是直接的数字。</p>\n<h3 id=\"filter\"><a href=\"#filter\" class=\"headerlink\" title=\"filter\"></a>filter</h3><p>filter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream。</p>\n<p>eg10. 留下偶数<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Integer[] sixNums = &#123;<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>&#125;;</span><br><span class=\"line\">Integer[] evens =</span><br><span class=\"line\">Stream.of(sixNums).filter(n -&gt; n%<span class=\"number\">2</span> == <span class=\"number\">0</span>).toArray(Integer[]::<span class=\"keyword\">new</span>);</span><br></pre></td></tr></table></figure></p>\n<p>经过条件“被 2 整除”的 filter，剩下的数字为 {2, 4, 6}。</p>\n<p>eg11. 把单词挑出来<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;String&gt; output = reader.lines().</span><br><span class=\"line\">    flatMap(line -&gt; Stream.of(line.split(REGEXP))).</span><br><span class=\"line\">    filter(word -&gt; word.length() &gt; <span class=\"number\">0</span>).</span><br><span class=\"line\">    collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>\n<p>这段代码首先把每行的单词用 flatMap 整理到新的 Stream，然后保留长度不为 0 的，就是整篇文章中的全部单词了。</p>\n<h3 id=\"forEach\"><a href=\"#forEach\" class=\"headerlink\" title=\"forEach\"></a>forEach</h3><p>forEach 方法接收一个 Lambda 表达式，然后在 Stream 的每一个元素上执行该表达式。</p>\n<p>eg12. 打印姓名（forEach 和 pre-java8 的对比）<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Java 8</span></span><br><span class=\"line\">roster.stream()</span><br><span class=\"line\">    .filter(p -&gt; p.getGender() == Person.Sex.MALE)</span><br><span class=\"line\">    .forEach(p -&gt; System.out.println(p.getName()));</span><br><span class=\"line\"><span class=\"comment\">// Pre-Java 8</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (Person p : roster) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p.getGender() == Person.Sex.MALE) &#123;</span><br><span class=\"line\">        System.out.println(p.getName());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>对一个人员集合遍历，找出男性并打印姓名。可以看出来，forEach 是为 Lambda 而设计的，保持了最紧凑的风格。而且 Lambda 表达式本身是可以重用的，非常方便。当需要为多核系统优化时，可以 parallelStream().forEach()，只是此时原有元素的次序没法保证，并行的情况下将改变串行时操作的行为，此时 forEach 本身的实现不需要调整，而 Java8 以前的 for 循环 code 可能需要加入额外的多线程逻辑。</p>\n<p>但一般认为，forEach 和常规 for 循环的差异不涉及到性能，它们仅仅是函数式风格与传统 Java 风格的差别。</p>\n<p>另外一点需要注意，forEach 是 terminal 操作，因此它执行后，Stream 的元素就被“消费”掉了，你无法对一个 Stream 进行两次 terminal 运算。下面的代码是错误的：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">stream.forEach(element -&gt; doOneThing(element));</span><br><span class=\"line\">stream.forEa</span><br><span class=\"line\">ch(element -&gt; doAnotherThing(element));</span><br></pre></td></tr></table></figure>\n<p>相反，具有相似功能的 intermediate 操作 peek 可以达到上述目的。如下是出现在该 api javadoc 上的一个示例。</p>\n<p>eg13. peek 对每个元素执行操作并返回一个新的 Stream<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Stream.of(<span class=\"string\">\"one\"</span>, <span class=\"string\">\"two\"</span>, <span class=\"string\">\"three\"</span>, <span class=\"string\">\"four\"</span>)</span><br><span class=\"line\">    .filter(e -&gt; e.length() &gt; <span class=\"number\">3</span>)</span><br><span class=\"line\">    .peek(e -&gt; System.out.println(<span class=\"string\">\"Filtered value: \"</span> + e))</span><br><span class=\"line\">    .map(String::toUpperCase)</span><br><span class=\"line\">    .peek(e -&gt; System.out.println(<span class=\"string\">\"Mapped value: \"</span> + e))</span><br><span class=\"line\">    .collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>\n<p>forEach 不能修改自己包含的本地变量值，也不能用 break/return 之类的关键字提前结束循环。</p>\n<h3 id=\"findFirst\"><a href=\"#findFirst\" class=\"headerlink\" title=\"findFirst\"></a>findFirst</h3><p>这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。</p>\n<p>这里比较重点的是它的返回值类型：Optional。这也是一个模仿 Scala 语言中的概念，作为一个容器，它可能含有某值，或者不包含。使用它的目的是尽可能避免 NullPointerException。</p>\n<p>eg14. Optional 的两个用例<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String strA = <span class=\"string\">\" abcd \"</span>, strB = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">print(strA);</span><br><span class=\"line\">print(<span class=\"string\">\"\"</span>);</span><br><span class=\"line\">print(strB);</span><br><span class=\"line\">getLength(strA);</span><br><span class=\"line\">getLength(<span class=\"string\">\"\"</span>);</span><br><span class=\"line\">getLength(strB);</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title\">print</span><span class=\"params\">(String text)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Java 8</span></span><br><span class=\"line\">    Optional.ofNullable(text).ifPresent(System.out::println);</span><br><span class=\"line\">    <span class=\"comment\">// Pre-Java 8</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (text != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">        System.out.println(text);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">int</span> <span class=\"title\">getLength</span><span class=\"params\">(String text)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Java 8</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> Optional.ofNullable(text).map(String::length).orElse(-<span class=\"number\">1</span>);</span><br><span class=\"line\">    <span class=\"comment\">// Pre-Java 8</span></span><br><span class=\"line\">    <span class=\"comment\">// return if (text != null) ? text.length() : -1;</span></span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure></p>\n<p>在更复杂的 if (xx != null) 的情况中，使用 Optional 代码的可读性更好，而且它提供的是编译时检查，能极大的降低 NPE 这种 Runtime Exception 对程序的影响，或者迫使程序员更早的在编码阶段处理空值问题，而不是留到运行时再发现和调试。</p>\n<p>Stream 中的 findAny、max/min、reduce 等方法等返回 Optional 值。还有例如 IntStream.average() 返回 OptionalDouble 等等。</p>\n<h3 id=\"reduce\"><a href=\"#reduce\" class=\"headerlink\" title=\"reduce\"></a>reduce</h3><p>这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。例如 Stream 的 sum 就相当于</p>\n<p>Integer sum = integers.reduce(0, (a, b) -&gt; a+b); 或</p>\n<p>Integer sum = integers.reduce(0, Integer::sum);</p>\n<p>也有没有起始值的情况，这时会把 Stream 的前面两个元素组合起来，返回的是 Optional。</p>\n<p>eg15. reduce 的用例<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 字符串连接，concat = \"ABCD\"</span></span><br><span class=\"line\">String concat = Stream.of(<span class=\"string\">\"A\"</span>, <span class=\"string\">\"B\"</span>, <span class=\"string\">\"C\"</span>, <span class=\"string\">\"D\"</span>).reduce(<span class=\"string\">\"\"</span>, String::concat); </span><br><span class=\"line\"><span class=\"comment\">// 求最小值，minValue = -3.0</span></span><br><span class=\"line\"><span class=\"keyword\">double</span> minValue = Stream.of(-<span class=\"number\">1.5</span>, <span class=\"number\">1.0</span>, -<span class=\"number\">3.0</span>, -<span class=\"number\">2.0</span>).reduce(Double.MAX_VALUE, Double::min); </span><br><span class=\"line\"><span class=\"comment\">// 求和，sumValue = 10, 有起始值</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> sumValue = Stream.of(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>).reduce(<span class=\"number\">0</span>, Integer::sum);</span><br><span class=\"line\"><span class=\"comment\">// 求和，sumValue = 10, 无起始值</span></span><br><span class=\"line\">sumValue = Stream.of(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>).reduce(Integer::sum).get();</span><br><span class=\"line\"><span class=\"comment\">// 过滤，字符串连接，concat = \"ace\"</span></span><br><span class=\"line\">concat = Stream.of(<span class=\"string\">\"a\"</span>, <span class=\"string\">\"B\"</span>, <span class=\"string\">\"c\"</span>, <span class=\"string\">\"D\"</span>, <span class=\"string\">\"e\"</span>, <span class=\"string\">\"F\"</span>).</span><br><span class=\"line\">    filter(x -&gt; x.compareTo(<span class=\"string\">\"Z\"</span>) &gt; <span class=\"number\">0</span>).</span><br><span class=\"line\">    reduce(<span class=\"string\">\"\"</span>, String::concat);</span><br></pre></td></tr></table></figure></p>\n<p>上面代码例如第一个示例的 reduce()，第一个参数（空白字符）即为起始值，第二个参数（String::concat）为 BinaryOperator。这类有起始值的 reduce() 都返回具体的对象。而对于第四个示例没有起始值的 reduce()，由于可能没有足够的元素，返回的是 Optional，请留意这个区别。</p>\n<h3 id=\"limit-skip\"><a href=\"#limit-skip\" class=\"headerlink\" title=\"limit/skip\"></a>limit/skip</h3><p>limit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来）。</p>\n<p>eg16. limit 和 skip 对运行次数的影响<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">testLimitAndSkip</span> <span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    List&lt;Person&gt; persons = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= <span class=\"number\">10000</span>; i++) &#123;</span><br><span class=\"line\">        Person person = <span class=\"keyword\">new</span> Person(i, <span class=\"string\">\"name\"</span> + i);</span><br><span class=\"line\">        persons.add(person);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    List&lt;String&gt; personList2 = persons.stream().</span><br><span class=\"line\">            map(Person::getName).limit(<span class=\"number\">10</span>).skip(<span class=\"number\">3</span>).collect(Collectors.toList());</span><br><span class=\"line\">    System.out.println(personList2);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Person</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">int</span> no;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> String name;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"title\">Person</span><span class=\"params\">(<span class=\"keyword\">int</span> no, String name)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.no = no;</span><br><span class=\"line\">        <span class=\"keyword\">this</span>.name = name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> String <span class=\"title\">getName</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        System.out.println(name);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> name;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>输出结果为：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name1</span><br><span class=\"line\">name2</span><br><span class=\"line\">name3</span><br><span class=\"line\">name4</span><br><span class=\"line\">name5</span><br><span class=\"line\">name6</span><br><span class=\"line\">name7</span><br><span class=\"line\">name8</span><br><span class=\"line\">name9</span><br><span class=\"line\">name10</span><br><span class=\"line\">[name4, name5, name6, name7, name8, name9, name10]</span><br></pre></td></tr></table></figure></p>\n<p>这是一个有 10，000 个元素的 Stream，但在 short-circuiting 操作 limit 和 skip 的作用下，管道中 map 操作指定的 getName() 方法的执行次数为 limit 所限定的 10 次，而最终返回结果在跳过前 3 个元素后只有后面 7 个返回。</p>\n<p>有一种情况是 limit/skip 无法达到 short-circuiting 目的的，就是把它们放在 Stream 的排序操作后，原因跟 sorted 这个 intermediate 操作有关：此时系统并不知道 Stream 排序后的次序如何，所以 sorted 中的操作看上去就像完全没有被 limit 或者 skip 一样。</p>\n<p>eg17. limit 和 skip 对 sorted 后的运行次数无影响<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Person&gt; persons = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</span><br><span class=\"line\">    Person person = <span class=\"keyword\">new</span> Person(i, <span class=\"string\">\"name\"</span> + i);</span><br><span class=\"line\">    persons.add(person);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">List&lt;Person&gt; personList2 = persons.stream().sorted((p1, p2) -&gt;</span><br><span class=\"line\">    p1.getName().compareTo(p2.getName())).limit(<span class=\"number\">2</span>).collect(Collectors.toList());</span><br><span class=\"line\">System.out.println(personList2);</span><br></pre></td></tr></table></figure></p>\n<p>上面的示例对清单 13 做了微调，首先对 5 个元素的 Stream 排序，然后进行 limit 操作。输出结果为：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name2</span><br><span class=\"line\">name1</span><br><span class=\"line\">name3</span><br><span class=\"line\">name2</span><br><span class=\"line\">name4</span><br><span class=\"line\">name3</span><br><span class=\"line\">name5</span><br><span class=\"line\">name4</span><br><span class=\"line\">[stream.StreamDW$Person@<span class=\"number\">816f</span>27d, stream.StreamDW$Person@<span class=\"number\">87</span>aac27]</span><br></pre></td></tr></table></figure></p>\n<p>即虽然最后的返回元素数量是 2，但整个管道中的 sorted 表达式执行次数没有像前面例子相应减少。</p>\n<p>最后有一点需要注意的是，对一个 parallel 的 Steam 管道来说，如果其元素是有序的，那么 limit 操作的成本会比较大，因为它的返回对象必须是前 n 个也有一样次序的元素。取而代之的策略是取消元素间的次序，或者不要用 parallel Stream。</p>\n<h3 id=\"sorted\"><a href=\"#sorted\" class=\"headerlink\" title=\"sorted\"></a>sorted</h3><p>对 Stream 的排序通过 sorted 进行，它比数组的排序更强之处在于你可以首先对 Stream 进行各类 map、filter、limit、skip 甚至 distinct 来减少元素数量后，再排序，这能帮助程序明显缩短执行时间。我们对清单 14 进行优化：</p>\n<p>eg18. 优化：排序前进行 limit 和 skip<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Person&gt; persons = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt;= <span class=\"number\">5</span>; i++) &#123;</span><br><span class=\"line\">    Person person = <span class=\"keyword\">new</span> Person(i, <span class=\"string\">\"name\"</span> + i);</span><br><span class=\"line\">    persons.add(person);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">List&lt;Person&gt; personList2 = persons.stream().limit(<span class=\"number\">2</span>).sorted((p1, p2) -&gt; p1.getName().compareTo(p2.getName())).collect(Collectors.toList());</span><br><span class=\"line\">System.out.println(personList2);</span><br></pre></td></tr></table></figure></p>\n<p>结果会简单很多：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name2</span><br><span class=\"line\">name1</span><br><span class=\"line\">[stream.StreamDW$Person@<span class=\"number\">6</span>ce253f1, stream.StreamDW$Person@<span class=\"number\">53</span>d8d10a]</span><br></pre></td></tr></table></figure>\n<p>当然，这种优化是有 business logic 上的局限性的：即不要求排序后再取值。</p>\n<h3 id=\"min-max-distinct\"><a href=\"#min-max-distinct\" class=\"headerlink\" title=\"min/max/distinct\"></a>min/max/distinct</h3><p>min 和 max 的功能也可以通过对 Stream 元素先排序，再 findFirst 来实现，但前者的性能会更好，为 O(n)，而 sorted 的成本是 O(n log n)。同时它们作为特殊的 reduce 方法被独立出来也是因为求最大最小值是很常见的操作。</p>\n<p>eg19. 找出最长一行的长度<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">BufferedReader br = <span class=\"keyword\">new</span> BufferedReader(<span class=\"keyword\">new</span> FileReader(<span class=\"string\">\"c:\\\\SUService.log\"</span>));</span><br><span class=\"line\"><span class=\"keyword\">int</span> longest = br.lines().</span><br><span class=\"line\">    mapToInt(String::length).</span><br><span class=\"line\">    max().</span><br><span class=\"line\">    getAsInt();</span><br><span class=\"line\">br.close();</span><br><span class=\"line\">System.out.println(longest);</span><br></pre></td></tr></table></figure></p>\n<p>下面的例子则使用 distinct 来找出不重复的单词。</p>\n<p>eg20. 找出全文的单词，转小写，并排序<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;String&gt; words = br.lines().</span><br><span class=\"line\">flatMap(line -&gt; Stream.of(line.split(<span class=\"string\">\" \"</span>))).</span><br><span class=\"line\">filter(word -&gt; word.length() &gt; <span class=\"number\">0</span>).</span><br><span class=\"line\">map(String::toLowerCase).</span><br><span class=\"line\">distinct().</span><br><span class=\"line\">sorted().</span><br><span class=\"line\">collect(Collectors.toList());</span><br><span class=\"line\">br.close();</span><br><span class=\"line\">System.out.println(words);</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Match\"><a href=\"#Match\" class=\"headerlink\" title=\"Match\"></a>Match</h3><p>Stream 有三个 match 方法，从语义上说：</p>\n<ul>\n<li>allMatch：Stream 中全部元素符合传入的 predicate，返回 true</li>\n<li>anyMatch：Stream 中只要有一个元素符合传入的 predicate，返回 true</li>\n<li>noneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true</li>\n</ul>\n<p>它们都不是要遍历全部元素才能返回结果。例如 allMatch 只要一个元素不满足条件，就 skip 剩下的所有元素，返回 false。对清单 13 中的 Person 类稍做修改，加入一个 age 属性和 getAge 方法。</p>\n<p>eg21. 使用 Match<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">List&lt;Person&gt; persons = <span class=\"keyword\">new</span> ArrayList();</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">1</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">1</span>, <span class=\"number\">10</span>));</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">2</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">2</span>, <span class=\"number\">21</span>));</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">3</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">3</span>, <span class=\"number\">34</span>));</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">4</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">4</span>, <span class=\"number\">6</span>));</span><br><span class=\"line\">persons.add(<span class=\"keyword\">new</span> Person(<span class=\"number\">5</span>, <span class=\"string\">\"name\"</span> + <span class=\"number\">5</span>, <span class=\"number\">55</span>));</span><br><span class=\"line\"><span class=\"keyword\">boolean</span> isAllAdult = persons.stream().allMatch(p -&gt; p.getAge() &gt; <span class=\"number\">18</span>);</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"All are adult? \"</span> + isAllAdult);</span><br><span class=\"line\"><span class=\"keyword\">boolean</span> isThereAnyChild = persons.stream().anyMatch(p -&gt; p.getAge() &lt; <span class=\"number\">12</span>);</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"Any child? \"</span> + isThereAnyChild);</span><br></pre></td></tr></table></figure></p>\n<p>输出结果：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">All are adult? <span class=\"keyword\">false</span></span><br><span class=\"line\">Any child? <span class=\"keyword\">true</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"进阶：自己生成流\"><a href=\"#进阶：自己生成流\" class=\"headerlink\" title=\"进阶：自己生成流\"></a>进阶：自己生成流</h2><h3 id=\"Stream-generate\"><a href=\"#Stream-generate\" class=\"headerlink\" title=\"Stream.generate\"></a>Stream.generate</h3><p>通过实现 Supplier 接口，你可以自己来控制流的生成。这种情形通常用于随机数、常量的 Stream，或者需要前后元素间维持着某种状态信息的 Stream。把 Supplier 实例传递给 Stream.generate() 生成的 Stream，默认是串行（相对 parallel 而言）但无序的（相对 ordered 而言）。由于它是无限的，在管道中，必须利用 limit 之类的操作限制 Stream 大小。</p>\n<p>eg22. 生成 10 个随机整数<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Random seed = <span class=\"keyword\">new</span> Random();</span><br><span class=\"line\">Supplier&lt;Integer&gt; random = seed::nextInt;</span><br><span class=\"line\">Stream.generate(random).limit(<span class=\"number\">10</span>).forEach(System.out::println);</span><br><span class=\"line\"><span class=\"comment\">//Another way</span></span><br><span class=\"line\">IntStream.generate(() -&gt; (<span class=\"keyword\">int</span>) (System.nanoTime() % <span class=\"number\">100</span>)).</span><br><span class=\"line\">limit(<span class=\"number\">10</span>).forEach(System.out::println);</span><br></pre></td></tr></table></figure></p>\n<p>Stream.generate() 还接受自己实现的 Supplier。例如在构造海量测试数据的时候，用某种自动的规则给每一个变量赋值；或者依据公式计算 Stream 的每个元素值。这些都是维持状态信息的情形。</p>\n<p>eg23. 自实现 Supplier<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Stream.generate(<span class=\"keyword\">new</span> PersonSupplier()).</span><br><span class=\"line\">        limit(<span class=\"number\">10</span>).</span><br><span class=\"line\">        forEach(p -&gt; System.out.println(p.getName() + <span class=\"string\">\", \"</span> + p.getAge()));</span><br><span class=\"line\"><span class=\"keyword\">private</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PersonSupplier</span> <span class=\"keyword\">implements</span> <span class=\"title\">Supplier</span>&lt;<span class=\"title\">Person</span>&gt; </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> <span class=\"keyword\">int</span> index = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> Random random = <span class=\"keyword\">new</span> Random();</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Person <span class=\"title\">get</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> Person(index++, <span class=\"string\">\"StormTestUser\"</span> + index, random.nextInt(<span class=\"number\">100</span>));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>输出结果：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">StormTestUser1, <span class=\"number\">9</span></span><br><span class=\"line\">StormTestUser2, <span class=\"number\">12</span></span><br><span class=\"line\">StormTestUser3, <span class=\"number\">88</span></span><br><span class=\"line\">StormTestUser4, <span class=\"number\">51</span></span><br><span class=\"line\">StormTestUser5, <span class=\"number\">22</span></span><br><span class=\"line\">StormTestUser6, <span class=\"number\">28</span></span><br><span class=\"line\">StormTestUser7, <span class=\"number\">81</span></span><br><span class=\"line\">StormTestUser8, <span class=\"number\">51</span></span><br><span class=\"line\">StormTestUser9, <span class=\"number\">4</span></span><br><span class=\"line\">StormTestUser10, <span class=\"number\">76</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Stream-iterate\"><a href=\"#Stream-iterate\" class=\"headerlink\" title=\"Stream.iterate\"></a>Stream.iterate</h3><p>iterate 跟 reduce 操作很像，接受一个种子值，和一个 UnaryOperator（例如 f）。然后种子值成为 Stream 的第一个元素，f(seed) 为第二个，f(f(seed)) 第三个，以此类推。</p>\n<p>eg24. 生成一个等差数列<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Stream.iterate(<span class=\"number\">0</span>, n -&gt; n + <span class=\"number\">3</span>).limit(<span class=\"number\">10</span>). forEach(x -&gt; System.out.print(x + <span class=\"string\">\" \"</span>));</span><br></pre></td></tr></table></figure></p>\n<p>输出结果：<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">0</span> <span class=\"number\">3</span> <span class=\"number\">6</span> <span class=\"number\">9</span> <span class=\"number\">12</span> <span class=\"number\">15</span> <span class=\"number\">18</span> <span class=\"number\">21</span> <span class=\"number\">24</span> <span class=\"number\">27</span></span><br></pre></td></tr></table></figure></p>\n<p>与 Stream.generate 相仿，在 iterate 时候管道必须有 limit 这样的操作来限制 Stream 大小。</p>\n<h2 id=\"进阶：用-Collectors-来进行-reduction-操作\"><a href=\"#进阶：用-Collectors-来进行-reduction-操作\" class=\"headerlink\" title=\"进阶：用 Collectors 来进行 reduction 操作\"></a>进阶：用 Collectors 来进行 reduction 操作</h2><p>java.util.stream.Collectors 类的主要作用就是辅助进行各类有用的 reduction 操作，例如转变输出为 Collection，把 Stream 元素进行归组。</p>\n<h3 id=\"groupingBy-partitioningBy\"><a href=\"#groupingBy-partitioningBy\" class=\"headerlink\" title=\"groupingBy/partitioningBy\"></a>groupingBy/partitioningBy</h3><p>eg25. 按照年龄归组<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;Integer, List&lt;Person&gt;&gt; personGroups = Stream.generate(<span class=\"keyword\">new</span> PersonSupplier()).</span><br><span class=\"line\">        limit(<span class=\"number\">100</span>).</span><br><span class=\"line\">        collect(Collectors.groupingBy(Person::getAge));</span><br><span class=\"line\">Iterator it = personGroups.entrySet().iterator();</span><br><span class=\"line\"><span class=\"keyword\">while</span> (it.hasNext()) &#123;</span><br><span class=\"line\">    Map.Entry&lt;Integer, List&lt;Person&gt;&gt; persons = (Map.Entry) it.next();</span><br><span class=\"line\">    System.out.println(<span class=\"string\">\"Age \"</span> + persons.getKey() + <span class=\"string\">\" = \"</span> + persons.getValue().size());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>上面的 code，首先生成 100 人的信息，然后按照年龄归组，相同年龄的人放到同一个 list 中，可以看到如下的输出：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Age <span class=\"number\">0</span> = <span class=\"number\">2</span></span><br><span class=\"line\">Age <span class=\"number\">1</span> = <span class=\"number\">2</span></span><br><span class=\"line\">Age <span class=\"number\">5</span> = <span class=\"number\">2</span></span><br><span class=\"line\">Age <span class=\"number\">8</span> = <span class=\"number\">1</span></span><br><span class=\"line\">Age <span class=\"number\">9</span> = <span class=\"number\">1</span></span><br><span class=\"line\">Age <span class=\"number\">11</span> = <span class=\"number\">2</span></span><br><span class=\"line\">……</span><br></pre></td></tr></table></figure>\n<p>eg26. 按照未成年人和成年人归组<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Map&lt;Boolean, List&lt;Person&gt;&gt; children = Stream.generate(<span class=\"keyword\">new</span> PersonSupplier()).</span><br><span class=\"line\">    limit(<span class=\"number\">100</span>).</span><br><span class=\"line\">    collect(Collectors.partitioningBy(p -&gt; p.getAge() &lt; <span class=\"number\">18</span>));</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"Children number: \"</span> + children.get(<span class=\"keyword\">true</span>).size());</span><br><span class=\"line\">System.out.println(<span class=\"string\">\"Adult number: \"</span> + children.get(<span class=\"keyword\">false</span>).size());</span><br></pre></td></tr></table></figure></p>\n<p>输出结果：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Children number: <span class=\"number\">23</span> </span><br><span class=\"line\">Adult number: <span class=\"number\">77</span></span><br></pre></td></tr></table></figure>\n<p>在使用条件“年龄小于 18”进行分组后可以看到，不到 18 岁的未成年人是一组，成年人是另外一组。partitioningBy 其实是一种特殊的 groupingBy，它依照条件测试的是否两种结果来构造返回的数据结构，get(true) 和 get(false) 能即为全部的元素对象。</p>\n<h1 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h1><p>总之，Stream 的特性可以归纳为：</p>\n<ul>\n<li><p>不是数据结构</p>\n<p>  它没有内部存储，它只是用操作管道从 source（数据结构、数组、generator function、IO channel）抓取数据。</p>\n<p>  它也绝不修改自己所封装的底层数据结构的数据。例如 Stream 的 filter 操作会产生一个不包含被过滤元素的新 Stream，而不是从 source 删除那些元素。</p>\n</li>\n<li><p>所有 Stream 的操作必须以 lambda 表达式为参数</p>\n</li>\n<li><p>不支持索引访问</p>\n<p>  你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。不过请参阅下一项。</p>\n</li>\n<li><p>很容易生成数组或者 List</p>\n</li>\n<li><p>惰性化</p>\n<p>  很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。</p>\n<p>  Intermediate 操作永远是惰性化的。</p>\n</li>\n<li><p>并行能力</p>\n<p>  当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的。</p>\n</li>\n<li><p>可以是无限的</p>\n<p>  集合有固定大小，Stream 则不必。limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。</p>\n</li>\n</ul>"}],"PostAsset":[],"PostCategory":[{"post_id":"ckahwzkz10001qotnts9d2c8p","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzkzs000hqotnb4g4n4cs"},{"post_id":"ckahwzkz70003qotn4cna0mhb","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzkzy000nqotngm2lu4kv"},{"post_id":"ckahwzkze0007qotn9116clkv","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl02000sqotn4jbz8gip"},{"post_id":"ckahwzkzz000pqotn51ki9xsy","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl06000zqotnuihtq55s"},{"post_id":"ckahwzkzg0009qotn3h6ow8nt","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl090013qotnkrzba9ea"},{"post_id":"ckahwzkzj000aqotnrz093ln8","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl0c0017qotnqavn3ofq"},{"post_id":"ckahwzkzn000eqotnqbg61t16","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl0g001dqotnoln96q0z"},{"post_id":"ckahwzkzq000fqotniba6fcp6","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl0l001jqotn1nj5r2tc"},{"post_id":"ckahwzkzt000kqotnbmhw2n0f","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl0p001pqotn0mxc38pm"},{"post_id":"ckahwzl0j001hqotn2ctum201","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl0s001tqotnhen9pge5"},{"post_id":"ckahwzkzw000lqotnf9cg7h2n","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl0t001wqotnql4igr70"},{"post_id":"ckahwzl0r001sqotng43w0bcf","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl0y0023qotnvdh9yej9"},{"post_id":"ckahwzl01000rqotnf1ft3l5h","category_id":"ckahwzl0p001oqotnso8ckjg7","_id":"ckahwzl100027qotnjkl1aiyj"},{"post_id":"ckahwzl0s001vqotn92gdmcjl","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl12002aqotntiexmut9"},{"post_id":"ckahwzl03000wqotnbt1ma8rg","category_id":"ckahwzl0p001oqotnso8ckjg7","_id":"ckahwzl14002eqotn86n1l493"},{"post_id":"ckahwzl05000yqotnltmya9vw","category_id":"ckahwzl0p001oqotnso8ckjg7","_id":"ckahwzl16002hqotnrm7ziy02"},{"post_id":"ckahwzl080012qotnkzyzu09o","category_id":"ckahwzl13002bqotnixpj37jw","_id":"ckahwzl19002mqotnfgi1zukk"},{"post_id":"ckahwzl0a0015qotn054y6p0v","category_id":"ckahwzl13002bqotnixpj37jw","_id":"ckahwzl1b002qqotn2awrr1ky"},{"post_id":"ckahwzl0d0019qotnjtynbbxw","category_id":"ckahwzl13002bqotnixpj37jw","_id":"ckahwzl1c002tqotn26blxvt8"},{"post_id":"ckahwzl0f001bqotn3z71ee1v","category_id":"ckahwzl1a002pqotn5kxusich","_id":"ckahwzl1e002yqotnszvellvb"},{"post_id":"ckahwzl0h001fqotn49ynzxag","category_id":"ckahwzl0p001oqotnso8ckjg7","_id":"ckahwzl1g0031qotn7vcsehr4"},{"post_id":"ckahwzl0m001lqotn2s9rf7sf","category_id":"ckahwzl1e002xqotnkcpsezqu","_id":"ckahwzl1i0036qotnixfbt8kn"},{"post_id":"ckahwzl0o001nqotnefhc4osw","category_id":"ckahwzl1e002xqotnkcpsezqu","_id":"ckahwzl1k003aqotnmlpuqs6d"},{"post_id":"ckahwzl0v0020qotn4z9k3ynx","category_id":"ckahwzl13002bqotnixpj37jw","_id":"ckahwzl1m003dqotn6cez56ce"},{"post_id":"ckahwzl0x0022qotn3b7hwml9","category_id":"ckahwzl1k0039qotnahrla5wb","_id":"ckahwzl1n003hqotn57c0j122"},{"post_id":"ckahwzl0z0026qotnu1jmhf1q","category_id":"ckahwzl1m003eqotnomd8bcoi","_id":"ckahwzl1p003lqotn0l39ar2q"},{"post_id":"ckahwzl110029qotnpw52gmle","category_id":"ckahwzl1o003iqotn0a54tmgc","_id":"ckahwzl1r003qqotnabbpzd1i"},{"post_id":"ckahwzl13002dqotnlquukrpv","category_id":"ckahwzl1e002xqotnkcpsezqu","_id":"ckahwzl1t003tqotnnb1s8qp0"},{"post_id":"ckahwzl15002gqotn3kiytul0","category_id":"ckahwzl1e002xqotnkcpsezqu","_id":"ckahwzl1u003wqotn3pzp5if3"},{"post_id":"ckahwzl3h003yqotn8guopf4c","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl3o0044qotn793nw1eh"},{"post_id":"ckahwzl3j003zqotnqovf6pqo","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl3q0047qotnatssunqn"},{"post_id":"ckahwzl3l0041qotni75x53h4","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl3s004aqotninhl9ii6"},{"post_id":"ckahwzl3m0043qotnzbpiacar","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl3u004dqotn8fgswt5i"},{"post_id":"ckahwzl3p0046qotnkfo5cuvb","category_id":"ckahwzkzx000mqotnej2e74ci","_id":"ckahwzl3w004gqotna8svx51t"},{"post_id":"ckahwzl3r0049qotni0qanwer","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl3z004jqotnw27798bm"},{"post_id":"ckahwzl3t004cqotnmhgx0zrn","category_id":"ckahwzl13002bqotnixpj37jw","_id":"ckahwzl41004mqotn7o9xb07p"},{"post_id":"ckahwzl3v004fqotni7tv4a5k","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl42004pqotn32fya0ke"},{"post_id":"ckahwzl3y004iqotnkj19lj17","category_id":"ckahwzl1m003eqotnomd8bcoi","_id":"ckahwzl44004tqotn2k5rtjbx"},{"post_id":"ckahwzl43004sqotnsnlsr9ek","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl4b0051qotneep8mw0d"},{"post_id":"ckahwzl46004uqotnq6vlpplq","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl4d0054qotnu6sq432p"},{"post_id":"ckahwzl40004lqotn98uugnh8","category_id":"ckahwzl43004qqotnq9imgw1c","_id":"ckahwzl4e0056qotnvb48nd51"},{"post_id":"ckahwzl48004xqotnjbknqk8v","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl4f0058qotncgy4z80l"},{"post_id":"ckahwzl4a0050qotncyutw693","category_id":"ckahwzl1e002xqotnkcpsezqu","_id":"ckahwzl4f005aqotn3inxm985"},{"post_id":"ckahwzl41004nqotnw631xlyw","category_id":"ckahwzl43004qqotnq9imgw1c","_id":"ckahwzl4g005cqotnzsp79nb0"},{"post_id":"ckahwzl6o005dqotnmu1746tw","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl6t005jqotn544ufhxd"},{"post_id":"ckahwzl6p005eqotnx3t8nm4t","category_id":"ckahwzl1e002xqotnkcpsezqu","_id":"ckahwzl6u005lqotn6z98ychh"},{"post_id":"ckahwzl6q005gqotnmm44rypf","category_id":"ckahwzl13002bqotnixpj37jw","_id":"ckahwzl6v005oqotn310gx3bj"},{"post_id":"ckahwzl6s005iqotnd7ubjb1m","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl6w005qqotng9844opw"},{"post_id":"ckahwzl6t005kqotnbd4dtmrh","category_id":"ckahwzl13002bqotnixpj37jw","_id":"ckahwzl6x005rqotndvq7up5q"},{"post_id":"ckahwzl8p005vqotn9wuacnc9","category_id":"ckahwzkzb0005qotnw51e4mbi","_id":"ckahwzl8q005xqotntbcwji4w"}],"PostTag":[{"post_id":"ckahwzkz10001qotnts9d2c8p","tag_id":"ckahwzkzd0006qotnc8huc0ya","_id":"ckahwzkzn000dqotn013kyzwn"},{"post_id":"ckahwzkz70003qotn4cna0mhb","tag_id":"ckahwzkzd0006qotnc8huc0ya","_id":"ckahwzkzt000jqotnhf51y5nk"},{"post_id":"ckahwzkze0007qotn9116clkv","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl00000qqotnkbq8aqzv"},{"post_id":"ckahwzkzz000pqotn51ki9xsy","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl03000vqotn5gxjwxli"},{"post_id":"ckahwzkzg0009qotn3h6ow8nt","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl05000xqotniwbuexa1"},{"post_id":"ckahwzkzj000aqotnrz093ln8","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl0a0014qotncaitna5j"},{"post_id":"ckahwzkzn000eqotnqbg61t16","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl0e001aqotnnbvcrycr"},{"post_id":"ckahwzkzq000fqotniba6fcp6","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl0j001gqotnuuuxaaip"},{"post_id":"ckahwzkzt000kqotnbmhw2n0f","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl0o001mqotnk7hnbcfc"},{"post_id":"ckahwzl0j001hqotn2ctum201","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl0q001qqotn73vy41rs"},{"post_id":"ckahwzkzw000lqotnf9cg7h2n","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl0s001uqotnklm5v4vc"},{"post_id":"ckahwzl0r001sqotng43w0bcf","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl0u001yqotn94o3woqs"},{"post_id":"ckahwzl01000rqotnf1ft3l5h","tag_id":"ckahwzl0q001rqotn55swtnlw","_id":"ckahwzl0w0021qotng8afneks"},{"post_id":"ckahwzl03000wqotnbt1ma8rg","tag_id":"ckahwzl0q001rqotn55swtnlw","_id":"ckahwzl110028qotnnu5iijis"},{"post_id":"ckahwzl05000yqotnltmya9vw","tag_id":"ckahwzl0q001rqotn55swtnlw","_id":"ckahwzl15002fqotne4q18ove"},{"post_id":"ckahwzl080012qotnkzyzu09o","tag_id":"ckahwzl13002cqotnwf0z5s6w","_id":"ckahwzl18002kqotnqr9iqca3"},{"post_id":"ckahwzl0a0015qotn054y6p0v","tag_id":"ckahwzl13002cqotnwf0z5s6w","_id":"ckahwzl1a002oqotnxh7562dv"},{"post_id":"ckahwzl0d0019qotnjtynbbxw","tag_id":"ckahwzl19002nqotnu28d2zba","_id":"ckahwzl1c002sqotnelxqb0qg"},{"post_id":"ckahwzl0f001bqotn3z71ee1v","tag_id":"ckahwzl1b002rqotn7q8t8syh","_id":"ckahwzl1d002wqotndum253ac"},{"post_id":"ckahwzl0h001fqotn49ynzxag","tag_id":"ckahwzl0q001rqotn55swtnlw","_id":"ckahwzl1f0030qotn79vhzqed"},{"post_id":"ckahwzl0m001lqotn2s9rf7sf","tag_id":"ckahwzl1f002zqotn0r7tmeup","_id":"ckahwzl1h0034qotnre09ba5e"},{"post_id":"ckahwzl0o001nqotnefhc4osw","tag_id":"ckahwzl1f002zqotn0r7tmeup","_id":"ckahwzl1j0038qotn176q9uj7"},{"post_id":"ckahwzl0s001vqotn92gdmcjl","tag_id":"ckahwzl1j0037qotnqf9lq7mj","_id":"ckahwzl1m003cqotnhn26hg5i"},{"post_id":"ckahwzl0v0020qotn4z9k3ynx","tag_id":"ckahwzl1k003bqotns0sv3ewm","_id":"ckahwzl1n003gqotn5u3881n3"},{"post_id":"ckahwzl0x0022qotn3b7hwml9","tag_id":"ckahwzl1n003fqotnexfe7apv","_id":"ckahwzl1p003kqotn7l84xvqr"},{"post_id":"ckahwzl0z0026qotnu1jmhf1q","tag_id":"ckahwzl1o003jqotn7n0yaulb","_id":"ckahwzl1q003oqotnykeju5s0"},{"post_id":"ckahwzl110029qotnpw52gmle","tag_id":"ckahwzl1q003nqotn4fy36s4z","_id":"ckahwzl1s003sqotn737ynfl5"},{"post_id":"ckahwzl13002dqotnlquukrpv","tag_id":"ckahwzl1f002zqotn0r7tmeup","_id":"ckahwzl1u003vqotneqtanqvo"},{"post_id":"ckahwzl15002gqotn3kiytul0","tag_id":"ckahwzl1u003uqotna0hz30hv","_id":"ckahwzl1v003xqotn3pdv3a1k"},{"post_id":"ckahwzl3h003yqotn8guopf4c","tag_id":"ckahwzkzd0006qotnc8huc0ya","_id":"ckahwzl3k0040qotnu9i13m2j"},{"post_id":"ckahwzl3j003zqotnqovf6pqo","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl3m0042qotn0ebsktyw"},{"post_id":"ckahwzl3l0041qotni75x53h4","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl3p0045qotnpq42km3i"},{"post_id":"ckahwzl3m0043qotnzbpiacar","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl3r0048qotnms2dyb9b"},{"post_id":"ckahwzl3p0046qotnkfo5cuvb","tag_id":"ckahwzkzy000oqotn61t3fsiv","_id":"ckahwzl3t004bqotn1sduvvdm"},{"post_id":"ckahwzl3r0049qotni0qanwer","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl3v004eqotn8i7dyk1b"},{"post_id":"ckahwzl3v004fqotni7tv4a5k","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl3z004kqotnysjiz84u"},{"post_id":"ckahwzl3t004cqotnmhgx0zrn","tag_id":"ckahwzl3x004hqotnyj12td26","_id":"ckahwzl43004rqotnukznjvep"},{"post_id":"ckahwzl43004sqotnsnlsr9ek","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl48004wqotn7mpq1v5t"},{"post_id":"ckahwzl3y004iqotnkj19lj17","tag_id":"ckahwzl42004oqotnbajr9f07","_id":"ckahwzl4a004zqotn9lacrgp4"},{"post_id":"ckahwzl46004uqotnq6vlpplq","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl4c0053qotnrp979mta"},{"post_id":"ckahwzl48004xqotnjbknqk8v","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl4e0055qotncqqt18zu"},{"post_id":"ckahwzl40004lqotn98uugnh8","tag_id":"ckahwzl47004vqotnublefj3h","_id":"ckahwzl4f0057qotnxww0x6f6"},{"post_id":"ckahwzl4a0050qotncyutw693","tag_id":"ckahwzl1f002zqotn0r7tmeup","_id":"ckahwzl4f0059qotnlaene2zl"},{"post_id":"ckahwzl41004nqotnw631xlyw","tag_id":"ckahwzl47004vqotnublefj3h","_id":"ckahwzl4g005bqotnaly77b7p"},{"post_id":"ckahwzl6o005dqotnmu1746tw","tag_id":"ckahwzkzd0006qotnc8huc0ya","_id":"ckahwzl6q005fqotnrbeeebve"},{"post_id":"ckahwzl6s005iqotnd7ubjb1m","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl6v005mqotneidydfog"},{"post_id":"ckahwzl6p005eqotnx3t8nm4t","tag_id":"ckahwzl6r005hqotnftu87t87","_id":"ckahwzl6w005pqotnr4vdqhfx"},{"post_id":"ckahwzl6q005gqotnmm44rypf","tag_id":"ckahwzl6v005nqotnt8juxifc","_id":"ckahwzl6x005tqotnjhakwgss"},{"post_id":"ckahwzl6t005kqotnbd4dtmrh","tag_id":"ckahwzl6x005sqotn2ikk4bs0","_id":"ckahwzl6y005uqotnc61qdupy"},{"post_id":"ckahwzl8p005vqotn9wuacnc9","tag_id":"ckahwzkzs000iqotn6rb6c0h3","_id":"ckahwzl8q005wqotnujwphw1x"}],"Tag":[{"name":"JVM","_id":"ckahwzkzd0006qotnc8huc0ya"},{"name":"Java","_id":"ckahwzkzs000iqotn6rb6c0h3"},{"name":"docker","_id":"ckahwzkzy000oqotn61t3fsiv"},{"name":"ElasticSearch","_id":"ckahwzl0q001rqotn55swtnlw"},{"name":"hexo","_id":"ckahwzl13002cqotnwf0z5s6w"},{"name":"Lock","_id":"ckahwzl19002nqotnu28d2zba"},{"name":"Linux","_id":"ckahwzl1b002rqotn7q8t8syh"},{"name":"redis","_id":"ckahwzl1f002zqotn0r7tmeup"},{"name":"mybatis","_id":"ckahwzl1j0037qotnqf9lq7mj"},{"name":"事务","_id":"ckahwzl1k003bqotns0sv3ewm"},{"name":"分布式ID","_id":"ckahwzl1n003fqotnexfe7apv"},{"name":"数据库","_id":"ckahwzl1o003jqotn7n0yaulb"},{"name":"前端","_id":"ckahwzl1q003nqotn4fy36s4z"},{"name":"redisson","_id":"ckahwzl1u003uqotna0hz30hv"},{"name":"负载均衡","_id":"ckahwzl3x004hqotnyj12td26"},{"name":"MySQL","_id":"ckahwzl42004oqotnbajr9f07"},{"name":"设计模式","_id":"ckahwzl47004vqotnublefj3h"},{"name":"rabbitMQ","_id":"ckahwzl6r005hqotnftu87t87"},{"name":"性能优化","_id":"ckahwzl6v005nqotnt8juxifc"},{"name":"网络IO模型","_id":"ckahwzl6x005sqotn2ikk4bs0"}]}}